[{"categories":null,"content":" /** * 写博客的初衷不是为了炫耀所知，而是记录无知。 * 人知道得越多，就会发现自己的无知也越多。有更广阔的世界可以探索，这是一种莫大的快乐！ * 在这个信息爆炸的时代，知识的获取变得前所未有的便捷。 * 然而，真正有价值的知识并不是浅尝辄止的片段，而是经过深思熟虑和实践验证的结晶。 * 写博客的过程，就是一个不断反思和总结的过程，让我们在浩瀚的知识海洋中找到自己的航向。 * @since 2020-06-10 15:42:02 */ #include \u003ciostream\u003e int main() { std::cout \u003c\u003c \"Hello, World!\\n\" \u003c\u003c std::endl; return 0; } ","date":"2024-08-30","objectID":"/about/:0:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"1 关于博客 写博客的初衷不是为了炫耀所知，而是为了记录无知。 博客内容主要是以系统架构、后端开发为主，分享一些学习笔记、技巧、开发教程等等。如果你对我的博客内容感兴趣或者有任何建议，欢迎与我一起讨论，共同进步。也欢迎关注我的github。 或者通过以下方式关注我的博客。 RSS CSDN ","date":"2024-08-30","objectID":"/about/:1:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"2 关于我 向上而生，向善而行，向心而暖 👨‍💻 一名在读硕士研究生，对分布式系统有着浓厚的兴趣 👨‍💼 ENFP，对新鲜事物充满热情，敢于实践，总是寻找机会将创新的想法转化为实际应用。 📝 我经常在CSDN上撰写文章 ","date":"2024-08-30","objectID":"/about/:2:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"3 Sponsor 感谢大家的支持 🙏 给博主买杯卡布奇诺～ 赞赏 支付宝 微信 总计 ¥50.00 单笔最大 francs 的 ¥50.00 francs ¥50.00 francs 通过 支付宝 打赏了 ¥50.00 备注：大学生时期，第一次收到别人的支持，内心表示受宠若惊又非常开心。非常感谢老哥的支持！ 2018-09-28 ","date":"2024-08-30","objectID":"/about/:3:0","tags":null,"title":"关于","uri":"/about/"},{"categories":["系统架构"],"content":"1 1 实验要求 本实验旨在利用lab 3中的Raft库，构建一个具备容错能力的键值存储服务。服务将作为一个复制状态机，由多个服务器组成，各服务器通过Raft协议同步数据库状态。即使在部分故障或网络隔离的情况下，只要大多数服务器正常，服务仍需继续响应客户端请求。在lab 4完成后，你将实现图中Raft交互的所有部分（Clerk、Service和Raft）。 客户端通过Clerk与键值服务交互，发送RPC请求，支持Put、Append和Get三种操作。服务需确保这些操作线性化，如果逐个调用，这些方法应表现得好像系统只有一个状态副本，每个调用都应观察到前序调用序列对状态的修改。对于并发调用，返回值和最终状态必须与操作按某种顺序逐个执行时相同。如果调用在时间上重叠，则认为是并发调用。 为单一服务器提供线性化相对容易，但如果服务是复制的，则较为困难，因为所有服务器必须为并发请求选择相同的执行顺序，避免使用过时的状态回复客户端，并在故障恢复时以保留所有确认的客户端更新为前提。Raft 作者的博士论文的第 6.3 小节介绍了如何实现线性化语义，在知乎上也有关于这方面的讨论，可以参考 dragonboat 作者的回答。 实验分为两个阶段：A阶段实现基于Raft的键值服务，不使用快照；B阶段则集成快照功能，优化日志管理。 我的实验代码仓库：https://github.com/HeZephyr/MIT6.5840/tree/main/src/kvraft，已通过压力测试，代码严格遵守上述按要求实现。 注意：下述所贴代码为了简洁以及分块，进行了一定程度的删减，如果需要复现，可以前往仓库。 ","date":"2024-08-30","objectID":"/posts/09.mit-6.58406.824-lab4-fault-tolerant-kvservice/:1:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)】 Lab 4:Fault-tolerant KVService 设计实现","uri":"/posts/09.mit-6.58406.824-lab4-fault-tolerant-kvservice/"},{"categories":["系统架构"],"content":"2 2 实验设计 ","date":"2024-08-30","objectID":"/posts/09.mit-6.58406.824-lab4-fault-tolerant-kvservice/:2:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)】 Lab 4:Fault-tolerant KVService 设计实现","uri":"/posts/09.mit-6.58406.824-lab4-fault-tolerant-kvservice/"},{"categories":["系统架构"],"content":"2.1 2.1 思路 lab4需要我们基于lab3实现的Raft，实现一个可用的KV服务，这意味着我们需要保证线性一致性（要求从外部观察者的角度来看，所有操作都按照某个全局顺序执行，并且结果与这些操作按该顺序串行执行的结果相同）。尽管 Raft 共识算法本身支持线性化语义，但要真正保证线性化语义在整个系统中生效，仍然需要上层服务的配合。 例如，在下面这张图中：x初始值为0，client1发送put请求(x,1)，client2发送put请求(x,2)，并在put请求前后发送get请求，此时如果put请求因为超时不断重发，如果在client2的put请求之后才被应用，则导致最后client2读到的是1，RaftKV的结果也是1，这就违背了线性一致性。 这是因为当客户端向服务端提交command时，服务端在Raft层中同步、提交并应用后，客户端因为没有收到请求回复，会重试此操作，这种重试机制会导致相同的命令被执行多次。注意，这里讨论的都是写请求，因为读请求不会改变系统状态，可以重复执行多次。 为了解决重复执行命令导致线性一致性破坏的问题，Raft 作者提出了一种解决方案：客户端为每个命令分配一个唯一的序列号。状态机会记录每个客户端的最新序列号及其对应的执行结果。如果一个命令的序列号已经被处理过，则系统会直接返回先前的结果，而不会重新执行该命令。这样可以确保每个命令只被应用到状态机一次，避免了重复执行可能带来的线性一致性问题。 在这个lab中，我们可以按照如下机制具体实现： 客户端命令唯一化：每个客户端发送给服务端的每个command请求都携带一个由ClientId和CommandId组成的二元组。ClientId是客户端的唯一标识符，CommandId是一个递增的整数，用于唯一标识客户端发出的每一个命令。 服务器端状态记录：在服务器端，维护一个映射表，这个映射表以ClientId作为主键，其值是一个结构体包含： 最近执行的来自该客户端的CommandId。 对应的命令执行结果。 重复命令检测与处理： 当一个新命令到达时，首先检查映射表中是否存在对应的ClientId条目。 如果存在，则比较新命令的CommandId与映射表中记录的CommandId。 如果新命令的CommandId小于或等于记录的CommandId，则说明这是一个重复命令，服务器可以直接返回之前存储的结果。 如果新命令的CommandId大于记录的CommandId，则说明这是新的命令，服务器应该正常处理这个命令，并更新映射表中对应ClientId的CommandId及结果。 如果不存在对应的ClientId条目，则将此命令视为首次出现的命令进行处理，并添加一个新的条目到映射表中。 ","date":"2024-08-30","objectID":"/posts/09.mit-6.58406.824-lab4-fault-tolerant-kvservice/:2:1","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)】 Lab 4:Fault-tolerant KVService 设计实现","uri":"/posts/09.mit-6.58406.824-lab4-fault-tolerant-kvservice/"},{"categories":["系统架构"],"content":"2.2 2.2 lab4A：无快照 整体的时序图如下所示： 2.2.1 2.2.1 客户端 对于客户端，需要有(clientId, commandId)来标识唯一命令，对于clientId，通过lab提供的随机数生成器nrand生成即可，对于commandId，可以采用递增的方式进行管理。这意味着每当客户端发送一个新的命令时，commandId都会递增一次，从而确保每个命令都有一个唯一的标识符，这样也需要保证如果这条命令没处理完（请求的server不是leader或者请求超时）需重复执行的时候，不能改变commandId。 type CommandArgs struct { Key string Value string Op OpType ClientId int64 CommandId int64 } type CommandReply struct { Err Err Value string } type Clerk struct { servers []*labrpc.ClientEnd leaderId int clientId int64 commandId int64 } func (ck *Clerk) Get(key string) string { return ck.ExecuteCommand(\u0026CommandArgs{Key: key, Op: OpGet}) } func (ck *Clerk) Put(key string, value string) { ck.ExecuteCommand(\u0026CommandArgs{Key: key, Value: value, Op: OpPut}) } func (ck *Clerk) Append(key string, value string) { ck.ExecuteCommand(\u0026CommandArgs{Key: key, Value: value, Op: OpAppend}) } func (ck *Clerk) ExecuteCommand(args *CommandArgs) string { args.ClientId, args.CommandId = ck.clientId, ck.commandId for { reply := new(CommandReply) if !ck.servers[ck.leaderId].Call(\"KVServer.ExecuteCommand\", args, reply) || reply.Err == ErrWrongLeader || reply.Err == ErrTimeout { ck.leaderId = (ck.leaderId + 1) % len(ck.servers) continue } ck.commandId += 1 return reply.Value } } 2.2.2 2.2.2 服务端 KVServer结构体被设计成一个基于Raft一致性协议实现的键值存储服务。为了确保客户端请求的幂等性，并且能够正确地处理来自客户端的重复请求，lastOperations映射表用于跟踪每个客户端（由clientId标识）的最后已应用的commandId以及相应的reply。这使得服务器能够在接收到重复请求时返回之前的结果而无需再次执行相同的命令。 状态机stateMachine在此处被实现为内存中的键值对存储MemoryKV，这意味着所有的键值对数据都保存在内存中，这对于快速读写操作是非常有效的，但可能不是持久化存储的最佳选择，因为如果服务器重启或崩溃，所有数据都会丢失。 lastApplied字段被用来记录最后应用到状态机的日志条目的索引，以此来避免处理那些已经被应用过的过期日志条目。 notifyChs是一个映射，它的键是日志条目的索引，值是一个channel。用于通知Raft的处理结果（机即复制到大多数副本并且应用到状态机之后）。 type KVServer struct { mu sync.RWMutex me int rf *raft.Raft applyCh chan raft.ApplyMsg dead int32 // set by Kill() maxraftstate int // snapshot if log grows this big lastApplied int //record the last applied index to avoid duplicate apply stateMachine KVStateMachine lastOperations map[int64]OperationContext notifyChs map[int]chan *CommandReply } type KVStateMachine interface { Get(key string) (string, Err) Put(key, value string) Err Append(key, value string) Err } type OperationContext struct { MaxAppliedCommandId int64 LastReply *CommandReply } ExecuteCommandRPC实现如下，这段首先检查是否不是Get请求且为重复的命令，如果是则返回上次的结果，否则通过Raft的Start方法复制并应用日志，如果Start方法返回结果告知当前server不是Leader，则返回ErrWrongLeader，否则，去注册一个channel去阻塞等待执行结果（因为Start返回只是代表日志被复制到大多数节点中，有没有应用还不知道），这个执行结果由applier协程push。 func (kv *KVServer) ExecuteCommand(args *CommandArgs, reply *CommandReply) { kv.mu.RLock() if args.Op != OpGet \u0026\u0026 kv.isDuplicatedCommand(args.ClientId, args.CommandId) { lastReply := kv.lastOperations[args.ClientId].LastReply reply.Value, reply.Err = lastReply.Value, lastReply.Err kv.mu.RUnlock() return } kv.mu.RUnlock() index, _, isLeader := kv.rf.Start(Command{args}) if !isLeader { reply.Err = ErrWrongLeader return } kv.mu.Lock() ch := kv.getNotifyCh(index) kv.mu.Unlock() select { case result := \u003c-ch: reply.Value, reply.Err = result.Value, result.Err case \u003c-time.After(ExecuteTimeout): reply.Err = ErrTimeout } go func() { kv.mu.Lock() kv.deleteNotifyCh(index) kv.mu.Unlock() }() } 2.2.3 2.2.3 applier applier协程实现如下，主要是监控applyCh，根据Raft的应用结果来进行响应处理，需要注意的就是检测是否为重复的命令，如果不是，则需要应用到状态机，并保存最近的响应结果。最后，如果当前节点是领导者，并且该日志条目属于当前任期，则通知相关的客户端。 func (kv *KVServer) applier() { for kv.killed() == false { select { case message := \u003c-kv.applyCh: DPrintf(\"{Node %v} tries to apply message %v\", kv.rf.GetId(), message) if message.CommandValid { kv.mu.Lock() if message.CommandIndex \u003c= kv.lastApplied { DPrintf(\"{Node %v} discards outdated message %v because a newer snapshot which lastApplied is %v has been restored\", kv.rf.GetId(), message, kv.lastApplied) kv.mu.Unlock() continue } kv.lastApplied = message.CommandIndex reply := new(CommandReply) command := message.Command.(Command) // type assertion if command.Op != OpGet \u0026\u0026 kv.isDuplicatedCommand(command.ClientId, command.CommandId) { DPrintf(\"{Node %v} doesn't apply duplicated message %v to stateMachine beca","date":"2024-08-30","objectID":"/posts/09.mit-6.58406.824-lab4-fault-tolerant-kvservice/:2:2","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)】 Lab 4:Fault-tolerant KVService 设计实现","uri":"/posts/09.mit-6.58406.824-lab4-fault-tolerant-kvservice/"},{"categories":["系统架构"],"content":"2.3 2.2 lab4B：有快照 实现了lab4A，lab4B就好做了，只需要修改applier，每次应用了command之后，都需要检查是否达到maxraftstate，如果达到，则调用snapshot来制作快照，需要注意，快照中，不仅需要保存状态机的状态，还需要包含用来去重的lastOperations，这也是为了防止应用快照后的节点成为leader后，由于没有lastOperations导致重复执行命令。 然后，applyCh中还有Leader发来的快照，我们需要进行验证，如果有效，则需要更新相应的状态，具体实现代码如下： func (kv *KVServer) applier() { for kv.killed() == false { select { case message := \u003c-kv.applyCh: DPrintf(\"{Node %v} tries to apply message %v\", kv.rf.GetId(), message) if message.CommandValid { kv.mu.Lock() if message.CommandIndex \u003c= kv.lastApplied { DPrintf(\"{Node %v} discards outdated message %v because a newer snapshot which lastApplied is %v has been restored\", kv.rf.GetId(), message, kv.lastApplied) kv.mu.Unlock() continue } kv.lastApplied = message.CommandIndex reply := new(CommandReply) command := message.Command.(Command) // type assertion if command.Op != OpGet \u0026\u0026 kv.isDuplicatedCommand(command.ClientId, command.CommandId) { DPrintf(\"{Node %v} doesn't apply duplicated message %v to stateMachine because maxAppliedCommandId is %v for client %v\", kv.rf.GetId(), message, kv.lastOperations[command.ClientId], command.ClientId) reply = kv.lastOperations[command.ClientId].LastReply } else { reply = kv.applyLogToStateMachine(command) if command.Op != OpGet { kv.lastOperations[command.ClientId] = OperationContext{ MaxAppliedCommandId: command.CommandId, LastReply: reply, } } } // just notify related channel for currentTerm's log when node is leader if currentTerm, isLeader := kv.rf.GetState(); isLeader \u0026\u0026 message.CommandTerm == currentTerm { ch := kv.getNotifyCh(message.CommandIndex) ch \u003c- reply } if kv.needSnapshot() { kv.takeSnapshot(message.CommandIndex) } kv.mu.Unlock() } else if message.SnapshotValid { kv.mu.Lock() if kv.rf.CondInstallSnapshot(message.SnapshotTerm, message.SnapshotIndex, message.Snapshot) { kv.restoreStateFromSnapshot(message.Snapshot) kv.lastApplied = message.SnapshotIndex } kv.mu.Unlock() } else { panic(fmt.Sprintf(\"Invalid ApplyMsg %v\", message)) } } } } ","date":"2024-08-30","objectID":"/posts/09.mit-6.58406.824-lab4-fault-tolerant-kvservice/:2:3","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)】 Lab 4:Fault-tolerant KVService 设计实现","uri":"/posts/09.mit-6.58406.824-lab4-fault-tolerant-kvservice/"},{"categories":["系统架构"],"content":"3 3 压测结果 网上提供了一个测试脚本，功能强大。我的压测结果如下所示： ","date":"2024-08-30","objectID":"/posts/09.mit-6.58406.824-lab4-fault-tolerant-kvservice/:3:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)】 Lab 4:Fault-tolerant KVService 设计实现","uri":"/posts/09.mit-6.58406.824-lab4-fault-tolerant-kvservice/"},{"categories":["系统架构","论文阅读"],"content":"1 1 介绍 大型应用在分布式系统中遭遇多重挑战，如并发控制、故障恢复、网络不稳定及服务器时钟异步等。形式化验证则是一种严格确立系统正确性的方法，帮助处理边缘情况。 租约是分布式系统中的关键技术，用于保证系统某方面在一定时间内不变，GFS、Chubby和DynamoDB都具有类似的机制。例如租约允许领导者高效执行只读查询，无需频繁验证自身领导权，然而，这一机制的有效性验证却是一项艰巨任务。 Grove，作为前沿的并发分离逻辑（Concurrent Separation Logic, CSL）库，首开先河地解决了基于时间的租约验证问题，包括其与系统重新配置、故障恢复、线程级并发以及不可靠网络通信之间的复杂交互。 CSL的应用精髓在于，通过将系统状态细分为独立资源，并借助同步原语转移资源所有权，从而实现模块化且精确的推理分析。 Grove的创新亮点可概括如下： 时间有界不变性推理：引入新颖的时间维度，有效解析租约的有效期及其对系统状态的影响。 扩展Crash Hoare逻辑：强化逻辑体系，使之能妥善应对分布式环境下的节点崩溃情形。 抽象机制：提供工具集，支持对仅附加日志及单调时钟计数器的精准推理，增强系统的时间一致性。 Grove code ","date":"2024-08-30","objectID":"/posts/09.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0grove/:1:0","tags":["分布式系统"],"title":"【论文阅读笔记】Grove: a Separation-Logic Library for Verifying Distributed Systems (Extended Version)","uri":"/posts/09.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0grove/"},{"categories":["系统架构","论文阅读"],"content":"2 2 常见组件-Grove案例研究 ","date":"2024-08-30","objectID":"/posts/09.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0grove/:2:0","tags":["分布式系统"],"title":"【论文阅读笔记】Grove: a Separation-Logic Library for Verifying Distributed Systems (Extended Version)","uri":"/posts/09.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0grove/"},{"categories":["系统架构","论文阅读"],"content":"2.1 2.1 RPC库 RPC是分布式系统的重要构建模块，它允许客户端在远程服务器上调用过程。例如，客户端调用rpcClient.Call(\"f\", args)将在与rpcClient相连的服务器上调用f(args)。RPC库提供的是不可靠的RPC，意味着客户端的一次调用可能导致服务器运行对应的函数一次、零次或多于一次。这是因为底层网络可能会丢弃、重排或复制数据包。应用程序通常不会直接调用RPC，而是使用各种代理（clerk），它们封装了RPC并附加额外的处理（如添加请求ID、重试等）。 ","date":"2024-08-30","objectID":"/posts/09.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0grove/:2:1","tags":["分布式系统"],"title":"【论文阅读笔记】Grove: a Separation-Logic Library for Verifying Distributed Systems (Extended Version)","uri":"/posts/09.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0grove/"},{"categories":["系统架构","论文阅读"],"content":"2.2 2.2 复制状态机库 vRSM复制由应用程序提供的状态机，具体的接口如下图所示： vRSM由多个组件实现，每个组件处理状态机复制的不同方面，例如持久性可以与复制协议分开实现。 副本服务器：写入复制 副本组件管理被复制的状态机的副本。 主要角色包括主服务器(Primary)和备份服务器(Backup)。主服务器处理来自客户端的写请求，备份服务器则处理读请求。 主服务器在收到操作后，会先在本地应用，然后复制到所有备份服务器，最后回复客户端。复制操作时，主服务器会生成线程以并发方式向每个备份发送RPC，并使用Go WaitGroup等待所有线程完成，确保操作被所有副本服务器应用。 使用configservice重新配置 利用epochs和configservice来管理服务器的添加或移除。系统通过epoch来跟踪不同的服务器配置。每个epoch对应一组特定的服务器配置，包括一个主服务器和多个备份服务器。时代分为活跃epoch和保留epoch，后者指未实际运行的配置。configservice 负责维护当前系统的最新epoch和配置信息。它允许客户端获取当前配置，并在重新配置过程中提供原子操作以更新配置。 在重新配置期间，客户端可能向旧配置发送操作，这可能导致新配置中遗漏操作。为解决此问题，重新配置过程首先会封闭旧配置中的一个服务器，使其不再接受写操作，直到进入新的epoch。 重新配置步骤 包括： 原子性地创建新epoch 从旧配置中获取状态 在新服务器上初始化状态 更新configservice中的配置信息 激活新主服务器。 // Reserve a new epoch number for reconfiguration, and return the current configuration (set of servers). func (ck *Clerk) ReserveEpochAndGetConfig() (uint64, []Address) // Return current configuration, used by clients to determine what servers to talk to. func (ck *Clerk) GetConfig() []Address // Set new configuration, making epoch live, as long as no higher-numbered epoch has been reserved. func (ck *Clerk) TryWriteConfig(epoch uint64, config []Address) Error // Get a lease for specified epoch, as long as it’s the current epoch, returning the new lease expiration time. func (ck *Clerk) GetLease(epoch uint64) (Error, uint64) func Reconfigure(newServers []Address) { newEpoch, oldServers := configClerk.ReserveEpochAndGetConfig() // get state from a server from old config oldClerk := MakeClerk(oldServers[Rand() % len(oldServers)]) oldState := oldClerk.GetStateAndSeal(newEpoch) // make clerks to all of the new servers var newClerks = make([]Clerk, len(newServers)) for i := 0; i \u003c len(newServers); i++ { newClerks[i] = MakeClerk(newServers[i]) } // set state on all the new servers wg := new(WaitGroup) for i := 0; i \u003c len(newClerks); i++ { wg.Add(1) go func(i int) { newClerks[i].SetNewEpochState(newEpoch, oldState) wg.Done() }(i) } wg.Wait() // write new addresses to config service err := configClerk.TryWriteConfig(newEpoch, newServers) if err == nil { // activate the new primary server newClerks[0].BecomePrimary(newEpoch) } } 在网络分区的情况下，configservice通过仅接受最高编号的新epoch来避免创建多个冲突的系统实例。 副本服务器：基于租约的读取 副本服务器（主服务器和备份服务器）利用租约提供线性化读取服务，无需跨服务器通信。 func (s *Server) ApplyReadonly(op) Result { s.mutex.Lock() if s.leaseExpiry \u003e GetTimeRange().latest { e := s.epoch idx, res := s.stateLogger.LocalRead(op) s.mutex.Unlock() // 如果在此期间发生重新配置，服务器会通知客户端重试 if s.waitForCommitted(e, op, idx) { return res } else { return ErrRetry } } else { s.mutex.Unlock() return ErrRetry } } 租约机制： 租约防止重新配置时返回过时数据，确保各服务器同步。 后台线程定期更新租约，承诺配置不变，直至租约到期（如1秒后）。 读取流程： 服务器收到只读请求且租约有效时，根据本地状态计算响应。本地状态包含所有已提交操作，可能含未提交的写操作。 读取依赖的前序写操作需全部提交，方能向客户端发送结果。 Grove使用类似TrueTime的GetTimeRange()API，提供当前时间的上下限，解决时钟偏移问题。 存储库：状态日志器 副本服务器使用存储库管理持久状态，提供“状态日志器”用于在追加型文件中持久化新操作。状态日志器在内存中缓冲追加操作，后台线程异步追加并同步缓冲区到文件，以提升性能。存储库提供 Wait() 函数，允许等待直到文件的前缀部分被持久化。副本库在回复 RPC 之前使用 Wait() 确保变更被持久存储。 基于Paxos的容错配置服务 Paxos 库用于处理配置服务自身的服务器故障，是一个简单的基于 Paxos 一致性算法的复制库。Paxos在固定服务器集上运行，仅需要多数服务器处理请求，使用 leader 协调操作，但在 leader 崩溃时允许更换。与主-备份复制的差异： Paxos 自行选择新的epoch编号，因为服务器集不会在运行时改变。 仅要求多数服务器提交操作，新 leader 必须从多数服务器获取最新状态。 Paxos 较为简单，不使用租约，每次更新都写入整个状态到磁盘，而非追加操作到日志。 写操作性能较低，但对于配置服务是可接受的；提供快速但弱一致性的读取。 Paxos提供的接口如下： // 返回当前Paxos实例中的复制状态。可能过时或未提交，GetConfig 使用 WeakRead 以确保快速响应 func (p *Paxos) WeakRead() []byte // 开始一个新的提议过程。它返回当前的复制状态和一个commit回调函数。 func (p *Paxos) Begin() (oldstate []byte, commit func(newstate []byte) error) // 尝试使当前节点成为领导者。 func (p *Paxos) TryBecomingLeader() 要执行写操作，如下面这段代码所示，configserver使用Begin()方法。 // 参数args在此处未使用，通常用于接收客户端请求的参数。 // reply 是方法的输出，它将包含操作的结果状态以及预留的新epoch和配置信息。 func (c *ConfigService) ReserveEpochAndGetConfig(args []byte, reply *[]byte) { // 从Paxos实例开始一个新的提议，获取当前状态和提交函数。 // 应该在当前的领导者上调用此方法，否则提议无法成功提交。 oldstate, commit := c.paxos.Begin() // 反序列化旧状态，以便修改。 st := unmarshal(oldstate) // 更新状态中的预留epoch字段，准备进入下一个epoch。 st.reservedEpoch = st.reservedEpoch + 1 // 序列化更新后的状态，准备提交。 newstate := marshal(st) // 使用从Begin获得的提交函数尝试提交新状态。 // 此操作会与其他服务器通信，以确保新状态被复制到大多数","date":"2024-08-30","objectID":"/posts/09.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0grove/:2:2","tags":["分布式系统"],"title":"【论文阅读笔记】Grove: a Separation-Logic Library for Verifying Distributed Systems (Extended Version)","uri":"/posts/09.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0grove/"},{"categories":["系统架构","论文阅读"],"content":"2.3 2.3 vRSM上层应用 vKV实现 vKV 架构：基于 vRSM 和 exactlyonce 库实现。 服务器端：实现 vRSM 期望的状态机接口。 客户端：基于 exactlyonce clerk 实现的 clerk，提供简化的 API（Put、CondPut、Get）。 实现细节：vKV 实现简单，包括 (反)序列化方法和内存映射的读写函数。 性能优化：vKV 存储键到值的映射以及键的最后修改操作索引，利用 vRSM 的版本化状态机接口提升读取性能。 基于租约的客户端缓存-cachekv cachekv 库通过在 vKV 中存储数据和租约到期时间实现基于租约的客户端缓存。GetAndCache 函数如下所示： func (k *CacheKv) GetAndCache(key string, cachetime uint64) string { for { // first attempt to read from the local cache, and if not cached, call vKV's Get. old := k.kv.Get(key) new := old newExpiration := max(GetTimeRange().latest+cachetime, old.leaseExpiration) new.leaseExpiration = newExpiration // Try to update the lease expiration time on the backend resp := k.kv.CondPut(key, old, new) if resp == \"ok\" { k.mu.Lock() k.cache[key] = cacheValue{v: old.v, l: newLeaseExpiration} k.mu.Unlock() return old.v } } } 它返回指定键的值，并在内部缓存，使用 CondPut （确保仅在租约过期时更改值）原子增加租约持续时间，确保并发修改不会改变值。 锁服务 锁服务接口基于 vKV 实现，使用 vKV 的 CondPut() 操作实现锁。每个锁对应一个键值对，提供 Acquire() 和 Release() 方法的规范，支持应用实现独占锁。锁服务的规范与传统的并发分离逻辑锁规范不同，简化了资源保护。 银行事务 顶层应用，使用基于 vKV clerk 和锁服务接口构建的事务。 账户状态存储：使用 vKV 实例存储账户状态，每个账户余额用一对键值存储。 并发访问控制：使用锁服务处理账户的并发访问，每次转账操作获取两个锁，确保并发转账的安全执行。 审计功能 (Audit)：获取所有账户的锁，计算总余额，并释放锁。 容错处理：若银行节点崩溃，锁服务中的锁将保持锁定状态，恢复需要某种形式的撤销或重做日志，但原型中未实现。 ","date":"2024-08-30","objectID":"/posts/09.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0grove/:2:3","tags":["分布式系统"],"title":"【论文阅读笔记】Grove: a Separation-Logic Library for Verifying Distributed Systems (Extended Version)","uri":"/posts/09.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0grove/"},{"categories":["系统架构","论文阅读"],"content":"3 3 Grove性能评估 实验目的： 证明 Grove 能够验证现实世界中高性能的分布式系统。 展示 vKV 原型通过 Grove 验证后能够实现高性能。 特别强调租约在 vKV 中实现高性能读取的重要性。 baseline性能对比：将vKV与Redis进行比较，后者是高性能键值服务器，以C语言编写。为了使Redis与vKV在持久化保障上可比，Redis开启appendfsync always选项，而vKV运行于单核并禁用备份副本。结果显示，vKV吞吐量为Redis的67%-73%，请求延迟相当，多核下vKV吞吐量更高（例如，8核下YCSB 5%写入情况下，吞吐量提升5.1倍）。 重新配置能力：通过添加新服务器进行系统重配置，同时继续正确处理客户端请求的能力。实验中，主服务器在 10 秒时被杀掉，开始重配置过程。使用 YCSB 工作负载变体，100 个客户端持续写入，100 个客户端持续读取。重配置期间，写入操作会阻塞，但读取可以继续。实验结果显示 vKV 可以在重配置期间继续提供读取服务。 租约对读取性能的影响：写入密集型工作负载（50%或100%写入），增加副本会降低性能，因为写入在主服务器遇到更多开销，且其它副本处理的读取不足以抵消成本。对于读取密集型工作负载，增加副本可以提升性能，例如，YCSB 5%和0%写入情况下，3台服务器分别达到单服务器1.7倍和2.3倍的吞吐量。 ","date":"2024-08-30","objectID":"/posts/09.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0grove/:3:0","tags":["分布式系统"],"title":"【论文阅读笔记】Grove: a Separation-Logic Library for Verifying Distributed Systems (Extended Version)","uri":"/posts/09.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0grove/"},{"categories":["系统架构","论文阅读"],"content":"4 4 总结 ","date":"2024-08-30","objectID":"/posts/09.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0grove/:4:0","tags":["分布式系统"],"title":"【论文阅读笔记】Grove: a Separation-Logic Library for Verifying Distributed Systems (Extended Version)","uri":"/posts/09.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0grove/"},{"categories":["系统架构","论文阅读"],"content":"4.1 4.1 GroveKV系统 GroveKV特点： 容错、线性化的键值（KV）服务。 操作（Put/Get）exactlyonce。 崩溃安全且可重配置。 要进行重配置，GroveKV使用configservice管理服务器更改。如果没有configservice，类似VMWare-FT的问题，即两个备份可能是网络的彼此分区并且都想成为主分区。这可以通过ZooKeeper之类的配置服务解决。 lab3也是一个容错KV服务，但GroveKV使用主/备份复制而不是Raft。关键操作如下： 复制：Primary使用goroutines复制到其他服务器，基于RPC。执行操作时需要持有锁。 重配置：封闭当前的服务器组，从中获取状态副本，安装到新服务器。使用epoch编号处理并发重配置。 基于租约的读取：服务器不跟任何人协调回复Get请求。 ","date":"2024-08-30","objectID":"/posts/09.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0grove/:4:1","tags":["分布式系统"],"title":"【论文阅读笔记】Grove: a Separation-Logic Library for Verifying Distributed Systems (Extended Version)","uri":"/posts/09.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0grove/"},{"categories":["系统架构","论文阅读"],"content":"4.2 4.2 Grove核心 在正式验证领域，Grove 的核心在于证明代码在所有可能场景下均能表现得当，这一过程要求对代码执行的数学模型有深刻理解，以及对系统行为“正确”的明确定义。通过引入机械证明检查器，Grove 大幅降低了开发者在证明过程中犯错的可能性。 在 Grove 中，规范由前条件和后条件构成，用于描述操作前后的系统状态。以 GroveKV 为例，Put 和 Get 操作的规范不仅限定了操作的预期结果，还明确了数据所有权的转移。 Concurrent Separation Logic（CSL）是一种针对并发程序的形式化验证方法，Grove 对其进行了创新性的拓展，使之适用于分布式系统。CSL 强调基于资源所有权的代码分析，其中“堆指向”是一个典型的例子，它确保了数据的一致性不受并发访问的影响。 在 Grove 中，不变量指的是系统运行中必须始终保持为真的属性，而时间有界不变量（tinv）则进一步限制了特定资源的有效期。例如，GetTimeRange 函数允许在租约未到期的情况下，临时访问底层资源，这在处理基于租约的读取时尤为关键。 尽管正式验证能够显著减少某些类型的错误，但它并非万能药。验证不能保证所有实际中可能遇到的问题都被解决，特别是那些涉及系统活性性的问题，如死锁或饥饿。此外，编写高质量的证明和测试同样需要大量时间和精力，与开发代码无异，甚至有时还需经历重构的过程。 ","date":"2024-08-30","objectID":"/posts/09.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0grove/:4:2","tags":["分布式系统"],"title":"【论文阅读笔记】Grove: a Separation-Logic Library for Verifying Distributed Systems (Extended Version)","uri":"/posts/09.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0grove/"},{"categories":["系统架构"],"content":"1 1 实验要求 在本实验中，要求实现Raft，这是一种复制状态机协议，用于构建一个容错的键/值存储系统。实验的具体要求如下： 实现Raft： 将Raft实现为一个Go语言的对象类型，包含相关的方法，以便作为更大服务的一个模块使用。 Raft实例之间通过RPC通信，以维持复制的日志一致性。 支持无限数量的编号命令（日志条目），并能处理这些条目的提交。当一个特定索引的日志条目被提交后，Raft实现应将该条目发送给更大的服务执行。 遵循论文设计： 遵循Raft论文的设计，重点参考图2。 实现论文中描述的大部分功能，包括持久状态的保存和恢复，即使在节点故障和重启后也能保证数据的完整性。 不需要实现集群成员变更的部分（论文第六节）。 论文图2: Raft交互图： 我的实验代码仓库：https://github.com/HeZephyr/MIT6.5840/tree/main/src/raft，已通过压力测试，代码严格遵守上述按要求实现。 注意：下述所贴代码为了简洁以及分块，进行了一定程度的删减，如果需要复现，可以前往仓库。 ","date":"2024-08-11","objectID":"/posts/08.mit-6.58406.824-lab3-raft/:1:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824) 】Lab3:Raft 设计实现","uri":"/posts/08.mit-6.58406.824-lab3-raft/"},{"categories":["系统架构"],"content":"2 2 实验设计 ","date":"2024-08-11","objectID":"/posts/08.mit-6.58406.824-lab3-raft/:2:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824) 】Lab3:Raft 设计实现","uri":"/posts/08.mit-6.58406.824-lab3-raft/"},{"categories":["系统架构"],"content":"2.1 2.1 整体结构 此Raft结构体基于论文图2，基本上都是其中介绍的字段以及lab自带的字段，其中其他属性论文中也间接简述和支持，以确保Raft节点能够高效、稳定地运作。如选举定时器和心跳定时器，被明确地纳入了Raft结构体中。这些定时器对于触发关键的系统行为至关重要——选举定时器确保在必要时发起选举过程，而心跳定时器则维持着领导者与跟随者之间的连接，防止不必要的选举。 条件变量（sync.Cond）的引入则是为了精妙地控制两个核心后台goroutine的操作节奏：日志应用goroutine（applier，只需要一个，专门用于监控日志条目的提交状态，一旦日志条目被确认提交，它将负责将这些条目应用到状态机中。）和日志复制goroutine（replicator，负责进行日志条目的同步。考虑到集群中每个peer都需要与除了自身以外的其它peer进行日志同步，这意味着我们需要len(peers) - 1个replicator goroutines来分别处理与每个peer的交互）。 此外，还有一个goroutine ticker负责定期检查选举和心跳的超时，确保在适当的时间间隔内触发选举过程或发送心跳信号。 type Raft struct { mu sync.RWMutex // Lock to protect shared access to this peer's state, to use RWLock for better performance peers []*labrpc.ClientEnd // RPC end points of all peers persister *Persister // Object to hold this peer's persisted state me int // this peer's index into peers[] dead int32 // set by Kill() // Persistent state on all servers(Updated on stable storage before responding to RPCs) currentTerm int // latest term server has seen(initialized to 0 on first boot, increases monotonically) votedFor int // candidateId that received vote in current term(or null if none) logs []LogEntry // log entries; each entry contains command for state machine, and term when entry was received by leader(first index is 1) // Volatile state on all servers commitIndex int // index of highest log entry known to be committed(initialized to 0, increases monotonically) lastApplied int // index of highest log entry applied to state machine(initialized to 0, increases monotonically) // Volatile state on leaders(Reinitialized after election) nextIndex []int // for each server, index of the next log entry to send to that server(initialized to leader last log index + 1) matchIndex []int // for each server, index of highest log entry known to be replicated on server(initialized to 0, increases monotonically) // other properties state NodeState // current state of the server electionTimer *time.Timer // timer for election timeout heartbeatTimer *time.Timer // timer for heartbeat applyCh chan ApplyMsg // channel to send apply message to service applyCond *sync.Cond // condition variable for apply goroutine replicatorCond []*sync.Cond // condition variable for replicator goroutine } func Make(peers []*labrpc.ClientEnd, me int, persister *Persister, applyCh chan ApplyMsg) *Raft { rf := \u0026Raft{ mu: sync.RWMutex{}, peers: peers, persister: persister, me: me, dead: 0, currentTerm: 0, votedFor: -1, logs: make([]LogEntry, 1), // dummy entry at index 0 commitIndex: 0, lastApplied: 0, nextIndex: make([]int, len(peers)), matchIndex: make([]int, len(peers)), state: Follower, electionTimer: time.NewTimer(RandomElectionTimeout()), heartbeatTimer: time.NewTimer(StableHeartbeatTimeout()), applyCh: applyCh, replicatorCond: make([]*sync.Cond, len(peers)), } // initialize from state persisted before a crash rf.readPersist(persister.ReadRaftState()) // should use mu to protect applyCond, avoid other goroutine to change the critical section rf.applyCond = sync.NewCond(\u0026rf.mu) // initialize nextIndex and matchIndex, and start replicator goroutine for peer := range peers { rf.matchIndex[peer], rf.nextIndex[peer] = 0, rf.getLastLog().Index+1 if peer != rf.me { rf.replicatorCond[peer] = sync.NewCond(\u0026sync.Mutex{}) // start replicator goroutine to send log entries to peer go rf.replicator(peer) } } // start ticker goroutine to start elections go rf.ticker() // start apply goroutine to apply log entries to state machine go rf.applier() return rf } ","date":"2024-08-11","objectID":"/posts/08.mit-6.58406.824-lab3-raft/:2:1","tags":["分布式系统"],"title":"【MIT 6.5840(6.824) 】Lab3:Raft 设计实现","uri":"/posts/08.mit-6.58406.824-lab3-raft/"},{"categories":["系统架构"],"content":"2.2 2.2 lab3A：领导者选举 此任务需要实现Raft领导人选举和心跳（通过不附加日志条目的RPC）。对于这个要求，论文中其实给出了状态转移图，指导我们怎么去做。这个选举流程逻辑如下： 在lab3A实现过程中，需要注意如下几点： 当发起投票时，务必使用goroutine并行发起RPC调用，以避免阻塞ticker协程。这样，即使在等待投票响应期间，候选者（Candidate）仍能响应新的选举超时，从而有机会自增任期并启动新一轮的选举。 有两种常见的实现投票统计的方式：一种是在函数作用域内定义一个局部变量，并利用闭包来维护投票计数；另一种是在Raft结构体中维护一个全局的voteCnt变量。为了保持Raft结构体的简洁，推荐采用局部变量和闭包的方案。 对于过期的RPC请求回复，应直接忽略，不作任何处理。这是因为Raft协议假设网络环境不可靠，可能发生的延迟或重播不应影响当前的决策流程。 如果在RPC通信中，节点A发现其任期小于节点B的任期，不论节点A当前的角色如何，都应立即转换为跟随者（Follower）。这是为了维护任期的权威性，确保集群的一致性。 为防止多个节点几乎同时启动选举，导致资源浪费和潜在的领导权争夺，应为选举超时设置一个随机的误差范围（如150~300ms），以拉长不同节点选举的时间间隔，这里采用时间戳作为随机种子。且每一次一个节点重置自己的选举定时器时，都需要重新选择一个随机的超时时间。避免服务器会以极小的概率选择相同的随机超时时间，那么会永远处于分割选票的场景中。 Go RPC 仅发送名称以大写字母开头的结构体字段。子结构还必须具有大写的字段名称（例如数组中日志记录的字段）。这 labgob 软件包会警告您这一点；不要忽视警告。 在同一个任期内，Follower只能投出一票，这是为了防止出现多个Leader的情况。票数的刷新应在任期转换时进行，以确保投票的有效性和一致性。 为了提高并发性能，应尽量缩短临界区的长度。合理的锁使用策略是只在真正需要保护共享资源的最小时间内使用锁。 核心的Ticker实现： func (rf *Raft) ticker() { for rf.killed() == false { select { case \u003c-rf.electionTimer.C: rf.mu.Lock() rf.ChangeState(Candidate) rf.currentTerm += 1 // start election rf.StartElection() rf.electionTimer.Reset(RandomElectionTimeout()) // reset election timer in case of split vote rf.mu.Unlock() case \u003c-rf.heartbeatTimer.C: rf.mu.Lock() if rf.state == Leader { // should send heartbeat rf.BroadcastHeartbeat(true) rf.heartbeatTimer.Reset(StableHeartbeatTimeout()) } rf.mu.Unlock() } } } StartElection函数实现： func (rf *Raft) StartElection() { rf.votedFor = rf.me args := rf.genRequestVoteArgs() grantedVotes := 1 for peer := range rf.peers { if peer == rf.me { continue } go func(peer int) { reply := new(RequestVoteReply) if rf.sendRequestVote(peer, args, reply) { rf.mu.Lock() defer rf.mu.Unlock() if args.Term == rf.currentTerm \u0026\u0026 rf.state == Candidate { if reply.VoteGranted { grantedVotes += 1 // check over half of the votes if grantedVotes \u003e len(rf.peers)/2 { rf.ChangeState(Leader) rf.BroadcastHeartbeat(true) } } else if reply.Term \u003e rf.currentTerm { rf.ChangeState(Follower) rf.currentTerm, rf.votedFor = reply.Term, -1 } } } }(peer) } } RequestVoteRPC严格按照图2描述实现： func (rf *Raft) RequestVote(args *RequestVoteArgs, reply *RequestVoteReply) { rf.mu.Lock() defer rf.mu.Unlock() defer DPrintf(\"{Node %v}'s state is {state %v, term %v}} after processing RequestVote, RequestVoteArgs %v and RequestVoteReply %v \", rf.me, rf.state, rf.currentTerm, args, reply) // Reply false if term \u003c currentTerm(§5.1) // if the term is same as currentTerm, and the votedFor is not null and not the candidateId, then reject the vote(§5.2) if args.Term \u003c rf.currentTerm || (args.Term == rf.currentTerm \u0026\u0026 rf.votedFor != -1 \u0026\u0026 rf.votedFor != args.CandidateId) { reply.Term, reply.VoteGranted = rf.currentTerm, false return } if args.Term \u003e rf.currentTerm { rf.ChangeState(Follower) rf.currentTerm, rf.votedFor = args.Term, -1 } // if candidate's log is not up-to-date, reject the vote(§5.4) if !rf.isLogUpToDate(args.LastLogIndex, args.LastLogTerm) { reply.Term, reply.VoteGranted = rf.currentTerm, false return } rf.votedFor = args.CandidateId rf.electionTimer.Reset(RandomElectionTimeout()) reply.Term, reply.VoteGranted = rf.currentTerm, true } ","date":"2024-08-11","objectID":"/posts/08.mit-6.58406.824-lab3-raft/:2:2","tags":["分布式系统"],"title":"【MIT 6.5840(6.824) 】Lab3:Raft 设计实现","uri":"/posts/08.mit-6.58406.824-lab3-raft/"},{"categories":["系统架构"],"content":"2.3 2.3 lab3B：日志 在Lab3B阶段，我们的目标转向实现Raft协议中至关重要的日志复制机制。其中入口是Start函数（应用程序与Raft的接口）。具体的日志复制流程： 一旦Leader接收到新的日志条目，它首先会在自己的日志中追加这个条目。 随后，Leader通过BroadcastHeartbeat函数将这个日志条目广播至集群中的所有Peer，确保所有节点都能同步最新的状态。此过程涉及对日志条目的校验与冲突解决，确保每个Peer的日志保持一致且最新。 在日志条目被发送给Peers后，Leader会等待来自Peer的确认回复。只有当Leader收到大多数Peer（即超过半数）的确认，表明这些Peer已经成功复制了日志条目，Leader才能认为该日志条目已经被安全地复制。这是Raft协议中“多数原则”的体现，确保了即使在部分节点失败的情况下，系统仍然能够达成一致。当然，也需要根据回复确认自己Leader的地位，如果不再是Leader，需要更改为Follower。 一旦日志条目被确认复制到了大多数节点，Leader就会标记这个条目为已提交（committed）。随后，Leader会通过AppendEntries RPC将最新的LeaderCommit信息广播给所有Peer，指示它们哪些日志条目现在可以被提交并应用到各自的状态机中。每个Peer根据接收到的LeaderCommit值来决定其日志中哪些条目可以被提交，从而确保所有活跃Peer的状态机保持一致。 在lab3B实现过程中，需要注意如下几点： 在发送RPC、接收RPC、推送和接收channel时，绝对不要持有锁，否则极易引发死锁。这在locking博客中有详细介绍，应时刻牢记。使用读写锁时，对于只读操作，只需持有读锁，避免不必要的写锁持有，以提高并发性能。 对于过期的RPC请求回复，应直接忽略，避免执行任何业务逻辑 根据图2的规定，Raft Leader只能提交属于当前任期的日志条目，不得提交前任期的日志。在根据matchIndex[]判断是否可以提交日志时，必须检查该日志的任期是否与当前Leader的任期相匹配。 Follower对Leader的leaderCommit应无条件服从，无需额外判断。 Leader需维护好matchIndex[]（跟踪Follower的提交状态）和nextIndex[]（追踪Follower的日志复制进度），并在Leader崩溃后正确地初始化这两个数组。 当Follower接收到日志时，需检查RPC中Leader认定的当前Follower的prevLogIndex和prevLogTerm，判断日志是否存在冲突，若存在冲突，需由Leader从冲突点开始强制覆盖Follower的日志。 新的Leader的日志需确保包含了所有已提交的日志条目。Follower可能在Leader提交日志期间进入不可用状态，从而导致被选为新Leader的Follower可能覆盖已提交的日志条目。为避免这种情况，选举时需加入Leader限制机制，即Follower只给任期和日志更新的Candidate投票，具体规则如下： 如果任期号不同，任期号较大的Candidate更新； 如果任期号相同，日志索引值较大（即日志更长）的Candidate更新。 核心的AppendEntries RPC实现： func (rf *Raft) AppendEntries(args *AppendEntriesArgs, reply *AppendEntriesReply) { // Your code here (3A, 3B). rf.mu.Lock() defer rf.mu.Unlock() defer DPrintf(\"{Node %v}'s state is {state %v, term %v}} after processing AppendEntries, AppendEntriesArgs %v and AppendEntriesReply %v \", rf.me, rf.state, rf.currentTerm, args, reply) // Reply false if term \u003c currentTerm(§5.1) if args.Term \u003c rf.currentTerm { reply.Term, reply.Success = rf.currentTerm, false return } // indicate the peer is the leader if args.Term \u003e rf.currentTerm { rf.currentTerm, rf.votedFor = args.Term, -1 } rf.ChangeState(Follower) rf.electionTimer.Reset(RandomElectionTimeout()) // Reply false if log doesn’t contain an entry at prevLogIndex whose term matches prevLogTerm(§5.3) if args.PrevLogIndex \u003c rf.getFirstLog().Index { reply.Term, reply.Success = rf.currentTerm, false return } // check the log is matched, if not, return the conflict index and term // if an existing entry conflicts with a new one (same index but different terms), delete the existing entry and all that follow it(§5.3) if !rf.isLogMatched(args.PrevLogIndex, args.PrevLogTerm) { reply.Term, reply.Success = rf.currentTerm, false lastLogIndex := rf.getLastLog().Index // find the first index of the conflicting term if lastLogIndex \u003c args.PrevLogIndex { // the last log index is smaller than the prevLogIndex, then the conflict index is the last log index reply.ConflictIndex, reply.ConflictTerm = lastLogIndex+1, -1 } else { firstLogIndex := rf.getFirstLog().Index // find the first index of the conflicting term index := args.PrevLogIndex for index \u003e= firstLogIndex \u0026\u0026 rf.logs[index-firstLogIndex].Term == args.PrevLogTerm { index-- } reply.ConflictIndex, reply.ConflictTerm = index+1, args.PrevLogTerm } return } // append any new entries not already in the log firstLogIndex := rf.getFirstLog().Index for index, entry := range args.Entries { // find the junction of the existing log and the appended log. if entry.Index-firstLogIndex \u003e= len(rf.logs) || rf.logs[entry.Index-firstLogIndex].Term != entry.Term { rf.logs = append(rf.logs[:entry.Index-firstLogIndex], args.Entries[index:]...) break } } // If leaderCommit \u003e commitIndex, set commitIndex = min(leaderCommit, index of last new entry) (paper) newCommitIndex := Min(args.LeaderCommit, rf.getLastLog().Index) if newCommitIndex \u003e rf.commitIndex { rf.commitIndex = newCommitIndex rf.applyCond.Signal() } reply.Term, reply.Success = rf.currentTerm, true } replicateOnceRound用来调用AppendEntriesRPC，并根据reply继续相应处理： func (rf *Raft) replicateOnceRound(peer int) { rf.mu.RLock() if rf.state != Lea","date":"2024-08-11","objectID":"/posts/08.mit-6.58406.824-lab3-raft/:2:3","tags":["分布式系统"],"title":"【MIT 6.5840(6.824) 】Lab3:Raft 设计实现","uri":"/posts/08.mit-6.58406.824-lab3-raft/"},{"categories":["系统架构"],"content":"2.4 2.4 lab3C：持久化 如果基于 Raft 的服务器重新启动，它应该从中断处恢复服务。这要求 Raft 保持在重启后仍然存在的持久状态。论文的图 2 提到了哪种状态应该是持久的，即logs、currentTerm和votedFor。在Lab3C中，我们的任务便是实现persist()和readPersist()这两个核心函数，前者负责保存Raft的状态，后者则是在Raft启动时恢复之前保存的数据。 readPersist函数实现： func (rf *Raft) readPersist(data []byte) { if data == nil || len(data) \u003c 1 { // bootstrap without any state? return } r := bytes.NewBuffer(data) d := labgob.NewDecoder(r) var currentTerm, votedFor int var logs []LogEntry if d.Decode(\u0026currentTerm) != nil || d.Decode(\u0026votedFor) != nil || d.Decode(\u0026logs) != nil { DPrintf(\"{Node %v} fails to decode persisted state\", rf.me) } rf.currentTerm, rf.votedFor, rf.logs = currentTerm, votedFor, logs rf.lastApplied, rf.commitIndex = rf.getFirstLog().Index, rf.getFirstLog().Index } persist函数实现： func (rf *Raft) encodeState() []byte { w := new(bytes.Buffer) e := labgob.NewEncoder(w) e.Encode(rf.currentTerm) e.Encode(rf.votedFor) e.Encode(rf.logs) return w.Bytes() } func (rf *Raft) persist() { rf.persister.SaveStateAndSnapshot(rf.encodeState(), nil) } 实现好后，我们只需要在入口处Make调用readPersist即可，关键需要在什么时候保存状态呢？其实很简单，只需要对我们需要持久化的三个字段修改的时候就进行persist操作。即persist()操作应当在以下几种情况下被触发： 日志条目更新：当有新的日志条目被添加到logs中，或是已有条目被删除或替换时。 任期变更：当currentTerm发生变化，比如在选举期间或接收到更高任期的领导者信息时。 投票行为：当votedFor字段被更新，意味着节点投出了新的一票或取消了之前的投票。 ","date":"2024-08-11","objectID":"/posts/08.mit-6.58406.824-lab3-raft/:2:4","tags":["分布式系统"],"title":"【MIT 6.5840(6.824) 】Lab3:Raft 设计实现","uri":"/posts/08.mit-6.58406.824-lab3-raft/"},{"categories":["系统架构"],"content":"2.5 2.5 lab3D：日志压缩 按照目前的情况，重新启动的服务器会重放完整的 Raft 日志以恢复其状态。然而，对于一个长期运行的服务来说，永远记录完整的 Raft 日志是不切实际的。需要使用快照服务配合，此时Raft会丢弃快照之前的日志条目。lab3D就是需要我们实现日志压缩，具体来说是核心是Snapshot（快照保存函数）以及InstallSnapshotRPC，快照压缩的流程： 每个peer都会通过Snapshot捕获当前系统状态的一个快照。这通常包括但不限于状态机的当前状态、任何必要的元数据、以及快照生成时的任期信息。 当Leader认为有必要向Follower发送快照时，它将发起InstallSnapshotRPC调用。这通常发生在Follower的日志状态与Leader严重脱节时，例如日志冲突无法通过常规的AppendEntriesRPC解决。 Follower接收到快照后，会验证其完整性和一致性，然后应用快照以替换其当前状态和日志。这包括清除快照点之前的所有日志条目，并将状态机恢复到快照所表示的状态。 Follower在成功应用快照后，应通过RPC回复向Leader确认，表明快照已被正确安装。Leader据此更新其matchIndex和nextIndex数组，以反映Follower的最新状态。 在lab3D实现过程中，需要注意以下几点： 在更新 lastApplied 时，必须采用前一时刻的 commitIndex 值，而非实时的 rf.commitIndex。这是因为，在执行 push applyCh 过程中，rf.commitIndex 可能因其他操作而动态变化，使用其历史值可以保证 lastApplied 更新的准确性。 需要注意使用CondInstallSnapshot来验证快照的有效性。 在修剪log的时候注意留一个dummy log 使用 Max(rf.lastApplied, commitIndex) 而不是直接使用 commitIndex 来避免并发 InstallSnapshot RPC 导致 lastApplied 回滚 InstallSnapshot RPC实现如下： func (rf *Raft) InstallSnapshot(args *InstallSnapshotArgs, reply *InstallSnapshotReply) { rf.mu.Lock() defer rf.mu.Unlock() reply.Term = rf.currentTerm // reply immediately if term \u003c currentTerm if args.Term \u003c rf.currentTerm { return } if args.Term \u003e rf.currentTerm { rf.currentTerm, rf.votedFor = args.Term, -1 rf.persist() } rf.ChangeState(Follower) rf.electionTimer.Reset(RandomElectionTimeout()) // check the snapshot is more up-to-date than the current log if args.LastIncludedIndex \u003c= rf.commitIndex { return } go func() { rf.applyCh \u003c- ApplyMsg{ SnapshotValid: true, Snapshot: args.Data, SnapshotTerm: args.LastIncludedTerm, SnapshotIndex: args.LastIncludedIndex, } }() } Snapshot函数实现如下，它接收客户端创建的快照。 func (rf *Raft) Snapshot(index int, snapshot []byte) { rf.mu.Lock() defer rf.mu.Unlock() snapshotIndex := rf.getFirstLog().Index if index \u003c= snapshotIndex || index \u003e rf.getLastLog().Index { DPrintf(\"{Node %v} rejects replacing log with snapshotIndex %v as current snapshotIndex %v is larger in term %v\", rf.me, index, snapshotIndex, rf.currentTerm) return } // remove log entries up to index rf.logs = rf.logs[index-snapshotIndex:] rf.logs[0].Command = nil rf.persister.SaveStateAndSnapshot(rf.encodeState(), snapshot) } 还有一个CondInstallSnapshot，用来peer判断leader发过来的快照是否满足条件，如果满足，则安装快照。这个需要修改到config.go文件中。 func (rf *Raft) CondInstallSnapshot(lastIncludedTerm int, lastIncludedIndex int, snapshot []byte) bool { rf.mu.Lock() defer rf.mu.Unlock() // outdated snapshot if lastIncludedIndex \u003c= rf.commitIndex { return false } // need dummy entry at index 0 if lastIncludedIndex \u003e rf.getLastLog().Index { rf.logs = make([]LogEntry, 1) } else { rf.logs = rf.logs[lastIncludedIndex-rf.getFirstLog().Index:] rf.logs[0].Command = nil } rf.logs[0].Term, rf.logs[0].Index = lastIncludedTerm, lastIncludedIndex rf.commitIndex, rf.lastApplied = lastIncludedIndex, lastIncludedIndex rf.persister.SaveStateAndSnapshot(rf.encodeState(), snapshot) } ","date":"2024-08-11","objectID":"/posts/08.mit-6.58406.824-lab3-raft/:2:5","tags":["分布式系统"],"title":"【MIT 6.5840(6.824) 】Lab3:Raft 设计实现","uri":"/posts/08.mit-6.58406.824-lab3-raft/"},{"categories":["系统架构"],"content":"3 3 压测脚本 我自己实现了一个压测脚本： #!/bin/bash # check the number of arguments if [ \"$#\" -ne 2 ]; then echo \"Usage: $0 \u003ctest_type\u003e \u003citerations\u003e\" echo \"test_type must be one of 3A, 3B, 3C, 3D\" exit 1 fi test_type=$1 iterations=$2 # check the test_type if [[ \"$test_type\" != \"3A\" \u0026\u0026 \"$test_type\" != \"3B\" \u0026\u0026 \"$test_type\" != \"3C\" \u0026\u0026 \"$test_type\" != \"3D\" ]]; then echo \"Invalid test_type: $test_type\" echo \"test_type must be one of 3A, 3B, 3C, 3D\" exit 1 fi # check the iterations is a positive integer if ! [[ \"$iterations\" =~ ^[0-9]+$ ]]; then echo \"Invalid iterations: $iterations\" echo \"iterations must be a positive integer\" exit 1 fi echo \"go test -run $test_type\" for ((i=1; i\u003c=iterations; i++)) do echo \"Running test iteration $i\" output=$(go test -run $test_type 2\u003e\u00261) # 2\u003e\u00261 redirects stderr to stdout if [[ $? -ne 0 ]]; then echo \"Error in iteration $i:\" echo \"$output\" fi done 网上也提供了一个测试脚本，功能更为强大。压测结果如下所示： ","date":"2024-08-11","objectID":"/posts/08.mit-6.58406.824-lab3-raft/:3:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824) 】Lab3:Raft 设计实现","uri":"/posts/08.mit-6.58406.824-lab3-raft/"},{"categories":["系统架构"],"content":"4 4 优化 如果我们使用的空间少于数组的一半，我们就替换该数组。这个数字是相当任意的，选择它是为了平衡内存使用与分配数量，这个数字可能还可以改进。 func shrinkEntries(entries []LogEntry) []LogEntry { const lenMultiple = 2 if cap(entries) \u003e len(entries)*lenMultiple { newEntries := make([]LogEntry, len(entries)) copy(newEntries, entries) return newEntries } return entries } 因为日志的索引是单调递增的，而term则是非递减的。所以这里应该可以使用二分优化。 ","date":"2024-08-11","objectID":"/posts/08.mit-6.58406.824-lab3-raft/:4:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824) 】Lab3:Raft 设计实现","uri":"/posts/08.mit-6.58406.824-lab3-raft/"},{"categories":["系统架构","论文阅读"],"content":"1 摘要 这篇论文介绍了ZooKeeper，一个用于协调分布式应用进程的服务。ZooKeeper旨在提供一个简单且高性能的内核，用于构建更复杂的客户端协调原语。它整合了组消息传递、共享寄存器和分布式锁服务的元素，形成了一个复制的、集中式的服务。Zookeeper提供了一个接口，具有共享寄存器的无等待特性和类似分布式文件系统缓存失效的事件驱动机制，以提供简单而强大的协调服务。ZooKeeper还保证了每个客户端请求的FIFO执行和所有更改ZooKeeper状态的请求的线性化。 ","date":"2024-08-11","objectID":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/:1:0","tags":["分布式系统","ZAP","ZooKeeper"],"title":"【论文阅读笔记】ZooKeeper: Wait-free coordination for Internet-scale systems","uri":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/"},{"categories":["系统架构","论文阅读"],"content":"2 1 介绍 分布式系统中的基本协调机制： 配置：最基本的形式，可能是静态或动态的操作参数列表。 组成员资格和领导者选举：进程需要了解其他进程的状态及职责。 锁：实现对临界区的互斥访问的强大协调原语。 一种协调方法是为每种不同的协调需求（如队列服务、领导者选举服务）开发服务。也可以使用更强大的服务来实现其他原语（如Chubby是一种具有强同步保证的锁服务，它可以用于实现领导者选举、组成员资格等）。 ZooKeeper的设计原则： API暴露。使开发人员能够实现自己的原语，而不是在服务器端实现特定原语。 无等待数据对象。避免使用阻塞原语（如锁），使系统性能更高、容错性更好。 操作顺序保证。实现FIFO客户端排序和可线性化写入。 Zookeeper实现了一个API，用于操作像文件系统那样层次化组织的简单无等待数据对象。ZooKeeper服务由一组使用复制来实现高可用性和高性能的服务器组成，并且使用流水线架构实现，该架构支持大量未完成请求，保持低延迟。这样的流水线自然地支持了单个客户端按FIFO顺序执行操作。保证FIFO客户端顺序使得客户端可以异步提交操作。通过异步操作，客户端可以同时有多个未完成的操作。 为了保证更新操作满足可线性化，作者实现了一个基于领导者的原子广播协议，称为Zab。然而，Zookeeper应用程序的典型工作负载主要是读操作，因此需要进行读操作优化，即不使用Zab对它们进行全序排序，而是本地处理读操作，利用客户端缓存和监视机制（只缓存不直接管理）提高性能。Chubby直接管理客户端缓存，其使用租约来防止故障客户端无限期地阻塞系统。然而，租约只能限制慢或故障客户端的影响，而ZooKeeper的监视机制则完全避免了这个问题。 ","date":"2024-08-11","objectID":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/:2:0","tags":["分布式系统","ZAP","ZooKeeper"],"title":"【论文阅读笔记】ZooKeeper: Wait-free coordination for Internet-scale systems","uri":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/"},{"categories":["系统架构","论文阅读"],"content":"3 2 Zookeeper服务 客户端通过ZooKeeper客户端库的API向ZooKeeper服务提交请求，该库不仅提供了服务接口，还负责管理客户端与服务器之间的网络连接。客户端在连接ZooKeeper时建立会话，并通过会话句柄发送请求。 相关术语： 客户端：ZooKeeper服务的用户 服务器：提供ZooKeeper服务的进程 znode：ZooKeeper数据中的内存数据节点，该数据节点组织在称为数据树的分层命名空间中 “update\"和\"write”：来指代任何修改数据树状态的操作。 ","date":"2024-08-11","objectID":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/:3:0","tags":["分布式系统","ZAP","ZooKeeper"],"title":"【论文阅读笔记】ZooKeeper: Wait-free coordination for Internet-scale systems","uri":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/"},{"categories":["系统架构","论文阅读"],"content":"3.1 2.1 服务概述 ZooKeeper服务为客户端提供了数据节点（znodes）的抽象概念，这些节点在层次命名空间中组织，类似于文件系统（如/A/B/C表示znode C的路径，其中C父节点是B），便于用户理解和组织数据。每个znode都存储数据，除了临时znode外，都可以有子节点。客户端可以创建两种类型znode： 常规znode：客户端显示创建和删除 临时znode：客户端显示创建和删除，或者在创建它们的会话终止后由系统自动删除。、 创建znode时，可以设置顺序标志，使用顺序标志创建的znode在其名称后附加一个单调递增的计数器值，确保节点名称的唯一性。 ZooKeeper的监视机制允许客户端在变更发生时接收通知，无需轮询。这种机制是一次性的，与会话关联，触发后或会话关闭时取消。客户端通过监视事件得知数据变化，但不会获得变化的具体内容。 ZooKeeper的数据模型本质是一个简化API的文件系统或具有层次键的键值表，层次化命名空间对于不同应用程序的命名空间分配子树和设置这些子树的访问权限非常有用。znode不是为一般数据存储设计，而是作为客户端应用协调的抽象。 例如，在下图中，有两个子树，一个用于app1（/app1），另一个用于app2（/app2）。app1的子树实现了一个简单的组成员协议：每个客户端进程p_i在/app1下创建一个znode p_i，该znode在进程运行期间持续存在。ZooKeeper允许客户端用znode存储一些可以用于分布式计算的元数据或配置的信息（例如当前领导者信息）。znode还包含时间戳和版本计数器，使客户端能够追踪变更并执行条件更新。 客户端与ZooKeeper的会话具有超时机制，超时未收到信息即认为客户端故障。当客户端显式关闭会话句柄或ZooKeeper检测到客户端故障时，会话结束。会话期间，客户端可以跨服务器透明迁移，保持状态连续性。 ","date":"2024-08-11","objectID":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/:3:1","tags":["分布式系统","ZAP","ZooKeeper"],"title":"【论文阅读笔记】ZooKeeper: Wait-free coordination for Internet-scale systems","uri":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/"},{"categories":["系统架构","论文阅读"],"content":"3.2 2.2 客户端API 以下是ZooKeeper API的相关子集： create(path, data, flags)：创建一个具有路径名path的znode，存储data[]，并返回新znode的名称。flags使客户端可以选择znode的类型：常规、临时，并设置顺序标志。 delete(path, version)：如果znode的版本与预期版本匹配，则删除路径为path的znode。 exists(path, watch)：如果路径为path的znode存在，则返回true，否则返回false。watch标志允许客户端在znode上设置监视。 getData(path, watch)：返回与znode关联的数据和元数据（如版本信息）。watch标志的工作方式与exists()相同，只是如果znode不存在，ZooKeeper不会设置监视。 setData(path, data, version)：如果znode的版本号是当前版本，则将data[]写入路径为path的znode。 getChildren(path, watch)：返回znode的子节点名称集合。 sync(path)：等待在操作开始时挂起的所有更新传播到客户端连接的服务器。当前忽略路径。 所有方法在API中都有同步和异步版本。当应用程序需要执行单个ZooKeeper操作且没有并发任务时，使用同步API，使其阻塞直到完成。而异步API允许应用程序执行多个ZooKeeper操作和其他任务，ZooKeeper客户端保证按顺序调用每个操作的相应回调。 ZooKeeper不使用句柄访问znode。每个请求都包括被操作的znode的完整路径。这不仅简化了API（没有open()或close()方法），还消除了服务器需要维护的额外状态。每个更新方法都接受一个预期版本号，如果znode的实际版本号与预期版本号不匹配，更新将失败并返回版本错误。如果版本号为-1，则不进行版本检查。 ","date":"2024-08-11","objectID":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/:3:2","tags":["分布式系统","ZAP","ZooKeeper"],"title":"【论文阅读笔记】ZooKeeper: Wait-free coordination for Internet-scale systems","uri":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/"},{"categories":["系统架构","论文阅读"],"content":"3.3 2.3 Zookeeper保证 ZooKeeper通过两项基本的顺序保证来确保操作的一致性和可预测性： 线性化写入：所有更新ZooKeeper状态的请求都是可序列化的，并且遵循优先级。 FIFO客户端顺序：来自同一客户端的所有请求按照它们被发送的顺序执行。 ZooKeeper的线性化定义扩展了Herlihy的原始定义，称为异步线性化，允许客户端有多个未完成的操作，并保证这些操作的FIFO顺序。 这种顺序保证对于分布式系统中的领导者选举和配置更新至关重要。例如，当新领导者需要更新大量配置参数时，可以利用ZooKeeper的顺序保证来确保配置的一致性和完整性。新领导者通过创建一个ready znode来控制配置的更新，其他进程只有在该znode存在时才会采用新的配置。新领导者通过删除ready、更新各种配置znode和创建ready来进行配置更改。所有这些更改可以流水线处理，并异步发布，以快速更新配置状态。 此外，ZooKeeper的通知机制确保了客户端能够及时接收到变更通知，而sync操作则允许客户端在需要时强制更新读取，以获取最新的系统状态。 ZooKeeper的设计允许它在保持高吞吐量的同时，也保证了系统的活性和持久性。只要大多数服务器处于活动状态并能够通信，服务就能保持可用。而且，一旦服务成功响应了更改请求，那么只要法定数量的服务器能够恢复，这些更改能在任何数量的故障中持久化。 ","date":"2024-08-11","objectID":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/:3:3","tags":["分布式系统","ZAP","ZooKeeper"],"title":"【论文阅读笔记】ZooKeeper: Wait-free coordination for Internet-scale systems","uri":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/"},{"categories":["系统架构","论文阅读"],"content":"3.4 2.4 原语示例 ZooKeeper API提供了实现复杂原语的能力，这些原语完全在客户端实现，服务端并不感知。无论是配置管理、汇合点、组成员关系还是锁机制，ZooKeeper都能通过其API提供支持。ZooKeeper的顺序保证允许高效地推理系统状态，而监视则允许高效地等待。 配置管理：最简单的形式是将配置存储在一个 znode（$z_c$）中。进程启动时获取 $z_c$ 的完整路径名。启动的进程通过读取 $z_c$ 并将监视标志设置为 true 来获得其配置。如果 $z_c$ 中的配置被更新，进程会收到通知并读取新配置，重新设置监视标志为 true。 在这种方案中，尽管有很多次变化，但通常进程只会收到一次，这并不会影响进程的行为，因为监视是用来通知进程它已经知道的信息：它所拥有的 $z_c$ 信息是过时的。 汇合点：在分布式系统中，有时并不总是能事先明确最终的系统配置。可以使用 ZooKeeper 处理这种情况，通过一个称为汇合点的 znode（$z_r$），这是由客户端创建的节点。客户端将 $z_r$ 的完整路径名作为启动参数传递给主进程和工作进程。当主进程启动时，它会将其使用的地址和端口信息填充到 $z_r$ 中。当工作进程启动时，它们会读取 $z_r$ 并将监视设置为 true。如果 $z_r$ 尚未填充，工作进程将等待被通知 $z_r$ 更新。如果 $z_r$ 是一个临时节点，主进程和工作进程可以监视 $z_r$ 的删除，并在客户端结束时进行清理。 组成员关系：我们利用临时节点允许查看创建该节点的会话状态。首先指定一个 znode（$z_g$）来代表组。当组中的一个进程成员启动时，它会在 $z_g$ 下创建一个临时子 znode。如果每个进程都有唯一的名称或标识符，则该名称用于子 znode 的名称；否则，进程将使用 SEQUENTIAL 标志创建 znode 以获得唯一的名称分配。 进程可以将进程信息放入子 znode 的数据中，例如进程使用的地址和端口。在 $z_g$ 下创建子 znode 后，进程正常启动，不需要做其他任何事情。如果进程失败或结束，代表它的 znode 在 $z_g$ 下自动移除。进程可以通过列出 $z_g$ 的子节点来获取组信息。如果进程想监视组成员变动，可以将监视标志设置为 true，并在收到变动通知时刷新组信息（始终将监视标志设置为 true）。 简单锁：尽管 ZooKeeper 不是一个锁服务，但它可以用来实现锁，以实现各种通用同步原语。最简单的锁实现使用“锁文件”。锁由一个 znode 表示。 要获取锁，客户端尝试创建带有 EPHEMERAL 标志的指定 znode。如果创建成功，客户端持有锁。否则，客户端可以读取 znode 并设置监视标志，以便在当前持有锁的客户端死亡时收到通知。 客户端在死亡或显式删除 znode 时释放锁。等待锁的其他客户端在观察到 znode 被删除后再次尝试获取锁。 虽然这种简单的锁协议有效，但它确实存在一些问题。 它遭受群体效应。如果有许多客户端等待获取锁，当锁被释放时，它们都会争夺锁，尽管只有一个客户端可以获取锁。 它只实现了独占锁。 以下两个原语展示了如何克服这两个问题。 无群体效应的简单锁：我们定义一个锁 znode（$l$）来实现这样的锁。直观上，我们将所有请求锁的客户端排队，每个客户端按请求到达的顺序获取锁。因此，客户端希望获取锁时执行以下操作： # Lock # 使用 SEQUENTIAL 标志将客户端获取锁的尝试按与其他所有尝试的顺序排列。n代表Zookeeper自动分配的唯一序列号 1 n = create(l + “/lock-”, EPHEMERAL|SEQUENTIAL) # 获取锁路径下所有子节点的列表。 2 C = getChildren(l, false) # 如果当前创建的节点 n 是子节点列表 C 中最小的一个，即没有其他节点有更小的序号，那么这个客户端获得了锁，退出。 3 if n is lowest znode in C, exit # 果当前节点 n 不是最小的，找到列表中直接排在 n 前面的节点 p。（即每个都等待前一个，这样避免了群体效应，因为只有一个进程在锁被释放或锁请求被放弃时被唤醒） 4 p = znode in C ordered just before n # 检查节点 p 是否仍然存在。由于节点是临时的，如果持有锁的客户端断开了连接，节点 p 将被自动删除。 5 if exists(p, true) # 设置一个监视器，等待节点 p 的状态变化事件 wait for watch event # 如果 p 不存在，说明那个客户端已经释放了锁，仍然有一个更低序列号的 znode 正在等待或持有锁，所以当前客户端应该再次检查自己是否是最小的节点。 6 goto 2 # Unlock 1 delete(n) 这种锁方案具有以下优点： znode 的删除只会唤醒一个客户端，因为每个 znode 只有一个其他客户端在监视，所以我们没有群体效应； 没有轮询或超时； 由于我们实现锁的方式，我们可以通过浏览 ZooKeeper 数据查看锁争用情况、破坏锁和调试锁问题。 读/写锁：为了实现读/写锁，我们稍微更改了锁过程，并有单独的读锁和写锁过程。解锁过程与全局锁的情况相同。 # Write Lock 1 n = create(l + “/write-”, EPHEMERAL|SEQUENTIAL) 2 C = getChildren(l, false) 3 if n is lowest znode in C, exit 4 p = znode in C ordered just before n 5 if exists(p, true) wait for event 6 goto 2 # Read Lock 1 n = create(l + “/read-”, EPHEMERAL|SEQUENTIAL) 2 C = getChildren(l, false) 3 if no write znodes lower than n in C, exit 4 p = write znode in C ordered just before n 5 if exists(p, true) wait for event 6 goto 3 此锁过程与之前的锁略有不同。写锁仅在命名上有所不同。读锁第 3 行和第 4 行有所不同，因为只有较早的写锁 znode 会阻止客户端获取读锁。看起来当有多个客户端等待读锁时，会出现“群体效应”，并在较低序列号的“write-” znode 被删除时收到通知；实际上，这正是我们所期望的行为。一旦写锁被释放，所有等待读锁的客户端都应该被唤醒，因为它们现在有可能共同持有读锁。这是因为读锁是可以共享的，一旦没有任何写锁存在，所有的读锁请求都可以被满足，所有等待读锁的客户端都能继续它们的操作，无需再等待。这种机制确保了读操作的高并发性，同时保证了写操作的独占性，从而维护了数据的一致性和完整性。 双重屏障：双重屏障机制为客户端提供了一种优雅的方式来同步计算阶段的启动与终止，确保所有参与方在统一的信号下协同行动。当加入屏障的进程数量超过屏障阈值时，标志着计算活动的开启；而随着各进程完成任务并相继退出，屏障亦随之解除。在这一机制中，屏障自身以ZooKeeper中的 znode 表示，我们将其命名为 $b$。 每当进程 $p$ 欲进入屏障，它首先通过在 $b$ 下创建一个子 znode 来进行注册，表明自身已加入计算预备队列；而当进程准备撤离屏障，即宣告任务完成之时，它将移除先前创建的子 znode，以此来注销。屏障的激活与释放，分别对应于 $b$ 下子节点数目越过阈值及全部子节点被清除这两个条件。 为了确保进程高效等待进入与退出条件的达成，Zookeeper巧妙地运用了监视器。在进程寻求进入屏障时，它会设置监视器以监听 $b$ 的某个子 znode 的存在状态——这个子 znode 是由导致子节点数量首次超越屏障阈值的那个进程创建的。如此一来，进程得以实时知晓屏障开启的瞬间。相反，在进程意欲退出屏障之际，它将监视某个特定的子 znode 的消失，只有当这个标记着屏障即将解除的子 znode 被移除后，进程才检查是否满足退出条件，进而安全有序地脱离屏障环境。 ","date":"2024-08-11","objectID":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/:3:4","tags":["分布式系统","ZAP","ZooKeeper"],"title":"【论文阅读笔记】ZooKeeper: Wait-free coordination for Internet-scale systems","uri":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/"},{"categories":["系统架构","论文阅读"],"content":"4 3 ZooKeeper应用 ZooKeeper作为一种强大的协调服务，在多种应用程序中发挥着关键作用。 Yahoo!的抓取服务（FS）利用ZooKeeper来管理配置元数据、进行领导者选举，并从主进程故障中恢复，确保服务的高可用性。此外，ZooKeeper的监视机制允许FS在不直接与服务器通信的情况下，通过读取ZooKeeper中的状态信息来向健康的服务器发送请求。 Katta作为一个非Yahoo!的分布式索引器，使用ZooKeeper进行协调，通过分片来分配索引工作。Katta使用ZooKeeper来跟踪主从服务器的状态（组成员关系），并处理主服务器的故障转移（领导者选举）。Katta还使用ZooKeeper来跟踪和管理分片分配给从服务器的分配（配置管理）。 Yahoo!消息代理（YMB）是一个分布式发布-订阅系统。该系统管理数千个主题，客户端可以发布消息并接收消息。为了提供可扩展性，主题分布在一组服务器中。每个主题都使用主-备方案进行复制，确保消息被复制到两台机器上，以确保可靠地消息传递。构成YMB的服务器使用无共享分布式架构，这使得协调对于正确操作至关重要。YMB使用ZooKeeper来管理主题的分配（配置元数据），处理系统中机器的故障（故障检测和组成员关系），以及控制系统操作。YMB的znode数据布局显示了如何通过ZooKeeper实现对活跃服务器的负载和状态信息的监控，以及如何通过集中控制实现对服务的管理和协调。 ","date":"2024-08-11","objectID":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/:4:0","tags":["分布式系统","ZAP","ZooKeeper"],"title":"【论文阅读笔记】ZooKeeper: Wait-free coordination for Internet-scale systems","uri":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/"},{"categories":["系统架构","论文阅读"],"content":"5 4 Zookeeper实现 ZooKeeper通过在构成其服务的每台服务器上进行数据复制来保障高可用性。这一设计考虑到了服务器可能发生的故障，同时假设故障服务器在后期能够恢复。为了维持服务的连续性和一致性，ZooKeeper采用了所下图所展示的一系列关键组件，确保了即使在单个服务器故障的情况下，整体服务仍能继续运行。 当ZooKeeper服务器接收到请求时，首先通过请求处理器进行预处理。如果请求涉及服务器间的协作（如写操作），则会启动一个基于原子广播协议的共识机制。这种机制确保所有服务器最终将请求导致的变更同步至完全复制的数据库中，从而维护数据的一致性。对于只读请求，则可以直接从服务器本地的数据库副本中获取数据并形成响应，无需触发复杂的共识过程，这大大提升了读取操作的效率。 数据库是内存中的，包含整个数据树，每个znode默认存储最大1MB的数据，但此值可配置。为了确保可恢复性，更新高效地记录到磁盘，且在应用于内存数据库前，强制写入磁盘。如同Chubby，我们维护一个重播日志，即写前日志，记录已提交的操作，并定期生成内存数据库的快照。 每个ZooKeeper服务器服务于客户端，客户端连接至某一台服务器提交请求。读请求从各服务器本地数据库的副本中服务，而写请求则通过共识协议处理。作为共识协议的一部分，写请求被转发至被称为领导者的单一服务器。其余服务器，即跟随者，接收来自领导者的状态变更提议，并对状态变更达成一致。 ","date":"2024-08-11","objectID":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/:5:0","tags":["分布式系统","ZAP","ZooKeeper"],"title":"【论文阅读笔记】ZooKeeper: Wait-free coordination for Internet-scale systems","uri":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/"},{"categories":["系统架构","论文阅读"],"content":"5.1 4.1 请求处理 由于消息层的原子性，Zookeeper保证本地副本不会分歧，尽管任一时刻某些服务器可能应用了更多事务。不同于客户端发出的请求，事务是幂等的。当领导者接收到写请求时，它计算出写操作应用后的系统状态，并转换为捕捉新状态的事务。必须计算未来状态，因为可能有尚未应用到数据库的待处理事务。例如，客户端执行条件setData操作，如果请求中的版本号与待更新znode的未来版本号匹配，服务生成包含新数据、新版本号和更新时间戳的setDataTXN。若出现错误，如版本号不匹配或待更新的znode不存在，将生成errorTXN。 ","date":"2024-08-11","objectID":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/:5:1","tags":["分布式系统","ZAP","ZooKeeper"],"title":"【论文阅读笔记】ZooKeeper: Wait-free coordination for Internet-scale systems","uri":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/"},{"categories":["系统架构","论文阅读"],"content":"5.2 4.2 原子广播 所有更新ZooKeeper状态的请求均转发至领导者。领导者执行请求并通过Zab，一种原子广播协议，广播状态变更。接收客户端请求的服务器在交付相应状态变更时响应客户端。Zab默认使用简单多数票机制决定提案，因此Zab和ZooKeeper仅在多数服务器正常（即在$2f+1$服务器中可容忍$f$次故障）时工作。 为了实现高吞吐量，ZooKeeper尽力保持请求处理管道满载，可能有成千上万的请求处于管道的不同部分。由于状态变更依赖于先前状态变更的应用，Zab提供了比常规原子广播更强的顺序保证： 由领导者广播的变更按照发送顺序交付 所有来自之前领导者的变更在新领导者广播自身变更前交付。 使用TCP作为传输层简化了实施，因为消息顺序由网络维护。Zab选出的领导者同时也是ZooKeeper的领导者，创建事务的同时也提议事务。使用日志作为内存数据库的写前日志，避免了两次写磁盘。Zab在常规操作中确实按顺序和恰好一次交付所有消息，但由于Zab未持久记录每个已交付消息的ID，因此在恢复过程中可能重传消息。由于使用了幂等事务，只要按顺序交付，多次交付是可以接受的。 ","date":"2024-08-11","objectID":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/:5:2","tags":["分布式系统","ZAP","ZooKeeper"],"title":"【论文阅读笔记】ZooKeeper: Wait-free coordination for Internet-scale systems","uri":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/"},{"categories":["系统架构","论文阅读"],"content":"5.3 4.3 复制数据库 每个副本在内存中保存一份ZooKeeper状态的拷贝。当服务器从崩溃中恢复，需要恢复此内部状态。重放所有已交付的消息以恢复状态可能耗时过长，故ZooKeeper使用周期性快照，仅要求重传自快照开始以来的消息。我们称ZooKeeper快照为模糊快照，因为不锁定ZooKeeper状态来生成快照；相反，进行深搜，原子读取每个znode的数据和元数据，写入磁盘。但是，由于快照的生成并非瞬时完成，这意味着在快照生成的过程中，新的状态变更可能会发生。因此，最终的快照可能包含了部分已提交但未被快照捕获的状态变更，导致快照中的数据并不完全反映某个时间点的系统状态。然而，由于状态变更是幂等的，我们可以按顺序重复应用它们。 例如，假设ZooKeeper数据树中两个节点/foo和/goo分别具有值f1和g1，且版本均为$1$，当模糊快照开始时，以下状态变更流\u003ctransactionType, path, value, new-version\u003e到达： \u003cSetDataTXN, /foo, f2, 2\u003e \u003cSetDataTXN, /goo, g2, 2\u003e \u003cSetDataTXN, /foo, f3, 3\u003e 处理这些状态变更后，/foo和/goo的值分别为f3和g2，版本为$3$和$2$。然而，模糊快照可能记录了/foo和/goo的值为f3和g1，版本为$3$和$1$，即第一个变更和第三个变更被快照捕获，但第二个变更之前快照生成完成，这不是ZooKeeper数据树的有效状态。 当服务器崩溃并重新启动时，它会从最近的快照恢复，然后重放自该快照之后的所有事务日志。由于事务是幂等的，即使快照中的状态与实际的某时刻状态不完全一致，重放事务日志也能确保服务器恢复到最后一致的状态。 ","date":"2024-08-11","objectID":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/:5:3","tags":["分布式系统","ZAP","ZooKeeper"],"title":"【论文阅读笔记】ZooKeeper: Wait-free coordination for Internet-scale systems","uri":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/"},{"categories":["系统架构","论文阅读"],"content":"5.4 4.4 客户端-服务器交互 ZooKeeper通过客户端-服务器交互实现高效的分布式协调。服务器在处理写请求时，会发送并清除相关监视通知，保证通知的顺序性。服务器顺序处理写请求，而读请求则在本地服务器上独立处理，每个读请求都会标记一个zxid，代表服务器已看到的最后事务，从而确保读写请求的部分顺序性。 本地处理读请求带来了出色的读取性能，因为它仅仅是本地服务器上的内存操作，无需磁盘活动或运行协议。然而，这种快速读取可能不保证读操作的顺序性，可能会返回过时的数据。为了解决这个问题，ZooKeeper提供了同步操作sync()，通过领导者异步执行并排序，客户端只需读取后立即调用sync()，确保读操作能够返回最新（sync之前所有的变更）的数据。 ZooKeeper服务器使用FIFO顺序处理客户端请求，并在响应中包含相关的zxid，确保客户端即使在服务器间切换时也能看到最新的数据（需要检查zxid）。此外，ZooKeeper使用超时机制来检测客户端会话故障，客户端通过发送心跳消息（包含最后一个zxid）来维持会话，如果无法与当前服务器通信，会自动切换到其他服务器。 ","date":"2024-08-11","objectID":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/:5:4","tags":["分布式系统","ZAP","ZooKeeper"],"title":"【论文阅读笔记】ZooKeeper: Wait-free coordination for Internet-scale systems","uri":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/"},{"categories":["系统架构","论文阅读"],"content":"6 5 评估 ZooKeeper展现出了卓越的性能，其高吞吐量和低请求延迟在多个基准测试中得到了证明。在模仿Chubby基准的测试中，即使处理的数据量增加，ZooKeeper的吞吐量也达到了Chubby的三倍以上。具体来说，单个工作进程在三个服务器上的平均请求延迟仅为1.2毫秒，在九个服务器上为1.4毫秒。 在屏障性能测试中，ZooKeeper处理屏障操作的能力随着屏障数量和客户端数量的增加而线性增长，显示出对并发访问的高效管理，并没有出现意外的延迟。即使在高比例的读操作下（80%），ZooKeeper的屏障操作吞吐量也保持在每秒1,950到3,100次之间，远高于实际应用中所需的性能。 ","date":"2024-08-11","objectID":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/:6:0","tags":["分布式系统","ZAP","ZooKeeper"],"title":"【论文阅读笔记】ZooKeeper: Wait-free coordination for Internet-scale systems","uri":"/posts/08.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0zookeeper-wait-free-coordination-for-internet-scale-systems/"},{"categories":["工具"],"content":"1 tunnelmole source Tunnelmole 是一个简单的工具，可以为本地运行的 HTTP(s) 服务器提供公共 URL。例如，您可以获得一个公共 URL： 网络服务器 Docker容器 API 静态网站 etc.. 安装方法如下： curl -O https://install.tunnelmole.com/n3d5g/install \u0026\u0026 sudo bash install 使用方法： tmole \u003cyour_server_port\u003e 例如： ","date":"2024-08-02","objectID":"/posts/03.%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/:1:0","tags":["network"],"title":"好用的工具","uri":"/posts/03.%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/"},{"categories":["系统架构"],"content":"1 脑裂 许多容错系统使用一个单主节点来决定主副本。 MapReduce：由单主节点控制计算复制。 GFS：主备复制数据，并由单主节点确定主拷贝的位置。 VMware FT：主虚机和备份虚机之间复制指令，需要单点的Test-and-Set服务确认主虚机。 这三个例子都是一个多副本系统，系统容错的关键点转移到这个主节点上。 使用单主节点，我们则需要避免脑裂（Split-Brain）问题。脑裂指的是在多副本系统中，因网络分裂导致多个副本都认为自己是主副本，从而出现数据不一致或功能冲突的问题。 这里有两种解决方案 构建高可靠网络：如果网络完全不出现故障，客户端无法访问的服务器即被认为是关机，这样可以排除脑裂的可能。但需要大量资金和控制物理环境。 人工解决问题：客户端默认等待两个服务器的响应。如果只收到一个响应，需人工检查两个服务器的状态。人工检查虽然能解决问题，但可能不够及时。 ","date":"2024-07-25","objectID":"/posts/07.raft/:1:0","tags":["分布式系统","Raft"],"title":"【MIT 6.5840(6.824)学习笔记】Raft","uri":"/posts/07.raft/"},{"categories":["系统架构"],"content":"2 过半票决 在构建能自动恢复，同时又避免脑裂的多副本系统时，关键点在于过半票决（Majority Vote），这是Raft论文中提出的一个基本概念，即在一个多副本系统中，任何操作必须得到超过一半的服务器同意才能完成。为了有效使用过半票决，服务器数量应该是奇数。这样在出现网络分区时，一个分区无法拥有超过半数的服务器，从而避免脑裂。对于过半票决，可以用下面这个通用方程来描述： 如果系统有$2\\times F+1$个服务器，那么系统最多可以接受$F$个服务器出现故障。 Raft协议依赖过半票决来进行Leader选举和日志提交。每个操作需要过半的服务器批准。任何两个操作的过半服务器至少有一个重叠。 Leader选举：新选出的Leader必然获得过半服务器的选票，而这些服务器与旧Leader的服务器有重叠，因此知道旧Leader的任期号。 日志一致性：新Leader的过半服务器包含了旧Leader的操作，确保日志一致性。 ","date":"2024-07-25","objectID":"/posts/07.raft/:2:0","tags":["分布式系统","Raft"],"title":"【MIT 6.5840(6.824)学习笔记】Raft","uri":"/posts/07.raft/"},{"categories":["系统架构"],"content":"3 Raft概述 Raft协议作为库（Library）存在于服务中，每个Raft副本包含应用程序代码和Raft库。应用程序代码处理RPC或其他客户端请求，Raft库负责同步多副本之间的操作。 操作流程如下： 客户端请求：客户端发送请求（如Put或Get）到Raft集群的Leader节点。 请求处理： Raft层：Leader节点将请求操作传递给Raft层，要求将操作写入日志。Raft节点之间的交互确保操作被过半节点复制。当Leader节点确认过半副本都有操作的拷贝后，通知应用程序层执行操作。 应用程序层：仅在收到Raft层的确认后才执行操作（更新数据库或读取值）。 操作提交： Raft层：通知应用程序层，操作已在过半副本中复制完成，可以执行。 应用程序层：执行操作并最终返回结果给客户端。 为何不需要拷贝到所有节点？ 为了容错，系统只需过半的副本即可完成操作，这样即使部分服务器故障，系统仍能继续工作。 除了Leader节点，其他节点的应用程序层会有什么样的动作？ 在操作在Leader节点提交后，其他副本的Raft层将操作传递给本地应用程序层，确保所有副本的操作序列一致，状态最终保持一致。 ","date":"2024-07-25","objectID":"/posts/07.raft/:3:0","tags":["分布式系统","Raft"],"title":"【MIT 6.5840(6.824)学习笔记】Raft","uri":"/posts/07.raft/"},{"categories":["系统架构"],"content":"4 日志 如下图所示，展示了Raft协议在处理客户端请求时的消息交互流程，AE代表AppendEntries RPC。 客户端请求：客户端发送一个Put请求到当前Raft集群的Leader节点（S1）。 Leader节点处理：S1的Raft层发送AppendEntries RPC到其他两个副本节点（S2、S3）。S1等待至少一个Follower节点（S2或S3）的响应以达到过半节点的响应。 Follower节点响应：S2、S3接收AppendEntries RPC并返回响应给Leader（S1）。S1只需等待一个Follower节点的正确响应即可。 操作提交：一旦S1收到过半节点的正确响应（包括自己），S1执行客户端请求并返回结果给客户端。 通知其他副本：S2、S3在收到AppendEntries后不确定请求是否被Leader提交。Leader需要在下一次AppendEntries或心跳消息中通知其他副本请求已被commit。其他副本收到此消息后，更新本地状态，执行已提交的请求。 Raft系统对Log的关注有几个关键原因： 操作排序：所有副本不仅要执行相同的操作，还要以相同的顺序执行这些操作。Log由编号的槽位（类似一个数组）组成，槽位的数字表示了Leader选择的顺序。 临时存储：Follower收到操作但还未执行时，需要将操作存放在某处，直到收到Leader发送的commit号。Log就是这个临时存储的地方。Follower在操作commit前不确定这些操作是否会被执行，有时这些操作可能会被丢弃。 重传机制：Leader记录操作在其Log中，因为这些操作可能需要重传给Follower。如果Follower短时间离线或丢失了一些消息，Leader需要能够向Follower重传丢失的Log消息。即使是已commit的请求，为了向丢失相应操作的副本重传，Leader也需要在Log中存储这些操作。 状态恢复：Log帮助重启的服务器恢复状态。故障重启后的服务器使用存储在磁盘中的Log，从头执行其中的操作，重建故障前的状态并继续运行。每个Raft节点都需要将Log写入磁盘，确保故障重启后Log能保留，帮助服务器恢复状态。 ","date":"2024-07-25","objectID":"/posts/07.raft/:4:0","tags":["分布式系统","Raft"],"title":"【MIT 6.5840(6.824)学习笔记】Raft","uri":"/posts/07.raft/"},{"categories":["系统架构"],"content":"5 应用层接口 在Raft集群中，每一个副本上，应用层（如key-value数据库）和Raft层之间主要有两个接口。这两个接口分别用于转发客户端请求给Raft层，以及Raft层通知应用层请求已被commit。 第一个接口是key-value层用来转发客户端请求的接口—Start函数。当客户端发送请求给key-value层时，key-value层会将请求转发给Raft层，并告诉Raft层将请求存放在Log中。Start函数只接收一个参数，即客户端请求。Start函数的返回值包括： 请求在Log中的位置（index） 当前的任期号（term number） 其他信息 第二个接口是applyCh channel，以Go channel中的一条消息形式存在。Raft层会通过发送ApplyMsg消息给applyCh来通知key-value层哪些请求已经commit，key-value层读取这些消息。ApplyMsg包含： 请求（command） 对应的Log位置（index） 所有的副本都会收到ApplyMsg消息，知道应该执行请求并应用在本地状态中。Leader需要知道ApplyMsg中的请求对应哪个客户端请求，以便响应客户端请求。 ","date":"2024-07-25","objectID":"/posts/07.raft/:5:0","tags":["分布式系统","Raft"],"title":"【MIT 6.5840(6.824)学习笔记】Raft","uri":"/posts/07.raft/"},{"categories":["系统架构"],"content":"6 Leader 选举 引入Leader的原因： 有Leader系统效率更高，因为请求只需一轮消息即可获得过半认可。 无Leader系统需要一轮消息确认临时Leader，再一轮确认请求，效率较低。 Raft使用任期号（term number）区分不同的Leader。每个任期最多有一个Leader。Followers只需知道当前的任期号。 Leader选举过程如下： 如果Follower在选举定时器时间内未收到Leader消息，会认为Leader下线，开始选举。 当前节点增加任期号，发起选举。 节点发送RequestVote RPC给其他节点，自己投票给自己。 节点需要获得过半服务器的认可投票才能成为Leader。 任期内每个节点只投一次票，就不可能有两个候选人同时获得过半的选票，确保每个任期最多一个Leader。成功当选后，Leader立即发送AppendEntries消息（心跳）通知其他节点自己当选。 如果Leader在网络分区中少数服务器内，无法获得过半认可，不能commit请求。旧Leader在小分区内运行，但不能执行客户端请求，只能发送心跳。 有没有可能出现极端的情况，导致单向的网络出现故障，进而使得Raft系统不能工作？ 如果当前Leader的网络单边出现故障，Leader可以发出心跳，但是又不能收到任何客户端请求。它发出的心跳被送达了，因为它的出方向网络是正常的，那么它的心跳会抑制其他服务器开始一次新的选举。但是它的入方向网络是故障的，这会阻止它接收或者执行任何客户端请求。这个场景是Raft并没有考虑的众多极端的网络故障场景之一。 可以通过一个双向的心跳机制来解决。即Leader发送心跳，Follower要响应这个心跳，如果Leader没有收到响应，则会决定卸任。 所有Raft节点收到任何一条AppendEntries消息都会重置其选举定时器。只要Leader以合理的速率发送心跳或其他AppendEntries消息，Followers就会重置选举定时器，阻止其他节点成为候选人。在没有网络故障或丢包的情况下，连续的心跳消息会防止新的选举发生。 如果出现服务器故障或网络问题或者分割选票（多个候选人几乎同时竞选，选票分散），可能导致无法凑齐过半服务器，无法选出Leader，这次选举就失败了。 Raft不能完全避免分割选票问题，但可以大大降低发生概率。通过随机选择选举定时器的超时时间，减少同步超时的概率。 超时时间设置： 下限：至少大于Leader的心跳间隔，多次心跳间隔更好（例如3次心跳间隔）。 上限：远小于服务器两次故障之间的平均时间。 时间差：足够大以确保第一个超时节点能够完成一轮选举，至少需要大于发送一条RPC的往返时间。 lab tip 每一次一个节点重置自己的选举定时器时，都需要重新选择一个随机的超时时间。避免服务器会以极小的概率选择相同的随机超时时间，那么会永远处于分割选票的场景中 ","date":"2024-07-25","objectID":"/posts/07.raft/:6:0","tags":["分布式系统","Raft"],"title":"【MIT 6.5840(6.824)学习笔记】Raft","uri":"/posts/07.raft/"},{"categories":["系统架构"],"content":"7 日志恢复 Leader正常运行时，Follower必须同意并接收Leader的日志。但Leader故障后，新Leader需要整理各副本可能不一致的日志。 新Leader会发送包含prevLogIndex和prevLogTerm的AppendEntries RPC。 Follower检查本地日志是否匹配： 不匹配：拒绝AppendEntries，Leader减少nextIndex并重试。 匹配：接受AppendEntries，更新本地日志。 为什么Raft系统可以安全的删除不一致的日志？ 如果日志条目未存在于过半服务器中，旧Leader不可能commit该条目，也就不可能将它应用到应用程序的状态中，安全删除无影响。并且如果客户端未收到回复，将重发请求，确保请求最终被处理。 为什么总是删除Followers的Log的结尾部分？ Leader具有完整的Log记录，可以在任何需要的时候填充Followers的日志。如果系统刚启动，或发生反常情况，Leader能够从第一条记录开始恢复Followers的日志，因为它有所有必要的信息。 ","date":"2024-07-25","objectID":"/posts/07.raft/:7:0","tags":["分布式系统","Raft"],"title":"【MIT 6.5840(6.824)学习笔记】Raft","uri":"/posts/07.raft/"},{"categories":["系统架构"],"content":"8 选举约束 为了保证系统的正确性，并非任意节点都可以成为Leader。不是说第一个选举定时器超时了并触发选举的节点，就一定是Leader。Raft对于谁可以成为Leader，存在一些限制。限制条件如下： 候选人最后一条Log条目的任期号大于本地最后一条Log条目的任期号； 或者，候选人最后一条Log条目的任期号等于本地最后一条Log条目的任期号，且候选人的Log记录长度大于等于本地Log记录长度。 所以Raft更倾向于选择拥有更高任期号记录的候选人，确保系统一致性。 ","date":"2024-07-25","objectID":"/posts/07.raft/:8:0","tags":["分布式系统","Raft"],"title":"【MIT 6.5840(6.824)学习笔记】Raft","uri":"/posts/07.raft/"},{"categories":["系统架构"],"content":"9 快速恢复 基于上述介绍，Leader现行机制是每次回退一条Log条目来解决日志冲突。如果Follower长时间关机，错过大量AppendEntries消息。Leader重启后需逐条RPC回退Log条目，耗时较长。 Raft论文中提供了一个快速恢复方法。Follower返回足够信息给Leader，使Leader能按任期（Term）为单位回退，而非逐条回退。Follower拒绝AppendEntries消息时，返回以下3个信息： XTerm：Follower中与Leader冲突的Log条目的任期号。 XIndex：Follower中，任期号为XTerm的第一条Log条目的槽位号。 XLen：Follower中空白Log槽位数。 可以使用二分查找等更高效的方法进一步加速。 ","date":"2024-07-25","objectID":"/posts/07.raft/:9:0","tags":["分布式系统","Raft"],"title":"【MIT 6.5840(6.824)学习笔记】Raft","uri":"/posts/07.raft/"},{"categories":["系统架构"],"content":"10 持久化 在Raft协议中，持久化存储（persistence）和非持久化存储（volatile）的区别在于服务器重启时的状态保持。持久化存储确保服务器重启后能够恢复到之前的状态，从而保证服务的连续性和数据的一致性。持久化存储通常使用磁盘或电池供电的RAM来保存数据。 根据Raft论文图2，以下三个数据需要持久化存储： Log：保存所有的日志条目，是唯一记录应用程序状态的地方。 currentTerm：当前的任期号，用于确保每个任期只有一个Leader。 votedFor：记录当前任期投票给了哪个服务器，用于确保每个任期内只有一个Leader被选举出来。 每当Log、currentTerm或votedFor发生变化时，服务器必须将这些数据写入磁盘以确保其持久化。这可以通过调用系统的write和fsync函数来实现，其中fsync确保数据在磁盘上安全存储。 为了提高性能，可以采用批量操作的方法。例如，当Leader接收到多个客户端请求时，可以累积这些请求，然后一次性持久化存储多个Log条目，减少持久化存储的次数。 ","date":"2024-07-25","objectID":"/posts/07.raft/:10:0","tags":["分布式系统","Raft"],"title":"【MIT 6.5840(6.824)学习笔记】Raft","uri":"/posts/07.raft/"},{"categories":["系统架构"],"content":"11 日志快照 在Raft一致性算法中，日志条目（Log entries）会随着系统运行时间的延长而不断增加。这会带来两个问题： 存储空间：日志条目数量过多，会占用大量的内存和磁盘空间。 系统重启：如果服务器重启，需要重放所有日志条目来恢复状态，耗时较长。 为了应对上述问题，Raft引入了快照机制。快照是对应用程序状态的压缩表示。通过创建快照，可以丢弃部分已应用的日志条目，减少存储空间，并加快重启时的恢复过程。 Raft会将应用程序创建的快照存储在磁盘上，确保数据的持久性。服务器重启时，Raft会从磁盘读取最近的快照，并将其传递给应用程序，恢复到快照对应的状态。然后，从快照之后的日志条目开始继续恢复。 如果某个Follower的日志比Leader的短，且短于Leader快照的起始位置，那么Leader无法通过发送日志条目来同步Follower的日志。Raft引入了InstallSnapshot RPC。当Follower的日志长度不够时，Leader会发送快照给Follower，然后继续通过AppendEntries RPC发送后续的日志条目。 快照的生成和恢复需要应用程序与Raft组件之间的紧密协同。应用程序负责生成和吸纳快照，Raft负责管理快照和日志条目的持久化存储。Leader可能并发发送多个RPC消息，包括AppendEntries和InstallSnapshot，需要处理可能的乱序和冗余消息。 快照生成是否依赖应用程序 是的，快照生成函数是应用程序的一部分，应用程序负责生成和恢复快照。只有应用程序自己才知道自己的状态（进而能生成快照）。而通过快照反向生成应用程序状态的函数，同样也是依赖应用程序的。 ","date":"2024-07-25","objectID":"/posts/07.raft/:11:0","tags":["分布式系统","Raft"],"title":"【MIT 6.5840(6.824)学习笔记】Raft","uri":"/posts/07.raft/"},{"categories":["系统架构"],"content":"12 课程QA Raft 通常用于什么？是否用于实际软件中？ Raft（以及 Paxos）主要用于构建容错的“配置服务”，跟踪在大型部署中的服务器职责分配。这种服务对复制部署尤为重要，可以避免脑裂问题。Raft 还被一些数据库（如 Spanner、CockroachDB）用于数据复制。 有多个实际应用使用 Raft，如 Docker、etcd 和 MongoDB。许多基于 Paxos 的系统（如 Chubby、ZooKeeper）也在实际生产环境中使用。 Raft 如何与 VMware FT 比较？ Raft 更具容错性，没有单点故障，而 VMware FT 存在一个测试和设置服务器作为单点故障。Raft 用作库集成在应用软件中，而 VMware FT 可用于任何虚拟机。 Raft 如何防止恶意攻击？ Raft 默认没有防御恶意攻击的机制。实际部署中需要通过防火墙保护，或使用加密验证 Raft 数据包。 Raft 的“非拜占庭”条件是什么？ Raft 假设服务器要么按协议运行，要么停止运行。拜占庭故障指计算机执行错误操作，这可能导致 Raft 发送不正确的结果。 Raft 可以在地理分布的数据中心中使用吗？ 通常，Raft 部署在单一数据中心。跨数据中心的系统（如 Spanner）更适合无领导协议，以便客户可以与本地副本通信。 Raft 的日志为何是从 1 开始编号的？ 日志从零编号，但第一个条目（索引为 0）具有Term 0，使得初始 AppendEntries RPC 可以包含有效的 PrevLogIndex。 Raft 的副本优化是什么？ 副本优化通过在服务快照时使用 fork()，实现了“写时复制”。操作系统会延迟实际的内存复制，优化了性能。 为什么新领导在其任期开始时需要提交一个无操作（no-op）日志条目？ 新领导提交无操作日志条目可以确保其日志中所有之前的条目都是已提交的。这是为了防止新领导在自己失败时，前一个领导的日志条目未被提交，从而保持系统一致性。 使用心跳机制提供租约（leases）进行只读操作是如何工作的？为什么需要时间同步？ 领导者通过在心跳消息中暗示下一段时间内不能选举新领导，从而提供只读操作的租约。为了保证安全，服务器的时钟需要保持同步，确保租约时间的准确性。 在 Raft 的配置变更过程中，如何理解旧配置（$C_\\text{old}$）到新配置（$C_\\text{new}$）的过渡？ 在联合共识阶段（$C_\\text{old,new}$），领导者需要获得旧配置和新配置的多数支持。配置变更日志条目需要同时被旧配置和新配置的多数服务器确认。 快照（snapshot）的创建和恢复过程中的数据是否需要压缩？ 快照通常会对数据进行压缩，以减少传输和存储成本。压缩方案应根据具体应用的数据类型来选择，如使用 JPEG 压缩图像数据，或使用通用压缩算法如 ZIP。 领导者如何决定什么时候向跟随者发送快照？ 领导者会在跟随者的 matchIndex 小于其日志开始索引时发送快照，以确保跟随者能够赶上最新的日志状态。 在 Raft 中，添加日志条目是否算作执行操作？ 不算。仅当领导者将日志条目标记为已提交后，服务器才会执行日志条目中的操作。执行操作指的是将日志条目交给实际服务进行处理。 ","date":"2024-07-25","objectID":"/posts/07.raft/:12:0","tags":["分布式系统","Raft"],"title":"【MIT 6.5840(6.824)学习笔记】Raft","uri":"/posts/07.raft/"},{"categories":["深度学习","论文阅读","CAD"],"content":"1 摘要 SkexGen是一种新颖的自回归生成模型，用于创建CAD构造序列，其中包含草图和拉伸建模操作。这个模型利用不同的Transformer架构将构造序列中的拓扑、几何和拉伸变化编码到解耦的码本中。自回归Transformer解码器根据码本向量生成具有特定属性的CAD构造序列。广泛的实验表明，我们的解耦码本表示可以生成多样且高质量的CAD模型，增强了用户的控制能力，并能够有效探索设计空间。 【code】 ","date":"2024-07-19","objectID":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/:1:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】 SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks","uri":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/"},{"categories":["深度学习","论文阅读","CAD"],"content":"2 引言 SkexGen是一种新颖的自回归生成模型，使用离散码本进行CAD模型生成。作者采用草图和拉伸建模语言来描述CAD构造序列，其中草图操作创建二维原语，拉伸操作将它们提升并组合成三维。Transformer编码器学习到解耦的潜在表示，作为三个码本，分别捕捉构造序列的拓扑、几何和拉伸变化。给定码本向量，自回归Transformer解码器生成草图和拉伸构造序列，进而处理成CAD模型。 作者在一个大规模草图和拉伸数据集（DeepCAD数据集，需要将其转换为SkexGen格式）上评估了SkexGen。与多个baseline和最先进方法进行的定性和定量评估表明，SkexGen生成了更真实和多样的CAD模型，同时实现了有效的控制和高效的设计空间探索，这是以往方法无法实现的。作者做出了以下贡献： SkexGen架构，自回归生成高质量和多样化的CAD构造序列。 解耦的码本，编码构造序列的拓扑、几何和拉伸变化，实现了设计的有效控制和探索。 在公共基准上的广泛定性和定量评估，展示了最先进的性能。 ","date":"2024-07-19","objectID":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/:2:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】 SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks","uri":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/"},{"categories":["深度学习","论文阅读","CAD"],"content":"3 相关工作 构造性实体几何（CSG） 3D形状由参数化基元通过布尔运算组成的CSG树表达。这种轻量级表示已广泛用于与程序合成、神经引导程序合成、无监督学习和专用参数化基元结合的重建任务中。但参数化CAD仍主导机械设计，并且广泛使用草图和拉伸建模操作。 构造序列生成 PolyGen开创：使用Transformer和指针网络预测n-gon网格顶点和面。 数据集推动：大规模CAD建模操作数据集促进直接学习用户建模操作。 拉伸操作预测：预测拉伸操作序列以部分恢复构造序列，但没有底层草图信息。预测线、弧、圆等草图基元的序列是形成CAD二维基础的关键构造块，可通过添加拉伸操作轻松扩展到3D。 Transformer架构的应用：应用于草图和拉伸序列生成，但在用户控制方面存在局限。 现有的方法通常将网络条件设置为用户提供的图像、点云或手绘草图，只是将现有设计转换为CAD构造序列表示，而没有提供对拓扑和几何的单独控制来探索相关设计的空间。作者的方法则提供对拓扑和几何的单独控制。 码本架构 自引入以来，码本已在许多图像和音频生成任务中证明有效，提高了生成图像的多样性并提供了额外的用户控制。由于其高结构规律性，它们特别适合于编码CAD建模序列。 ","date":"2024-07-19","objectID":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/:3:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】 SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks","uri":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/"},{"categories":["深度学习","论文阅读","CAD"],"content":"4 草图和拉伸构造序列 作者定义了一个草图和拉伸构造序列表示法，作为基元的层次结构，这一构造基于TurtleGen和DeepCAD的基础，并进行了若干修改，使表示法更具表现力和学习适应性，如下图所示，该示例模型由两个草图组成，这些草图由面、环和曲线构成。序列以拓扑token（$T_1$）开始，表示曲线的起点（类型为弧线），接着两个几何token（$G_1,G_2$），每个token存储一个二维点坐标，。 基元层次结构： 曲线：最低级别的基元，包括直线、弧线或圆。 环：一个闭合路径，由一个（例如圆）或多个曲线（例如直线-弧线-直线）组成。 面：一个由环限定的二维区域，这是我们的表示法中新增加的。具体来说，一个面由一个外环和若干内环（洞）构成，这在许多CAD系统中是一个惯例。 草图：由一个或多个面组成。 拉伸草图：通过拉伸草图形成的三维体积。 草图和拉伸模型：通过布尔操作（例如交集、并集和差集）由多个拉伸草图组成。注意，DeepCAD的表示法没有面基元，无法表示具有多个面的草图（例如Figure 1中的ES1）。 ","date":"2024-07-19","objectID":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/:4:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】 SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks","uri":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/"},{"categories":["深度学习","论文阅读","CAD"],"content":"5 SkexGen架构 SkexGen 是一种自回归生成模型，通过两个网络分支中的三个解耦码本学习草图和拉伸模型的变体。图2展示了SkexGen的架构。“草图”分支学习二维草图的拓扑和几何变体，“拉伸”分支学习三维拉伸的变体（如方向）。两个分支架构类似，本节重点介绍草图分支，包含两个编码器和一个解码器。 ","date":"2024-07-19","objectID":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/:5:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】 SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks","uri":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/"},{"categories":["深度学习","论文阅读","CAD"],"content":"5.1 拓扑编码器 拓扑编码器接收输入的子序列，token为： 拓扑token（T）：表示三种曲线类型之一（直线/弧线/圆）。 结束基元token（E）：表示三种基元类型之一（环/面/草图）的结束。 结束序列token（End）：表示序列的结束。 因此，token初始化为一个7维（= 3+3+1）的独热向量 嵌入 独热向量转换为256维嵌入。作者考虑拓扑token $T$，其中$h_{T} ^{tp}$是7维独热向量，$i_T$表示其在输入子序列中的索引，其嵌入向量计算公式为： $$ T \\leftarrow \\mathbf{W}^\\text{tp} h_{T} ^{tp} + \\mathbf{p}^{(i_T)} $$ 其中$\\mathbf{W}^\\text{tp}\\in \\mathbb{R}^{d_E\\times 7}$表示可学习矩阵，$\\mathbf{p}^{(i_T)}$表示拓扑子序列索引$i_T$处的可学习位置编码。 架构 编码器基于Transformer（四层，每层包含八头自注意层、层规范化和前馈层）。根据Vision Transformer，输入的拓扑信息编码为一个“码token”，预先加入到输入中，并初始化为一个可学习的嵌入$Z_{tp}$。令$Z_{tp}^e$为编码器输出的码token嵌入。嵌入$Z_{tp}^e$被量化为大小为$N({\\mathbf{b}_{tp}\\text{ | }i=1,2\\cdots N})$的码本最近码。 编码和量化后的最终码token $Z_{tp}^Q$被传递给解码器。 $$ Z^Q_{tp} \\leftarrow \\mathbf{b}^{(k)}_{tp}, \\text{where } k = \\text{argmin}_{j} | Z^e_{_{tp}} - b^{(j)}_{tp} |^2 $$ f这里为了简单起见，只假设了一个码token，拓扑编码器实际上由四个码token，并产生四个输出码token（$Z^{Q_{(1)}}_{tp},Z^{Q_{(2)}}_{tp},Z^{Q_{(3)}}_{tp},Z^{Q_{(4)}}_{tp}$）。作者尝试了不同的码本大小，发现 $N = 500$ 可以取得良好效果。 ","date":"2024-07-19","objectID":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/:5:1","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】 SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks","uri":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/"},{"categories":["深度学习","论文阅读","CAD"],"content":"5.2 几何编码器 输入token 几何token（G）：包含一个二维点坐标 结束基元token（E）：表示四种基元类型之一（曲线/面/环/草图）的结束 结束序列token（End） 几何token G 指定沿曲线的一个二维点坐标。由于坐标是数值型的，作者将草图离散化为$64\\times 64$（6位）像素，并考虑$64^2$个可能的像素位置。因此，一个$4101(=64^2+4+1)$维的独热向量唯一确定了token信息。 嵌入 我们按照4.1中的嵌入公式并使用$\\mathbf{W^{ge}}\\in\\mathbb{R}^{d_E\\times 4101}$和位置编码来初始化输入token嵌入。token E和End类似于拓扑Token的初始化，通过将它们的独热向量$h^{ge}_G\\in \\mathbb{R}^{4101}$乘以$\\mathbf{W^{ge}}$并加上位置编码。几何Token G的初始化不同： $$ G \\leftarrow \\mathbf{W^{ge}} h^{ge}_G + \\mathbf{W}^xh^x_G + \\mathbf{W}^y h^y_G + \\mathbf{p}^{(i_G)}. $$ 几何token $G$具有附加的坐标嵌入，$h^x_G,h^y_G\\in \\mathbb{R}^{64}$是指示像素的$x,y$坐标的独热向量。坐标嵌入是可选的，但可以进一步提高实验结果。 架构 类似于拓扑编码器，基于Transformer。 生成嵌入 $Z^{{e_{(i)}}}_{ge}$ 和量化后的码token $Z^{Q_{(i)}}_{ge}$ 。 使用两个码token，码本大小 $N = 1000$。 ","date":"2024-07-19","objectID":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/:5:2","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】 SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks","uri":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/"},{"categories":["深度学习","论文阅读","CAD"],"content":"5.3 草图解码器 草图解码器以拓扑和几何码本为输入，生成几何token $G$和结束基元token $E$（用于曲线/环/面/草图），以恢复草图子序列。 注意，不生成拓扑标记T，因为它们可以根据每条曲线内的几何标记数量推断出来（即，直线/弧线/圆分别有1/2/4个G标记）。这意味着几何编码器和草图解码器有相似的子序列（Figure 2）。 输入 给定前$k-1$个token，自回归解码器预测第$k$个token的条件概率。训练输入序列向右移一位，前面添加“start”符号（由位置编码初始化）。由于解码器中可能的token类型与几何编码器相同，我们使用相同的$4101$维独热编码方案，并使用带有位置编码的可学习矩阵（大小为 $d_E \\times 4101$）初始化嵌入向量。 输出 解码器生成“向左移一位”的子序列，即预测输入中的原始$k$个标记（见Figure 2）。令$K$为草图解码器输出中的一个标记，其具有 $d_E$ 维嵌入。我们使用可学习矩阵 $\\mathbf{W^{out}} \\in \\mathbb{R}^{4101 \\times d_E}$ 来预测4101个类别的概率：$h^\\text{out}_K \\leftarrow \\text{softmax} (\\mathbf{W^\\text{out}} K)$ 交叉注意力 Transformer架构通过交叉注意力从拓扑和几何码本中分别取四个和两个量化码本向量。为了区分两个不同的码本，我们借鉴位置编码的思想，分别向拓扑码 ${ Z^{Q_{(i)}}_{tp} }$ 和几何码 ${ Z^{Q_{(i)}}_{ge} }$ 添加可学习嵌入向量 $\\mathbf{p}^{(q_{tp})} \\in \\mathbb{R}^{4 \\times d_E}$和 $\\mathbf{p}^{(q_{ge})} \\in \\mathbb{R}^{2 \\times d_E}$ ： $$ Z^{{Q_{(i)}}}_{tp} + p^{(q_{tp})} \\quad \\text{or} \\quad Z^{Q_{(i)}}_{ge}+ p^{(q_{ge})}. $$ 基础网络设置与编码器相同（即四层，每层八头），但它是带掩码的自回归（仅关注先前的标记）。 ","date":"2024-07-19","objectID":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/:5:3","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】 SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks","uri":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/"},{"categories":["深度学习","论文阅读","CAD"],"content":"5.4 训练 拓扑编码器、几何编码器和草图解码器通过三种损失函数联合训练： $$ \\sum_K \\text{CrossEntropy}(h^\\text{out}_K, h^\\text{gt}_K) + \\ | \\text{sg} (Z^{e}_{tp}) - \\mathbf{b}_{tp} |_2^2 + \\beta | Z^{e}_{tp} - \\text{sg} (\\mathbf{b}_{tp}) |_2^2 + \\ | \\text{sg} (Z^{e}_{ge}) - \\mathbf{b}_{ge} |_2^2 + \\beta | Z^{e}_{ge} - \\text{sg} (b_{ge}) |_2^2. $$ 第一行计算序列重建损失，其中 $h^\\text{out}_K$ 是草图解码器预测的概率， $h^\\text{gt}_K$ 是真实的独热向量，利用交叉熵损失衡量准确度。 第二行和第三行是VQ-VAE使用的标准码本和承诺损失。 $\\text{sg}$ 表示停止梯度操作，在前向传播中是恒等函数，但在后向传播中阻止梯度。 $\\beta$ 缩放承诺损失，设为$0.25$，用于调整承诺损失的权重，这确保编码器输出绑定一个码向量。 为了简化，我们省略了每个编码器中多个码本标记的明确写出。给定一个真实子序列，我们运行两个编码器并自回归地运行解码器，直到生成相同数量的标记。训练采用教师强制的方式，即将真实token而非预测token输入解码器，保证每次迭代解码器仅专注于单步训练，从而简化训练流程并提升效率 ","date":"2024-07-19","objectID":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/:5:4","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】 SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks","uri":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/"},{"categories":["深度学习","论文阅读","CAD"],"content":"5.5 生成 SkexGen 生成 CAD 模型分两步： 从三个码本生成码。 采用训练完成的编码器（拓扑、几何、拉伸）从样本中提取码。 Transformer解码器被训练来生成这些非正态分布的量化码，即从码本中挑选码索引。 允许架构微小修改以支持条件码生成，如“拓扑条件码选择器”，它基于给定拓扑码来挑选相应的几何和拉伸码。 给定码生成草图和拉伸构造序列。 给定码，草图和拉伸解码器便通过核采样，自回归方式生成构造子序列。 这些子序列整合成完整的草图和拉伸序列，最终由CAD软件解析为边界表示。 ","date":"2024-07-19","objectID":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/:5:5","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】 SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks","uri":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/"},{"categories":["深度学习","论文阅读","CAD"],"content":"6 实验 实验验证目标： SkexGen生成高质量和多样化结果的能力 码本对生成过程控制的程度 SkexGen在设计探索和插值应用中的表现 ","date":"2024-07-19","objectID":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/:6:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】 SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks","uri":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/"},{"categories":["深度学习","论文阅读","CAD"],"content":"6.1 实验设置 数据集：使用DeepCAD数据集，包含178,238个序列，经去重和无效操作剔除，最终训练集含74,584个草图子序列与86,417个拉伸子序列。针对单一草图实验，经过从构造序列的步骤中提取草图并去重后，最终收集到114,985个训练样本。 实现细节：SkexGen基于PyTorch开发，在RTX A5000上训练。采用与DeepCAD一致的设置，四层Transformer结构，每层含八个注意力头，层规范化，前馈维度512，输入嵌入256维，Dropout率0.1。使用Adam优化器，学习率0.001。线性预热和梯度裁剪与 DeepCAD 一致。我们在前25个epoch中跳过代码量化，发现这有助于稳定码本训练。对于数据增强，我们向几何标记的坐标添加小的随机噪声。训练300个epoch，批量大小128。草图与拉伸子序列最大长度分别为200与100。在测试时，我们使用核采样方法以自回归方式采样码选择器和解码器。 指标： Fréchet Inception Distance (FID)：比较真实和生成数据分布的均值和协方差来衡量生成的保真度。 覆盖率（COV）：基于表面上2,000个均匀采样点的最小 Chamfer 距离来衡量真实数据与生成数据的匹配百分比。 最小匹配距离 (MMD)：生成样本与其在真实数据集中最近邻的平均最小匹配距离。 Jensen-Shannon散度 (JSD)：基于边缘点分布衡量真实和生成分布的相似性。 Novel Score：生成数据中未出现在训练集中的百分比。 Unique Score：生成样本中仅出现一次的数据百分比，如果序列中的所有token在6位量化后相同，我们认为两个数据样本是相同的。 ","date":"2024-07-19","objectID":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/:6:1","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】 SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks","uri":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/"},{"categories":["深度学习","论文阅读","CAD"],"content":"6.2 随机生成 为了评估 SkexGen 生成高质量和多样化结果的能力，我们随机生成每种类型的20,000个样本，并将 SkexGen 与四个其他基线进行比较： CurveGen DeepCAD 单一码本的 SkexGen 带 VAE 的 SkexGen。 由于其他来自同时研究的草图生成模型依赖于草图约束标签，并且理想情况下需要草图约束求解器，这使得它们无法直接比较。 草图生成评估：结果如下表所示。SkexGenFID分数表现最优，证明其生成的草图质量最高。SkexGen在Novel上虽不及DeepCAD，但在Unique上与CurveGen相当或更优。且定性分析显示，DeepCAD虽然Novel得分高，但存在大量无效结果，如自相交曲线和未闭合几何，影响了FID评分。总体而言： SkexGen 生成的草图在质量上更好，形状更复杂，自相交更少，对称性更强。 CurveGen 也生成了质量不错的结果，但矩形和圆的复杂排列较少。 DeepCAD 可以生成比 CurveGen 更复杂的形状，但噪音很多。 CAD模型生成评估：结果如下表所示，SkexGen在所有评估指标上领先，尤其在形状复杂度、对称性以及频繁使用弧线方面表现出色。SkexGen能生成涉及多步骤草图和拉伸序列的CAD模型，而DeepCAD则主要生成单步模型。表中间两行展示了多个解耦码本的有效性。减少到单个码本后，生成质量下降，SkexGen 类似于 VQ-VAE。当不使用码本时，结果最差，SkexGen 实际上变成了 VAE。 运行时间评估：尽管SkexGen的自回归采样过程使其比DeepCAD慢，但比CurveGen（具有两个依赖的自回归解码器）快，显示出采样效率的优化空间。 ","date":"2024-07-19","objectID":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/:6:2","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】 SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks","uri":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/"},{"categories":["深度学习","论文阅读","CAD"],"content":"6.3 可控生成 解耦码本实现了设计控制与探索，如下图所示：左侧“拓扑条件”：固定拓扑码，其他码通过核采样获得，展示相同结构的不同变体。右侧“几何条件”：固定几何码，改变其他码，体现一致几何下的多样形态。 为了定量衡量三个码本之间的解耦程度，作者参考了$\\beta\\text{-VAE}$的评估方法。通过保持一个拓扑、几何或拉伸标记相同，并对其他部分进行采样，生成一对草图和拉伸序列。然后训练一个小型基于Transformer的分类器，通过编码潜在空间中所有数据对的平均成对差异来识别固定的码。SkexGen的分类准确率为99.8 ± 0.1%，证实码本间解耦效果显著。 ","date":"2024-07-19","objectID":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/:6:3","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】 SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks","uri":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/"},{"categories":["深度学习","论文阅读","CAD"],"content":"6.4 应用 插值应用 利用线性插值技术在模型的码之间探索，生成过渡模型。过程包括：编码模型提取关键码、线性插值这些码，再量化及生成插值模型。插值结果示例如Figure所示，线条演化为圆，矩形实体转为圆形空心盘，显示拓扑和几何动态变化。插值效果可能不平滑，因涉及复杂的离散拓扑变换。 码混合应用 通过混合不同数据的拓扑、几何和拉伸码，创造新颖设计组合。图8示例：保持拓扑形状，调整几何位置，如多个圆柱按方形布局排列。这些混合结果体现了系统的创新设计能力，超越了传统方法的局限。 ","date":"2024-07-19","objectID":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/:6:4","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】 SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks","uri":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/"},{"categories":["深度学习","论文阅读","CAD"],"content":"7 总结 SkexGen是一种新颖的自回归生成模型，专为CAD构造序列设计。它利用不同的Transformer架构将CAD构造序列中的拓扑、几何和拉伸变化编码为解耦码本。这些解码器可以生成具有特定属性的CAD构造序列。SkexGen的优势在于其能够生成多样且高质量的CAD模型，同时提高用户的控制能力和设计空间的探索效率。 模型的评估在一个大规模的CAD数据集上进行，结果表明，SkexGen相比多个基准和最新方法，生成的CAD模型更为真实和多样。此外，SkexGen的架构也增强了用户在设计过程中的控制能力，使其能够更有效地探索不同设计空间。 7.0.1 限制 数据依赖：SkexGen依赖于大量的已标注CAD数据集，这些数据集的质量和多样性直接影响模型的表现。 模型复杂性：该模型使用多个Transformer编码器和解码器来处理复杂的CAD构建序列，这增加了模型的复杂性和计算成本。 拓扑和几何的分离：虽然这种分离有助于提高控制和生成多样性，但在实际应用中可能会导致模型难以学习到拓扑和几何之间的复杂关系。 有限的建模操作：SkexGen主要关注草图和拉伸操作，未涉及其他的CAD建模操作，如旋转、扫掠、布尔运算等，限制了其应用范围（但可以通过导入CAD工具后编辑实现其他CAD建模操作）。 7.0.2 创新点 自回归生成模型：SkexGen是一个自回归生成模型，能够生成高质量和多样化的CAD构建序列。 解耦码本：使用了解耦码本架构，分别编码CAD构建序列中的拓扑、几何和拉伸变化，提高了用户控制和设计空间的探索效率。 ","date":"2024-07-19","objectID":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/:7:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】 SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks","uri":"/posts/06.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/"},{"categories":["深度学习","论文阅读","CAD"],"content":"1 摘要 作者提出了一种CAD的创新生成模型，该模型将CAD模型的高级设计概念表示为从全局部件排列到局部曲线几何的三层神经代码的层级树，并且通过指定目标设计的代码树来控制CAD模型的生成或完成。具体而言，一种带有“掩码跳过连接”的向量量化变分自编码器(VAE)的新变体在三个层次上提取设计变化作为神经码本。两阶段的级联自回归Transformer学习从不完整的CAD模型生成代码树，然后根据预期设计完成CAD模型。广泛的实验表明，在无条件生成等传统任务上表现出优越性能，同时在条件生成任务中实现了新颖的交互能力。 【code】 ","date":"2024-07-19","objectID":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/:1:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】Hierarchical Neural Coding for Controllable CAD Model Generation","uri":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/"},{"categories":["深度学习","论文阅读","CAD"],"content":"2 引言 大多数现代CAD设计工具采用“草图和拉伸”风格的工作流程，以这种方式创建的CAD模型具有自然的树结构，支持局部编辑。树叶处的曲线可以调整并重新生成拉伸以更新最终形状。对于设计师来说，重要的是编辑要保留“设计意图”。而设计意图定义也有不同： Otey等人将设计意图定义为“在修改时CAD模型的预期行为” Martin描述为“对象之间的关系，使得对一个对象的更改可以自动传播到其他对象”。 虽然“草图和拉伸”允许局部更改，但它不提供在编辑模型时给出预期行为所需的关系。一个能理解设计意图的计算系统将彻底改变CAD的实践。这种系统可以帮助设计师在： 根据高级设计概念生成多样化的CAD模型； 在约束某些模型属性的情况下修改现有的CAD模型； 交互式地自动完成设计（如下图）。 但目前还没有这样的系统，当前行业标准通过手动指定参数和方程，以定义轮廓的位置和尺寸，以及用于对齐几何的约束，这种称为参数化CAD的过程需要专业技能，并且在意外编辑时很容易出错。下图展示了编辑约束不良的CAD模型的几何形状时原始设计意图被破坏的示例。 现有的工作并未利用CAD设计的层次性来提供有效的设计控制。作者提出了一种新颖的生成网络，将CAD模型的设计意图捕获为从局部几何特征到全局部件排列的三层神经代码树，并根据编码树或不完整的CAD模型指定的设计意图控制CAD模型的生成或完成。CAD模型以建模操作的序列形式生成，然后转换为工业标准的边界表示（B-Rep）格式，以便在CAD软件中进行编辑。 具体来说，作者提出了一种带有“掩码跳过连接”的矢量量化VAE变体，从大规模草图和拉伸CAD数据集（DeepCAD数据集）中学习设计变化形成三个神经码本。掩码跳过连接简单但有效，可以提取高度抽象的码本，使代码与生成的几何形状之间的关系变得直观。然后，两阶段级联自回归Transformer学习生成： 给定不完整CAD模型的三层代码树 给定编码树和不完整数据的完整CAD模型 设计师还可以直接提供编码树以生成模型。 与其他生成baseline的定性和定量评估表明，在随机生成任务中，该系统生成了更逼真和复杂的模型。在用户控制的条件生成任务中，系统展示了灵活和优越的几何控制，这得益于层次编码树表示，优于当前最先进的基于深度学习的生成模型（例如SkexGen，DeepCAD）。总之，我们的贡献包括： 编码层次设计概念的神经代码树表示，支持高质量和复杂模型的生成、设计意图感知的用户编辑和设计自动完成。 带有掩码跳过连接的新型向量量化变分自编码器，用于增强代码簿学习。 在CAD模型生成方面相对于之前的最先进方法的性能提升。 ","date":"2024-07-19","objectID":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/:2:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】Hierarchical Neural Coding for Controllable CAD Model Generation","uri":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/"},{"categories":["深度学习","论文阅读","CAD"],"content":"3 相关工作 构造性实体几何（CSG） 3D形状由参数化基元通过布尔运算组成的CSG树表达。这种轻量级表示通过程序合成和无监督学习重建CAD形状。但参数化CAD仍主导机械设计，并且广泛使用草图和拉伸建模操作。 直接CAD生成 最近一些工作专注于在没有任何CAD建模序列监督的情况下直接生成CAD模型。作者更专注于以草图和拉伸序列形式进行的参数化CAD的可控生成。 草图和拉伸CAD生成 最近大规模参数化CAD数据集的可用性使基于学习的方法能够利用CAD建模序列历史和草图约束生成工程草图和实体模型。生成的序列可以用实体建模内核解析，以获得包含2D工程草图或3D CAD形状的可编辑参数化CAD文件。此外，生成可以受目标B-rep、草图、图像、体素网格或点云的影响。但这种控制是全局级别的，而作者旨在支持设计保持编辑和自动完成等应用程序的全局和局部级别的层次控制。 用户控制的CAD生成 提供用户对生成过程的控制，同时保持设计意图，是生成模型在实际CAD软件中采用的关键。尽管以前的方法可以基于高级指导生成多样化的形状，但使用户能够控制生成过程更具挑战性。Sketch2CAD和Free2CAD专注于设计过程的局部控制，并且需要大量的输入。最近的一些工作还利用文本提示和用户指定的指导。SkexGen允许用户通过解耦全局控制CAD形状的拓扑和几何来探索设计变化。然而，其方法仅有助于从零开始创建新设计，无法轻易修改以提供用户期望的智能编辑CAD模型或自动完成下一步操作的交互体验。与现有工作不同，作者的方法利用CAD模型内部存在的自然层次结构，提供对生成过程的全局和局部控制。 ","date":"2024-07-19","objectID":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/:3:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】Hierarchical Neural Coding for Controllable CAD Model Generation","uri":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/"},{"categories":["深度学习","论文阅读","CAD"],"content":"4 层次CAD属性 草图和拉伸的CAD模型具有自然的层次结构，如下图所示。 其中一个环定义了一条封闭的曲线路径，一个轮廓在草图平面内由一个外环和一些内环限定了一个封闭区域，而一个实体则表示一组拉伸的轮廓组合成整个模型。我们的目标是实现在生成CAD模型时的局部和全局控制，即用户可以编辑任何一个实体，并期望其余部分自动进行合理的更新。为了实现这一目标，我们在神经网络的潜在空间中捕捉这种层次结构。在层次结构的较高层上，网络学习较低层次几何实体的相对位置，即构成模型的轮廓和拉伸的边界框。具体来说，我们将CAD模型视为一个实心（S）—轮廓（P）—环（L）树： 环（L） ：在树的叶子上，我们有环。每个环由一组线和弧或一个圆组成。环（L）的属性定义为一系列由特殊$\\text{\u003cSEP\u003e}$ token分隔的x-y坐标： $$ L = {(x_1, y_1), (x_2, y_2), \\text{\u003cSEP\u003e}, (x_3, y_3), \\ldots}. $$ 线由两个点（起点和终点）的xy坐标表示；弧由三个点表示，包括起点、中点和终点；圆由曲线上四个均匀分布的点表示。使用这种表示法，可以通过点的数量识别曲线类型。我们对环中的曲线进行排序，使得初始曲线是起点坐标最小的曲线，下一条是与其逆时针方向相连的曲线。 轮廓（P）：轮廓位于叶子层之上。由于环的几何结构在叶子层捕捉，轮廓节点的属性定义为草图平面内环的二维边界框参数系列： $$ P = {(x_i, y_i, w_i, h_i)}_{i=1}^{N^{\\text{loop}}_i}. $$ 其中$i$是轮廓内$N^{\\text{loop}}_i$个环的索引。$(x_i, y_i)$是边界框的左下角，$(w_i, h_i)$是宽度和高度。我们通过对所有二维边界框的左下角进行升序排序来确定轮廓$P$中边界框参数的顺序。 实体（S）：在轮廓层之上，我们有通过拉伸一个或多个轮廓形成的三维实体模型。实体节点的属性捕获拉伸轮廓的排列，使用一系列三维边界框参数： $$ S = {(x_j, y_j, z_j, w_j, h_j, d_j)}_{j=1}^{N^{\\text{profile}}_j}. $$ 其中$j$是模型中$N^{\\text{profile}}_j$个拉伸轮廓的索引。$(x_j, y_j, z_j)$是边界框的左下角，$(w_j, h_j, d_j)$是其尺寸。同样，$S$中的参数按所有拉伸的三维边界框的左下角进行升序排序。 ","date":"2024-07-19","objectID":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/:4:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】Hierarchical Neural Coding for Controllable CAD Model Generation","uri":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/"},{"categories":["深度学习","论文阅读","CAD"],"content":"5 三层码本学习 给定一个以S-P-L树格式表示的草图和拉伸CAD模型数据集，一种新的向量量化VAE（VQ-VAE）变体学习它们的潜在模式，作为三个离散的码本，这些码本将CAD模型编码为一棵神经码树，用于下游应用。 遵循SkexGen，我们用于学习码本的架构基础是一个VQ-VAE，由一个Transformer编码器$E$和解码器$D$组成，如下图所示。 我们独立学习L、P和S的码本。与SkexGen和之前的掩码学习工作不同，我们在从编码器输入到解码器输入的跳过连接上应用掩码。直观来说，一个标准的VQ-VAE（即没有跳过连接）被训练用来恢复实例特定的输入细节，这对于正在学习实例无关设计模式的量化码来说是一个挑战。一个天真的跳过连接允许解码器通过直接复制输入来作弊。掩码跳过连接迫使解码器从未掩码元素中关联部分细节和填补缺失部分，其中关系由编码在码中的设计模式引导。 编码器： 考虑一个$L$（方程1），包含一系列的x-y坐标和特殊的$\\text{\u003cSEP\u003e}$ token。我们使用65维的独热向量来表示一个token，其中一个坐标被量化为6位（即64维），$\\text{\u003cSEP\u003e}$需要一个额外的维度。设$T^E_t$表示Transformer编码器的第$t$个token的256维嵌入。嵌入初始化为： $$ T_t^E\\leftarrow\\begin{cases}\\text{MLP}(W_\\text{emb}x_t\\parallel W_\\text{emb}y_t)+\\gamma_t\\quad\\text{(for x-y)},\\\\text{MLP} (W_\\text{emb}\u003c\\text{SEP}\u003e\\parallel W_\\text{emb}\u003c\\text{SEP}\u003e)+ \\gamma_t.\\end{cases} $$ $W_\\text{emb}$是一个$65\\times 32$的token嵌入矩阵。$\\parallel$是拼接运算符。$\\text{MLP}$是一个两层的多层感知器。$\\gamma_t$是一个可学习的256维位置嵌入。第二种情况是对于$\\text{\u003cSEP\u003e}$，其值重复两次。对于P和S，我们处理每个二维或三维边界框参数的方式与$x_t, y_t$坐标相同，但没有$\\text{\u003cSEP\u003e}$ token。 向量量化： 编码器$E$的输出，序列长度为$T$，首先进行平均池化，形成$\\overline{E}(T^E)$。然后应用标准的向量量化程序来获得一个256维的码本向量$c$。更具体地说，我们比较码本向量$\\mathbf{b}$和编码的$\\overline{E}(T^E)$之间的欧几里得距离，并执行最近邻查找。 $$ \\mathbf{c}\\leftarrow\\mathbf{b}_k,\\quad\\text{where}\\quad k=\\mathrm{argmin}_i\\left|\\left|\\overline{E}(T^E)-\\mathbf{b}_i\\right|\\right|^2. $$ 带掩码跳过连接的解码器： 解码器接收量化码$c$和掩码的x-y坐标和$\\text{\u003cSEP\u003e}$ token序列，并预测被掩码的token。例如，在一个环节点的情况下，任何$x_t, y_t$和$\\text{\u003cSEP\u003e}$ token都可以被掩码（具体来说，每个模型随机掩码30%到70%的token）。设$T^D_t$表示为解码器输入的第$t$个token的嵌入。每个token的嵌入方式与编码器嵌入方程完全相同，只是被掩码的token的嵌入被一个可学习的共享32维掩码token嵌入$m$取代。来自编码器的256维码本向量$c$与${T^D_t}$拼接在一起并传递给解码器$D$，解码器有四个自注意力层。这里的思想是迫使编码器学习有用的潜在特征，可以帮助解码器预测被掩码的token。最后，在解码器后对每个token嵌入（除了码本向量）应用一个MLP，以生成(2 × 65)维的logits，即一对在65类标签上的概率值，分别用于预测xy坐标或$\\text{\u003cSEP\u003e}$ token。 损失函数： 训练损失由三项组成： $$ \\begin{aligned}\u0026\\sum_{t}\\mathrm{EMD}\\Big(D(\\mathbf{c},{T_{t}^{D}}) , \\mathbb{1}_{T_{t}}\\Big)+\\\u0026\\left|\\left|sg[\\overline{E}(T^{E})]-\\mathbf{c}\\right|\\right|_{2}^{2}+\\beta\\left|\\left|\\overline{E}(T^{E})-sg[\\mathbf{c}]\\right|\\right|_{2}^{2}.\\end{aligned} $$ 第一项是解码器输出概率和相应数据属性的独热编码$\\mathbb{1}_{T_t}$之间的平方EMD损失。损失仅应用于被掩码的token。我们使用的EMD损失函数，该函数假设有序的类标签，并对接近真实值的预测进行较少的惩罚。这比交叉熵损失更好，因为x-y坐标携带距离关系，使得损失可以集中在远离真实值的预测上。注意，我们对环数据属性中的$\\text{\u003cSEP\u003e}$ token处理不同，应用标准的交叉熵损失，因为这不是一个有序类标签。 第二和第三项是VQ-VAE中使用的码本和承诺损失。$sg$表示停止梯度操作，在前向传播中是恒等函数，但在后向传播中阻止梯度。$\\beta$缩放承诺损失，设为$0.25$。我们使用衰减率为$0.99$的指数移动平均更新。 ","date":"2024-07-19","objectID":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/:5:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】Hierarchical Neural Coding for Controllable CAD Model Generation","uri":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/"},{"categories":["深度学习","论文阅读","CAD"],"content":"6 可控CAD生成 环、轮廓和实体码本使我们能够将CAD模型的设计概念表达为层次化的神经代码，从而实现多样化和高质量的生成、新颖的用户控制以指定设计意图，以及自动完成不完整的CAD模型。具体来说，给定一个不完整的CAD模型作为草图和拉伸构建序列： 模型编码器将输入序列转换为潜在嵌入； 自回归Transformer根据嵌入的输入序列生成代码树； 第二个自回归Transformer根据嵌入的输入序列和代码树生成完整的CAD模型。 模型编码器： 模型编码器的主体是标准的Transformer编码器模块，具有6个自注意力层。我们借用了SkexGen中使用的格式，并将模型表示为一个token序列，每个token是一个独热向量，唯一确定一个曲线类型、量化曲线参数和量化拉伸参数。编码器将独热向量转换为一系列256维的潜在嵌入${T^E_t}$。 编码树生成器： $G_\\text{code}$是一个自回归解码器，它生成代码的层次结构${T^C_t}$。每个实体、轮廓或环从相应的码本中分配一个代码，条件是编码的嵌入${T^E_t}$。类似于层次属性表示，层次代码表示为一系列特征向量，指示代码或分隔token。具体来说，一个特征是一个独热向量，其大小是三个码本中代码的总数加上一个分隔符。例如，考虑上图示例中的代码树，包含一个实体、两个轮廓和两个或四个环。这个树的特征表示为$[S, \\text{\u003cSEP\u003e}, P, L, L, \\text{\u003cSEP\u003e}, P, L, L, L, L]$。这里我们执行神经代码树的深度优先遍历，边界命令$\\text{\u003cSEP\u003e}$用于指示轮廓和环代码的新分组。 $G_\\text{code}$有6个自注意力（SA）层与6个交叉注意力（CA）层交替。第一个SA层是在查询token${T^{\\bar{C}}_t}$上，每个查询token由位置编码$\\gamma_t$初始化并自回归估计。每个CA层的输入是${T^E_t}$。每个SA或CA层都有8个头的注意力，随后是一个Add-Norm层。一个查询token ${T^{\\bar{c}}_t}$将有一个生成的代码索引，该索引转换为一个代码${T^C_t}$。分隔符被一个可学习的嵌入取代。 Codebook表示从代码索引到代码的映射。我们使用标准的交叉熵损失训练$G_\\text{code}$。注意，对于无条件生成，我们删除部分CAD模型编码器，并仅使用查询token ${T^{\\bar{C}}_t}$训练SA层，没有交叉注意力层和${T^E_t}$。 模型生成器： 模型生成器是第二个自回归解码器$G_\\text{cad}$，生成一个草图和拉伸的CAD模型。$G_\\text{cad}$与SkexGen解码器相同，不同的是部分CAD模型嵌入${T^E_t}$和层次神经代码${T^C_t}$通过交叉注意力层控制生成，而SkexGen仅允许全局代码的指定。架构规格与第一个解码器相同。查询token ($T^\\text{out}_t$)包含生成的CAD命令序列作为独热向量，我们使用相同的标准交叉熵损失。 ","date":"2024-07-19","objectID":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/:6:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】Hierarchical Neural Coding for Controllable CAD Model Generation","uri":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/"},{"categories":["深度学习","论文阅读","CAD"],"content":"7 实验 本节展示了无条件和有条件生成的结果，证明了以下几点： 相较于当前最先进的技术，生成的质量更高、种类更多、复杂性更强； 通过层次化神经代码实现可控生成； 两个重要应用，用户编辑和自动补全。 ","date":"2024-07-19","objectID":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/:7:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】Hierarchical Neural Coding for Controllable CAD Model Generation","uri":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/"},{"categories":["深度学习","论文阅读","CAD"],"content":"7.1 实验设置 数据集: 使用大规模DeepCAD数据集，包含178,238个草图及拉伸模型，按90%训练、5%验证、5%测试划分。去除重复模型和属性，并限制训练模型的复杂度（最多5个实体、20个环/轮廓、60条曲线/环、200个命令/序列），最终训练集包含102,114个实体、60,584个轮廓、150,158个环和124,451个草图和拉伸序列用于CAD模型训练。对于CAD工程图，我们遵循SkexGen并从DeepCAD中提取草图。在移除重复后，共有99,650个草图用于训练。 实施细节: 在Nvidia RTX A6000 GPU上训练，批次大小256。码本模块和生成模块分别训练250和350轮。采用改进的Transformer主干，输入嵌入维度256，前馈维度512，Dropout率0.1，各含6层、每层8头注意力。码本学习网络有4层。使用AdamW优化器，学习率0.001，线性预热2000步。测试时采用核采样，对输入曲线坐标添加随机噪声减少过拟合，针对码本坍塌问题采取重新初始化策略。最优代码本大小约为轮廓和实体3,500，环2,500，压缩比约60x、17x和29x。 ","date":"2024-07-19","objectID":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/:7:1","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】Hierarchical Neural Coding for Controllable CAD Model Generation","uri":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/"},{"categories":["深度学习","论文阅读","CAD"],"content":"7.2 指标 五个已建立的指标定量评估随机生成 点云指标：基于模型表面采样的2000点比较生成和真实数据的点云集，评估多样性与质量。 覆盖率（COV）：至少匹配一个生成样本的真实模型百分比，反映生成形状的多样性。 最小匹配距离（MMD）：平均最小匹配距离，衡量两组之间的接近程度。 Jensen-Shannon散度（JSD）：两个概率分布间的相似性，计算占用相同空间位置的频率。 token指标：衡量唯一性。数值字段量化为6位。 新颖性（Novel）：未出现在训练集中的生成CAD序列比例。 唯一性（Unique）：在生成集中仅出现一次的数据比例。 ","date":"2024-07-19","objectID":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/:7:2","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】Hierarchical Neural Coding for Controllable CAD Model Generation","uri":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/"},{"categories":["深度学习","论文阅读","CAD"],"content":"7.3 无条件生成 对比DeepCAD与SkexGen，所有方法生成10,000个CAD模型，与测试集随机选取的2,500个真实模型比较。 **定量评估：**如下表所示，我们的方法在所有三个点云评估指标上超越baseline，展现显著的质量和多样性提升。在Unique指标上，我们的方法与SkexGen相当，远超DeepCAD。Novel指标上略逊于SkexGen，但明显优于DeepCAD；此差距源于较小且多样性不足的训练集，且仅包含少量复杂形状所致。SkexGen因无法生成非常复杂的模型而受此影响较小。 定性评估： 下图显示我们的方法能生成结构良好、几何形状复杂、部件布局精细的CAD模型，与真实世界实例相似。 人工评估： 通过亚马逊众包平台进行人类感知质量评估，针对具有三个或更多拉伸的模型。在与真实模型并列展示的情况下，我们的方法在“真实感”评分上表现突出，分布对称，表明生成模型难以被区分。比较之下，DeepCAD和SkexGen的分布偏向“较不真实”，表明易被识别为简单或不规范的模型。我们的方法中有49.2%的生成模型被认定为比训练数据更“真实”，SkexGen为46.9%，DeepCAD为38.7%。 ","date":"2024-07-19","objectID":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/:7:3","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】Hierarchical Neural Coding for Controllable CAD Model Generation","uri":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/"},{"categories":["深度学习","论文阅读","CAD"],"content":"7.4 可控生成 我们在两种“编辑”和一种“自动补全”应用场景中展示了可控生成。 代码树编辑： 用户可编辑不同层次的代码节点，实现局部到全局的CAD层次修改，这是以往方法所不具备的。编辑结果多样化且控制精确，如下图所示。 保持设计的编辑： 在固定代码树的基础上，用户可迭代地调整模型参数以细化设计，同时保持当前设计不变。如下图所示，局部尺寸调整后，相关部分会自动调整以适应更改。 从用户输入的自动补全： 根据用户提供的部分轮廓或环，预测可能的代码集以完成CAD模型。图9和图10展示了从部分轮廓和拉伸轮廓开始的自动补全结果，每行展示不同生成代码的结果。相比最近邻搜索baseline，我们的方法在多样性和精确匹配用户输入方面表现更优，如图11所示。 ","date":"2024-07-19","objectID":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/:7:4","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】Hierarchical Neural Coding for Controllable CAD Model Generation","uri":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/"},{"categories":["深度学习","论文阅读","CAD"],"content":"8 总结 作者引入了一种新颖的可控CAD生成模型。方法的关键是三层神经编码，它在建模层次结构的不同层次上捕获设计模式和意图。本文在包含用户反馈的智能生成设计方向上又迈出了重要一步。广泛的评估显示，生成质量有了显著提升，并展示了作者的分层神经编码在意图感知编辑和自动补全等应用中的巨大潜力。其主要创新点和限制如下： 创新点： 分层神经编码：提出了一种三层次的神经编码方法，将CAD模型的高级设计概念表示为从全局部件布局到局部曲线几何的树状结构。 设计意图的捕捉与控制：通过指定目标设计来生成或完成CAD模型，使用代码树来控制生成过程。 新型变分自编码器（VAE）：提出了一种新型的向量量化VAE变体，具有“掩蔽跳跃连接”，用于从大规模草图和挤出CAD数据集中提取设计变化作为神经代码本。 两阶段级联自回归变换器：用于从不完整的CAD模型生成代码树，然后根据预期设计完成CAD模型。 限制： 有效性问题：当前系统在生成具有自相交边或实体的CAD模型时可能存在有效性问题，因为损失函数没有明确地惩罚无效的几何形状。未来的工作是增加一个损失函数，利用领域知识明确对 CAD 模型的无效性进行惩罚。 恢复失败的能力：系统在面对失败情况时，缺乏从错误中恢复的能力，这主要是因为缺乏“无效CAD模型数据集”来训练这种恢复机制。 模型格式限制：该方法使用的是草图和拉伸CAD格式，这可能排除了其他流行的建模操作，如旋转、镜像和扫掠等。 ","date":"2024-07-19","objectID":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/:8:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】Hierarchical Neural Coding for Controllable CAD Model Generation","uri":"/posts/07.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/"},{"categories":["系统架构","论文阅读"],"content":"1 介绍 分布式一致性共识算法指的是在分布式系统中，使得所有节点对同一份数据的认知能够达成共识的算法。且算法允许所有节点像一个整体一样工作，即使其中一些节点出现故障也能够继续工作。之前的大部分一致性算法实现都是基于Paxos，但Paxos难以理解和实现，为此作者开始寻找一种新的易于理解的一致性算法，Raft则是作者工作的产出。 在设计Raft的过程中，作者采用了一系列策略来增强其可理解性，包括： 算法分解：Raft将核心功能模块化，分离出领导人选举、日志复制和安全性三个关键部分，使每个部分的逻辑更加清晰。 状态空间缩减：相比于Paxos，Raft减少了不确定性和服务器间的不一致性状态，简化了状态机模型，从而降低了理解和实现的难度。 Raft 算法在许多方面和现有的一致性算法都很相似，但是它也有一些特性： 强领导人机制：Raft采用了更强的领导人角色，所有日志条目仅由领导人发送给其他服务器，这种集中控制方式简化了日志管理，增强了算法的直观性。 领导人选举：Raft使用随机计时器来触发领导人选举，这种机制在心跳机制的基础上增加了少许复杂性，但有效地解决了选举冲突，实现了快速而简单的决策过程。 成员关系调整：Raft 使用一种联合共识的方法来处理集群成员变换的问题，在这种方法下，处于调整过程中的两种不同的配置集群中大多数机器会有重叠，这就使得集群在成员变换的时候依然可以继续工作。 ","date":"2024-07-19","objectID":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/:1:0","tags":["分布式系统","Raft"],"title":"【论文阅读笔记】In Search of an Understandable Consensus Algorithm (Extended Version)","uri":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/"},{"categories":["系统架构","论文阅读"],"content":"2 复制状态机 复制状态机是共识算法的核心应用背景，它是指一组服务器上的状态机生成相同状态的副本，即使部分服务器宕机也能持续运行。这种架构在大规模分布式系统中尤其重要，因为它能够解决一系列容错问题。例如，大规模的系统中通常都有一个集群领导人，像 GFS、HDFS 和 RAMCloud，典型应用就是一个独立的复制状态机去管理领导人选举和存储配置信息并且在领导人宕机的情况下也要存活下来。比如 Chubby 和 ZooKeeper。 复制状态机通常都是基于复制日志实现的，如图 1。每个服务器存储一个包含一系列指令的日志，并且按照日志的顺序进行执行。所有日志都包含相同的指令序列，确保状态机一致，因为每个状态机都是确定的，每一次执行操作都产生相同的状态和同样的序列。 一致性算法的任务是保证复制日志的一致性。服务器上的一致性模块接收客户端发送的指令然后添加到自己的日志中。它和其他服务器上的一致性模块进行通信来保证每一个服务器上的日志最终都以相同的顺序包含相同的请求，即使有些服务器发生故障。一旦指令被正确的复制，每一个服务器的状态机按照日志顺序处理他们，然后输出结果被返回给客户端。因此，服务器集群看起来形成了一个高可靠的状态机。 实际系统中使用的一致性算法主要有以下特性： 安全性保证（绝对不会返回一个错误的结果）。 即使部分服务器失败，只要多数服务器运行，系统依然可用。 不依赖于时序，能够应对时钟错误和消息延迟。 大多数情况下，指令可以在一轮远程过程调用后完成，不受少数慢节点影响。 ","date":"2024-07-19","objectID":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/:2:0","tags":["分布式系统","Raft"],"title":"【论文阅读笔记】In Search of an Understandable Consensus Algorithm (Extended Version)","uri":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/"},{"categories":["系统架构","论文阅读"],"content":"3 Paxos的问题 Paxos极其难以理解。 没有为构建实际系统实现提供良好的基础。 ","date":"2024-07-19","objectID":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/:3:0","tags":["分布式系统","Raft"],"title":"【论文阅读笔记】In Search of an Understandable Consensus Algorithm (Extended Version)","uri":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/"},{"categories":["系统架构","论文阅读"],"content":"4 为了可理解性的设计 设计Raft算法的初衷： 必须提供一个完整的实际的系统实现基础，减少开发者工作量； 必须在任何情况下都是安全的并且在大多数的情况下都是可用的； 它的大部分操作必须是高效的； 可理解性，它必须保证对于普遍的人群都可以十分容易的去理解； 便于系统构建者形成直观理解，便于实际应用和扩展； Raft设计原则： 问题分解：将复杂问题拆解为独立、易于理解和解决的子问题。例如，Raft 的领导人选举、日志复制、安全性和成员变更。 状态空间简化：减少状态数量，降低系统复杂性并在可能的时候消除不确定性。确保日志无空洞，限制日志不一致的可能性。 随机化应用：在领导人选举中使用随机化，简化机制，快速解决冲突。 ","date":"2024-07-19","objectID":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/:4:0","tags":["分布式系统","Raft"],"title":"【论文阅读笔记】In Search of an Understandable Consensus Algorithm (Extended Version)","uri":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/"},{"categories":["系统架构","论文阅读"],"content":"5 Raft一致性算法 Raft 是一种管理复制日志的一致性算法，通过选举领导人并由其管理日志来实现一致性。领导人从客户端接收日志条目，把日志条目复制到其他服务器上，并告诉其他的服务器什么时候可以安全地将日志条目应用到他们的状态机中。这一决策过程无需与其他服务器进行商议，从而简化了整个复制日志的管理流程，并且数据都从领导人流向其他服务器。一个领导人可能会发生故障，或者和其他服务器失去连接，在这种情况下一个新的领导人会被选举出来。 Raft算法的一致性问题被巧妙地分解为三个关键子问题： 领导选举：当领导人发生故障的时候, 一个新的领导人需要被选举出来，确保系统的连续性和稳定性（5.2） 日志复制：领导人必须从客户端接收日志条目然后复制到集群中的其他节点，并强制要求其他节点的日志和自己保持一致。 安全性：Raft通过特定的机制（5.4）确保一旦日志条目被应用到某个服务器的状态机中，其他服务器不会在同一日志索引位置应用不同的指令，从而保障了系统状态的一致性和安全性。 ","date":"2024-07-19","objectID":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/:5:0","tags":["分布式系统","Raft"],"title":"【论文阅读笔记】In Search of an Understandable Consensus Algorithm (Extended Version)","uri":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/"},{"categories":["系统架构","论文阅读"],"content":"5.1 Raft基础 一个 Raft 集群由若干个服务器节点构成，如常见的 5 节点配置，能容忍最多 2 个节点失效。节点有以下三种状态： 领导人：唯一决策者，处理所有客户端请求，并且管理复制日志。 跟随者：被动角色，仅响应领导人和候选人的请求。 候选人：竞选状态，用于选举新领导人 跟随者在收不到消息时，升级为候选人，启动选举；获得多数票的候选人成为领导人；领导人宕机或发现任期过期，降级为跟随者。 Raft 通过任期来划分时间，每个任期都始于一次选举。任期用整数标记，每段任期有其选举过程。如果选举成功，选出的领导人将负责管理集群，直到该任期结束。任期在Raft中充当逻辑时钟的作用，帮助节点检测过期信息，如过期的领导人。 每个节点维护一个当前任期号，通信时交换任期号，节点自动更新至较大值，领导人或候选人如果发现任期号过期，会恢复为跟随者；节点拒绝过期任期请求。 在 Raft 算法中，节点间的通信依赖于RPC。基本的一致性算法主要使用两种类型的 RPCs： 请求投票RPC：候选人发起，用于选举。 附加条目RPC：领导人发起，复制日志和提供心跳机制。 安装快照PRC：领导人发起，安装快照。为了提高性能，服务器在未及时收到响应时会重试 RPC，并且能够并行发起 RPC。 ","date":"2024-07-19","objectID":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/:5:1","tags":["分布式系统","Raft"],"title":"【论文阅读笔记】In Search of an Understandable Consensus Algorithm (Extended Version)","uri":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/"},{"categories":["系统架构","论文阅读"],"content":"5.2 领导人选举 Raft 算法采用心跳机制来触发领导人选举过程。服务器启动时，默认处于跟随者状态，仅当接收到来自领导人或候选人的有效 RPC 时才保持这一状态。领导人定期向所有跟随者发送心跳包，即不含日志项的附加条目RPC，以此维护其领导地位。若跟随者在设定的选举超时时间内未收到任何消息，它将假定无有效领导人并发起选举，以选出新的领导人。 选举流程开始时，跟随者增加自己的当前任期号并转换为候选人状态，然后向集群中其他服务器节点发送请求投票RPC来给自己投票。候选人保持该状态，直至出现以下三种情况之一： 赢得选举。 其他服务器成为领导人。 在一定时间内无明确获胜者。 赢得选举的条件是获得集群大多数服务器节点的选票，每台服务器对同一任期号的投票遵循先来先服务原则，并有额外限制（5.4）以确保选举安全性，避免了脑裂（同一人气，集群出现两个领导人）。一旦当选，候选人即刻转变为领导人，通过发送心跳消息确立领导地位并阻止发起新选举。 在等待投票的过程中，候选人可能接收到领导人发送的附加条目RPC，如果该领导人任期号不低于候选人的任期号，候选人将认可其合法性，回归跟随者状态；反之，候选人将拒绝RPC，继续竞选。若多个候选人同时发起选举，选票分散可能导致无人胜出，所有候选人均会因超时而重新开始选举，但任期号会递增。 为防止选票分散，Raft算法引入了随机化选举超时时间策略。各服务器在固定时间范围内（例如$[150,200]$）随机选取超时值，使得通常情况下仅有一台服务器超时，进而顺利赢得选举并在其他服务器超时前发送心跳。即使发生选票分散，随机化的超时机制也降低了下一轮选举中再次分散的可能性。 作者最初设计考虑过引入排名系统以决定优先级，但发现这可能导致高排名服务器故障时的可用性问题，且算法调整复杂，难以确保没有副作用。经过多次调整，最终确定随机重试方法更为直观易懂，且避免了排名系统带来的复杂性和潜在问题。 ","date":"2024-07-19","objectID":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/:5:2","tags":["分布式系统","Raft"],"title":"【论文阅读笔记】In Search of an Understandable Consensus Algorithm (Extended Version)","uri":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/"},{"categories":["系统架构","论文阅读"],"content":"5.3 日志复制 一旦选举产生领导人，它便开始处理客户端请求，每个请求携带一条被复制状态机执行的指令。领导人将此指令作为新日志条目追加至日志中，并并行发起附加条目RPC给其他服务器复制，日志条目在被安全复制后，领导人将其应用到状态机并将执行结果返回给客户端，即使面对跟随者崩溃、延迟或网络丢包，领导人也会持续重试RPC（尽管已经回复了客户端）直至所有跟随者存储所有日志条目。 日志结构如图6所示，条目按序编号，包含创建时的任期号及待执行指令。日志条目在满足一定条件时变为可提交状态，即安全地应用到状态机中。领导人决定何时提交日志条目，Raft算法保证所有提交条目持久化并最终被执行。日志条目在被复制到多数服务器时即被提交，包括前任领导人创建的条目。领导人追踪最大已提交条目索引，并在附加条目RPC中包含该索引，使跟随者同步应用已提交条目。 Raft的日志机制维持不同服务器日志之间的高层次一致性，简化系统行为并增强可预测性，是安全性的重要组成部分。关键特性是若两日志条目索引和任期号相同，则它们存储相同指令，并且前序条目也相同。。这是因为日志匹配特性，领导人最多在一个任期内特定索引创建日志条目，且日志条目位置固定不变。附加条目RPC包含前一条目的索引和任期号，若跟随者找不到匹配条目则拒绝，确保日志匹配特性。 正常运行时，领导人与跟随者日志一致，但在领导人崩溃后可能出现不一致，如图7所示。领导人通过强制跟随者复制自己的日志解决不一致，覆盖冲突条目。领导人维护nextIndex记录每个跟随者下一个待发送条目索引，初始化为自身最后条目索引+1。当一致性检查失败，领导人就会减小nextIndex直至找到共同点，删除跟随者冲突条目并发送自身条目。成功后，跟随者日志与领导人保持一直。 算法可优化减少拒绝次数，跟随者可返回冲突条目任期号及对应最小索引，领导人据此一次性跳过冲突任期所有条目。但实践中，这种优化可能非必需，因不一致性罕见且涉及条目不多。 通过日志复制机制，领导人无需特殊操作即可恢复一致性，只需执行常规流程，日志在响应一致性检查失败时自动对齐。领导人从不覆盖或删除自身日志，确保一致性。日志复制机制体现了高可用性、快速复制及对慢跟随者的容忍度。 ","date":"2024-07-19","objectID":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/:5:3","tags":["分布式系统","Raft"],"title":"【论文阅读笔记】In Search of an Understandable Consensus Algorithm (Extended Version)","uri":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/"},{"categories":["系统架构","论文阅读"],"content":"5.4 安全性 在 Raft 算法中，尽管已经描述了领导人的选举和日志的复制过程，但这些机制本身并不足以保证所有状态机按照相同的顺序执行相同的指令。存在一种情况，即一个跟随者在领导人提交了若干日志条目后变得不可用，之后这个跟随者可能被选举为新的领导人，并可能覆盖这些已提交的日志条目，导致不同状态机可能执行不同的指令序列。 为了解决这个问题，Raft 算法在领导选举时增加了限制，确保任何给定任期的领导人都拥有之前任期的所有已提交的日志条目（即领导人完整特性）。这一限制简化了提交规则，并为复制状态机的正确行为提供了证明。 5.4.1 选举限制 在基于领导人的一致性算法中，领导人都必须存储所有已提交的日志条目。Raft 算法通过简单的方法确保新选举的领导人拥有之前任期中所有已提交的日志条目，避免了额外的日志传输机制和复杂性。 Raft 使用投票机制来阻止未包含所有已提交日志条目的候选人赢得选举。候选人必须获得集群中大多数节点的同意，这确保了所有已提交的日志条目至少存在于一个节点上。如果候选人的日志至少和大多数的服务器节点一样新，那么他一定持有了所有已经提交的日志条目。请求投票RPC 实现了这样的限制：RPC 中包含了候选人的日志信息，然后投票人会拒绝掉那些日志没有自己新的投票请求。 Raft通过比较日志中最后一条条目的任期号和索引来判断哪个日志更“新”。 如果任期号不同，任期号更大的日志更“新”。 如果任期号相同，则条目更多（索引值更大）的日志更“新”。 5.4.2 提交之前任期内的日志条目 领导人在当前任期内创建的日志条目，当被复制到大多数服务器上时，则可认为是可提交的。如果一个领导人在提交日志条目之前崩溃了，未来后续的领导人会继续尝试复制这条日志记录。然而，对于之前任期中的日志条目，即使它们已经被复制到大多数服务器上，也不能简单地通过副本数量来确定它们是否已提交，如图8所示。这是因为在领导人崩溃和重新选举的过程中，可能会出现新的领导人并不包含所有之前任期的日志条目，这可能导致已复制的日志被覆盖。 为了避免这种情况，Raft不会通过副本数目去提交一个之前任期内的日志条目，只有当前任期的日志条目才能通过复制到大多数服务器来提交。一旦当前任期的日志条目被提交，根据日志匹配特性，之前任期的日志条目也会被间接的提交。 Raft 在处理日志时保留了原始的任期号，这虽然增加了提交规则的复杂性，但简化了日志的识别和管理。与其它算法不同，Raft 在复制之前任期日志不需要使用新的任期号，在提交前不用发送冗余的日志条目来重新编号， 5.4.3 安全性论证 在 Raft 算法中，领导人完整性特性是确保一致性的关键。这一特性保证了在任期 T 的领导人提交的日志条目，必须被存储在未来任期的领导人日志中。 设任期U（\u003eT）的领导人U缺失该条目，如下图所示，在U的选举中，至少存在一个节点（如S3）同时持有T任期的日志并投票给U。 关键点：此节点在投票前接受T任期已提交日志，且在投票时仍保存该条目。 矛盾一：此节点把自己选票投给领导人 U 时，说明领导人 U 的日志必须和投票者自己一样新。但假设U不包含T任期提交的日志。 矛盾二：若U最后日志任期大于此节点，则前领导人必含提交日志，由日志匹配特性知U亦应含该日志，产生矛盾。 故所有大于T任期的领导人必定包含T任期中所有已提交日志条目。日志匹配原则确保未来领导人同样包含间接提交的条目。领导人完整性特性支撑状态机安全特性，防止不同日志在相同索引值上被应用。 ","date":"2024-07-19","objectID":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/:5:4","tags":["分布式系统","Raft"],"title":"【论文阅读笔记】In Search of an Understandable Consensus Algorithm (Extended Version)","uri":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/"},{"categories":["系统架构","论文阅读"],"content":"5.5 追随者和候选人崩溃 崩溃影响：崩溃导致后续RPC失败，影响通信和一致性。 处理机制： 无限重试：系统通过持续重试RPC来处理这类失败。 重启恢复：当崩溃服务器重启，未完成的RPC能够继续执行至成功。 RPC幂等性保障：指多次执行相同操作产生的效果等同于一次执行，故重复执行RPC也不会引起不一致或错误状态。 ","date":"2024-07-19","objectID":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/:5:5","tags":["分布式系统","Raft"],"title":"【论文阅读笔记】In Search of an Understandable Consensus Algorithm (Extended Version)","uri":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/"},{"categories":["系统架构","论文阅读"],"content":"5.6 时间和可用性 Raft 算法的一个核心要求是安全性不应依赖于时间，即系统不应因为事件的快慢而产生错误的结果。然而，系统的可用性，即及时响应客户端的能力，不可避免地依赖于时间因素。特别是在领导人选举过程中，时间要求尤为关键。 关键的时间因素有： 广播时间 (Broadcast Time)：服务器向集群成员并行发送RPC并接收响应的平均时间。 选举超时时间 (Election Timeout)：跟随者等待领导人心跳的最长时限，过期则发起选举。 平均故障间隔时间 (Mean Time Between Failures, MTBF)：服务器两次故障之间的平均时间。 Raft 要求满足以下时间不等式以保证系统正常运行： $\\text{Broadcast Time}\\ll\\text{Election Timeout}\\ll\\text{MTBF}$ 广播时间和平均故障间隔时间是由系统决定的，但是选举超时时间是我们自己选择的。广播时间受存储技术影响，范围约为$[0.5,20]\\text{ ms}$，选举超时时间基于广播时间设置，要比广播时间大几个数量级，一般在$[10,500]\\text{ ms}$，而MTBF通常数月以上，远大于选举超时时间，满足系统稳定运行需求。 ","date":"2024-07-19","objectID":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/:5:6","tags":["分布式系统","Raft"],"title":"【论文阅读笔记】In Search of an Understandable Consensus Algorithm (Extended Version)","uri":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/"},{"categories":["系统架构","论文阅读"],"content":"6 集群成员变化 Raft 算法在设计时假设集群配置是固定的，但在实际应用中，集群配置需要动态调整，如替换宕机的机器或改变复制级别。直接更改集群配置存在风险，可能导致同一任期内两个领导人同时存在，因此需要一种安全的配置变更机制。为了确保配置变更的安全性，必须采用两阶段方法。在Raft中，集群切换到一个过渡配置，称为联合共识，结合了新旧配置： 日志条目被复制给新旧配置的所有服务器。 新旧配置的服务器都可以成为领导人。 达成一致（选举和提交）需要分别在新旧配置上获得大多数支持。 联合共识允许独立的服务器在不影响安全性的前提下，在不同的时间进行配置转换过程。此外，联合共识可以让集群在配置转换的过程中依然响应客户端的请求。配置变更过程如下图所示： 请求接收：领导人接收到从 $C_\\text{old}$ 到 $C_\\text{new}$ 的配置变更请求。 联合共识日志条目：领导人创建 $C_\\text{old,new}$ 配置条目并将其作为日志条目存储和复制。 提交联合共识：一旦 $C_\\text{old,new}$ 被提交，新旧配置都不能单方面做出决定，只有拥有 $C_\\text{old,new}$ 日志条目的服务器才能成为领导人。 新配置日志条目：这个时候，领导人创建 $C_\\text{new}$ 配置条目并复制给集群，最终在 $C_\\text{new}$ 规则下提交，旧的配置变得无关紧要。 ","date":"2024-07-19","objectID":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/:6:0","tags":["分布式系统","Raft"],"title":"【论文阅读笔记】In Search of an Understandable Consensus Algorithm (Extended Version)","uri":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/"},{"categories":["系统架构","论文阅读"],"content":"7 日志压缩 Raft 算法通过复制日志来维护一致性，但随着时间的推移，日志会不断增长，占用大量空间并影响性能。为了解决这个问题，Raft 使用快照技术压缩日志，通过存储系统状态至持久化存储，随后丢弃先前日志。 下图展示了快照的基本思想，每个服务器独立创建快照，只包含已提交的日志条目，主要的工作包括将状态机的状态写入快照中。Raft也包含一些少量元数据到快照中：最后索引和任期号。保留这些数据是为了支持一致性检查，允许服务器清除过期日志。 领导人偶尔也需要通过安装快照RPC将快照分块发送给一些落后的追随者，追随者收到快照后，他必须自己决定对于已经存在的日志该如何处理，一般来说是覆盖冲突日志，保留后续未冲突日志。 在快照时，有两个性能相关的因素需要考虑： 创建时机：服务器需要决定何时创建快照，以避免频繁写入或存储空间耗尽。Raft 的策略是当日志大小达到一个阈值之后，就开始快照。 写入时间：写入快照可能需要显著时间，为了不影响正常的操作，应通过写时复制技术避免影响正常操作。 ","date":"2024-07-19","objectID":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/:7:0","tags":["分布式系统","Raft"],"title":"【论文阅读笔记】In Search of an Understandable Consensus Algorithm (Extended Version)","uri":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/"},{"categories":["系统架构","论文阅读"],"content":"8 客户端交互 Raft中的客户端发送所有请求给领导人。客户端初始化时随机选择服务器，非领导人服务器会拒绝客户端请求并提供最近接收到的领导人信息。如果领导人崩溃后，客户端请求超时，重启随机选择过程直至找到新领导人。 Raft目标是要实现线性化语义，由于Raft是可能同时执行同一条命令多次的，为了解决这个问题，客户端为每条指令分配唯一序列号，状态机跟踪每个客户端的最新序列号和相应响应。如果接收到的指令序列号已经被执行，状态机直接返回结果而不重新执行。 只读操作可以不写入日志直接处理。但不记录日志可能导致返回脏数据，即领导人在不知情的情况下被新领导人取代。线性化的读操作必须不能返回脏数据，Raft 需要使用两个额外的措施在不使用日志的情况下保证这一点。 最新提交日志信息：领导人需要知道任期内所有被提交的日志条目。Raft 通过让领导人在任期开始时提交一个空白日志条目来实现。 领导人状态检查：在处理只读请求前，领导人必须检查自己是否已被废黜。Raft 通过让领导人在响应只读请求前与集群大多数节点交换心跳信息来处理这个问题。 ","date":"2024-07-19","objectID":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/:8:0","tags":["分布式系统","Raft"],"title":"【论文阅读笔记】In Search of an Understandable Consensus Algorithm (Extended Version)","uri":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/"},{"categories":["系统架构","论文阅读"],"content":"9 总结 Raft 是一种用于管理复制日志的一致性算法，旨在解决分布式系统中的一致性问题。它通过领导人选举、日志复制和安全性保证来实现系统的高可用性和一致性。 Raft 的五大保证： 选举安全性：在任一给定任期内，最多只能有一个领导人被选举出来。 领导人只追加：领导人不会覆盖或删除其日志中的条目；它只追加新的条目。 日志匹配：如果两个日志在相同索引和任期号处含有相同的条目，则在该索引之前的所有条目都是相同的。 领导人完整性：如果一个日志条目在给定任期被提交，那么该条目将出现在所有更高编号任期的领导人的日志中。 状态机安全性：如果一个服务器将某个索引的日志条目应用到其状态机中，其他服务器不会对该索引应用不同的日志条目。 ","date":"2024-07-19","objectID":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/:9:0","tags":["分布式系统","Raft"],"title":"【论文阅读笔记】In Search of an Understandable Consensus Algorithm (Extended Version)","uri":"/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0in-search-of-an-understandable-consensus-algorithm-extended-version/"},{"categories":["深度学习","论文阅读","CAD"],"content":"1 引言 现有3D生成模型： 3D点云：大量离散的3D点组成的数据表示形式； 多边形网格：一系列相连的多边形组成的3D模型； 水平集场：使用数值函数来表示物体的边界，并根据函数值的正负来确定物体内部和外部的区域； 仅能创建3D形状的离散表示，都缺少生成3D形状设计本质的能力—绘制过程。 作者提出了一个深度生成网络DeepCAD，能够输出CAD工具（如AutoCAD）中用于构建3D形状的操作序列，这是CAD模型的“绘制”过程。 这是CAD设计的生成模型的第一个工作，挑战在于CAD设计的顺序和参数化性质。CAD模型由一系列几何操作（例如，曲线草图、拉伸、圆角、布尔、倒角）组成，每个操作由某些不规则的参数（离散或连续）控制。故以前开发的3D生成模型不适合CAD模型生成。 为了克服这些挑战，需要寻求一种能够协调CAD模型中的不规则性的表示，作者考虑最常用的CAD操作（命令），并将它们统一在一个公共结构中，该结构对其命令类型、参数和序列顺序进行编码，通过类比CAD命令序列和自然语言，作者提出了一种基于Transformer网络的自编码器，它将CAD模型嵌入到潜在空间中，然后将潜在向量解码成CAD模型。【code】 为了训练这个自编码器，作者还创建了一个新的CAD命令序列数据集，以促进未来基于学习的CAD设计的研究。【dataset】 下图是DeepCAD的生成演示。 ","date":"2024-07-17","objectID":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/:1:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】DeepCAD: A Deep Generative Network for Computer-Aided Design Models","uri":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/"},{"categories":["深度学习","论文阅读","CAD"],"content":"2 相关工作 参数化形状推断 深度学习的进步使得神经网络模型能够分析几何数据，推断出参数化形状。具体工作如下： ParSeNet：将3D点云分解为一组参数化的表面补丁。 PIE-NET：从3D点云中提取参数化的边界曲线。 UV-Net 和 BrepNet：专注于编码参数化模型的边界曲线和表面。 Li等人：训练了一种神经网络，在合成数据上将2D用户草图转换为CAD操作。 Xu等人：应用神经引导搜索，从参数化实心形状中推断出CAD建模序列。 3D形状生成模型 大多数现有方法生成离散形式的3D形状，如体素化形状、点云、多边形网格、隐式签名距离场。生成的形状可能存在噪声，缺乏锐利的几何特征，不便于用户编辑。新方法使用神经网络模型生成3D形状作为一系列几何操作。 CSGNet：基于体素化形状输入推断CSG操作序列。 UCSG-Net：无监督情况下推断CSG树。 领域特定语言（DSLs）：通过DSLs合成3D形状，如ShapeAssembly。 作者工作：自编码器网络输出一系列CAD操作指定的CAD模型。CAD模型成为工业生产标准形状表示，可以直接导入CAD工具进行用户编辑，也可转换为点云和多边形网格。这是第一个直接生成CAD设计的生成模型。 基于Transformer的模型 Transformer网络作为基于注意力的构建模块，成功应用于自然语言处理、图像处理和其他类型数据。并行工作在约束的CAD草图生成上也依赖于Transformer网络。 与作者工作相关的还有DeepSVG-用于生成可缩放矢量图（SVG）图像的Transformer网络。SVG图像由参数化原语（如直线和曲线）描述，原语无特定顺序或依赖关系。 与SVG不同，CAD命令在3D中描述，可以是相互依赖的，必须遵循特定顺序。所以需要寻求一种新的方法在基于Transformer的自编码器中编码CAD命令及其顺序。 ","date":"2024-07-17","objectID":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/:2:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】DeepCAD: A Deep Generative Network for Computer-Aided Design Models","uri":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/"},{"categories":["深度学习","论文阅读","CAD"],"content":"3 方法 DeepCAD围绕对CAD命令序列的新表示方法（3.1.2），这种CAD表示方法特别适合于输入到神经网络中。此外，这种表示法还引导出一个自然的训练目标函数（3.4）。为了训练DeepCAD，作者创建了一个新数据集，其规模远远大于同类数据集（3.3）。 ","date":"2024-07-17","objectID":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/:3:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】DeepCAD: A Deep Generative Network for Computer-Aided Design Models","uri":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/"},{"categories":["深度学习","论文阅读","CAD"],"content":"3.1 神经网络的CAD表示 CAD 模型提供了两个层次的表示。 在用户交互层面，CAD 模型被描述为用户在 CAD 软件中创建实心形状时执行的一系列操作，例如用户在二维平面上绘制一个闭合曲线轮廓，然后将其拉伸成三维实心形状，再通过布尔运算等进行处理。我们将这种规范称为 CAD 命令序列。 在命令序列背后，是 CAD 模型的内核表示，广为人知的是边界表示（B-rep）。给定一个命令序列，其 B-rep 会自动计算出来，通常通过行业标准库 Parasolid。它由拓扑组件及其连接组成，以形成一个实心形状。 我们的目标是生成 CAD 命令序列的模型，而不是 B-rep。这是因为 B-rep 是命令序列的抽象：命令序列可以很容易地转换为 B-rep，但反之则很难，因为不同的命令序列可能会生成相同的 B-rep。此外，命令序列是人类可理解的，便于编辑和应用于各种下游任务。 3.1.1 CAD命令的规范 CAD 工具支持丰富的命令集，作者仅考虑了一组常用的命令，这些命令分为两类：草图和拉伸。 尽管概念上简单，但它们足够表达生成各种形状。 草图命令用于在三维空间中的二维平面上指定闭合曲线，每个闭合曲线称为一个环，多个环形成一个闭合区域，称为轮廓。我们的表示方法中，一个轮廓由其边界上的环列表描述（如Figure 2中的“Sketch 1”）；一个环总是以指示命令开始，后跟一系列曲线命令。我们列出环上的所有曲线，并按逆时针顺序排列，开始点为最左下角的曲线。实际中，我们考虑三种最常用的曲线命令：画直线、弧线和圆。这些命令占了我们大规模现实数据集中 92% 的比例。 每个曲线命令由其曲线类型（$t_i\\in {\\langle\\text{SQL}\\rangle,\\text{L,A,R}}$）和参数（Table 1）描述，曲线参数指定了曲线在草图平面的局部参考框架中的二维位置。由于每个环中的曲线是一个接一个连接的，为了简洁，我们从参数列表中排除了曲线的起始位置；第一条曲线总是从草图平面的原点开始，原点的世界空间坐标在拉伸命令中指定。简言之，一个草图轮廓由一个环列表描述（$S=[Q_1,\\dots,Q_N]$），每个环$Q_i$由一系列从指示命令开始的曲线组成，例如$Q_i=[\\langle\\text{SQL}\\rangle, C_1,\\dots,C_{n_i}]$，每个曲线命令$C_j=(t_j,p_j)$指定曲线类型$t_j$及其形状参数$p_j$。 拉伸命令有两个目的。 它将草图轮廓从二维平面拉伸成三维实体，拉伸类型可以是单向、对称或双向。 它通过布尔运算指定如何将新拉伸的三维实体与先前创建的形状合并：创建新实体，或者与现有实体连接、切割或相交。 拉伸命令还需要定义草图平面的三维方向和其二维局部参考框架，这是通过旋转矩阵（Table 1中$(\\theta,\\gamma,\\phi)$参数确定）定义的（为了跟平面局部参考系对齐，并将$z$轴与平面的法线方向对齐）。命令参数包括一个拉伸轮廓的比例因子$s$。 通过这些命令，我们将一个 CAD 模型$M$描述为交替出现的曲线命令和拉伸命令序列。换句话说$M=[C_1,\\dots,C_{N_c}]$，其中每个$C_i=(c_i,p_i)$指定命令类型和参数。 3.1.2 网络友好的表示 我们的 CAD 模型 M 的规范类似于自然语言，词汇表由一系列 CAD 命令组成，形成句子。句子的主语是草图轮廓；谓语是拉伸。这种类比表明我们可以利用在自然语言处理中成功的网络结构（如 Transformer 网络，LLMs）来实现我们的目标。 然而，CAD 命令在几个方面与自然语言不同。每个命令有不同数量的参数。在某些命令（例如拉伸）中，参数是连续值和离散值的混合，参数值跨越不同范围。这些特性使得命令序列不适合直接用于神经网络。 为了克服这一挑战，我们对命令序列的维度进行正则化。 首先，对于每个命令，其参数堆叠成一个 $16×1$ 的向量，其元素对应于Table 1中所有命令的集合参数（例如$p_i=[x,y,\\alpha,f,r,\\theta,\\phi,\\gamma,p_x,p_y,p_z,s,e_1,e_2,b,u]$）。每个命令的未使用参数设置为 -1。 接着，我们固定每个 CAD 模型 $M$ 的命令总数 $N_c$，并通过添加空命令来填充 CAD 模型的命令序列，直到序列长度达到 $N_c$。我们选择 $N_c = 60$，这是训练数据集中出现的最大命令序列长度。 此外，我们通过量化连续参数来统一连续和离散参数。为此，我们将每个 CAD 模型规范化到一个 $2×2×2$ 的立方体内；我们还将每个草图轮廓规范化到其边界框内，并在拉伸命令中包括一个比例因子$s$来恢复规范化轮廓到其原始大小。这种规范化限制了连续参数的范围，使我们能够将其值量化为 $256$ 个级别，并使用 $8$ 位整数表示。结果是，所有命令参数都只有离散值集合。参数量化不仅是训练基于 Transformer 网络的常见实践，对于 CAD 模型来说，它对于提高生成质量尤为重要。在 CAD 设计中，必须遵循某些几何关系，例如平行和垂直的草图线条。然而，如果生成模型直接生成连续参数，通过参数回归获得的值容易产生错误，破坏这些严格的关系。相反，参数量化使网络能够将参数“分类”到特定级别，从而更好地遵循学习到的几何关系。 作者在 4.1 中通过消融研究实验证明对 CAD 命令表示选择的正确性。 ","date":"2024-07-17","objectID":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/:3:1","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】DeepCAD: A Deep Generative Network for Computer-Aided Design Models","uri":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/"},{"categories":["深度学习","论文阅读","CAD"],"content":"3.2 CAD模型的自编码器 DeepCAD的网络架构如下： 一旦训练完成，网络的解码器部分将自然地作为 CAD 生成模型。我们的自编码器基于 Transformer 网络，受其在处理序列数据方面成功的启发。自编码器输入一个 CAD 命令序列$M = [C1,\\dots , C_{N_c}]$，其中 $N_c$ 是固定数量。 首先，每个命令 $C_i$ 被分别投射到维度为 $d_E = 256$ 的连续嵌入空间。然后，将所有嵌入组合起来输入编码器 $E$，输出一个潜在向量 $z\\in \\mathbb{R}^{256}$。解码器以潜在向量 $z$ 作为输入，输出生成的 CAD 命令序列 $\\hat{M}$。 嵌入部分 与自然语言处理的方法类似，我们首先将每个命令 $C_i$ 投射到一个公共嵌入空间。然而，不同于自然语言中的词语，一个 CAD 命令 $C_i = (t_i, p_i)$ 有两个部分：命令类型 $t_i$ 和参数 $p_i$。因此，我们将 $C_i$ 的嵌入计算为三个嵌入的总和，即 $$ e(C_i) = e^\\text{cmd}_i + e^{\\text{param}}_i + e^\\text{pos}_i\\in \\R^{d_E}, $$ 第一个嵌入 $e^{\\text{cmd}}_i$ 表示命令类型 $t_i$，由 $e^\\text{cmd}_i=W_\\text{cmd} \\delta_i^c$ 给出。这里 $W_\\text{cmd}\\in\\R^{d_E\\times 6}$ 是一个可学习矩阵，$\\delta_i^c\\in \\R^6$ 是一个指示命令类型 $t_i$ 的独热向量。 第二个嵌入$e^{\\text{param}}_i$ 考虑命令参数。每个命令有 $16$ 个参数，每个参数被量化为一个 $8$ 位整数。我们将这些整数转换为维度为 $2^8+1=257$ 的独热向量$\\delta^p_{i,j}(j=1\\dots16)$，并将所有独热向量堆叠成矩阵$\\delta^p_i\\in\\R^{257\\times16}$。然后使用另一个可学习矩阵 $W_\\text{param}^b\\in\\R^{d_E\\times 257}$ 单独嵌入每个参数，并通过线性层 $W_\\text{param}^a\\in\\R^{d_E\\times 16d_E}$组合这些单独的嵌入，即 $$ e^{\\text{param}}_i=W_\\text{param}^a\\text{flat}(W_\\text{param}^b\\delta^p_i), $$ 其中$\\text{flat}(\\cdot)$将输入矩阵展平为向量 最后，位置嵌入 $e^\\text{pos}_i$ 表示命令 $C_i$ 在整个命令序列中的索引，由 $e^\\text{pos}_i = W_\\text{pos}\\delta_i$ 定义，其中 $W_\\text{pos}\\delta_i\\in\\R^{d_E\\times N_c}$ 是一个可学习矩阵，$\\delta_i\\in\\R^{N_c}$ 是一个在索引 $i$ 处填充 $1$ 其他位置填充$0$的独热向量。 编码器 编码器 $E$ 由四层 Transformer 块组成，每层有八个注意力头和 $512$ 的前馈维度。编码器将嵌入序列 $[e_1, \\dots, e_{N_c}]$ 作为输入，输出向量 $[e’_1,\\dots, e’_{N_c}]$，每个向量的维度为 $d_E = 256$。输出向量最终被平均以生成一个 $d_E$ 维的潜在向量 $z$。 解码器 解码器 $D$ 也建立在 Transformer 块上，具有与编码器相同的超参数设置。它以学习到的常量嵌入为输入，同时关注潜在向量 $z$。最后一个 Transformer 块的输出被送入线性层，以预测 CAD 命令序列 $\\hat{M} = [ \\hat{C}_1,\\dots, \\hat{C}_{N_c}]$，包括每个命令的命令类型 $\\hat{t}_i$ 和参数 $\\hat{t}_i$。与自然语言处理中常用的自回归策略不同，我们采用前馈策略，模型的预测可以分解为 $$ p(\\hat{M}|z,\\Theta)=\\prod_{i=1}^{N_c}p(\\hat{t}_i,\\hat{p}_i|z,\\Theta), $$ 其中$\\Theta$表示解码器的网络参数。 ","date":"2024-07-17","objectID":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/:3:2","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】DeepCAD: A Deep Generative Network for Computer-Aided Design Models","uri":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/"},{"categories":["深度学习","论文阅读","CAD"],"content":"3.3 CAD数据集的创建 现有数据集： ABC数据集：虽包含百万级别的CAD设计，但这些设计采用B-rep格式，缺乏如何通过CAD操作构建设计的具体信息； Fusion 360 Gallery数据集：虽然提供了CAD设计及其构建指令序列，但规模仅有约8000个设计，不足以训练出泛化能力强大的生成模型。 鉴于此，作者决定创建一个全新的、大规模的数据集，该数据集不仅数量庞大，还提供了CAD命令序列，旨在满足训练自动编码网络的需求，并为未来的研究提供资源。 新数据集构建过程始于ABC数据集： 利用其中每个CAD模型链接至Onshape的原始设计。 接着，通过Onshape的FeatureScript语言（一种专门用于解析CAD操作与参数的领域特定语言），作者筛选出仅使用“草图”和“拉伸”操作的模型，舍弃了那些采用更复杂操作的模型。 对于符合条件的模型，作者编写了一段FeatureScript程序来提取其草图轮廓和拉伸操作，并将其转化为Table 1中列出的命令格式。 最终，作者收集到了总计178,238个以CAD命令序列形式描述的CAD设计，这个数量级远超现有同类型数据集。数据集进一步被随机划分为90%的训练集、5%的验证集以及5%的测试集，以备训练和测试之用。 ","date":"2024-07-17","objectID":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/:3:3","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】DeepCAD: A Deep Generative Network for Computer-Aided Design Models","uri":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/"},{"categories":["深度学习","论文阅读","CAD"],"content":"3.4 训练和运行时生成 3.4.1 训练阶段 我们利用构建的数据集对自编码器网络进行训练，采用标准的交叉熵损失函数作为优化目标。具体而言，定义预测的CAD模型$\\hat{M}$与真实模型$M$之间的损失函数为： $$ \\mathcal{L} = \\sum_{i=1}^{N_c} \\ell(\\hat{t}_i,t_i) + \\beta \\sum_{i=1}^{N_c} \\sum_{j=1}^{N_p} \\ell(\\hat{p}_{i,j},p_{i,j}), $$ 其中，$\\mathcal{L}(·, ·)$表示标准的交叉熵损失，$N_p$每个命令的参数数量（在我们的示例中，$N_p = 16$），而$\\beta$是一个权重项，用于平衡两项损失（在我们的示例中，$\\beta = 2$）。值得注意的是，在真实的命令序列中，有些命令是空的（即填充命令$\\langle \\text{EOS} \\rangle$），而有些命令参数未使用（标记为$-1$）。在这种情况下，这些元素对上述损失函数中的求和部分不做贡献。 训练过程中，我们使用Adam优化器，初始学习率为$0.001$，并设置线性预热期为前$2000$步。所有Transformer模块的Dropout率设定为$0.1$，并在反向传播中应用梯度裁剪值为$1.0$。我们以批处理大小$512$对网络进行$1000$轮的训练。 3.4.2 CAD生成阶段 当自编码器训练完成后，我们可以使用一个$256$维的潜在向量$z$来表示一个CAD模型。为了自动生成CAD模型，我们运用latent-GAN技术于已学得的潜在空间上。生成器和判别器都是简单的多层感知机（MLP）网络，各自包含四层隐藏层，它们的训练采用带有梯度惩罚的Wasserstein-GAN策略。最后，生成CAD模型时，我们从多元高斯分布中采样一个随机向量，并将其输入GAN的生成器中。GAN的输出是一个潜在向量$z$，随后将其输入基于Transformer的解码器，从而生成CAD模型。 ","date":"2024-07-17","objectID":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/:3:4","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】DeepCAD: A Deep Generative Network for Computer-Aided Design Models","uri":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/"},{"categories":["深度学习","论文阅读","CAD"],"content":"4 实验 我们从两个角度评估我们的自编码器网络：CAD模型的自编码性能（4.1）和潜在空间形状生成（4.2）。我们还讨论了可以受益于CAD生成模型的潜在应用（4.3）。由于之前没有针对CAD设计的生成模型，因此无法直接进行比较。我们的目标是通过一系列消融实验理解模型在不同指标下的性能，并验证我们的算法选择。 4.0.3 CAD模型的自编码 自编码性能通常用于指示生成模型表达目标数据分布的程度。我们使用自编码器网络对训练数据集中不存在的CAD模型$M$进行编码，然后将所得的潜在向量解码成CAD模型$\\hat{M}$。通过比较$M$和$\\hat{M}$的差异来评估自编码器的性能。 指标 命令准确率（$\\text{ACC}_{\\text{cmd}}$）：衡量预测的CAD命令类型的正确性； $$ \\text{ACC}_{\\text{cmd}}=\\frac{1}{N_c} \\sum_{t=1}^{N_c}\\mathbb{I}[t_i=\\hat{t_i}] , $$ 参数准确率（$\\text{ACC}_\\text{param}$）：衡量命令参数的正确性； $$ \\text{ACC}_\\text{param} = \\frac{1}{K} \\sum_{i=1}^{N_c} \\sum_{j=1}^{\\left| \\hat{p}_i \\right|} \\mathbb{I}[|p_{i,j} - \\hat{p}_{i,j}| \u003c \\eta]\\mathbb{I}[t_i = \\hat{t}_i], $$ 其中$K=\\sum_{i=1}^{N_c}\\mathbb{I}[t_i=\\hat{t}_i]|p_i|$是所有正确恢复命令中的参数总数。注意$p_{i,j}$和$\\hat{p}_{i,j}$都被量化为$8$位整数，选择$\\eta$是作为考虑参数量化的容差阈值，在实践中，我们选择了$\\eta=3$（256个级别） 此外，我们使用Chamfer距离（CD）来评估3D几何体的质量，通过均匀采样2000个点来计算参考形状和生成形状之间的CD。另外，我们还报告无效率，即无法转换为点云的输出CAD模型的百分比。 比较方法 由于缺乏现有的CAD生成模型，我们比较了几种模型变体以验证我们的数据表示和训练策略。具体包括以下几种变体：Alt-Rel、Alt-Trans、Alt-ArcMid、Alt-Regr和Ours+Aug。每种变体在数据表示或训练策略上有所不同。 总体而言，Ours+Aug（即使用合成数据增强训练）表现最佳，表明随机组合数据可以提高网络的泛化能力。Alt-ArcMid的性能与Ours相似，说明中点表示法是表示弧的可行替代方法。Alt-Trans在CD方面略逊于Ours。虽然Alt-Rel的参数准确率（ACCparam）高于Ours，但其CD分数较大且有时会出现无效拓扑，例如在Figure 4中第二行中的黄色模型有两个三角形环路相互相交，导致拓扑无效，这是由于预测曲线位置的误差累积导致的。Alt-Regr由于不量化连续参数，误差较大，可能破坏关键的几何关系，如平行边和垂直边，例如Figure 4中的第一行。 我们还验证了我们自编码器的泛化，在其他更小的数据集（来自Autodesk Fusion 360）上评估它表现出良好的泛化能力，实现了可比较的定量性能。 ","date":"2024-07-17","objectID":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/:4:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】DeepCAD: A Deep Generative Network for Computer-Aided Design Models","uri":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/"},{"categories":["深度学习","论文阅读","CAD"],"content":"4.1 形状生成 由于CAD设计没有现成的生成模型，我们选择将我们的模型与l-GAN进行比较，l-GAN是一种被广泛研究的点云三维形状生成模型。我们注意到，我们的目标并不是要显示出孰优孰劣，因为这两种生成模型有不同的应用领域。相反，我们证明了我们的模型即使在点云生成模型的度量下也能产生可比的形状质量。 此外，如Figure 5所示，我们模型中的形状具有更清晰的几何细节，并且可以轻松地进行用户编辑(Figure 7)。 为了与点云生成模型进行定量比较，我们遵循l-GAN中使用的指标。这些度量标准用于衡量两组3D点云形状之间的差异，即真实形状集合$S$和生成形状集合$G$。 覆盖率（COV）：衡量$S$中的形状有多少可以很好地近似为G中的形状； 最小匹配距离（MMD）：表示$S$和$G$中两个点云之间的最小匹配距离来衡量$G$的保真度； Jensen-Shannon散度(JSD)：衡量$S$和$G$的点云分布的相似性 然后，我们将真实和生成的CAD模型转换为点云，并评估这些度量标准。结果如下： 表明我们的方法在点云度量标准方面与l-GAN具有可比性的性能。然而，由于其参数化表示，CAD模型具有比点云更平滑的表面和更锐利的几何特征。 ","date":"2024-07-17","objectID":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/:4:1","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】DeepCAD: A Deep Generative Network for Computer-Aided Design Models","uri":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/"},{"categories":["深度学习","论文阅读","CAD"],"content":"4.2 未来应用 借助CAD生成模型，可以将点云（例如通过3D扫描获取的）重建为CAD模型，例如作者这里使用自编码器将CAD模型$M$编码为潜在向量$c$。然后，利用PointNet++编码器训练它将$M$的点云表示编码为相同的潜在向量$c$。在推断时，给定一个点云，我们使用PointNet++编码器将其映射到潜在向量，然后使用我们的自编码器解码为CAD模型。 生成的CAD模型可以直接导入CAD工具进行用户编辑。 ","date":"2024-07-17","objectID":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/:4:2","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】DeepCAD: A Deep Generative Network for Computer-Aided Design Models","uri":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/"},{"categories":["深度学习","论文阅读","CAD"],"content":"5 总结 作者提出了DeepCAD，第一个一个用于CAD设计的深度生成模型。几乎所有以前的3D生成模型都产生离散的3D形状，如体素、点云和网格。为此，作者还引入了一个大型CAD模型数据集，每个模型都表示为一个CAD命令序列。 在构建CAD生成模型的过程中，作者的方法存在以下几个主要限制： 曲线命令类型有限：目前，作者仅考虑了三种最常用的曲线命令类型（直线、弧线和圆）。然而，其他曲线命令也可以轻松添加，例如可以通过三个控制点以及起点来指定的三次贝塞尔曲线，其参数结构可以按照3.1中描述的方式进行。 操作命令的局限性：虽然像旋转草图这样的操作可以类似于拉伸命令进行编码，但某些CAD操作（如倒角）作用于形状边界的部分，因此需要参考模型的B-rep（边界表示），而不仅仅是其他命令。将这些命令纳入生成模型仍需进一步研究。 拓扑有效性无法保证：并非每个CAD命令序列都能生成拓扑上有效的形状。作者的生成网络不能保证其输出的CAD序列的拓扑一致性。在实践中，生成的CAD命令序列很少失败，但随着命令序列变长，失败的可能性增加。 ","date":"2024-07-17","objectID":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/:5:0","tags":["Transformer","模型","人工智能","CAD"],"title":"【论文阅读笔记】DeepCAD: A Deep Generative Network for Computer-Aided Design Models","uri":"/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0deepcad/"},{"categories":["深度学习","论文阅读"],"content":"1 引言 循环神经网络(RNN)，特别是长短期记忆和门控循环神经网络（编码器-解码器架构），已成为序列建模和转换问题（如语言建模和机器翻译）的先进方法，众多研究在不断推动其发展。 但RNN通常沿输入和输出序列的符号位置进行计算，其固有的顺序性导致训练示例内难以并行化，在序列长度较长时，由于内存限制跨示例的批处理，这一问题更加突出。尽管近期通过一些技术改进了计算效率，但顺序计算的基本限制仍未改变。 且RNN使用共享权值矩阵，在面临较长序列时，会有梯度消失的问题(也可以说是后面词的梯度会覆盖前面的梯度)。即使后序的LSTM和GRU对这一部分做了改进，但也无法完全解决该问题。 注意力机制已成为各种序列建模和转换模型的重要组成部分，能在不考虑输入或输出序列距离的情况下对依赖关系进行建模，但在大多数情况下与循环网络结合使用。 作者提出了 Transformer 模型，该模型摒弃了循环单元和卷积单元，完全依赖注意力机制来建立输入和输出之间的全局依赖关系，允许更多的并行化。 ","date":"2024-07-07","objectID":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/:1:0","tags":["Transformer","模型","人工智能"],"title":"【论文阅读笔记】Attention Is All You Need","uri":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/"},{"categories":["深度学习","论文阅读"],"content":"2 背景 减少序列计算量和加速计算是序列处理模型中的基本思想。ByteNet和ConvS2S通过使用卷积神经网络并行计算，计算量和序列中位置的距离相关。ConvS2S是线性关系，而ByteNet是对数关系，使得长距离关系学习困难。Transformer将这个过程减少到常数规模，尽管降低了有效分辨率，但多头注意力机制弥补了这一点。 自注意力机制（内部注意力机制）为序列的不同位置分配权重，并学习表示向量，已在阅读理解、文本摘要等任务中表现出色。 端到端记忆网络通常基于循环注意力机制，已用于简单语言翻译等任务。而Transformer 是第一个完全依赖自注意力来计算其输入和输出表示的转换模型。 ","date":"2024-07-07","objectID":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/:2:0","tags":["Transformer","模型","人工智能"],"title":"【论文阅读笔记】Attention Is All You Need","uri":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/"},{"categories":["深度学习","论文阅读"],"content":"3 模型架构 Transformer中沿用了非常经典的编码器-解码器架构，编码器将输入的序列$(x_1,\\dots,x_n)$转化成一个表示向量$\\boldsymbol{z}=(z_1,\\dots,z_n)$，而编码器依据向量$\\boldsymbol{z}$逐步生成输出序列$(y_1,\\dots,y_m)$，并且模型在每个步骤中都是自回归的，会将先前生成的符号作为生成下一个的额外输入，例如这一步要生成$y_t$，要将$(y_1,\\dots,y_{t-1})$都拿到也作为输入。 同时Transformer模型在编码器和解码器中都使用堆叠自注意力机制和逐点全连接层，如下图的左半部分和右半部分所示。 ","date":"2024-07-07","objectID":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/:3:0","tags":["Transformer","模型","人工智能"],"title":"【论文阅读笔记】Attention Is All You Need","uri":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/"},{"categories":["深度学习","论文阅读"],"content":"3.1 编码器堆叠和解码器堆叠 编码器由 $6$ 个相同的层堆叠而成。每个层包含两个子层：多头自注意力机制和逐位置全连接前馈神经网络。每个子层都使用了残差连接，然后进行层规范化（防止模型过拟合）。假设每一层的输入是$x$，那么每一层的输出结果可以表示为： $$ \\text{LayerNorm}(x+\\text{Sublayer(x)}) $$ 其中 $\\text{SubLayer}$是当前子层本身实现的运算函数，比如注意力运算和全连接运算； 模型中的所有子层以及嵌入层的输出维度均为 $d_{\\text{model}} = 512$（便于残差连接）。 解码器同样由 6 个层组成。其结构与编码器类似，但多了一个对编码器输出进行关注的多头注意力子层。并且在自注意力子层中进行了修改，以防止信息左向流动。这种掩码机制，结合输出嵌入向量向后偏移一个位置，确保位置 $i$ 的预测仅依赖于位置小于 $i$ 的已知输出。 ","date":"2024-07-07","objectID":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/:3:1","tags":["Transformer","模型","人工智能"],"title":"【论文阅读笔记】Attention Is All You Need","uri":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/"},{"categories":["深度学习","论文阅读"],"content":"3.2 注意力机制 注意力机制就是对一系列的query和一系列的key-value对，我们需要确定对于每个query而言不同 value 的重要程度，而这个权重是根据 query 和key 的相关度计算得到的。 3.2.1 缩放的点积注意力机制 Transformer模型中使用的是缩放的点积注意力机制。在这种机制中，注意力计算涉及query和key的维度为 $d_k$ )，以及value的维度为 $d_v$ 。通过引入一个缩放因子$\\sqrt{d_k}$，可以控制注意力分布的稳定性和计算效率。 我们用向量化的方式可以将这种注意力机制的计算过程表示成： $$ \\text{Attention}(Q,K,V)=\\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V $$ 与传统的注意力机制相比，缩放的点积注意力计算速度更快。缩放参数用于调节注意力计算的规模，以确保对于不同大小的输入，注意力权重的计算结果都能保持在合理的范围内。特别是在$\\text{softmax}$函数的应用中，由于指数函数的快速增长特性，缩放可以有效防止某些权重过大，而其他权重接近零的情况，确保了计算结果的平稳性和有效性。 3.2.2 多头注意力机制 3.2.3 Transformer采用了多头注意力机制，将query、key和value进行$h$次投影，然后对$h$个投影并行计算注意力，再将这些结果组合并线性投影生成最终的多头注意力输出。多头注意力使模型能够共同关注不同表示子空间和不同位置的信息。 多头注意力机制的计算公式为： $$ \\operatorname{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\ldots, \\text{head}_h) W^O $$ 其中每个头的计算方式为： $$ \\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V) $$ 参数的维度如下： $( Q, K, V)$ 的输入维度为 $( d_{model} )$（通常为$512$） $W_i^Q \\in \\mathbb{R}^{d_{model} \\times d_k}, W_i^K \\in \\mathbb{R}^{d_{model} \\times d_k}, W_i^V \\in \\mathbb{R}^{d_{model} \\times d_v}, W^O \\in \\mathbb{R}^{hd_v \\times d_{model}}$ 作者在Transformer中设置 $h = 8$ 个头，每个头的维度为 $d_k = d_v = \\frac{d_{model}}{h} = 64$。 3.2.4 Transformer中注意力机制的应用 在解码器的“编码器-解码器注意力层”中，query 来自上一个解码器层，而 key 和值 value 来自编码器的输出。这使得解码器中的每个位置都可以参与到输入序列所有位置的注意力计算中。 编码器-解码器注意力层： 在这一层中，query 来自上一个解码器，而记忆 key 和 value 来自编码器的输出。这使得解码器中的每个位置都可以关注输入序列中的所有位置。 编码器中的自注意力层： 编码器包含自注意力层。在这种自注意力机制中，query, key 和 value 都来自同一位置，即编码器前一层的输出。这样，编码器中的每个位置都可以关注编码器前一层中的所有位置，从而捕捉输入序列中不同位置之间的全局依赖关系。 解码器中的自注意力层： 解码器中的自注意力层的key，value和query也是同源的。但为了保持自回归属性，防止序列中前面的内容被后面的内容所影响，解码器在自注意力计算中加入了掩码机制。具体来说，通过在缩放的点积注意力中，将$\\operatorname{softmax}$输入中对应非法连接的值设置为$-\\infin$，来屏蔽这些连接。 ","date":"2024-07-07","objectID":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/:3:2","tags":["Transformer","模型","人工智能"],"title":"【论文阅读笔记】Attention Is All You Need","uri":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/"},{"categories":["深度学习","论文阅读"],"content":"3.3 逐位置全连接前馈神经网络 ","date":"2024-07-07","objectID":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/:3:3","tags":["Transformer","模型","人工智能"],"title":"【论文阅读笔记】Attention Is All You Need","uri":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/"},{"categories":["深度学习","论文阅读"],"content":"3.4 Transformer中的逐位置全连接前馈神经网络 在Transformer中，逐位置全连接前馈神经网络用于增强模型对序列中每个位置信息的处理能力，这种网络结构包含两个线性变换层和$\\operatorname{ReLU}$激活函数，用于每个位置独立地进行相同的操作。其数学表示如下： $$ \\text{FFN}(x) = \\max(0, x W_1 + b_1) W_2 + b_2 $$ 虽然不同位置的线性变换相同，但各层使用的参数不同。其中，$x$ 是输入向量，维度为 $d_{\\text{model}} = 512$ ，而内层的维度为$d_{ff}=2048$，$W_1$ 和 $W_2$ 是两个线性变换的权重矩阵，$b_1$ 和 $b_2$ 是相应的偏置向量。这个结构类似于kernel size为1的卷积操作。 ","date":"2024-07-07","objectID":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/:3:4","tags":["Transformer","模型","人工智能"],"title":"【论文阅读笔记】Attention Is All You Need","uri":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/"},{"categories":["深度学习","论文阅读"],"content":"3.5 嵌入和Softmax 和其他序列转换模型类似，Transformer 使用学习得到的嵌入将输入的token和输出的token转换为维度为 $ d_{\\text{model}} $ 的向量。Transformer 还使用学习得到的线性变换和$\\text{softmax}$函数将解码器的输出转换为预测的下一个token的概率。在Transformer中两个嵌入层和$\\text{softmax}$之前的线性变换层之间共享相同的权重矩阵（减少模型的参数数量，降低过拟合的风险），同时在嵌入层中，我们将这些权重乘以 $\\sqrt{d_{\\text{model}}}$（缩放嵌入权重，防止梯度消失）。 ","date":"2024-07-07","objectID":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/:3:5","tags":["Transformer","模型","人工智能"],"title":"【论文阅读笔记】Attention Is All You Need","uri":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/"},{"categories":["深度学习","论文阅读"],"content":"3.6 位置编码 在Transformer模型中，由于没有循环和卷积单元，为了处理序列数据的位置信息，引入了位置编码。位置编码是为序列中的每个位置添加特定的向量表示，以便模型能够区分不同位置的token。在Transformer中的位置编码使用了sin函数和cos函数，这种方法不同于传统的学习得到的位置嵌入，而是采用固定的函数形式，即 这里的$\\text{pos}$表示位置而$i$表示维度，也就是对于位于$\\text{pos}$位置的token的嵌入向量第$i$维加上这样一个值。 ","date":"2024-07-07","objectID":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/:3:6","tags":["Transformer","模型","人工智能"],"title":"【论文阅读笔记】Attention Is All You Need","uri":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/"},{"categories":["深度学习","论文阅读"],"content":"4 为什么使用自注意力机制 在处理序列数据时，长距离依赖关系的学习是一个关键挑战。论文中对比了使用自注意力、循环单元和卷积单元等不同模型结构时的计算量、时间复杂度和最大依赖路径长度。其中，最大依赖路径长度指的是任意两个输入输出位置之间信息传递的最长路径。 在传统的循环神经网络（RNN）中，信息是逐步传递的，因此全局视角下，任意两个位置之间的最长信息传递路径往往是以序列长度 $n$ 为量级的。这种逐步传递导致了RNN在捕捉长距离依赖时可能面临的挑战，尤其是在处理长序列时效果不佳。 相比之下，Transformer利用自注意力机制直接将每个位置与所有其他位置进行关联，避免了逐步传递的过程，使得任意两个位置之间的信息传递路径变得极为直接和高效。这种直接的路径传递方式使得Transformer能够更有效地捕捉到长距离的依赖关系，而不受序列长度的限制。 因此，Transformer凭借其独特的注意力机制，实现了“Attention is all you need”的理念，强调了在序列建模中注意力机制的重要性和效果。它不仅仅是一种模型结构的创新，更是在解决长距离依赖问题上的一次重大突破。Transformer的成功不仅在于其高效的信息传递路径，还在于其能够在更大范围内捕捉和利用序列中的关联信息，从而提升了序列建模任务的性能和效果。 ","date":"2024-07-07","objectID":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/:4:0","tags":["Transformer","模型","人工智能"],"title":"【论文阅读笔记】Attention Is All You Need","uri":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/"},{"categories":["深度学习","论文阅读"],"content":"5 训练 在论文中，训练Transformer模型涉及到几个关键的优化和正则化策略。 ","date":"2024-07-07","objectID":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/:5:0","tags":["Transformer","模型","人工智能"],"title":"【论文阅读笔记】Attention Is All You Need","uri":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/"},{"categories":["深度学习","论文阅读"],"content":"5.1 优化器 模型的训练使用了Adam优化器，并采用了一种自适应的学习率。学习率 $\\text{lr}$ 的计算方式如下所示： 这种自适应学习率的设计有助于在训练初期快速提升学习率，以加速模型收敛，而在训练后期逐渐降低学习率，以更细致地调整模型参数，提升训练的稳定性和效果。 ","date":"2024-07-07","objectID":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/:5:1","tags":["Transformer","模型","人工智能"],"title":"【论文阅读笔记】Attention Is All You Need","uri":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/"},{"categories":["深度学习","论文阅读"],"content":"5.2 正则化 Transformer模型采用了多种正则化方法，以提升泛化能力和训练稳定性： 残差连接：在每个子层之间都使用了残差连接，这种连接方式有助于减少梯度消失问题，并简化了模型的训练和优化过程。 Dropout：在输入嵌入向量和位置编码相加后的层中使用了Dropout，选择的Dropout概率为0.1。Dropout通过随机地将部分神经元的输出置为零，有助于防止模型过拟合，并增强泛化能力。 标签平滑处理：这是一种用于改善模型训练和提高评价指标（如BLEU分数）的技术。标签平滑处理通过将真实标签替换为一个分布更平滑的目标分布，从而减少模型对训练数据中特定标签的过度自信，提升泛化能力和性能评估的一致性。 ","date":"2024-07-07","objectID":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/:5:2","tags":["Transformer","模型","人工智能"],"title":"【论文阅读笔记】Attention Is All You Need","uri":"/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/"},{"categories":["系统架构"],"content":"1 统计文件的行数 编写一个shell脚本以输出一个文本文件nowcoder.txt中的行数 #!/bin/bash # 方法1：使用 wc -l 和 awk # 统计行数并使用 awk 提取第一个字段，即行数 lines=$(wc -l nowcoder.txt | awk '{print $1}') echo \"使用 wc -l 和 awk：$lines 行\" # 方法2：通过输入流传递文件内容给 wc -l # 使用 \u003c 操作符 lines=$(wc -l \u003c nowcoder.txt) echo \"通过输入流：$lines 行\" # 方法3：使用 cat 和管道传递给 wc -l # 使用 cat 命令和管道 lines=$(cat nowcoder.txt | wc -l) echo \"通过管道：$lines 行\" # 方法4：使用 sed 统计行数 # 使用 sed 的 -n '$=' 选项 lines=$(sed -n '$=' nowcoder.txt) echo \"使用 sed：$lines 行\" ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:1:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"2 打印文件的最后5行 查看日志的时候，经常会从文件的末尾往前查看，请你写一个bash shell脚本以输出一个文本文件nowcoder.txt中的最后5行。 #!/bin/bash # 查看文件的前5行 echo \"前5行：\" head -5 nowcoder.txt echo \"\" # 查看文件的后5行 echo \"后5行：\" tail -5 nowcoder.txt echo \"\" # 查看文件的第5行到第20行 echo \"第5行到第20行：\" sed -n '5,20p' nowcoder.txt ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:2:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"3 输出 0 到 500 中 7 的倍数 写一个 bash脚本以输出数字 $0$ 到 $500$ 中 $7$ 的倍数$(0 7 14 21…)$的命令 #!/bin/bash # 方法1：使用 Bash 的扩展语法的 for 循环 echo \"方法1：使用 Bash 的扩展语法的 for 循环\" for item in {0..500..7} do echo $item done echo \"\" # 分隔行 # 方法2：使用 seq 命令 # seq [选项]... 首部 增量 尾部 echo \"方法2：使用 seq 命令\" seq 0 7 500 echo \"\" # 分隔行 # 方法3：使用 while 循环 echo \"方法3：使用 while 循环\" # 初始化变量 i=0 # 使用 while 循环 while [ $i -le 500 ] do # 输出当前的 7 的倍数 echo $i # 增加 7 i=$((i + 7)) done ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:3:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"4 输出第5行的内容 编写一个bash脚本以输出一个文本文件nowcoder.txt中第$5$行的内容。 #!/bin/bash # head 命令拿到前五行，再通过通道，通过tail取出来最后一行，即第五行 head -n 5 nowcoder.txt | tail -n 1 #!/bin/bash # 使用sed 命令中的 p选项，打印第五行 sed -n 5p nowcoder.txt ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:4:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"5 打印空行的行号 编写一个shell脚本以输出一个文本文件nowcoder.txt中空行的行号（空行可能连续，从1开始输出） #!/bin/bash # 使用 grep 命令匹配所有空行，并且输出匹配的行号。-n 选项表示输出匹配行的行号，'^$' 匹配空行。使用 cut 命令以 : 作为分隔符，提取每行的第一个字段，即行号。 grep -n '^$' nowcoder.txt | cut -d':' -f1 # 使用 awk 命令，NF 表示当前行的字段数，NR 表示当前行号。当字段数为0时，即当前行为空行，{ print NR } 输出当前行的行号。 awk 'NF == 0 { print NR }' nowcoder.txt # 使用 sed 命令匹配所有空行，并输出匹配行的行号。-n 选项表示只输出指定的行，/^$/ 匹配空行，=表示输出匹配行的行号。 sed -n '/^$/=' nowcoder.txt ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:5:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"6 去掉空行 写一个 bash脚本以去掉一个文本文件nowcoder.txt中的空行 #!/bin/bash # 使用 grep 命令匹配所有非空行。-v 选项表示反转匹配，'^$' 匹配空行。 grep -v '^$' nowcoder.txt # 使用 sed 命令删除匹配空行的行。/^$/ 匹配空行，d 命令删除匹配的行 sed '/^$/d' nowcoder.txt \u003e nowcoder_no_empty_lines.txt # 使用 awk 命令，NF 表示字段数，NF 为真时表示非空行。 awk 'NF' nowcoder.txt ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:6:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"7 打印字母数小于8的单词 写一个bash脚本以统计一个文本文件nowcoder.txt中字母数小于8的单词。 #!/bin/bash # 使用 awk 命令遍历每个单词，NF 表示当前行的单词数，length($i) 表示当前单词的字母数，如果字母数小于8，则打印当前单词。 awk '{ for (i=1; i\u003c=NF; i++) if (length($i)\u003c8) print $i }' nowcoder.txt # 使用 grep 命令匹配字母数小于8的单词。-o 选项表示只输出匹配的内容，\\b 表示单词边界，\\w\\{1,7\\} 匹配字母数在1到7之间的单词。 grep -o '\\b\\w\\{1,7\\}\\b' nowcoder.txt ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:7:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"8 统计所有进程占用内存百分比的和 假设 nowcoder.txt 内容如下： USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.4 77744 8332 ? Ss 2021 1:15 /sbin/init noibrs splash root 2 0.0 0.0 0 0 ? S 2021 0:00 [kthreadd] root 4 0.0 0.0 0 0 ? I\u003c 2021 0:00 [kworker/0:0H] daemon 486 0.0 0.1 28340 2372 ? Ss 2021 0:00 /usr/sbin/atd -f root 586 0.0 0.3 72308 6244 ? Ss 2021 0:01 /usr/sbin/sshd -D root 12847 0.0 0.0 4528 68 ? S\u003c Jan03 0:13 /usr/sbin/atopacctd root 16306 1.7 1.2 151964 26132 ? S\u003csl Apr15 512:03 /usr/local/aegis/aegis_client/aegis_11_25/AliYunDun root 24143 0.0 0.4 25608 8652 ? S\u003cLs 00:00 0:03 /usr/bin/atop -R -w /var/log/atop/atop_20220505 600 root 24901 0.0 0.3 107792 7008 ? Ss 15:37 0:00 sshd: root@pts/0 root 24903 0.0 0.3 76532 7580 ? Ss 15:37 0:00 /lib/systemd/systemd --user root 24904 0.0 0.1 111520 2392 ? S 15:37 0:00 (sd-pam) 以上内容是通过ps aux命令输出到nowcoder.txt文件中的，请你写一个脚本计算一下所有进程占用内存大小的和。 #!/bin/bash # 使用awk命令过滤到第一行并累加$4 awk 'BEGIN { sum=0 } NR \u003e 1 { sum+=$4 } END { print sum }' nowcoder.txt # 使用while循环读取，并用if跳过第一行，使用bc进行浮点数加法运算 sum=0 cnt=1 while read -r line; do if [ $cnt -gt 1 ]; then mem=$(echo $line | awk '{ print $4 }') sum=$(echo \"$sum+$mem\" | bc) fi cnt=$((cnt+1)) done echo $sum #!/bin/bash sum=0 tail -n +2 nowcoder.txt | while read -r line; do mem=$(echo $line | awk '{ print $4 }') sum=$(echo \"$sum+$mem\" | bc) echo $sum done echo $sum 在 Bash 中，管道中的命令会在子 shell 中执行，因此变量修改不会影响主 shell 中的变量。这就是为什么看到 sum 在循环内部被正确更新，但在循环外部仍然是初始值 0。 ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:8:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"9 统计每个单词出现的个数 写一个bash脚本以统计一个文本文件nowcoder.txt 中每个单词出现的个数。 为了简单起见，你可以假设： nowcoder.txt只包括小写字母和空格，每个单词只由小写字母组成，单词间由一个或多个空格字符分隔。 #!/bin/bash # 将空格转换为换行符，以便每个单词占一行 tr -s ' ' '\\n' \u003cnowcoder.txt | # 对单词进行排序 sort | # 统计每个单词的出现次数 uniq -c | # 调整输出格式为\"单词 词频\" awk '{ print $2, $1 }' | # 按词频升序排序，-k2,2 意味着只使用第二列进行排序，表示按数值进行排序（默认情况按字典序排序） sort -k2,2n # 使用 awk 统计每个单词的出现次数 # NF 表示当前行的字段数，即单词数 # 使用一个关联数组 cnt 存储每个单词出现的次数 awk '{ for (i=1; i\u003c=NF; i++) # 遍历当前行的每个单词 cnt[$i] += 1 # 将单词加入关联数组 cnt，统计出现次数 } END { for (x in cnt) # 遍历关联数组 cnt print x, cnt[x] # 输出单词和对应的出现次数 }' nowcoder.txt | sort -k2,2n ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:9:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"10 第二列是否有重复 给定一个nowcoder.txt文件，其中有3列信息，如下： 20201001 python 99 20201002 go 80 20201002 c++ 88 20201003 php 77 20201001 go 88 20201005 shell 89 20201006 java 70 20201008 c 100 20201007 java 88 20201006 go 97 编写一个shell脚本来检查文件第二列是否有重复，且有几个重复，并提取出重复的行的第二列信息（先按次数排序，如果次数相同，按照单词字母顺序排序），输入如下： 2 java 3 go #!/bin/bash cat nowcoder.txt | awk '{ print $2 }' | sort | uniq -c | awk '{ print $1, $2 }' | # 重新格式化输出 sort -k1,1n -k2,2 | # 按照出现次数和字母顺序排序 grep -v '1' # 过滤出现次数不为 1 的行 ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:10:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"11 转置文件的内容 写一个bash脚本来转置文本文件nowcoder.txt中的文件内容。 文件中每行列数相同，并且每个字段由空格分隔 #!/bin/bash # 读取文件并使用 awk 转置文件内容 awk ' { # 遍历当前行的每一个字段 for (i = 1; i \u003c= NF; i++) { a[NR, i] = $i # 将每个字段存储在一个二维数组中，a[行号, 列号] = 值 } } NF \u003e p { p = NF } # 如果当前行的字段数大于 p，则更新 p 为当前行的字段数 END { # 遍历每一列（由最大字段数 p 确定） for (i = 1; i \u003c= p; i++) { # 遍历每一行（由总行数 NR 确定） for (j = 1; j \u003c= NR; j++) { printf(\"%s%s\", a[j,i], (j==NR ? \"\" : \" \")) # 输出数组中对应的字段值，并在每个字段后添加空格，除非是最后一个字段 } printf(\"\\n\") # 每一列输出完之后换行 } }' nowcoder.txt ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:11:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"12 打印每一行出现的数字个数 写一个bash脚本，统计一个文本文件nowcoder.txt中每一行出现的1~5数字的个数，并且计算一下整个文档中一共出现了几个1~5数字的总数。 #!/bin/bash # 使用 awk 读取文件并统计每行中包含的特定数字（1, 2, 3, 4, 5）的数量 awk -F \"[1,2,3,4,5]\" ' BEGIN { sum = 0 # 初始化 sum 变量，用于存储总和 } { # 打印当前行号 NR 以及当前行中包含的特定数字的数量 (NF - 1) print(\"line\" NR \" number: \" (NF - 1)) # 将当前行中包含的特定数字的数量累加到 sum sum += (NF - 1) } END { # 打印总和 print(\"sum is \" sum) }' nowcoder.txt ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:12:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"13 去掉所有包含this的句子 编写一个shell脚本以实现如下功能：去掉输入中含有this的语句，把不含this的语句输出 #!/bin/bash # -v 反转匹配 grep -v \"this\" nowcoder.txt # sed 命令 -\u003e d 删除 -\u003e // 包含要搜索的字符串 sed '/this/d' nowcoder.txt # awk 命令，$0为当前行的所有内容，!~ 是 awk 的模式匹配运算符，表示模式不匹配 awk '$0!~/this/ {print $0}' nowcoder.txt ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:13:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"14 求平均值 写一个bash脚本以实现一个需求，求输入的一个数组的平均值 第1行为输入的数组长度N 第2~N行为数组的元素，如以下为: 数组长度为4，数组元素为1 2 9 8 #!/bin/bash awk 'BEGIN { sum = 0 }{ if (NR == 1) { N = $1 # 将第一行的数字数量保存到变量 N 中 } else { sum += $1 # 对随后的数字进行累加求和 } } END { printf(\"%.3f\", sum / N) # 输出平均值，保留三位小数 }' ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:14:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"15 去掉不需要的单词 写一个bash脚本以实现一个需求，去掉输入中含有B和b的单词。 #!/bin/bash # 使用 sed -n 命令打印不包含 'B' 和 'b' 的行 # /^[^bB]*$/ 表示匹配不包含 'B' 和 'b' 的行，^ 表示行开头，[^bB] 表示不包含 'B' 和 'b' 的任何字符，* 表示零次或多次重复，$ 表示行结尾 sed -n '/^[^bB]*$/p' nowcoder.txt # 使用 grep -E -v 命令排除包含 'B' 和 'b' 的行 # -E 选项启用扩展的正则表达式，-v 选项表示反转匹配 grep -E -v \"[bB]\" nowcoder.txt # 使用 awk 命令，遍历每个单词，如果不包含 'B' 和 'b'，则输出该单词 awk '{ for (i = 1;i \u003c= NF; i++) { if ($i !~ /b|B/) { # 使用正则表达式匹配单词中不包含 'B' 和 'b' 的部分 printf(\"%s \", $i) # 输出不包含 'B' 和 'b' 的单词 } } }' nowcoder.txt ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:15:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"16 判断输入的是否为IP地址 写一个脚本统计文件nowcoder.txt中的每一行是否是正确的IP地址。 如果是正确的IP地址输出：yes 如果是错误的IP地址，且是四段号码的话输出：no，否则的话输出：error #!/bin/bash awk -F \".\" '{ flag = \"error\" if (NF == 4) { flag = \"yes\" for (i = 1; i \u003c= NF; i++) { if ($i \u003e 255) { flag = \"no\"; break; } } } printf(flag\"\\n\") }' nowcoder.txt ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:16:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"17 将字段逆序输出文件的每行 编写一个shell脚本，将文件nowcoder.txt中每一行的字段逆序输出，其中字段之间使用英文冒号:相分隔。 假设nowcoder.txt内容如下： nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false root:*:0:0:System Administrator:/var/root:/bin/sh 你的脚本应当输出 /usr/bin/false:/var/empty:Unprivileged User:-2:-2:*:nobody /bin/sh:/var/root:System Administrator:0:0:*:root #!/bin/bash awk -F \":\" '{ for (i = 1; i \u003c= NF; i++) { temp[i] = $i } for (i = NF; i \u003e= 1; i--) { printf(\"%s%s\", temp[i], (i == 1 ? \"\\n\" : \":\")) } }' nowcoder.txt ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:17:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"18 域名进行计数排序处理 假设有一些域名，存储在nowcoder.txt里，现在需要写一个shell脚本，将域名取出并根据域名进行计数排序处理（降序）。 假设nowcoder.txt内容如下： http://www.nowcoder.com/index.html http://www.nowcoder.com/1.html http://m.nowcoder.com/index.html 你的脚本应该输出： 2 www.nowcoder.com 1 m.nowcoder.com #!/bin/bash awk -F '/' '{ print($3) }' nowcoder.txt | sort | uniq -c | sort -r | awk '{ print($1\" \"$2) }' ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:18:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"19 打印等腰三角形 编写一个shell脚本，输入正整数n，打印边长为n的等腰三角形。 示例： 输入：5 输出： * * * * * * * * * * * * * * * #!/bin/bash read n for ((i = 1; i \u003c= n; i++)) do for ((j = 1; j \u003c= n - i; j++)) do printf \" \" done for ((j = 1; j \u003c= i; j++)) do if [[ $j -eq $i ]]; then printf \"*\" else printf \"* \" fi done printf \"\\n\" done ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:19:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"20 打印只有一个数字的行 假设有一个nowcoder.txt，编写脚本，打印只有一个数字的行。 #!/bin/bash awk -F \"[0-9]\" '{ if (NF == 2) { print($0) } }' ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:20:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"21 格式化输出 有一个文件nowcoder.txt，里面的每一行都是一个数字串，编写一个shell脚本对文件中每一行的数字串进行格式化：每$3$个数字加入一个逗号（,）。 例如：数字串为“123456789”，那么需要格式化为123,456,789。 #!/bin/bash # 使用-F分割数字串 awk -F \"\" '{ for (i = 1; i \u003c= NF; i++) { printf($i) if ((NF - i) % 3 == 0 \u0026\u0026 i != NF) { printf(\",\") } } printf(\"\\n\") }' ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:21:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"22 处理文本 有一个文本文件nowcoder.txt，假设内容格式如下： 111:13443 222:13211 111:13643 333:12341 222:12123 现在需要编写一个shell脚本，按照以下的格式输出： [111] 13443 13643 [222] 13211 12123 [333] 12341 #!/bin/bash awk -F \":\" '{ cnt[$1] = cnt[$1] $2 \"\\n\" } END { for (i in cnt) { printf(\"[%s]\\n%s\", i, cnt[i]) } }' nowcoder.txt ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:22:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"23 Nginx日志分析1-IP访问次数统计 假设 Nginx 的日志存储在 nowcoder.txt 里，内容如下： 192.168.1.20 - - [21/Apr/2020:14:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [21/Apr/2020:15:27:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [21/Apr/2020:21:27:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.23 - - [21/Apr/2020:22:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.24 - - [22/Apr/2020:15:27:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.25 - - [22/Apr/2020:15:26:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.20 - - [23/Apr/2020:08:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:09:20:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:10:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:10:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.20 - - [23/Apr/2020:14:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:15:27:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:15:27:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.25 - - [23/Apr/2020:16:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.24 - - [23/Apr/2020:20:27:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.25 - - [23/Apr/2020:20:27:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.20 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:15:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 现在需要编写 Shell 脚本统计出 2020 年 4 月 23 号访问 IP 的对应次数，并且按照次数降序排序。你的脚本应该输出： 5 192.168.1.22 4 192.168.1.21 3 192.168.1.20 2 192.168.1.25 1 192.168.1.24 #!/bin/bash # 通过grep过滤，再统计排序 grep \"23/Apr/2020\" nowcoder.txt | awk '{ print $1 }' | sort | uniq -c | sort -r | awk '{ print $1, $2 }' ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:23:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"24 Nginx日志分析2-统计某个时间段的IP访问量 假设 Nginx 的日志存储在 nowcoder.txt 里，内容如下： 192.168.1.20 - - [21/Apr/2020:14:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [21/Apr/2020:15:27:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [21/Apr/2020:21:27:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.23 - - [21/Apr/2020:22:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.24 - - [22/Apr/2020:15:27:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.25 - - [22/Apr/2020:15:26:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.20 - - [23/Apr/2020:08:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:09:20:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:10:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:10:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.20 - - [23/Apr/2020:14:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:15:27:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:15:27:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.25 - - [23/Apr/2020:16:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.24 - - [23/Apr/2020:20:27:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.25 - - [23/Apr/2020:20:27:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.20 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:22:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:23:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 现在需要编写 Shell 脚本统计 2020年04月23日20点至23点去重后的 IP 访问量，你的脚本应该输出： 5 输出说明：2020年04月23日20点至23点，共有 192.168.1.24、192.168.1.25、192.168.1.20、192.168.1.21、192.168.1.22 共 5 个 IP 访问了。 #!/bin/bash grep \"23/Apr/2020:2[0-3]\" nowcoder.txt | awk '{ print $1 }' | sort | uniq | wc -l ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:24:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"25 nginx日志分析3-统计访问3次以上的IP 假设nginx的日志我们存储在nowcoder.txt里，格式如下： 192.168.1.20 - - [21/Apr/2020:14:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [21/Apr/2020:15:27:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [21/Apr/2020:21:27:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.23 - - [21/Apr/2020:22:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.24 - - [22/Apr/2020:15:27:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.25 - - [22/Apr/2020:15:26:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.20 - - [23/Apr/2020:08:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:09:20:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:10:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:10:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.20 - - [23/Apr/2020:14:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:15:27:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:15:27:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.25 - - [23/Apr/2020:16:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.24 - - [23/Apr/2020:20:27:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.25 - - [23/Apr/2020:20:27:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.20 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:22:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:23:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 现在需要编写shell脚本统计访问3次以上的IP，你的脚本应该输出： 6 192.168.1.22 5 192.168.1.21 4 192.168.1.20 #!/bin/bash awk '{ print $1 }' nowcoder.txt | sort | uniq -c | sort -r | awk '{ if ($1 \u003e 3) { print $1, $2 } }' ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:25:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"26 Nginx日志分析4-查询某个IP的详细访问情况 假设Nginx的日志存储在nowcoder.txt里，内容如下： 192.168.1.20 - - [21/Apr/2020:14:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [21/Apr/2020:15:27:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [21/Apr/2020:21:27:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.23 - - [21/Apr/2020:22:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.24 - - [22/Apr/2020:15:27:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.25 - - [22/Apr/2020:15:26:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.20 - - [23/Apr/2020:08:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:09:20:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:10:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:10:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.20 - - [23/Apr/2020:14:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:15:27:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:15:27:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.25 - - [23/Apr/2020:16:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.24 - - [23/Apr/2020:20:27:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.25 - - [23/Apr/2020:20:27:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.20 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:22:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:23:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 现在需要编写shell脚本查询192.168.1.22的详细访问次数情况，按访问频率降序排序。你的脚本应该输出： 4 /1/index.php 2 /3/index.php #!/bin/bash grep \"192.168.1.22\" | awk '{ print $7 }' | sort | uniq -c | sort -r | awk '{ print $1, $2 }' ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:26:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"27 nginx日志分析5-统计爬虫抓取404的次数 假设nginx的日志存储在nowcoder.txt里，内容如下： 192.168.1.20 - - [21/Apr/2020:14:12:49 +0800] \"GET /1/index.php HTTP/1.1\" 301 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [21/Apr/2020:15:00:49 +0800] \"GET /2/index.php HTTP/1.1\" 500 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [21/Apr/2020:21:21:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.23 - - [21/Apr/2020:22:10:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.24 - - [22/Apr/2020:15:00:49 +0800] \"GET /2/index.php HTTP/1.1\" 200 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.25 - - [22/Apr/2020:15:26:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.20 - - [23/Apr/2020:08:05:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)\" 192.168.1.21 - - [23/Apr/2020:09:20:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:10:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 200 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:10:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.20 - - [23/Apr/2020:14:12:49 +0800] \"GET /1/index.php HTTP/1.1\" 200 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:15:00:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:15:00:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)\" 192.168.1.22 - - [23/Apr/2020:15:00:49 +0800] \"GET /3/index.php HTTP/1.1\" 200 490 \"-\" \"Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)\" 192.168.1.24 - - [23/Apr/2020:20:27:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.25 - - [23/Apr/2020:20:27:49 +0800] \"GET /3/index.php HTTP/1.1\" 200 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.20 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 300 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 500 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:22:10:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:23:59:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 现在需要编写shell脚本统计百度爬虫抓取404的次数，你的脚本应该输出 2 #!/bin/bash grep \"404\" | grep \"www.baidu.com\" | wc -l ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:27:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"28 Nginx日志分析6-统计每分钟的请求数 假设Nginx的日志存储在nowcoder.txt里，内容如下： 192.168.1.20 - - [21/Apr/2020:14:12:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [21/Apr/2020:15:00:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [21/Apr/2020:21:21:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.23 - - [21/Apr/2020:22:10:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.24 - - [22/Apr/2020:15:00:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.25 - - [22/Apr/2020:15:26:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.20 - - [23/Apr/2020:08:05:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Baiduspider\" 192.168.1.21 - - [23/Apr/2020:09:20:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:10:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:10:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.20 - - [23/Apr/2020:14:12:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:15:00:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:15:00:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Baiduspider\" 192.168.1.25 - - [23/Apr/2020:16:15:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.24 - - [23/Apr/2020:20:27:49 +0800] \"GET /2/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.25 - - [23/Apr/2020:20:27:49 +0800] \"GET /3/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.20 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:20:27:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.22 - - [23/Apr/2020:22:10:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 192.168.1.21 - - [23/Apr/2020:23:59:49 +0800] \"GET /1/index.php HTTP/1.1\" 404 490 \"-\" \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:45.0) Gecko/20100101 Firefox/45.0\" 现在需要编写Shell脚本统计每分钟的请求数，并且按照请求数降序排序。你的脚本应该输出： 5 20:27 4 15:00 2 22:10 2 14:12 2 10:27 1 23:59 1 21:21 1 16:15 1 15:26 1 09:20 1 08:05 #!/bin/bash awk -F \":\" '{ print $2\":\"$3 }' | sort | uniq -c | sort -r | awk '{ print $1, $2 }' ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:28:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"29 netstat练习1-查看各个状态的连接数 假设netstat命令运行的结果我们存储在nowcoder.txt里，格式如下： Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:6160 0.0.0.0:* LISTEN tcp 0 0 127.0.0.53:53 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0 0 172.16.56.200:41856 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:49822 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:49674 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:42316 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:44076 172.16.240.74:6379 ESTABLISHED tcp 0 0 172.16.56.200:49656 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:58248 100.100.142.4:80 TIME_WAIT tcp 0 0 172.16.56.200:50108 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:41944 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:35548 100.100.32.118:80 TIME_WAIT tcp 0 0 172.16.56.200:39024 100.100.45.106:443 TIME_WAIT tcp 0 0 172.16.56.200:41788 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:58260 100.100.142.4:80 TIME_WAIT tcp 0 0 172.16.56.200:41812 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:41854 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:58252 100.100.142.4:80 TIME_WAIT tcp 0 0 172.16.56.200:49586 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:41754 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:50466 120.55.222.235:80 TIME_WAIT tcp 0 0 172.16.56.200:38514 100.100.142.5:80 TIME_WAIT tcp 0 0 172.16.56.200:49832 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:52162 100.100.30.25:80 ESTABLISHED tcp 0 0 172.16.56.200:50372 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:50306 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:49600 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:41908 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:60292 100.100.142.1:80 TIME_WAIT tcp 0 0 172.16.56.200:37650 100.100.54.133:80 TIME_WAIT tcp 0 0 172.16.56.200:41938 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:49736 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:41890 172.16.34.144:3306 ESTABLISHED udp 0 0 127.0.0.1:323 0.0.0.0:* udp 0 0 0.0.0.0:45881 0.0.0.0:* udp 0 0 127.0.0.53:53 0.0.0.0:* udp 0 0 172.16.56.200:68 0.0.0.0:* udp6 0 0 ::1:323 :::* raw6 0 0 :::58 :::* 7 现在需要编写shell脚本查看系统tcp连接中各个状态的连接数，并且按照连接数降序输出。你的脚本应该输出如下： ESTABLISHED 22 TIME_WAIT 9 LISTEN 3 #!/bin/bash grep \"tcp\" | awk '{ print $6 }' | sort | uniq -c | sort -nr | awk '{ print $2, $1 }' ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:29:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"30 netstat练习2-查看和3306端口建立的连接 假设netstat命令运行的结果我们存储在nowcoder.txt里，格式如下： Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:6160 0.0.0.0:* LISTEN tcp 0 0 127.0.0.53:53 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0 0 172.16.56.200:41856 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:49822 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:49674 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:42316 172.16.34.143:3306 ESTABLISHED tcp 0 0 172.16.56.200:44076 172.16.240.74:6379 ESTABLISHED tcp 0 0 172.16.56.200:49656 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:58248 100.100.142.4:80 TIME_WAIT tcp 0 0 172.16.56.200:50108 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:41944 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:35548 100.100.32.118:80 TIME_WAIT tcp 0 0 172.16.56.200:39024 100.100.45.106:443 TIME_WAIT tcp 0 0 172.16.56.200:41788 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:58260 100.100.142.4:80 TIME_WAIT tcp 0 0 172.16.56.200:41812 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:41854 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:58252 100.100.142.4:80 TIME_WAIT tcp 0 0 172.16.56.200:49586 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:41754 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:50466 120.55.222.235:80 TIME_WAIT tcp 0 0 172.16.56.200:38514 100.100.142.5:80 TIME_WAIT tcp 0 0 172.16.56.200:49832 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:52162 100.100.30.25:80 ESTABLISHED tcp 0 0 172.16.56.200:50372 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:50306 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:49600 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:41908 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:60292 100.100.142.1:80 TIME_WAIT tcp 0 0 172.16.56.200:37650 100.100.54.133:80 TIME_WAIT tcp 0 0 172.16.56.200:41938 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:49736 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:41890 172.16.34.144:3306 ESTABLISHED udp 0 0 127.0.0.1:323 0.0.0.0:* udp 0 0 0.0.0.0:45881 0.0.0.0:* udp 0 0 127.0.0.53:53 0.0.0.0:* udp 0 0 172.16.56.200:68 0.0.0.0:* udp6 0 0 ::1:323 :::* raw6 0 0 :::58 :::* 7 现在需要你查看和本机3306端口建立连接并且状态是established的所有IP，按照连接数降序排序。你的脚本应该输出 10 172.16.0.24 9 172.16.34.144 1 172.16.34.143 #!/bin/bash grep \"tcp.*ESTABLISHED\" | awk '{ print $5 }' | awk -F \":\" '$2 == 3306 { print $1 }' | sort | uniq -c | sort -nr | awk '{ print $1, $2 }' ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:30:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"31 netstat练习3-输出每个IP的连接数 假设netstat命令运行的结果我们存储在nowcoder.txt里，格式如下： Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:6160 0.0.0.0:* LISTEN tcp 0 0 127.0.0.53:53 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0 0 172.16.56.200:41856 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:49822 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:49674 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:42316 172.16.34.143:3306 ESTABLISHED tcp 0 0 172.16.56.200:44076 172.16.240.74:6379 ESTABLISHED tcp 0 0 172.16.56.200:49656 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:58248 100.100.142.4:80 TIME_WAIT tcp 0 0 172.16.56.200:50108 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:41944 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:35548 100.100.32.118:80 TIME_WAIT tcp 0 0 172.16.56.200:39024 100.100.45.106:443 TIME_WAIT tcp 0 0 172.16.56.200:41788 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:58260 100.100.142.4:80 TIME_WAIT tcp 0 0 172.16.56.200:41812 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:41854 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:58252 100.100.142.4:80 TIME_WAIT tcp 0 0 172.16.56.200:49586 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:41754 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:50466 120.55.222.235:80 TIME_WAIT tcp 0 0 172.16.56.200:38514 100.100.142.5:80 TIME_WAIT tcp 0 0 172.16.56.200:49832 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:52162 100.100.30.25:80 ESTABLISHED tcp 0 0 172.16.56.200:50372 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:50306 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:49600 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:41908 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:60292 100.100.142.1:80 TIME_WAIT tcp 0 0 172.16.56.200:37650 100.100.54.133:80 TIME_WAIT tcp 0 0 172.16.56.200:41938 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:49736 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:41890 172.16.34.144:3306 ESTABLISHED udp 0 0 127.0.0.1:323 0.0.0.0:* udp 0 0 0.0.0.0:45881 0.0.0.0:* udp 0 0 127.0.0.53:53 0.0.0.0:* udp 0 0 172.16.56.200:68 0.0.0.0:* udp6 0 0 ::1:323 :::* raw6 0 0 :::58 :::* 7 现在需要你输出每个IP的连接数，按照连接数降序排序。你的脚本应该输出 172.16.0.24 10 172.16.34.144 9 100.100.142.4 3 0.0.0.0 3 172.16.34.143 1 172.16.240.74 1 120.55.222.235 1 100.100.54.133 1 100.100.45.106 1 100.100.32.118 1 100.100.30.25 1 100.100.142.5 1 100.100.142.1 1 #!/bin/bash grep \"tcp\" | awk '{ print $5 }' | awk -F \":\" '{ print $1 }' | sort | uniq -c | sort -nr | awk '{ print $2, $1 }' ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:31:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"32 netstat练习4-输出和3306端口建立连接总的各个状态的数目 假设netstat命令运行的结果我们存储在nowcoder.txt里，格式如下： Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:6160 0.0.0.0:* LISTEN tcp 0 0 127.0.0.53:53 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0 0 172.16.56.200:41856 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:49822 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:49674 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:42316 172.16.34.143:3306 ESTABLISHED tcp 0 0 172.16.56.200:44076 172.16.240.74:6379 ESTABLISHED tcp 0 0 172.16.56.200:49656 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:58248 100.100.142.4:80 TIME_WAIT tcp 0 0 172.16.56.200:50108 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:41944 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:35548 100.100.32.118:80 TIME_WAIT tcp 0 0 172.16.56.200:39024 100.100.45.106:443 TIME_WAIT tcp 0 0 172.16.56.200:41788 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:58260 100.100.142.4:80 TIME_WAIT tcp 0 0 172.16.56.200:41812 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:41854 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:58252 100.100.142.4:80 TIME_WAIT tcp 0 0 172.16.56.200:49586 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:41754 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:50466 120.55.222.235:80 TIME_WAIT tcp 0 0 172.16.56.200:38514 100.100.142.5:80 TIME_WAIT tcp 0 0 172.16.56.200:49832 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:52162 100.100.30.25:80 ESTABLISHED tcp 0 0 172.16.56.200:50372 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:50306 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:49600 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:41908 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:60292 100.100.142.1:80 TIME_WAIT tcp 0 0 172.16.56.200:37650 100.100.54.133:80 TIME_WAIT tcp 0 0 172.16.56.200:41938 172.16.34.144:3306 ESTABLISHED tcp 0 0 172.16.56.200:49736 172.16.0.24:3306 ESTABLISHED tcp 0 0 172.16.56.200:41890 172.16.34.144:3306 ESTABLISHED udp 0 0 127.0.0.1:323 0.0.0.0:* udp 0 0 0.0.0.0:45881 0.0.0.0:* udp 0 0 127.0.0.53:53 0.0.0.0:* udp 0 0 172.16.56.200:68 0.0.0.0:* udp6 0 0 ::1:323 :::* raw6 0 0 :::58 :::* 7 现在需要你输出和本机3306端口建立连接的各个状态的数目，按照以下格式输出 TOTAL_IP表示建立连接的ip数目 TOTAL_LINK表示建立连接的总数目 TOTAL_IP 3 ESTABLISHED 20 TOTAL_LINK 20 #!/bin/bash # 统计包含3306且协议为tcp的总IP数量 TOTAL_IP=$(grep \"tcp\" nowcoder.txt | awk '{ print $5 }' | awk -F: '$2 == 3306 {print $1, $2 }' | sort | uniq | wc -l) echo \"TOTAL_IP $TOTAL_IP\" # 统计包含3306且状态为ESTABLISHED且协议为tcp的数量 ESTABLISHED=$(awk '/3306/ { if ($6 == \"ESTABLISHED\" \u0026\u0026 $1 == \"tcp\") print $5 }' nowcoder.txt | wc -l) echo \"ESTABLISHED $ESTABLISHED\" # 统计包含3306且协议为tcp的连接数量 TOTAL_LINK=$(awk '/3306/ { if ($1 == \"tcp\") print $5 }' nowcoder.txt | wc -l) echo \"TOTAL_LINK $TOTAL_LINK\" ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:32:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"33 业务分析-提取值 假设我们的日志nowcoder.txt里，内容如下 12-May-2017 10:02:22.789 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Server version:Apache Tomcat/8.5.15 12-May-2017 10:02:22.813 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Server built:May 5 2017 11:03:04 UTC 12-May-2017 10:02:22.813 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Server number:8.5.15.0 12-May-2017 10:02:22.814 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log OS Name:Windows, OS Version:10 12-May-2017 10:02:22.814 信息 [main] org.apache.catalina.startup.VersionLoggerListener.log Architecture:x86_64 现在需要你提取出对应的值，输出内容如下 serverVersion:Apache Tomcat/8.5.15 serverName:8.5.15.0 osName:Windows osVersion:10 #!/bin/bash grep -o \"Server version:.*\" nowcoder.txt | awk -F \":\" '{print \"serverVersion:\" $2}' grep -o \"Server number:.*\" nowcoder.txt | awk -F \":\" '{print \"serverName:\" $2}' grep -o \"OS Name:.*\" nowcoder.txt | awk -F \"[:,]\" '{print \"osName:\" $2}' grep -o \"OS Version:.*\" nowcoder.txt | awk -F \":\" '{print \"osVersion:\" $2}' ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:33:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["系统架构"],"content":"34 ps分析-统计VSZ,RSS各自总和 假设命令运行的结果我们存储在nowcoder.txt里，格式如下： USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.1 37344 4604 ? Ss 2020 2:13 /sbin/init root 231 0.0 1.5 166576 62740 ? Ss 2020 15:15 /lib/systemd/systemd-journald root 237 0.0 0.0 0 0 ? S\u003c 2020 2:06 [kworker/0:1H] root 259 0.0 0.0 45004 3416 ? Ss 2020 0:25 /lib/systemd/systemd-udevd root 476 0.0 0.0 0 0 ? S\u003c 2020 0:00 [edac-poller] root 588 0.0 0.0 276244 2072 ? Ssl 2020 9:49 /usr/lib/accountsservice/accounts-daemon message+ 592 0.0 0.0 42904 3032 ? Ss 2020 0:01 /usr/bin/dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation root 636 0.0 0.0 65532 3200 ? Ss 2020 1:51 /usr/sbin/sshd -D daemon 637 0.0 0.0 26044 2076 ? Ss 2020 0:00 /usr/sbin/atd -f root 639 0.0 0.0 29476 2696 ? Ss 2020 3:29 /usr/sbin/cron -f root 643 0.0 0.0 20748 1992 ? Ss 2020 0:26 /lib/systemd/systemd-logind syslog 645 0.0 0.0 260636 3024 ? Ssl 2020 3:17 /usr/sbin/rsyslogd -n root 686 0.0 0.0 773124 2836 ? Ssl 2020 26:45 /usr/sbin/nscd root 690 0.0 0.0 19472 252 ? Ss 2020 14:39 /usr/sbin/irqbalance --pid=/var/run/irqbalance.pid ntp 692 0.0 0.0 98204 776 ? Ss 2020 25:18 /usr/sbin/ntpd -p /var/run/ntpd.pid -g -u 108:114 uuidd 767 0.0 0.0 28624 192 ? Ss 2020 0:00 /usr/sbin/uuidd --socket-activation root 793 0.0 0.0 128812 3148 ? Ss 2020 0:00 nginx: master process /usr/sbin/nginx -g daemon on; master_process on; www-data 794 0.0 0.2 133376 9120 ? S 2020 630:57 nginx: worker process www-data 795 0.0 0.2 133208 8968 ? S 2020 633:02 nginx: worker process www-data 796 0.0 0.2 133216 9120 ? S 2020 634:24 nginx: worker process www-data 797 0.0 0.2 133228 9148 ? S 2020 632:56 nginx: worker process web 955 0.0 0.0 36856 2112 ? Ss 2020 0:00 /lib/systemd/systemd --user web 956 0.0 0.0 67456 1684 ? S 2020 0:00 (sd-pam) root 1354 0.0 0.0 8172 440 tty1 Ss+ 2020 0:00 /sbin/agetty --noclear tty1 linux root 1355 0.0 0.0 7988 344 ttyS0 Ss+ 2020 0:00 /sbin/agetty --keep-baud 115200 38400 9600 ttyS0 vt220 root 2513 0.0 0.0 0 0 ? S 13:07 0:00 [kworker/u4:1] root 2587 0.0 0.0 0 0 ? S 13:13 0:00 [kworker/u4:2] root 2642 0.0 0.0 0 0 ? S 13:17 0:00 [kworker/1:0] root 2679 0.0 0.0 0 0 ? S 13:19 0:00 [kworker/u4:0] root 2735 0.0 0.1 102256 7252 ? Ss 13:24 0:00 sshd: web [priv] web 2752 0.0 0.0 102256 3452 ? R 13:24 0:00 sshd: web@pts/0 web 2753 0.5 0.1 14716 4708 pts/0 Ss 13:24 0:00 -bash web 2767 0.0 0.0 29596 1456 pts/0 R+ 13:24 0:00 ps aux root 10634 0.0 0.0 0 0 ? S Nov16 0:00 [kworker/0:0] root 16585 0.0 0.0 0 0 ? S\u003c 2020 0:00 [bioset] root 19526 0.0 0.0 0 0 ? S Nov16 0:00 [kworker/1:1] root 28460 0.0 0.0 0 0 ? S Nov15 0:03 [kworker/0:2] root 30685 0.0 0.0 36644 2760 ? Ss 2020 0:00 /lib/systemd/systemd --user root 30692 0.0 0.0 67224 1664 ? S 2020 0:00 (sd-pam) root 32689 0.0 0.0 47740 2100 ? Ss 2020 0:00 /usr/local/ilogtail/ilogtail root 32691 0.2 0.5 256144 23708 ? Sl 2020 1151:31 /usr/local/ilogtail/ilogtail 现在需要你统计VSZ，RSS各自的总和（以M兆为统计），输出格式如下 MEM TOTAL VSZ_SUM:3250.8M,RSS_SUM:179.777M #!/bin/bash awk '{ sum_vsz = sum_vsz + $5 sum_rss = sum_rss + $6 }END{ print(\"MEM TOTAL \\n\" \"VSZ_SUM:\" sum_vsz/1024 \"M,\" \"RSS_SUM:\" sum_rss/1024 \"M\")}' ","date":"2024-06-09","objectID":"/posts/07.shell%E5%AE%9E%E6%88%98/:34:0","tags":["Shell"],"title":"Shell 23道例题实战","uri":"/posts/07.shell%E5%AE%9E%E6%88%98/"},{"categories":["面试","计算机网络"],"content":"1 基础 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:1:0","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"1.1 计算机网络体系结构 计算机网络体系结构通过将复杂的网络通信分解成不同的层次，来标准化交互的过程。常见的模型包括 OSI 七层模型、TCP/IP 四层模型和五层体系结构。OSI 是理论上的网络通信模型，TCP/IP 是实际应用层面上的网络通信模型，五层结构是为了方便理解和记忆。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:1:1","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"1.2 说说 OSI 七层模型？ OSI七层模型是一个用来描述计算机网络体系结构的标准模型。它将网络通信划分为七个抽象层，每一层都负责特定的功能，从物理连接到应用程序。这些层从下到上分别是： 物理层（Physical Layer）：负责传输比特流，并管理物理介质。 数据链路层（Data Link Layer）：处理帧的传输，通过物理地址进行寻址。 网络层（Network Layer）：负责数据包的路由和转发，实现不同网络之间的通信。 传输层（Transport Layer）：提供端到端的可靠数据传输，包括错误检测、流量控制和分段重组。 会话层（Session Layer）：负责建立、管理和终止会话连接，以及数据的同步和恢复。 表示层（Presentation Layer）：处理数据的格式化和表示，确保不同系统的数据格式能够互相理解。 应用层（Application Layer）：提供用户与网络服务的接口，包括各种应用程序和协议，如HTTP、FTP和SMTP。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:1:2","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"1.3 说说 TCP/IP 四层模型？ TCP/IP 合并了 OSI 的部分层次，专注于高效的网络通信实践，更具实用性。 网络接口层（Network Interface Layer）：对应于 OSI 模型的物理层和数据链路层。负责数据帧的物理传输，包括硬件地址寻址（MAC 地址），数据封装和解封装，错误检测和纠正等。 网际层（Internet Layer）对应于 OSI 模型的网络层。主要协议是 IP，负责数据包的寻址和路由。这一层还包括 ICMP 协议。 传输层（Transport Layer）：对应于 OSI 模型的传输层。负责提供端到端的数据传输服务，包括数据分割、流量控制、错误恢复等。主要的协议有 TCP 和 UDP 应用层（Application Layer）：对应于 OSI 模型的会话层、表示层和应用层。包括所有与网络有关的高级协议，如 HTTP、FTP、SMTP 等。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:1:3","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"1.4 说说五层体系结构？ 是对 OSI 和 TCP/IP 的折衷，它保留了 TCP/IP 的实用性，同时提供了比四层模型更细致的分层，便于教学和理解网络的各个方面。 应用层：作为网络服务和最终用户之间的接口。它提供了一系列供应用程序使用的协议，如 HTTP（网页）、FTP（文件传输）、SMTP（邮件传输）等。使用户的应用程序可以访问网络服务。 传输层：提供进程到进程的通信管理，这一层确保数据按顺序、无错误地传输。主要协议包括 TCP 和 UDP。 网络层：负责数据包从源到目的地的传输和路由选择，包括跨越多个网络（即互联网）。它使用逻辑地址（如 IP 地址）来唯一标识设备。路由器是网络层设备。 数据链路层：确保从一个节点到另一个节点的可靠、有效的数据传输。交换机、网桥是数据链路层设备。 物理层：电缆、光纤、无线电频谱、网络适配器等。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:1:4","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"1.5 说一下每一层对应的网络协议有哪些？ OSI七层网络模型 TCP/IP四层模型 对应的网络协议 应用层 应用层 HTTP、DNS、FTP、NFS、WAIS、SMIP、Telnet、SNMP 表示层 应用层 TIFF、GIF、JPEG、PICT 会话层 应用层 RPC、SQL、NFS、NetBIOS、names、AppleTalk 传输层 传输层 TCP、UDP 网络层 网络层 IP、ICMP、ARP、RAPP、RIP、IPX 数据链路层 网络接口层 FDDI、Frame Relay、HDLC、PPP 物理层 网络接口层 EIA/TIA-232、EIA/TIA-499 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:1:5","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"1.6 数据在各层之间是怎么传输的呢？ 对于发送方而言，从上层到下层层层包装，对于接收方而言，从下层到上层，层层解开包装。 发送方的应用进程向接收方的应用进程传送数据 AP 先将数据交给本主机的应用层，应用层加上本层的控制信息 H5 就变成了下一层的数据单元 传输层收到这个数据单元后，加上本层的控制信息 H4，再交给网络层，成为网络层的数据单元 到了数据链路层，控制信息被分成两部分，分别加到本层数据单元的首部（H2）和尾部（T2） 最后的物理层，进行比特流的传输 这个过程类似写信，写一封信，每到一层，就加一个信封，写一些地址的信息。到了目的地之后，又一层层解封，传向下一个目的地。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:1:6","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"2 网络综合 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:2:0","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"2.1 从浏览器地址栏输入 URL 到显示主页的过程 从在浏览器地址栏输入 URL 到显示主页的过程包括多个步骤，涵盖了 DNS 解析、TCP 连接、发送 HTTP 请求、服务器处理请求并返回 HTTP 响应、浏览器处理响应并渲染页面等多个环节。 DNS 解析：浏览器发起一个 DNS 请求到 DNS 服务器，将域名解析为服务器的 IP 地址。 TCP 连接：浏览器通过解析得到的 IP 地址与服务器建立 TCP 连接（通常是通过 443 端口进行 SSL 加密的 HTTPS 连接）。这一步涉及到 TCP 的三次握手过程，确保双方都准备好进行数据传输。 发送 HTTP 请求：浏览器构建 HTTP 请求消息，包括请求行（如 GET / HTTP/1.1）、请求头（包含用户代理、接受的内容类型等信息）和请求体（如果有）；将请求发送到服务器。 服务器处理请求：服务器接收到 HTTP 请求后，根据请求的资源路径，经过后端处理（可能包括数据库查询等），生成 HTTP 响应消息；响应消息包括状态行（如 HTTP/1.1 200 OK）、响应头（内容类型、缓存控制等信息）和响应体（请求的资源内容）。 浏览器接收 HTTP 响应：浏览器接收到服务器返回的 HTTP 响应数据，开始解析响应体中的 HTML 内容；然后构建 DOM 树、解析 CSS 和 JavaScript 文件等，最终渲染页面。 断开连接：TCP 四次挥手，连接结束 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:2:1","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"2.2 各个过程都使用了哪些协议？ DNS:获取域名对应的IP TCP:与服务器建立连接和断开连接 IP：使用TCP协议时，网络层需要使用IP协议。 OPSF：IP数据包在路由器之间，路由选择使用OPSF协议 ARP：路由器再与服务器通信时，需要将IP地址转换为MAC地址，需要使用ARP协议 HTTP：TCP连接建立完成之后，使用HTTP协议传递HTTP报文 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:2:2","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"2.3 说说 DNS 的解析过程？ DNS 的全称是 Domain Name System，也就是域名解析系统，它可以将域名映射到对应的 IP 地址上，比如说我们访问 www.google.com，实际上访问的是谷歌的一台服务器，它的 IP 地址是 xxx.xxx.xxx.xxx。可以通过 IP 地址直接访问服务器，但不方便记忆，所以就有了域名系统。域名到 IP 之间的映射，就需要 DNS 来完成。 假设我们在浏览器地址栏里键入了www.google.com： 浏览器会首先检查自己的缓存中是否有这个域名对应的 IP 地址，如果有，直接返回；如果没有，进入下一步。 检查本地 DNS 缓存是否有该域名的记录。 如果没有，向根域名服务器发送请求，根域名服务器将请求指向更具体的服务，如 com 顶级域名服务器。 顶级域名服务器再将请求指向权限域名服务器，通常由域名注册机构直接管理，所以机构会提供对应的 DNS 解析服务，将域名和谷歌服务器绑定起来。 最终，浏览器使用获得的 IP 地址发起一个 HTTP 请求到目标服务器，然后该服务器返回所请求的网页内容。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:2:3","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"2.4 说说 WebSocket 与 Socket 的区别？ Socket 其实就是等于 IP 地址 + 端口 + 协议。具体来说，Socket 是一套标准，它完成了对 TCP/IP 的高度封装，屏蔽网络细节，以方便开发者更好地进行网络编程。 WebSocket: 是一种网络协议，属于应用层协议。它是在单个 TCP 连接上进行全双工通信的协议，设计用于浏览器和服务器之间的通信，用来解决 http 不支持持久化连接的问题。 Socket 一个是网络编程的标准接口，而 WebSocket 则是应用层通信协议。 Socket工作在传输层，可以基于 TCP 或 UDP 协议。它需要开发者自己处理数据的发送和接收、连接的建立和断开等低层次的细节。 WebSocket工作在应用层，依赖于 TCP 协议。WebSocket 在初次连接时通过 HTTP 请求进行握手，一旦连接建立，后续的数据传输都在 WebSocket 协议上进行，浏览器和服务器都可以主动向对方发送数据，保持连接直到显式断开。 Socket传输的是字节流，需要开发者自行定义数据的格式和协议。WebSocket传输的是文本帧或二进制帧，协议本身定义了消息的格式，能够直接发送 JSON 或二进制数据，方便开发者使用。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:2:4","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"2.5 说一下你了解的端口及对应的服务？ 端口 服务 用途 21 FTP(文件传输协议) 用于在计算机之间传输文件 22 SSH 用于远程登录、文件传输和命令行界面交互 23 Telnet(远程登录服务) 允许用户从一台计算机登录到另一台计算机 53 DNS域名解析服务 将域名转换为IP地址以便访问网站 80 HTTP超文本传输协议 用于在万维网上交换信息 443 HTTPS 提供安全的HTTP通信 1080 SOCKS 用于在计算机之间安全地传输数据。它通过代理服务器来隐藏原始的IP地址和端口号，从而提供匿名性和安全性 3306 MySQL默认端口号 用于MySQL数据库服务器上的数据访问 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:2:5","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3 HTTP ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:0","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3.1 说说 HTTP 常用的状态码及其含义？ HTTP 响应状态码是由服务器返回给客户端，用于表示对请求的响应结果。 这些状态码分为五个不同的类别，每个类别用一个数字开头，共有三位数： 1XX：信息性状态码，临时的响应，客户端应继续请求。 2XX：成功状态码，请求已成功被服务器接收。 3XX：重定向状态码，用来重定向。 4XX：客户端错误状态码，请求可能出错。 5XX：服务器错误状态码，服务器在尝试处理请求时发生了错误。 常见HTTP状态码如下： 状态码 含义 101 Switching Protocols 切换请求协议 200 OK 请求成功 301 Moved Permanently 请求资源永久移动，返回新URI 302 Found 请求资源临时移动，继续使用原有URI 400 Bad Request 客户端请求的语法错误，服务端无法理解 401 Unauthorized 当前请求需要认证 403 Forbidden 服务器拒绝请求，客户端无权访问该资源 404 Not Found 请求的资源在服务器上不存在 500 Internal Server Error 服务器内部错误 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:1","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3.2 HTTP 有哪些请求方式？ HTTP 协议定义了多种请求方式，用以指示请求的目的。常见的请求方式有 GET、POST、DELETE、PUT。在正确实现的条件下，GET、HEAD、PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是（每次发送 POST 请求，服务器可能会生成新的资源 ID 或处理生成的唯一值（如订单号、事务 ID）。因此，重复发送 POST 请求会导致创建多个不同的资源或多次执行某个操作）。 GET：请求检索指定的资源。应该只用于获取数据，并且是幂等的，即多次执行相同的 GET 请求应该返回相同的结果，并且不会改变资源的状态。 POST：向指定资源提交数据，请求服务器进行处理（如提交表单或上传文件）。数据被包含在请求体中。可能会创建新的资源或修改现有资源。 DELETE：删除指定的资源。 PUT：用于替换指定的资源。如果指定的资源不存在，创建一个新资源。 HEAD：类似于 GET 请求，但只请求响应头信息，不会返回响应体。常用于检查资源是否存在以及资源的元数据（如检查链接是否有效）。 OPTIONS：请求服务器返回该资源所支持的所有 HTTP 方法。常用于检查服务器的功能或资源的通信选项。 PATCH：用于对资源进行部分修改，而不是完全替代资源。 TRACE：回显服务器收到的请求，主要用于测试和诊断。 CONNECT：用于将请求连接转换为透明的 TCP/IP 隧道，通常用于 HTTPS 通过代理服务器的请求。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:2","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3.3 HTTP 的 GET 方法可以实现写操作吗? 严格来说，HTTP 的 GET 方法不应该用于实现写操作，因为它设计为一种安全的、幂等的读取操作。GET 请求的主要作用是从服务器获取资源，而不应对服务器上的数据进行任何修改。 但是，实际上，有些 Web 应用可能会滥用 GET 请求进行写操作，例如通过在 URL 中传递参数来修改服务器上的数据。这种做法是不推荐的，主要有以下几个原因： 安全性：GET 请求会将参数包含在 URL 中，这使得敏感数据容易暴露，且容易受到攻击（如 CSRF 攻击）。 缓存问题：GET 请求通常会被缓存，而缓存的 GET 请求不应引发服务器状态的变化。如果 GET 请求用于写操作，可能会导致缓存的副作用。 幂等性和安全性：HTTP 标准要求 GET 请求是幂等的（多次相同的请求应产生相同的结果）和安全的（不应对服务器状态产生副作用）。使用 GET 实现写操作违背了这些原则。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:3","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3.4 说一下 GET 和 POST 的区别？ 从 HTTP 报文层面： GET 请求：将请求参数放在 URL 中，因此 URL 的长度有限制。数据在 URL 中传输，不安全，容易被窃取。 POST 请求：将请求参数放在请求体中，没有长度限制。数据在报文体中传输，相对更安全。 从幂等性和安全性： GET 请求： 幂等性：多次请求不会改变服务器状态，每次结果相同。 安全性：不会对服务器资源进行修改。 POST 请求： 不幂等：每次请求可能导致服务器状态变化（如创建资源）。 不安全：请求会对服务器资源进行修改。 从其他层面： GET 请求：能够被缓存，减轻服务器负担。能够保存在浏览器的浏览记录里。URL 可以保存为浏览器书签。 POST 请求：不能被缓存，不保存在浏览器历史记录里。URL 不便于保存为书签。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:4","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3.5 GET 的长度限制是多少？ HTTP 中的 GET 方法是通过 URL 传递数据的，但是 URL 本身其实并没有对数据的长度进行限制，真正限制 GET 长度的是浏览器。 例如 IE 浏览器对 URL 的最大限制是 2000 多个字符，大概 2kb 左右，像 Chrome、Firefox 等浏览器支持的 URL 字符数更多，其中 FireFox 中 URL 的最大长度限制是 65536 个字符，Chrome 则是 8182 个字符。 这个长度限制也不是针对数据部分，而是针对整个 URL。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:5","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3.6 HTTP 请求的过程与原理？ HTTP 全称是超文本传输协议（HyperText Transfer Protocol），是一个基于请求与响应模式的应用层协议，基于 TCP/IP 协议传输数据。 HTTP 遵循标准的客户端-服务器模型，客户端打开连接以发出请求，然后等待它收到服务器端响应。 在浏览器输入 URL 后，浏览器首先会通过 DNS 解析获取到服务器的 IP 地址，然后与服务器建立 TCP 连接。 TCP 连接建立后，浏览器会向服务器发送 HTTP 请求。 服务器收到请求后，会根据请求的信息处理请求。 处理完请求后，服务器会返回一个 HTTP 响应给浏览器。 浏览器收到响应后，会根据响应的信息渲染页面。然后，浏览器和服务器断开 TCP 连接。 客户端发送一个请求到服务器，服务器处理请求并返回一个响应。这个过程是同步的，也就是说，客户端在发送请求后必须等待服务器的响应。在等待响应的过程中，客户端不会发送其他请求。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:6","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3.7 说一下 HTTP 的报文结构？ HTTP 的报文结构可以分为两类：请求报文和响应报文。两者在结构上相似，都包含了起始行、头部和消息正文。 请求报文结构 请求行 (Request Line) 方法 (Method)：如 GET、POST、PUT、DELETE 等。 请求目标 (Request-URI)：即请求的资源路径。 HTTP 版本 (HTTP-Version)：如 HTTP/1.1。 请求头部 (Request Headers) 包含多个首部字段，每个字段由字段名和字段值组成。 用于提供客户端信息、请求的资源信息等。 常见请求头： Host：请求的主机名和端口。 User-Agent：发起请求的客户端信息。 Accept：客户端可接受的响应内容类型。 Content-Type：请求体的媒体类型。 Authorization：认证信息。 空行：用于分隔请求头部和请求主体。 请求主体 (Request Body)：包含实际要发送给服务器的数据，仅在 POST、PUT 等方法中存在。 GET /index.html HTTP/1.1 Host: www.example.com User-Agent: Mozilla/5.0 Accept: text/html 响应报文结构 状态行 (Status Line) HTTP 版本 (HTTP-Version)：如 HTTP/1.1。 状态码 (Status Code)：如 200、404、500 等。 原因短语 (Reason-Phrase)：对状态码的简短描述。 响应头部 (Response Headers) 包含多个首部字段，每个字段由字段名和字段值组成。 用于提供服务器信息、响应的资源信息等。 常见响应头： Date：响应生成的日期和时间。 Content-Type：响应体的媒体类型。 Content-Length：响应体的长度。 Set-Cookie：设置 HTTP Cookie。 空行：用于分隔响应头部和响应主体。 响应主体 (Response Body)：包含实际要返回给客户端的数据。 HTTP/1.1 200 OK Date: Mon, 27 Jul 2009 12:28:53 GMT Content-Type: text/html Content-Length: 138 \u003chtml\u003e \u003cbody\u003e \u003ch1\u003eHello, World!\u003c/h1\u003e \u003c/body\u003e \u003c/html\u003e ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:7","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3.8 URI 和 URL 有什么区别? 属性 URI URL 定义 统一资源标识符，用于标识一个资源 统一资源定位符，提供资源的定位方法 组成部分 [scheme:][//authority][path][?query][#fragment] scheme://authority/path[?query][#fragment]（必须包含scheme（协议），authority（域名/IP），路径） 例子 urn:isbn:0451450523（为URN，不是URL，但是URI） https://www.example.com/index.html 子集 可以是 URL 或 URN 是 URI 的子集 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:8","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3.9 说下 HTTP1.0，1.1，2.0 的区别？ HTTP1.0 默认短连接，HTTP 1.1 默认长连接，HTTP 2.0 采用多路复用。 特性 HTTP/1.0 HTTP/1.1 HTTP/2.0 连接管理 短连接（默认每个请求/响应对后都关闭连接） 长连接（默认 keep-alive） 多路复用（同一连接多请求） Host 头部 不支持 支持 支持 缓存控制 简单的 Expires 头部 复杂的 Cache-Control 头部 同 HTTP/1.1 传输编码 无 支持分块传输编码 二进制分帧 请求方法 GET, POST GET, POST, PUT, DELETE, OPTIONS 等 同 HTTP/1.1 头部压缩 无 无 HPACK 压缩（减少了冗余头部信息的带宽消耗） 服务器推送 无 无 支持 流优先级 无 无 支持 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:9","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3.10 HTTP/3 了解吗？ HTTP/2.0 基于 TCP 协议，而 HTTP/3.0 则基于 QUIC 协议，Quick UDP Connections，直译为快速 UDP 网络连接。 基于 TCP 的 HTTP/2.0，尽管从逻辑上来说，不同的流之间相互独立，不会相互影响，但在实际传输的过程中，数据还是要一帧一帧的发送和接收，一旦某一个流的数据有丢包，仍然会阻塞在它之后传输的流数据。 而基于 UDP 的 QUIC 协议可以更彻底解决了 HTTP/2 中的队头阻塞问题，让不同的流之间真正的实现相互独立传输，互不干扰。同时，QUIC 协议在传输的过程中就完成了 TLS 加密握手，更直接了。 目前使用最广泛的是哪个HTTP版本还是是 HTTP/2，在 2022 年 1 月达到峰值，占所有网站的 46.9%。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:10","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3.11 HTTP 如何实现长连接？在什么时候会超时？ 什么是 HTTP 的长连接？ HTTP 分为长连接和短连接，本质上说的是 TCP 的长短连接。TCP 连接是一个双向的通道，它是可以保持一段时间不关闭的，因此 TCP 连接才具有真正的长连接和短连接这一说法。 TCP 长连接可以复用一个 TCP 连接，来发起多次的 HTTP 请求，这样就可以减少资源消耗，比如一次请求 HTML，如果是短连接的话，可能还需要请求后续的 JS/CSS。 通过在头部（请求和响应头）设置 Connection 字段指定为keep-alive，HTTP/1.0 协议支持，但是是默认关闭的，从 HTTP/1.1 以后，连接默认都是长连接。 在什么时候会超时呢？ HTTP 一般会有 httpd 守护进程，里面可以设置 keep-alive timeout，当 tcp 连接闲置超过这个时间就会关闭，也可以在 HTTP 的 header 里面设置超时时间 TCP 的 keep-alive 包含三个参数，支持在系统内核的 net.ipv4 里面设置；当 TCP 连接之后，闲置了 tcp_keepalive_time，则会发生侦测包，如果没有收到对方的 ACK，那么会每隔 tcp_keepalive_intvl 再发一次，直到发送了 tcp_keepalive_probes，就会丢弃该连接。 tcp_keepalive_intvl = 15 tcp_keepalive_probes = 5 tcp_keepalive_time = 1800 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:11","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3.12 说说 HTTP 与 HTTPS 有哪些区别？ HTTPS 是 HTTP 的增强版，在 HTTP 的基础上加入了 SSL/TLS 协议，确保数据在传输过程中是加密的。SSL/TLS 需要向 CA（证书权威机构）申请数字证书，用于验证服务器的身份。 HTTP 的默认端⼝号是 80，URL 以http://开头；HTTPS 的默认端⼝号是 443，URL 以https://开头。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:12","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3.13 为什么要用 HTTPS？解决了哪些问题？ 使用 HTTPS 主要是为了解决 HTTP 传输过程中的一些安全问题，因为 HTTP 是明文传输，所以 HTTPS 在 HTTP 的基础上加入了 SSL/TLS 协议。 HTTPS 主要解决了以下几个问题： 窃听风险：第三方可以截获传输的数据包，获取敏感信息。 篡改风险：第三方可以在传输过程中篡改数据包，修改数据。 冒充风险：第三方可以冒充服务器，与客户端通信。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:13","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3.14 HTTPS 工作流程是怎样的？ HTTPS 的连接建立在 SSL/TLS 握手之上，工作流程如下图所示： 如果通信内容被截取，但由于没有会话密钥，所以无法解密。当通信结束后，连接会被关闭，会话密钥也会被销毁，下次通信会重新生成一个会话密钥。 HTTPS 在不同阶段会使用不同的加密方式： 非对称加密：在握手阶段使用，特别是在密钥交换过程中。非对称加密使用公钥和私钥，其中公钥可以公开，私钥保密。客户端使用公钥加密信息，服务器使用私钥解密。 对称加密：在完成握手后，所有的数据传输都使用对称加密。对称加密使用相同的密钥进行加密和解密，这种加密方式比非对称加密更快。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:14","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3.15 HTTPS 会加密 URL 吗？ HTTPS 通过 SSL/TLS 协议确保了客户端与服务器之间交换的数据被加密，这包括 HTTP 头部和正文。而 URL 是 HTTP 头部的一部分，因此这部分信息也是加密的。但因为涉及到 SSL 握手的过程，所以域名信息会被暴露出来，需要注意。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:15","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3.16 客户端怎么去校验证书的合法性？ 首先，所有的证书都是由 CA 机构签发的，CA 机构是一个受信任的第三方机构，它会对证书的申请者进行身份验证，然后签发证书，它具有极高的可信度。 客户端（通常是浏览器，通常会集成 CA 的公钥信息）在校验证书的合法性时，主要通过以下步骤来校验证书的合法性。 浏览器会读取证书的所有者、有效期、颁发者等信息，先校验网站域名是否一致，然后校验证书的有效期是否过期； 浏览器开始查找内置的 CA，与服务器返回证书中的颁发者进行对比，确认是否为合法机构； 如果是，从内部植入的 CA 公钥解密 Certificate 的 Signature 内容，得到⼀个 Hash 值 H2； 使⽤同样的 Hash 算法获取证书的 Hash 值 H1，⽐较 H1 和 H2，如果值相同，则为可信赖的证书，否则告警。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:16","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3.17 如何理解 HTTP 协议是无状态的？ 这个无状态的的状态值的是什么？是客户端的状态，所以字面意思，就是 HTTP 协议中服务端不会保存客户端的任何信息。 比如当浏览器第一次发送请求给服务器时，服务器响应了；如果同个浏览器发起第二次请求给服务器时，它还是会响应，但是呢，服务器不知道你就是刚才的那个浏览器。 那有什么办法记录状态呢？ 主要有两个办法，Session 和 Cookie。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:17","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"3.18 说说 Session 和 Cookie 有什么联系和区别? Cookie 是保存在客户端的一小块文本串的数据。客户端向服务器发起请求时，服务端会向客户端发送一个 Cookie，客户端就把 Cookie 保存起来。在客户端下次向同一服务器再发起请求时，Cookie 被携带发送到服务器（通过 HTTP 请求头的 Cookie 字段在客户端和服务器之间传递）。服务端可以根据这个 Cookie 判断用户的身份和状态。Cookie可以设置过期时间。如果不设置过期时间，则 Cookie 在会话结束（浏览器关闭）时失效。可以通过设置 Expires 或 Max-Age 属性来定义 Cookie 的持久性。 Session 指的就是服务器和客户端一次会话的过程。它是另一种记录客户状态的机制。不同的是 cookie 保存在客户端浏览器中，而 session 保存在服务器上（客户端只保存 Session ID）。客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上，这就是 session。客户端浏览器再次访问时只需要从该 session 中查找用户的状态。Session一般在用户会话结束时（例如关闭浏览器、超时）失效。服务器端可以配置 Session 的过期时间。 Session 和 Cookie 联系：依赖于 Cookie 来传递 Session ID（通常是服务器在创建 Session 时设置一个 Cookie 来存储 Session ID）。 Session 和 Cookie 的使用场景也不同： Cookie：适用于存储用户偏好、登录状态等较小的数据，可以跨页面持久化数据。常用于记录用户信息、跟踪用户行为等。 Session：适用于存储用户会话中的临时信息，如购物车、登录状态等。更适合需要较高安全性的场景，因为数据存储在服务器端。 分布式环境下 Session 怎么处理呢？ 分布式环境下，客户端请求经过负载均衡，可能会分配到不同的服务器上，假如一个用户的请求两次没有落到同一台服务器上，那么在新的服务器上就没有记录用户状态的 Session。 可以使用 Redis 等分布式缓存来存储 Session，在多台服务器之间共享。 客户端无法使用 Cookie 怎么办？ 有可能客户端无法使用 Cookie，比如浏览器禁用 Cookie，或者客户端是安卓、IOS 等等。 这时候怎么办？SessionID 怎么存？怎么传给服务端呢？首先是 SessionID 的存储，可以使用客户端的本地存储，比如浏览器的 sessionStorage。 接下来怎么传呢？ 拼接到 URL 里：直接把 SessionID 作为 URL 的请求参数 放到请求头里：把 SessionID 放到请求的 Header 里，比较常用。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:3:18","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4 TCP ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:0","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.1 详细说一下 TCP 的三次握手机制？ TCP（Transmission Control Protocol）是一个面向连接的、可靠的、基于字节流的传输层协议。TCP 通过三次握手机制来建立连接，确保双方准备就绪并能可靠地进行通信。以下是三次握手的详细过程： 第一次握手 客户端：发送一个带有 SYN 标志的 TCP 报文段（称为 SYN 报文段），并选择一个初始序列号 seq = x。 服务器：收到这个 SYN 报文段后，服务器处于 “SYN_RCVD” 状态。 目的：客户端通知服务器它希望建立连接，并告知服务器自己的初始序列号。 报文内容： 客户端 --\u003e 服务器: SYN, seq = x 第二次握手 服务器：服务器收到 SYN 报文段后，回复一个带有 SYN 和 ACK 标志的 TCP 报文段（称为 SYN-ACK 报文段）。该报文段中包含服务器选择的初始序列号 seq = y，以及对客户端序列号 x 的确认 ack = x + 1。 客户端：收到这个 SYN-ACK 报文段后，客户端处于 “ESTABLISHED” 状态。 目的：服务器告诉客户端，它的连接请求被接受了，并通知客户端自己的初始序列号。 报文内容： 服务器 --\u003e 客户端: SYN, ACK, seq = y, ack = x + 1 第三次握手 客户端：客户端收到 SYN-ACK 报文段后，回复一个带有 ACK 标志的 TCP 报文段（称为 ACK 报文段）。该报文段中包含对服务器序列号 y 的确认 ack = y + 1。 服务器：收到这个 ACK 报文段后，服务器处于 “ESTABLISHED” 状态，连接建立完成。 目的：客户端确认收到了服务器的同步应答，完成三次握手，建立连接。 报文内容： 客户端 --\u003e 服务器: ACK, seq = x + 1, ack = y + 1 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:1","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.2 TCP 握手为什么是三次，为什么不能是两次？不能是四次？ 使用三次握手可以建立一个可靠的连接。这一过程的目的是确保双方都知道对方已准备好进行通信，并同步双方的序列号，从而保持数据包的顺序和完整性。 两次握手无法确保连接的可靠性。具体原因如下： 旧的重复报文干扰：在两次握手情况下，旧的 SYN 报文可能会被错误地当作新的连接请求。如果服务器发送 SYN-ACK 报文后客户端没有响应，服务器会认为连接失败，但实际上客户端可能已经收到了 SYN-ACK 报文，这样就会导致服务器资源浪费和连接不一致。 确认机制不完整：两次握手不能保证双方都能正确接收到对方的确认报文。服务器无法确认客户端是否收到了自己的 SYN-ACK 报文，而客户端也无法确认服务器是否收到了自己的 SYN 报文。 四次握手在正常情况下是多余的，会增加连接建立的复杂性和开销。三次握手已经足够保证连接的可靠性和正确性： 增加复杂性和开销：四次握手会增加额外的一个报文传输，使得连接建立的过程变得复杂，不必要地增加了传输的延迟和开销。 三次握手足够可靠：三次握手已经可以确保双方都能确认连接的建立，并且可以避免旧的重复报文的干扰，再增加一次握手并不会带来额外的安全性或可靠性提升。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:2","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.3 三次握手中每一次没收到报文会发生什么情况？ 在TCP三次握手的过程中，每一次没收到报文都会触发重传机制，并最终导致连接建立失败。具体情况如下： 第一次握手：客户端发送 SYN 报文 情况：如果客户端发送的 SYN 报文没有收到服务器的 SYN-ACK 报文（比如报文丢失或服务器没有响应）。 处理：客户端会进行超时重传。客户端在发送 SYN 报文后会启动一个定时器，如果在一定时间内没有收到服务器的响应（SYN-ACK 报文），客户端会重传 SYN 报文。 结果：重传次数达到一定次数（通常是三次）后，客户端会放弃连接，报错并关闭连接请求。 第二次握手：服务器发送 SYN-ACK 报文 情况：如果服务器发送的 SYN-ACK 报文没有收到客户端的 ACK 报文（比如报文丢失或客户端没有响应）。 处理：服务器会进行超时重传。服务器在发送 SYN-ACK 报文后也会启动一个定时器，如果在一定时间内没有收到客户端的 ACK 报文，服务器会重传 SYN-ACK 报文。 结果：重传次数达到一定次数后，服务器会放弃连接，报错并关闭连接请求。 第三次握手：客户端发送 ACK 报文 情况：如果客户端发送的 ACK 报文没有收到服务器的确认（ACK 报文本身一般不会单独确认，但此处假设服务器未能进入 ESTABLISHED 状态）。 处理：服务器会因为没有收到 ACK 报文而保持在 SYN-RECEIVED 状态，并可能最终超时并关闭连接。 结果：客户端会认为连接已经建立，并进入 ESTABLISHED 状态，但如果服务器超时关闭连接，客户端在尝试发送数据时会发现连接无法使用，从而报错并关闭连接。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:3","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.4 第二次握手传回了 ACK，为什么还要传回 SYN？ ACK 标志是为了告诉客户端，它发送的 SYN 报文已经被服务器正确接收。 而传回 SYN 是为了告诉客户端，服务器也希望建立连接，并且响应的确实是客户端发送的报文。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:4","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.5 第 3 次握手可以携带数据吗？ 第 3 次握手是可以携带数据的。此时客户端已经处于 ESTABLISHED 状态。对于客户端来说，它已经建立连接成功，并且确认服务端的接收和发送能力是正常的。 但实际应用中通常不会携带数据，因为在第三次握手中发送数据可能会引发安全和可靠性问题。此时连接还未完全建立，发送数据可能导致数据丢失或安全漏洞。 第一次握手不能携带数据是出于安全的考虑，因为如果允许携带数据，攻击者每次在 SYN 报文中携带大量数据，就会导致服务端消耗更多的时间和空间去处理这些报文，会造成 CPU 和内存的消耗。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:5","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.6 说说半连接队列和 SYN Flood 攻击的关系？ TCP 进入三次握手前，服务端会从 CLOSED 状态变为 LISTEN 状态, 同时在内部创建了两个队列：半连接队列（SYN 队列）和全连接队列（ACCEPT 队列）。 半连接队列（Half-Open Connection Queue）是指在 TCP 三次握手过程中，服务器在收到客户端的 SYN 报文后，返回 SYN-ACK 报文并等待客户端的 ACK 报文确认连接的这段时间内，服务器为每个未完成的连接分配的资源队列。 SYN Flood 攻击是指攻击者发送大量的 SYN 报文请求与服务器建立连接，但在服务器返回 SYN-ACK 报文后，攻击者不发送最终的 ACK 报文完成握手。这样，服务器的半连接队列会被大量未完成的连接占满，导致服务器资源耗尽，无法处理正常的连接请求，进而造成拒绝服务（Denial of Service，DoS）。 因此，SYN Flood 攻击的核心在于利用半连接队列的有限资源，通过大量伪造的连接请求使服务器无法处理合法用户的连接。 那有什么应对方案呢？ 主要有 syn cookie 和 SYN Proxy 防火墙等。 syn cookie：在收到 SYN 包后，服务器根据一定的方法，以数据包的源地址、端口等信息为参数计算出一个 cookie 值作为自己的 SYNACK 包的序列号，回复 SYN+ACK 后，服务器并不立即分配资源进行处理，等收到发送方的 ACK 包后，重新根据数据包的源地址、端口计算该包中的确认序列号是否正确，如果正确则建立连接，否则丢弃该包。 SYN Proxy 防火墙：服务器防火墙会对收到的每一个 SYN 报文进行代理和回应，并保持半连接。等发送方将 ACK 包返回后，再重新构造 SYN 包发到服务器，建立真正的 TCP 连接。 缩短 SYN-ACK 超时时间：调整系统的 SYN-ACK 超时时间，使未完成的连接请求能够更快地被清理出队列。 分布式拒绝服务防护（DDoS Protection Services）：使用专业的 DDoS 防护服务，如 Cloudflare、Akamai 等，这些服务可以在网络边缘过滤恶意流量，减轻服务器的压力。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:6","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.7 说说 TCP 四次挥手的过程？ TCP 四次挥手是指 TCP 连接终止时所进行的四个步骤，数据传输结束之后，通信双方都可以主动发起断开连接请求，这里假定客户端发起（通常是客户端），具体过程如下： 第一次挥手：FIN 报文： 客户端发送一个 FIN 报文段，表明它已经完成了数据发送，请求关闭连接。客户端进入 FIN_WAIT_1 状态。 报文段格式：FIN=1, seq=x。 第二次挥手：ACK 报文： 服务器接收到 FIN 报文后，返回一个 ACK 报文段，确认收到了关闭请求。发送完毕后，服务器端进入 CLOSE_WAIT 状态，客户端接收到这个确认包之后，进入 FIN_WAIT_2 状态。 报文段格式：ACK=1, ack=x+1。 此时，服务器可能还需要继续发送数据，因此连接处于半关闭状态。 第三次挥手：FIN 报文： 服务端在完成数据发送后，发送一个 FIN 报文段，表明它也已经完成了数据发送，请求关闭连接。发送完毕后，服务器端进入 LAST_ACK 状态，等待来自客户端的最后一个 ACK。 报文段格式：FIN=1, seq=y。 第四次挥手：ACK 报文： 客户端接收到 FIN 报文后，返回一个 ACK 报文段，确认收到了关闭请求，并进入 TIME_WAIT 状态，等待了某个固定时间（两个最大段生命周期，2MSL，2 Maximum Segment Lifetime）之后，没有收到服务器端的 ACK ，认为服务器端已经正常关闭连接，于是自己也关闭连接，进入 CLOSED 状态。服务器端接收到这个确认包之后，关闭连接，进入 CLOSED 状态。 报文段格式：ACK=1, ack=y+1。 此时，连接正式关闭，双方都完成了连接的释放。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:7","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.8 TCP 挥手为什么需要四次呢？。 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。 服务端收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。 从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送，从而比三次握手导致多了一次。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:8","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.9 TCP 四次挥手过程中，为什么需要等待 2MSL, 才进入 CLOSED 关闭状态？ 为了保证客户端发送的最后一个 ACK 报文段能够到达服务端。 这个 ACK 报文段有可能丢失，因而使处在 LAST-ACK 状态的服务端就收不到对已发送的 FIN 报文段的确认。服务端会超时重传这个 FIN 报文段，而客户端就能在 2MSL 时间内（超时 + 1MSL 传输）收到这个重传的 FIN 报文段。接着客户端重传一次确认，重新启动 2MSL 计时器。最后，客户端和服务器都正常进入到 CLOSED 状态。 防止已失效的连接请求报文段出现在本连接中。客户端在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样就可以使下一个连接中不会出现这种旧的连接请求报文段。 为什么等待的时间是 2MSL？ MSL 是 Maximum Segment Lifetime，报⽂最⼤⽣存时间，它是任何报⽂在⽹络上存在的最⻓时间，超过这个时间报⽂将被丢弃。 TIME_WAIT 等待 2 倍的 MSL，⽐较合理的解释是：⽹络中可能存在来⾃发送⽅的数据包，当这些发送⽅的数据包被接收⽅处理后⼜会向对⽅发送响应，所以⼀来⼀回需要等待 2 倍的时间。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:9","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.10 保活计时器有什么用？ 除时间等待计时器外，TCP 还有一个保活计时器（keepalive timer），用于在长时间闲置的 TCP 连接中检测对端是否仍然存活，并防止连接因为长时间没有活动而被认为是不活跃的而被关闭。 设想这样的场景：客户已主动与服务器建立了 TCP 连接。但后来客户端的主机突然发生故障。显然，服务器以后就不能再收到客户端发来的数据。因此，应当有措施使服务器不要再白白等待下去。这就需要使用保活计时器了。 服务器每收到一次客户端的数据，就重新设置保活计时器，时间的设置通常是两个小时。若两个小时都没有收到客户端的数据，服务端就发送一个探测报文段，以后则每隔 75 秒钟发送一次。若连续发送 10 个探测报文段后仍然无客户端的响应，服务端就认为客户端出了故障，接着就关闭这个连接。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:10","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.11 CLOSE-WAIT 和 TIME-WAIT 的状态和意义？ CLOSE-WAIT 状态有什么意义？ 服务端收到客户端关闭连接的请求并确认之后，就会进入 CLOSE-WAIT 状态。此时服务端可能还有一些数据没有传输完成，因此不能立即关闭连接，而 CLOSE-WAIT 状态就是为了保证服务端在关闭连接之前将待发送的数据处理完。 TIME-WAIT 有什么意义？ TIME-WAIT 状态发生在第四次挥手，当客户端向服务端发送 ACK 确认报文后进入 TIME-WAIT 状态。 防⽌旧连接的数据包 保证连接正确关闭 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:11","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.12 TIME_WAIT 状态过多会导致什么问题？怎么解决？ TIME_WAIT 状态过多会导致什么问题? 如果服务器有处于 TIME-WAIT 状态的 TCP，则说明是由服务器⽅主动发起的断开请求。 什么场景下服务端会主动断开连接呢？ HTTP 没有使用长连接 HTTP 长连接超时 HTTP 长连接的请求数量达到上限 过多的 TIME-WAIT 状态主要的危害有两种： 端口资源耗尽：每个处于 TIME_WAIT 状态的连接都会占用一个本地端口。如果 TIME_WAIT 状态的连接过多，可能会导致可用的本地端口资源耗尽，新的连接请求无法分配端口，从而导致服务不可用。 内存和资源占用：TIME_WAIT 状态的连接会占用一定的系统内存和资源。如果连接过多，会导致系统资源被大量占用，影响服务器的性能和其他应用的运行。 怎么解决 TIME_WAIT 状态过多？ 服务器可以设置 SO_REUSEADDR 套接字来通知内核，如果端口被占用，但是 TCP 连接位于 TIME_WAIT 状态时可以重用端口。 还可以使用长连接的方式来减少 TCP 的连接和断开，在长连接的业务里往往不需要考虑 TIME_WAIT 状态。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:12","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.13 说说 TCP 报文头部的格式？ 一个 TCP 报文段主要由报文段头部（Header）和数据两部分组成。头部包含了确保数据可靠传输所需的各种控制信息，比如说序列号、确认号、窗口大小等。 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Source Port | Destination Port | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Acknowledgment Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Data |Reser-| Flags | | | Offset|ved | (6 bits) | Window | | (4 | (6 | | | | | bits)| bits)| | | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Checksum | Urgent Pointer | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Options (if any) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | | | data | | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 源端口号（Source Port）：16 位（2 个字节），用于标识发送端的应用程序。 目标端口号（Destination Port）：也是 16 位，用于标识接收端的应用程序。 序列号（Sequence Number）：32 位，用于标识从 TCP 发送者发送的数据字节流中的第一个字节的顺序号。确保数据按顺序接收。 确认号（Acknowledgment Number）：32 位，如果 ACK 标志被设置，则该字段包含发送确认的序列号，即接收 TCP 希望收到的下一个序列号。 数据偏移（Data Offset）：4 位，表示 TCP 报文头部的长度，用于指示数据开始的位置。 保留（Reserved）：6 位，为将来使用预留，目前必须置为 0。 控制位（Flags）：共 6 位，包括 URG（紧急指针字段是否有效）、ACK（确认字段是否有效）、PSH（提示接收端应该尽快将这个报文段交给应用层）、RST（重置连接）、SYN（同步序号，用于建立连接）、FIN（结束发送数据）。 窗口大小（Window）：16 位，用于流量控制，表示接收端还能接收的数据的字节数（基于接收缓冲区的大小）。 校验和（Checksum）：16 位，覆盖整个 TCP 报文段（包括 TCP 头部、数据和一个伪头部）的校验和，用于检测数据在传输过程中的任何变化。 紧急指针（Urgent Pointer）：16 位，只有当 URG 控制位被设置时才有效，指出在报文段中有紧急数据的位置。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:13","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.14 TCP 是如何保证可靠性的？ TCP（传输控制协议）通过多种机制来确保数据传输的可靠性。以下是TCP保证可靠性的主要方法： 连接管理（Connection Management）：TCP 使用三次握手（Three-Way Handshake）建立连接和四次挥手（Four-Way Handshake）关闭连接，确保连接的建立和释放过程可靠、无误。 校验和（Checksum）：TCP 报文段包含一个校验和字段，用于验证报文段在传输过程中是否被损坏。发送方计算并填充校验和，接收方根据接收到的数据重新计算校验和并进行验证，确保数据的完整性。 序列号（Sequence Numbers）：TCP 为每个字节分配一个序列号。发送方和接收方使用序列号来确保数据按照正确的顺序接收并重组，防止数据丢失或重复。 确认应答（Acknowledgments, ACKs）：TCP 使用确认应答机制来确认数据的接收。接收方在收到数据后，会发送一个带有确认号的ACK报文段，告知发送方已成功接收到的数据。这种机制确保了数据的传递和确认。 拥塞控制（Congestion Control）：TCP 通过慢启动、拥塞避免、快重传和快恢复等算法来防止网络拥塞，保证数据传输的稳定性和可靠性。 流量控制（Flow Control）：TCP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。（TCP 利用滑动窗口实现流量控制） 重传机制（Retransmission）：发送方在发送数据后会启动一个计时器。如果在指定时间内未收到对应的ACK报文段，发送方会认为该数据包丢失并进行重传。TCP还使用快速重传机制，当收到三个重复的ACK时，立即重传相应的数据包。 最大消息长度（Maximum Message Length）：在建立 TCP 连接的时候，双方约定一个最大的长度（MSS）作为发送的单位，重传的时候也是以这个单位来进行重传。理想的情况下是该长度的数据刚好不被网络层分块。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:14","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.15 说说 TCP 的流量控制？ TCP 提供了一种机制，可以让发送端根据接收端的实际接收能力控制发送的数据量，以确保接收方能够及时处理数据而不会因为数据过多而溢出缓冲区，这就是流量控制。 TCP 的流量控制主要通过滑动窗口（Sliding Window）机制来实现。示例如下： ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:15","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.16 详细说说 TCP 的滑动窗口？ TCP 发送一个数据，如果需要收到确认应答，才会发送下一个数据。这样的话就会有个缺点：效率会比较低。而滑动窗口允许发送方在未接收到 ACK 确认之前可以发送多个数据段，以提高网络的利用率和传输效率，同时避免了发送方过度发送导致接收方缓冲区溢出。 TCP 滑动窗口分为两种: 发送窗口和接收窗口。发送端的滑动窗口包含四大部分，如下： 已发送且已收到 ACK 确认 已发送但未收到 ACK 确认 未发送但可以发送 未发送也不可以发送 蓝色框里就是发送窗口。SND.WND 表示发送窗口的大小，SND.NXT表示下一个发送的位置，它指向未发送但可以发送的第一个字节的序列号；SND.UNA: 一个绝对指针，它指向的是已发送但未确认的第一个字节的序列号。 接收方的滑动窗口包含三大部分，如下： 已成功接收并确认 未收到数据但可以接收 未收到数据并不可以接收的数据 蓝色框内，就是接收窗口。REV.WND 表示接收窗口的大小；REV.NXT表示下一个接收的位置，它指向未收到但可以接收的第一个字节的序列号。 发送方和接收方通过 ACK 确认报文段来协商窗口大小。发送方根据接收方的接收窗口大小来调整自己的发送窗口大小，以确保不会发送超出接收方能力的数据量。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:16","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.17 了解 Nagle 算法和延迟确认吗？ Nagle 算法和延迟确认是干什么的？ 当我们 TCP 报⽂的承载的数据⾮常⼩的时候，例如⼏个字节，那么整个⽹络的效率是很低的，因为每个 TCP 报⽂中都会有 20 个字节的 TCP 头部，也会有 20 个字节的 IP 头部，⽽数据只有⼏个字节，所以在整个报⽂中有效数据占有的比例就会⾮常低。 那么就出现了常⻅的两种策略，来减少⼩报⽂的传输，分别是： Nagle 算法：当应用程序发送数据时，Nagle 算法会先将数据放入缓冲区，并等待一定的时间（称为 Nagle 算法定时器），以便将多个小数据包合并成一个大数据包一起发送。只有当缓冲区中的数据量达到一定阈值（Nagle 算法的最小传输单元）或者定时器超时时，才会触发数据的发送。Nagle 算法主要用于避免发送大量小数据包的情况，从而减少网络的拥塞，提高网络的性能和效率。 延迟确认：当接收方收到数据时，不会立即发送 ACK 确认报文，而是等待一段时间（一般是等待 200 毫秒左右），以便将多个 ACK 合并成一个 ACK 一起发送。如果在延迟时间内收到新的数据包，则会立即发送 ACK 报文，以确认收到的数据。延迟确认主要用于减少确认报文的数量，避免网络中出现过多的 ACK 报文，从而减少网络的负载和提高网络的吞吐量。 一般情况下，Nagle 算法和延迟确认不能一起使用，Nagle 算法意味着延迟发，延迟确认意味着延迟接收，两个凑在一起就会造成更大的延迟，会产生性能问题。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:17","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.18 说说 TCP 的拥塞控制？ 什么是拥塞控制？不是有了流量控制吗？ 前⾯的流量控制是避免发送⽅的数据填满接收⽅的缓存，但是并不知道整个⽹络之中发⽣了什么。 ⼀般来说，计算机⽹络都处在⼀个共享的环境。因此也有可能会因为其他主机之间的通信使得⽹络拥堵。 在⽹络出现拥堵时，如果继续发送⼤量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是⼀重传就会导致⽹络的负担更重，于是会导致更⼤的延迟以及更多的丢包，这个情况就会进⼊恶性循环被不断地放⼤…. 所以，TCP 不能忽略整个网络中发⽣的事，它被设计成⼀个⽆私的协议，当⽹络发送拥塞时，TCP 会⾃我牺牲，降低发送的数据流。 于是，就有了拥塞控制，控制的⽬的就是避免发送⽅的数据填满整个⽹络。 发送方维护一个拥塞窗口 cwnd（congestion window） 的变量，调节所要发送数据的量。 什么是拥塞窗⼝？和发送窗⼝有什么关系呢？ 拥塞窗⼝ cwnd是发送⽅维护的⼀个的状态变量，它会根据⽹络的拥塞程度动态变化的。 发送窗⼝ swnd 和接收窗⼝ rwnd 是约等于的关系，那么由于加⼊了拥塞窗⼝的概念后，此时发送窗⼝的值是 swnd = min(cwnd, rwnd)，也就是拥塞窗⼝和接收窗⼝中的最⼩值。 拥塞窗⼝ cwnd 变化的规则： 只要⽹络中没有出现拥塞， cwnd 就会增⼤； 但⽹络中出现了拥塞， cwnd 就减少； 拥塞控制有哪些常用算法？ 拥塞控制主要有这几种常用算法： 慢启动：先发出少量数据，就像探路一样，先摸清当前的网络拥堵状态后，再决定按照多大的速度传送数据） 拥塞避免：在拥塞避免阶段，TCP的拥塞窗口以线性增长的方式增加，而不是指数级增长 快重传：发送方不必等待超时计时器的到期，而是立即进行快速重传，重传丢失的数据包 快恢复：快恢复算法用于在收到重复ACK时，迅速调整拥塞窗口大小以恢复传输速度 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:18","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.19 说说 TCP 的重传机制？ TCP 的重传机制是确保数据传输可靠性的重要部分之一。它通过在发送方定时器超时或者接收到连续的重复确认时触发，重新发送丢失或者未确认的数据段，以确保数据能够在网络中正确传输。以下是 TCP 的重传机制的主要原理： 超时重传：当发送方发送数据后，在等待一定时间内未收到确认 ACK 报文时，触发超时重传机制，重新发送未确认的数据段。超时时间通常根据网络往返时间（RTT）动态调整，以适应网络延迟的变化。 快速重传：当发送方接收到连续的重复 ACK 报文时，表明接收方已经成功接收了一些数据，但有一个或多个数据段丢失。为了尽快重传丢失的数据段，发送方立即触发快速重传机制，重新发送丢失的数据段，而不必等待超时定时器的到期。 带选择确认的重传（SACK）：选择确认（SACK）为了解决应该重传多少个包的问题，允许接收方在确认报文中指示出连续的数据段中哪些已经成功接收，哪些丢失了。发送方可以根据 SACK 报文中指示的丢失数据段信息，选择性地进行重传，而不是重传整个窗口内的所有未确认数据段。 重复 SACK：是在 SACK 的基础上做了一些扩展，在接收方收到连续的重复数据段时，会生成多个相同的 SACK 报文，用于指示哪些数据段已经成功接收。主要用来告诉发送方，有哪些数据包，自己重复接受了。DSACK 的目的是帮助发送方判断，是否发生了包失序、ACK 丢失、包重复或伪重传。让 TCP 可以更好的做网络流控。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:19","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.20 说说 TCP 的粘包和拆包？ TCP 是面向流，没有界限的一串数据。TCP 底层并不了解上层业务数据的具体含义，它会根据 TCP 缓冲区的实际情况进行包的划分。 粘包指的是在 TCP 连接中，发送方发送的多个数据包在接收方接收时被合并成一个数据包。这种情况通常发生在以下几种场景中： 发送方发送数据过于频繁，发送的数据量较小，多个小数据包在发送时被合并成一个数据包。Nagle 算法的作用使得发送方在网络未确认前将小数据包合并发送。 接收方读取数据不及时，一次性读取多个数据包。 拆包指的是一个完整的数据包在接收方接收时被拆分成了多个数据包。这种情况通常发生在以下几种场景中： 网络传输过程中，由于 MTU（最大传输单元）的限制，一个大的数据包被拆分成多个小的数据包进行传输。 待发送数据大于 MSS（最大报文长度），TCP 在传输前将进行拆包。即 TCP 报文长度 - TCP 头部长度 \u003e MSS。 那怎么解决呢？ 发送端将每个数据包封装为固定长度； 在数据尾部增加特殊字符进行分割； 将数据分为两部分，一部分是头部，一部分是内容体；其中头部结构大小固定，且有一个字段声明内容体的大小； 设计特定的应用层协议，包含数据包头部（例如，标识符、长度字段、校验和等）和数据部分。接收方根据协议解析数据包。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:20","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.21 如果已经建立了连接，但是服务端的进程崩溃会发生什么？服务器断电呢？ TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程。 当服务器断电时，情况会有所不同：客户端在尝试与服务器通信时，会发现连接中断，通常会收到一个错误（如 ECONNRESET 或 ETIMEDOUT），客户端的应用程序需要处理这个错误，并可能尝试重新建立连接或采取其他应对措施。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:21","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.22 如果已经建立了连接，但是客户端突然出现故障了怎么办？ 客户端出现故障指的是客户端的主机发生了宕机，或者断电的场景。发生这种情况的时候，如果服务端一直不会发送数据给客户端，那么服务端是永远无法感知到客户端宕机这个事件的，也就是服务端的 TCP 连接将一直处于 ESTABLISH 状态，占用着系统资源。 为了避免这种情况，TCP 搞了个保活机制。这个机制的原理是这样的： 定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:22","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"4.23 服务器出现大量 CLOSE_WAIT 状态的原因有哪些？ CLOSE_WAIT 状态是【被动关闭方】才会有的状态，而且如果【被动关闭方】没有调用 close 函数关闭连接，那么就无法发出 FIN 报文，从而无法使得 CLOSE_WAIT 状态的连接转变为 LAST_ACK 状态。 所以，当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接。 我们先来分析一个普通的 TCP 服务端的流程： 创建服务端 socket，bind 绑定端口、listen 监听端口 将服务端 socket 注册到 epoll epoll_wait 等待连接到来，连接到来时，调用 accpet 获取已连接的 socket 将已连接的 socket 注册到 epoll epoll_wait 等待事件发生 对方连接关闭时，我方调用 close 可能导致服务端没有调用 close 函数的原因是：2，3，4，6步没有做 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:4:23","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"5 UDP ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:5:0","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"5.1 说说 TCP 和 UDP 的区别？ 特性 TCP UDP 连接 面向连接，传输数据前需建立连接 无需连接，立即传输数据 服务对象 一对一的两点服务 支持一对一、一对多、多对多的交互通信 可靠性 可靠交付，数据无差错、不丢失、不重复、按序到达 尽最大努力交付，不保证可靠交付数据 拥塞控制、流量控制 有拥塞控制和流量控制机制 无拥塞控制和流量控制机制，发送速率不受网络拥堵影响 首部开销 首部长度较长（20 字节—60字节） 首部只有 8 字节，且固定不变，开销较小 传输方式 字节流式传输，无边界，保证顺序和可靠 数据段报文传输，有边界，可能丢包和乱序 分片 在传输层进行分片，丢失分片时只重传丢失部分 在 IP 层进行分片，接收后在 IP 层组装再传给传输层 应用场景 文件传输、邮件传输 即时通讯、域名转换 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:5:1","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"5.2 为什么 QQ 采用 UDP 协议？ 首先，QQ 并不是完全基于 UDP 实现。比如在使用 QQ 进行文件传输等活动的时候，就会使用 TCP 作为可靠传输的保证。 使用 UDP 进行交互通信的好处在于，延迟较短，对数据丢失的处理比较简单。同时，TCP 是一个全双工协议，需要建立连接，所以网络开销也会相对大。 如果使用 QQ 语音和 QQ 视频的话，UDP 的优势就更为突出了，首先延迟较小。最重要的一点是不可靠传输，这意味着如果数据丢失的话，不会有重传。因为用户一般来说可以接受图像稍微模糊一点，声音稍微不清晰一点，但是如果在几秒钟以后再出现之前丢失的画面和声音，这恐怕是很难接受的。 由于 QQ 的服务器设计容量是海量级的应用，一台服务器要同时容纳十几万的并发连接，因此服务器端只有采用 UDP 协议与客户端进行通讯才能保证这种超大规模的服务 简单总结一下：UDP 协议是无连接方式的协议，它的效率高，速度快，占资源少，对服务器的压力比较小。但是其传输机制为不可靠传送，必须依靠辅助的算法来完成传输控制。QQ 采用的通信协议以 UDP 为主，辅以 TCP 协议。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:5:2","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"5.3 UDP 协议为什么不可靠？ UDP 在传输数据之前不需要先建立连接，远地主机的运输层在接收到 UDP 报文后，不需要确认，提供不可靠交付。总结就以下四点： 不保证消息交付：不确认，不重传，无超时 不保证交付顺序：不设置包序号，不重排，不会发生队首阻塞 不跟踪连接状态：不必建立连接或重启状态机 不进行拥塞控制：不内置客户端或网络反馈机制 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:5:3","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"5.4 DNS 为什么要用 UDP? 更准确地说，DNS 既使用 TCP 又使用 UDP。 当进行区域传送（主域名服务器向辅助域名服务器传送变化的那部分数据）时会使用 TCP，因为数据同步传送的数据量比一个请求和应答的数据量要多，而 TCP 允许的报文长度更长，因此为了保证数据的正确性，会使用基于可靠连接的 TCP。即在需要可靠传输或处理大数据包的特定场景下，DNS 也会使用 TCP 以确保传输的可靠性和完整性。 当客户端想 DNS 服务器查询域名（域名解析）的时候，一般返回的内容不会超过 UDP 报文的最大长度，即 512 字节，用 UDP 传输时，不需要创建连接，从而大大提高了响应速度，但这要求域名解析服务器和域名服务器都必须自己处理超时和重传从而保证可靠性。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:5:4","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"5.5 你会如何设计QQ中的网络协议？ 首先，我们要实现登录功能，这是使用 QQ 的第一步，为了保证账号和密码的安全性，我们可以选择 TCP + SSL/TLS 协议来进行登录。 因为 TCP 协议是一种可靠的传输协议，能够保证数据的完整性，而 SSL/TLS 能够对通信进行加密，保证数据的安全性。 接下来，我们需要考虑消息传递的实时性，如语音视频通话等，这时候我们可以选择 UDP 协议。UDP 的传输速度更快，对于实时性服务来说，速度是最重要的。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:5:5","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"5.6 UDP如何尽量保证消息的不丢失 对于 TCP 协议来说，如果数据包在传输过程中丢失，TCP 协议会自动进行重传。 而对于 UDP 协议来说，我们可以通过应用层的重传机制来保证消息的不丢失。当接收方收到消息后，返回一个确认信息给发送方，如果发送方在一定时间内没有收到确认信息，就重新发送消息。 同时，每个消息都附带一个唯一的序列号，接收方根据序列号判断是否有消息丢失，如果发现序列号不连续，就可以要求发送方重新发送。这样还可以防止消息重复。 当然了，消息持久化也很重要，可以将消息保存在服务器或者本地的数据库中，即使在网络中断或者其他异常情况下，也能从数据库中恢复消息。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:5:6","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"6 QUIC ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:6:0","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"6.1 QUIC是如何实现可靠传输的？（UDP如何实现可靠传输？） 把TCP可靠传输的特性（序号，确认应答，超时重传，流量控制）在应用层实现一遍。 基于UDP：QUIC 建立在 UDP 之上，通过在 UDP 数据报中封装自己的数据包来实现可靠传输。 可靠传输：QUIC 提供了类似于 TCP 的可靠传输机制，包括序列号、确认应答、重传和流量控制。 多路复用：QUIC 支持多条独立的流，解决了 TCP 的队头阻塞问题。 拥塞控制：QUIC 实现了拥塞控制算法，确保高效的数据传输。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:6:1","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"6.2 QUIC是如何解决TCP队头阻塞问题的？ TCP的队头阻塞（Head-of-Line Blocking）问题是指在数据传输过程中，如果某个数据包丢失了，后续的数据包即使已经到达接收方，也无法被处理，因为接收方必须按顺序处理数据包。 QUIC通过以下机制解决了这个问题： 多路复用：QUIC允许多个独立的流在同一个连接中传输，每个流都有自己的序列号和确认机制。这意味着即使某个流的数据包丢失了，也不会影响其他流的数据传输。 独立流处理：接收方可以独立处理每个流的数据包，即使某个流的数据包丢失了，接收方仍然可以处理其他流的数据包，避免了队头阻塞。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:6:2","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"6.3 QUIC是如何做流量控制的？ QUIC的流量控制机制与TCP类似，但更为灵活和高效： 流级别的流量控制：每个流都有自己的流量控制窗口，发送方在发送数据之前，必须确保数据大小不超过接收方为该流设定的窗口大小。 连接级别的流量控制：除了流级别的流量控制，QUIC还支持连接级别的流量控制，限制整个连接上的未确认数据总量，防止网络拥塞。 动态调整窗口大小：QUIC可以根据网络状况动态调整流量控制窗口的大小，提高数据传输的效率和适应性。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:6:3","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"6.4 QUIC是如何迁移连接的？ 基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。 那么当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接。 而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过以下机制： 连接ID：QUIC为每个连接分配一个唯一的连接ID，连接ID与客户端和服务器的IP地址和端口无关。因此，即使客户端的IP地址或端口发生变化，只要连接ID不变，连接仍然有效。 路径验证：在迁移连接时，QUIC会验证新的路径是否可用，确保数据能够通过新路径传输。 迁移过程：当客户端检测到网络变化（例如，从WiFi切换到移动网络）时，会通知服务器新的地址和端口。服务器验证新的路径后，继续通过新的路径传输数据。 无缝切换：通过连接ID和路径验证机制，QUIC实现了连接的无缝迁移，避免了因网络变化导致的连接中断和数据丢失。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:6:4","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"7 IP ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:7:0","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"7.1 IP 协议的定义和作用？ IP 协议（Internet Protocol）又被称为互联网协议，是支持网间互联的数据包协议，工作在网际层，主要目的就是为了提高网络的可扩展性。 通过网际协议 IP，可以把参与互联的，性能各异的网络看作一个统一的网络。 和传输层 TCP 相比，IP 协议是一种无连接/不可靠、尽力而为的数据包传输服务，和 TCP 协议一起构成了 TCP/IP 协议的核心。 IP 协议有哪些作用？ IP 协议主要有以下几个作用： 寻址和路由：在 IP 数据报中携带源 IP 地址和目的 IP 地址来表示该数据包的源主机和目标主机。IP 数据报在传输过程中，每个中间节点（IP 网关、路由器）只根据网络地址来进行转发，如果中间节点是路由器，则路由器会根据路由表选择合适的路径。IP 协议根据路由选择协议提供的路由信息对 IP 数据报进行转发，直至目标主机。 分段和重组：IP 数据报在传输过程中可能会经过不同的网络，在不同的网络中数据报的最大长度限制是不同的，IP 协议通过给每个 IP 数据报分配一个标识符以及分段与组装的相关信息，使得数据报在不同的网络中能够被传输，被分段后的 IP 数据报可以独立地在网络中进行转发，在达到目标主机后由目标主机完成重组工作，恢复出原来的 IP 数据报。 差错处理：虽然 IP 是尽力而为的协议，不保证数据报一定到达目的地，但它包含一些基本的差错处理机制，例如校验和（checksum），用于检测数据报头部的错误。 控制信息：IP 头部包含了多个字段，用于控制和管理数据报的传输，如生存时间（TTL，Time to Live）字段，防止数据报在网络中无限循环。 传输层协议和网络层协议有什么区别？ 网络层协议负责提供主机间的逻辑通信；传输层协议负责提供进程间的逻辑通信。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:7:1","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"7.2 IP 地址有哪些分类？ IP地址（Internet Protocol Address）是用于标识网络中设备的唯一地址。IP地址有两种版本：IPv4和IPv6。IPv4是目前最广泛使用的版本，IPv6是为解决IPv4地址耗尽问题而设计的新版本。 IPv4地址是32位长的二进制数，通常表示为四个十进制数（每个数对应8位）之间用点分隔（例如，192.168.1.1）。IPv4地址可以按其用途和结构分为A，B，C，D，E五大类： A 类地址 (1~126)：以 0 开头，网络号占前 8 位，主机号占后面 24 位，主要用于大型网络； B 类地址 (128~191)：以 10 开头，网络号占前 16 位，主机号占后面 16 位，主要用于中型网络； C 类地址 (192~223)：以 110 开头，网络号占前 24 位，主机号占后面 8 位，主要用于小型网络； D 类地址 (224~239)：以 1110 开头，保留为多播地址，用于一对多通信； E 类地址 (240~255)：以 1111 开头，保留位为将来使用，用于实验和研究。 IPv4有以下特殊地址： 本地回环地址（Loopback Address）：127.0.0.0 到 127.255.255.255，用于主机自我测试，通常使用127.0.0.1。 广播地址（Broadcast Address）：用于将信息发送到网络上的所有设备。例如，192.168.1.255。 私有地址（Private Address）：用于局域网（LAN）内部通信，不可在互联网上使用。包括以下范围： A类：10.0.0.0 到 10.255.255.255 B类：172.16.0.0 到 172.31.255.255 C类：192.168.0.0 到 192.168.255.255 IPv6地址是128位长的二进制数，通常表示为八组十六进制数之间用冒号分隔（例如，2001:0db8:85a3:0000:0000:8a2e:0370:7334）。IPv6地址类型主要有以下几种： 单播地址（Unicast Address）：标识单一接口的地址。 全球单播地址（Global Unicast Address）：类似于IPv4的公有地址。 链路本地地址（Link-Local Address）：仅在单一链路上有效，前缀为fe80::/10。 站点本地地址（Site-Local Address）：类似于IPv4的私有地址，但已被弃用，前缀为fec0::/10。 多播地址（Multicast Address）：用于一对多通信，前缀为ff00::/8。 任播地址（Anycast Address）：分配给多个接口，但数据包仅发送到距离最近的接口 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:7:2","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"7.3 域名和 IP 的关系？一个 IP 可以对应多个域名吗？一个域名可以对应多个IP吗？ 域名（Domain Name）：人类可读的地址，用于标识和访问网站及其他网络资源（例如，www.example.com）。 IP地址（Internet Protocol Address）：计算机可读的地址，用于标识网络中的设备（例如，192.168.1.1）。 域名和IP地址之间是通过DNS（Domain Name System）来进行映射和解析的。 一个域名可以对应多个 IP，但这种情况 DNS 做负载均衡的，在用户访问过程中，一个域名只能对应一个 IP。 而一个IP却可以对应多个域名，是一对多的关系。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:7:3","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"7.4 IPV4 地址不够如何解决？ DHCP：动态主机配置协议，动态分配 IP 地址，只给接入网络的设备分配 IP 地址，因此同一个 MAC 地址的设备，每次接入互联网时，得到的 IP 地址不一定是相同的，该协议使得空闲的 IP 地址可以得到充分利用。 CIDR：无类别域间路由。CIDR 消除了传统的 A 类、B 类、C 类地址以及划分子网的概念，因而更加有效地分配 IPv4 的地址空间，但无法从根本上解决地址耗尽的问题。 NAT：网络地址转换协议，我们知道属于不同局域网的主机可以使用相同的 IP 地址，从而一定程度上缓解了 IP 资源枯竭的问题，然而主机在局域网中使用的 IP 地址是不能在公网中使用的，当局域网主机想要与公网主机进行通信时，NAT 方法可以将该主机 IP 地址转换为全球 IP 地址。该协议能够有效解决 IP 地址不足的问题。 IPv6：作为接替 IPv4 的下一代互联网协议，其可以实现 2 的 128 次方个地址，而这个数量级，即使给地球上每一粒沙子都分配一个 IP 地址也够用，该协议能够从根本上解决 IPv4 地址不够用的问题。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:7:4","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"7.5 说下 ARP 协议的工作过程？ ARP（Address Resolution Protocol，地址解析协议）是用于将IP地址解析为对应物理网络地址（如MAC地址）的协议，主要在IPv4网络中使用。它在局域网（LAN）中起到了关键作用，使设备能够通过IP地址找到对应的硬件地址，从而实现数据帧在局域网中的正确传输。 ARP请求：当主机 A 要发送数据给主机 B 时，首先会在自己的 ARP 缓存中查找主机 B 的 MAC 地址。如果没有找到，主机 A 会向网络中广播一个 ARP 请求数据包，请求网络中的所有主机告诉它们的 MAC 地址；这个请求包含了请求设备和目标设备的 IP 和 MAC 地址。 ARP应答：网络中的所有主机都会收到这个 ARP 请求，但只有主机 B 会回复 ARP 应答，告诉主机 A 自己的 MAC 地址。并且主机 B 会将主机 A 的 IP 和 MAC 地址映射关系缓存到自己的 ARP 缓存中，以便下次通信时直接使用。 数据传输：在获得主机B的MAC地址后，主机A（也会将主机 B 的 IP 和 MAC 地址映射关系缓存到自己的 ARP 缓存中）就可以将目标MAC地址设置为主机B的MAC地址，从而正确地构建以太网帧并发送到局域网中，这些数据帧会通过交换机或集线器等网络设备正确地传送到主机B。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:7:5","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"7.6 为什么既有 IP 地址，又有 MAC 地址？ MAC 地址和 IP 地址都有什么作用？ MAC 地址是数据链路层和物理层使用的地址，是写在网卡上的物理地址，用来定义网络设备的位置，不可变更。 IP 地址是网络层和以上各层使用的地址，是一种逻辑地址。IP 地址用来区别网络上的计算机。 为什么有了 MAC 地址还需要 IP 地址？ 如果我们只使用 MAC 地址进行寻址的话，我们需要路由器记住每个 MAC 地址属于哪个子网，不然一次路由器收到数据包都要满世界寻找目的 MAC 地址。而我们知道 MAC 地址的长度为 48 位，也就是最多共有 2 的 48 次方个 MAC 地址，这就意味着每个路由器需要 256T 的内存，显然是不现实的。 和 MAC 地址不同，IP 地址是和地域相关的，在一个子网中的设备，我们给其分配的 IP 地址前缀都是一样的，这样路由器就能根据 IP 地址的前缀知道这个设备属于哪个子网，剩下的寻址就交给子网内部实现，从而大大减少了路由器所需要的内存。 为什么有了 IP 地址还需要 MAC 地址？ 只有当设备连入网络时，才能根据他进入了哪个子网来为其分配 IP 地址，在设备还没有 IP 地址的时候，或者在分配 IP 的过程中。我们需要 MAC 地址来区分不同的设备。 IP 地址可以比作为地址，MAC 地址为收件人，在一次通信过程中，两者是缺一不可的。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:7:6","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"7.7 ICMP 协议的功能？ ICMP（Internet Control Message Protocol，网际控制报文协议） 是用于在IP网络中传递控制和错误信息的协议。它是在网络层（OSI模型的第三层）之上运行的协议，主要用于在IP网络中进行诊断、错误报告和控制消息的传递。ICMP协议的功能包括但不限于以下几点： 错误报告：ICMP用于向发送者报告网络层发生的错误，例如目标不可达、超时、路由器发生故障等。 路由器发现：ICMP可用于路由器的发现和配置，例如路由器通告消息（Router Advertisement）和路由器请求消息（Router Solicitation）。 Ping测试：ICMP的Echo请求和Echo应答消息被用于Ping测试，以测试主机之间的连通性和延迟。 TTL过期：ICMP的TTL（Time to Live）过期消息用于报告数据包在网络中被丢弃的情况，通常由于数据包在转发过程中超过了其TTL值。 片段超时：ICMP的片段超时消息用于报告IP数据报在传输过程中被丢弃的情况，通常由于数据包片段未能在超时时间内到达目的地而被丢弃。 重定向：ICMP的重定向消息用于告知发送者修改其路由表以改进数据包的转发效率。 MTU探测：ICMP的路径MTU探测（Path MTU Discovery）用于发现通向目标主机的最大传输单元（MTU）以避免分片。 多播/任播测试：ICMP用于进行多播和任播地址的测试和诊断。 比如我们日常使用得比较多的 ping，就是基于 ICMP 的。 在 IP 通信中如果某个 IP 包因为某种原因未能达到目标地址，那么这个具体的原因将由 ICMP 负责通知。 ICMP 报文是封装在 IP 包里面，它工作在网络层，是 IP 协议的助手。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:7:7","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"7.8 ping的工作原理 ping，Packet Internet Groper，一个网络工具，主要用来测试网络连接的可达性和延迟。 ping 的过程主要基于 ICMP（Internet Control Message Protocol，互联网控制消息协议）实现，其基本过程包括： 当执行 Ping 命令，如ping www.google.com，Ping 首先解析域名获取 IP 地址，然后向目标 IP 发送一个 ICMP Echo Request 消息。 当目标 IP 收到 ICMP Echo Request 消息后，它会生成一个 ICMP Echo Reply 消息并返回，即 Ping 响应消息。 发起 Ping 命令的设备接收到 ICMP Echo Reply 消息后，计算并显示从发送 Echo Request 到接收到 Echo Reply 的时间（通常称为往返时间 RTT，Round-Trip Time），以及可能的丢包情况。 Ping 通常会发送多个请求，以便提供平均响应时间和丢包率等信息，以便我们了解网络连接的质量。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:7:8","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"7.9 断网了，还能ping通127.0.0.1吗？ 通常情况下，即使网络连接断开，也可以通过回环接口（Loopback Interface）ping通本地主机的回环地址127.0.0.1。回环地址是本地主机自身的虚拟网络接口，用于在本地主机内部进行通信，不经过物理网络设备，因此即使网络断开也可以正常工作。 回环接口是网络协议栈中的一个虚拟接口，用于模拟数据在网络中的传输。当数据发送到回环地址时，操作系统会将数据直接传输给回环接口，然后再从回环接口发送到目标地址，实现了数据的回环传输。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:7:9","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"7.10 和 localhost 以及 0.0.0.0 有区别吗 127.0.0.1：127.0.0.1是回环地址（Loopback Address），通常用于本地主机内部进行通信。当数据发送到127.0.0.1时，操作系统会将数据传输给回环接口，然后再从回环接口发送到目标地址，实现了数据的回环传输。127.0.0.1始终指向本地主机自身，不会通过网络传输，用于测试本地主机的网络协议栈是否正常工作以及网络服务是否可用。 localhost：localhost是一个主机名（Hostname），通常映射到回环地址127.0.0.1。当在计算机上使用localhost时，实际上是在使用回环地址127.0.0.1，用于访问本地主机上的网络服务。localhost是一个常见的网络标识符，用于指代本地主机。 0.0.0.0：0.0.0.0是一个特殊的IP地址，通常用于表示任意主机或任意地址。当服务器配置为监听0.0.0.0时，表示它将接受来自任何IP地址的连接，可以用于在所有可用网络接口上监听服务。在某些情况下，0.0.0.0也用于指示目标地址未指定或未知。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:7:10","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"8 网络安全 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:8:0","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"8.1 说说有哪些安全攻击？ 络安全攻击主要分为两种类型，被动攻击和主动攻击 被动攻击：是指攻击者从网络上窃听他人的通信内容，通常把这类攻击称为截获，被动攻击主要有两种形式：消息内容泄露攻击和流量分析攻击。由于攻击者没有修改数据，使得这种攻击很难被检测到。 主动攻击：直接对现有的数据和服务造成影响，常见的主动攻击类型有： 篡改：攻击者故意篡改网络上送的报文，甚至把完全伪造的报文传送给接收方。 恶意程序：恶意程序种类繁多，包括计算机病毒、计算机蠕虫、特洛伊木马、后门入侵、流氓软件等等。 拒绝服务 Dos：攻击者向服务器不停地发送分组，使服务器无法提供正常服务。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:8:1","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"8.2 DNS 劫持了解吗？ DNS劫持是一种网络攻击，通过篡改DNS（Domain Name System）解析结果来劫持用户的网络流量。DNS劫持攻击者会修改DNS解析请求或响应，将用户重定向到恶意网站或者欺骗页面。 DNS劫持可以通过多种方式实现，其中包括： 本地DNS劫持：攻击者在受害者计算机或网络中植入恶意软件，使其修改本地主机的DNS设置，将合法的DNS服务器替换为攻击者控制的恶意DNS服务器。 路由器DNS劫持：攻击者入侵路由器或者通过社会工程手段获取路由器管理权限，然后修改路由器的DNS设置，使其指向恶意DNS服务器。 ISP级别的DNS劫持：攻击者控制了受害者所使用的ISP（Internet Service Provider，互联网服务提供商）的DNS服务器，通过篡改ISP的DNS解析结果来实现DNS劫持。 中间人攻击：攻击者通过中间人攻击拦截DNS请求或响应，然后篡改其中的域名解析结果，将用户重定向到恶意网站或者欺骗页面。 怎么应对 DNS 劫持？ 直接通过 IP 地址访问网站，避开 DNS 劫持 由于域名劫持往往只能在特定的网络范围内进行，因此一些高级用户可以通过网络设置让 DNS 指向正常的域名服务器以实现对目标网址的正常访问，例如计算机首选 DNS 服务器的地址固定为 8.8.8.8。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:8:2","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"8.3 什么是 CSRF 攻击？如何避免？ CSRF（Cross-Site Request Forgery，跨站请求伪造）攻击是一种网络安全攻击，利用用户在已认证的Web应用程序上的身份验证信息执行未经授权的操作。攻击者通过诱使受害者在访问包含恶意代码的网页时，触发向目标网站发送请求的行为，从而在用户不知情的情况下执行攻击者预先设定的操作，如转账、更改密码等。 CSRF攻击通常包含以下步骤： 攻击者准备好一个包含恶意请求的页面，例如一个钓鱼网站或者注入了恶意代码的广告。 受害者在已经登录的情况下访问了包含恶意请求的页面。 受害者的浏览器自动发送了被伪造的请求到目标网站，由于受害者已经在目标网站登录，因此请求被认为是合法的，从而执行了攻击者的操作。 要防止CSRF攻击，可以采取以下措施： 使用CSRF Token：在Web应用程序中引入CSRF Token，确保每个请求都包含一个随机生成的Token，并在服务端验证Token的有效性。攻击者无法获取到有效的CSRF Token，因此无法伪造有效的请求。 检查Referer头：Web应用程序可以检查请求的Referer头，确保请求来自合法的来源。但需要注意的是，Referer头可能会被篡改或者缺失，因此不能单独依赖Referer头来防止CSRF攻击。 限制敏感操作：对于涉及到敏感操作的请求，应该要求用户输入额外的身份验证信息，例如密码、验证码等，以增加攻击者执行CSRF攻击的难度。 使用SameSite属性：在设置Cookie时，可以使用SameSite属性来限制Cookie的发送，防止第三方网站携带Cookie发送CSRF攻击。可以将Cookie设置为SameSite=Strict或者SameSite=Lax，以限制Cookie仅在同源请求中发送。 定期审查和更新代码：定期审查和更新Web应用程序的代码，修补已知的安全漏洞，并遵循安全最佳实践，以减少CSRF攻击的风险。 添加校验 token：以在 HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token，如果请求中没有 token 或者 token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:8:3","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"8.4 什么是 DoS、DDoS、DRDoS 攻击？ DoS（Denial of Service，拒绝服务）攻击、DDoS（Distributed Denial of Service，分布式拒绝服务）攻击和DRDoS（Distributed Reflection Denial of Service，分布式反射拒绝服务）攻击都是针对网络服务的攻击手法，旨在使目标系统无法正常提供服务，从而导致服务不可用或严重受损。 DoS 攻击：DoS攻击是由单个攻击者发起的攻击，通过向目标系统发送大量的请求或者恶意数据包，耗尽目标系统的资源（如带宽、处理能力、存储空间等），从而使正常用户无法访问或使用目标系统的服务。DoS攻击可以采用多种手段实现，包括网络层攻击（如SYN Flood、UDP Flood）、应用层攻击（如HTTP Flood、Slowloris攻击）等。 DDoS 攻击：DDoS攻击是由多个攻击者协同发起的攻击，通过分布在全球各地的大量“僵尸”计算机（也称为“肉鸡”或“僵尸网络”）向目标系统发送大量的请求或者恶意数据包，造成目标系统过载，从而使其无法正常提供服务。DDoS攻击通常规模更大、更难以应对，因为攻击流量来自于多个来源，并且攻击者可以很容易地控制和伪装攻击流量的来源。 DRDoS 攻击：DRDoS攻击是一种利用第三方系统的资源反射攻击目标系统的攻击方式。攻击者向第三方系统发送请求，伪装成目标系统的IP地址，并请求返回大量的响应数据，这些响应数据会发送到目标系统，造成目标系统的过载。DRDoS攻击利用了第三方系统的反射响应特性，使攻击者能够轻易地放大攻击流量，并且很难追溯到攻击者的真实身份。 如何防范 DDoS? 针对 DDoS 中的流量攻击，最直接的方法是增加带宽，理论上只要带宽大于攻击流量就可以了，但是这种方法成本非常高。在有充足带宽的前提下，我们应该尽量提升路由器、网卡、交换机等硬件设施的配置。 针对资源耗尽攻击，我们可以升级主机服务器硬件，在网络带宽得到保证的前提下，使得服务器能够有效对抗海量的 SYN 攻击包。我们也可以安装专业的抗 DDoS 防火墙，从而对抗 SYN Flood 等流量型攻击。瓷碗，负载均衡，CDN 等技术都能有效对抗 DDos 攻击。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:8:4","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"8.5 什么是 XSS 攻击，如何避免? XSS（Cross-Site Scripting，跨站脚本攻击）是一种常见的网络安全攻击，攻击者通过在受害者的浏览器中注入恶意脚本，来执行恶意操作。这些脚本通常以HTML、JavaScript等形式存在，可以窃取用户的会话信息、篡改网页内容、重定向用户到恶意网站等。XSS攻击通常分为以下几种类型： 存储型 XSS：攻击者将恶意脚本存储到目标网站的数据库中，当用户访问包含恶意脚本的页面时，脚本会从服务器端加载并执行。 反射型 XSS：攻击者将恶意脚本作为参数或者URL的一部分，发送给目标用户，当用户点击恶意链接时，脚本会在用户的浏览器中执行。 DOM-based XSS：攻击者利用客户端的DOM环境，通过修改页面的DOM结构来执行恶意脚本。 如何应对 XSS 攻击？ 对输入进行过滤，过滤标签等，只允许合法值。 HTML 转义 对于链接跳转，如\u003ca href=\"xxx\" 等，要校验内容，禁止以 script 开头的非法链接。 限制输入长度 将Cookie设置为HttpOnly标志，可以防止JavaScript访问Cookie，从而减少XSS攻击的风险。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:8:5","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","计算机网络"],"content":"8.6 对称加密与非对称加密有什么区别？ 对称加密和非对称加密是两种常见的加密算法，它们之间有几个关键区别： 密钥数量： 对称加密使用相同的密钥来加密和解密数据，因此只需要一个密钥。发送方使用该密钥将数据加密，接收方使用相同的密钥将数据解密。 非对称加密使用一对密钥：公钥和私钥。公钥用于加密数据，私钥用于解密数据。因此，发送方使用接收方的公钥来加密数据，接收方使用自己的私钥来解密数据。 密钥分发： 对称加密需要确保加密和解密双方都安全地共享相同的密钥。这意味着必须在通信双方之间建立一个安全的渠道来传输密钥，否则密钥可能会被窃取或篡改。 非对称加密不需要在通信双方之间共享密钥。接收方将自己的公钥公开发布，发送方使用该公钥加密数据，接收方使用自己的私钥解密数据。因此，不需要建立安全的通道来传输密钥。 性能： 对称加密通常比非对称加密更快速，因为它使用的密钥较少，加密和解密过程更简单。 非对称加密通常比对称加密更慢，因为它使用更复杂的数学运算来加密和解密数据。 适用场景： 对称加密通常用于加密大量数据，如传输文件或通信内容。 非对称加密通常用于加密小块数据，如数字签名、SSL/TLS握手过程等。 ","date":"2024-06-02","objectID":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/:8:6","tags":[null],"title":"计算机网络 面试题目总结","uri":"/posts/03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","数据结构与算法"],"content":"1 排序算法 排序算法 平均时间复杂度 最差时间复杂度 空间复杂度 数据对象稳定性 算法基本思路 冒泡排序 $$O(n^2)$$ $$O(n^2)$$ $$O(1)$$ 稳定 反复交换相邻逆序的元素，直到没有逆序对 选择排序 $$O(n^2)$$ $$O(n^2)$$ $$O(1)$$ 数组不稳定、链表稳定 反复选择未排序部分中的最小（大）元素，放在已排序部分的末尾 插入排序 $$O(n^2)$$ $$O(n^2)$$ $$O(1)$$ 稳定 逐一选择未排序元素，将其插入到已排序部分的正确位置 快速排序 $$O(n \\log_2 n)$$ $$O(n^2)$$ $$O(\\log_2 n)$$ 不稳定 选择基准，将数组分为小于和大于基准的两部分，递归排序 堆排序 $$O(n \\log_2 n)$$ $$O(n \\log_2 n)$$ $$O(1)$$ 不稳定 构建最大（小）堆，将堆顶元素与末尾元素交换，调整堆 归并排序 $$O(n \\log_2 n)$$ $$O(n \\log_2 n)$$ $$O(n)$$ 稳定 递归地将数组分为两部分，分别排序后合并 希尔排序 $$O(n \\log_2 n)$$ $$O(n^2)$$ $$O(1)$$ 不稳定 分组进行插入排序，逐渐减少间隔，直到间隔为1 计数排序 $$O(n + m)$$ $$O(n + m)$$ $$O(n + m)$$ 稳定 统计每个元素的出现次数，根据计数对元素进行排序 桶排序 $$O(n)$$ $$O(n)$$ $$O(m)$$ 稳定 将元素分配到不同的桶中，分别排序后合并 基数排序 $$O(k \\cdot n)$$ $$O(n^2)$$ 取决于实现 稳定 逐位排序，从最低有效位到最高有效位进行 ","date":"2024-06-01","objectID":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/:1:0","tags":[null],"title":"数据结构与算法 面试题目总结","uri":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","数据结构与算法"],"content":"2 栈与队列的区别 队列（Queue）：是限定只能在表的一端进行插入和在另一端进行删除操作的线性表； 栈（Stack）：是限定只能在表的一端进行插入和删除操作的线性表。 队列先进先出，栈先进后出。 栈只能在表尾插入删除，队列在表尾插入表头删除。 应用场景不同： 栈：括号问题的求解等 队列：计算机系统中各种资源的管理等。 遍历速度不同： 队列：基于地址指针进行遍历，而且可以从头部或者尾部进行遍历，但不能同时遍历，无需开辟空间，因为在遍历的过程中不影响数据结构，所以遍历速度要快； 栈：只能从顶部取数据，也就是说最先进入栈底的，需要遍历整个栈才能取出来，而且在遍历数据的同时需要为数据开辟临时空间，保持数据在遍历前的一致性。 ","date":"2024-06-01","objectID":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/:2:0","tags":[null],"title":"数据结构与算法 面试题目总结","uri":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","数据结构与算法"],"content":"3 两个栈实现一个队列 使用两个栈来实现一个队列，可以有效地利用栈的特性（后进先出）来模拟队列的特性（先进先出）。我们可以使用两个栈来分离入队和出队操作，具体实现步骤如下： 栈1（stack1）用于处理入队操作。 栈2（stack2）用于处理出队操作。 入队列：直接压入元素至stack1即可 出队列：如果stack2不为空，把stack2中的栈顶元素直接弹出。否则，把stack1的所有元素全部弹出压入stack2中，再弹出stack2的栈顶元素 void enqueue(int x) { stack1.push(x); } int dequeue() { if (stack2.empty()) { while (!stack1.empty()) { stack2.push(stack1.top()); stack1.pop(); } } if (stack2.empty()) { throw std::runtime_error(\"Queue is empty\"); } int result = stack2.top(); stack2.pop(); return result; } ","date":"2024-06-01","objectID":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/:3:0","tags":[null],"title":"数据结构与算法 面试题目总结","uri":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","数据结构与算法"],"content":"4 两个队列实现栈 使用两个队列来实现一个栈，可以利用队列的特性（先进先出）来模拟栈的特性（后进先出）。我们可以使用两个队列来分离入栈和出栈操作，具体实现步骤如下： 队列1（queue1）用于存储元素。 队列2（queue2）作为辅助队列用于操作元素。 入栈操作：将元素直接入队到queue1中。 出栈操作： 将queue1中的所有元素（除了最后一个）逐个出队并入队到queue2中。 最后一个元素是栈顶元素，将其出队。 交换queue1和queue2，以保持queue1始终为主队列。 void push(int x) { queue1.push(x); } int pop() { if (queue1.empty()) { throw std::runtime_error(\"Stack is empty\"); } while (queue1.size() \u003e 1) { queue2.push(queue1.front()); queue1.pop(); } int result = queue1.front(); queue1.pop(); std::swap(queue1, queue2); return result; } ","date":"2024-06-01","objectID":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/:4:0","tags":[null],"title":"数据结构与算法 面试题目总结","uri":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","数据结构与算法"],"content":"5 链表与数组的区别 数组静态分配内存，链表动态分配内存；。 数组在内存中连续，链表不连续。 数组利用下标定位，时间复杂度为O(1)，链表定位元素时间复杂度O(n)。 数组插入或删除元素的时间复杂度O(n)，链表的时间复杂度O(1)。 数组元素在栈区，链表元素在堆区。 ","date":"2024-06-01","objectID":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/:5:0","tags":[null],"title":"数据结构与算法 面试题目总结","uri":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","数据结构与算法"],"content":"6 什么是堆？ 如果一棵完全二叉树的任意一个非终端结点的元素都不小于其左儿子结点和右儿子结点（如果有的话） 的元素，则称此完全二叉树为最大堆。 同样，如果一棵完全二叉树的任意一个非终端结点的元素都不大于其左儿子结点和右儿子结点（如果 有的话）的元素，则称此完全二叉树为最小堆。 最大堆的根结点中的元素在整个堆中是最大的； 最小堆的根结点中的元素在整个堆中是最小的。 ","date":"2024-06-01","objectID":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/:6:0","tags":[null],"title":"数据结构与算法 面试题目总结","uri":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","数据结构与算法"],"content":"7 什么是二叉排序树 二叉排序树（Binary Sort Tree）又称二叉查找树（Binary Search Tree），亦称二叉搜索树。 二叉排序树或者是一棵空树，或者是具有下列性质的二叉树： 若左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若右子树不空，则右子树上所有结点的值均大于或等于它的根结点的值； 左、右子树也分别为二叉排序树； 没有键值相等的节点 二分查找的时间复杂度是O(log(n))，最坏情况下的时间复杂度是O(n)（相当于顺序查找） ","date":"2024-06-01","objectID":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/:7:0","tags":[null],"title":"数据结构与算法 面试题目总结","uri":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","数据结构与算法"],"content":"8 什么是平衡二叉树？ 平衡二叉树（balanced binary tree）,又称 AVL 树。它或者是一棵空树,或者是具有如下性质的二叉树： 它的左子树和右子树都是平衡二叉树， 左子树和右子树的深度之差的绝对值不超过1。 平衡二叉树是对二叉搜索树(又称为二叉排序树)的一种改进。二叉搜索树有一个缺点就是，树的结构是无法预料的，随意性很大，它只与节点的值和插入的顺序有关系，往往得到的是一个不平衡的二叉树。在最坏的情况下，可能得到的是一个单支二叉树，其高度和节点数相同，相当于一个单链表，对其正常的时间复杂度有O(log(n))变成了O(n)，从而丧失了二叉排序树的一些应该有的优点。 旋转是平衡二叉树维护平衡性的核心操作，包括以下几种： 单右旋转（Right Rotation）：用于修复左子树过高的情况。 单左旋转（Left Rotation）：用于修复右子树过高的情况。 双旋转（Double Rotation）：包括先左后右旋转和先右后左旋转，用于修复特定的不平衡情况。 ","date":"2024-06-01","objectID":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/:8:0","tags":[null],"title":"数据结构与算法 面试题目总结","uri":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","数据结构与算法"],"content":"9 什么是B树 B树是一种自平衡的多路查找树，其中每个节点可以有多个子节点和多个键。B树具有以下特性： 节点包含多个键和子节点：每个节点可以存储多个键和子节点。节点中的键按照递增顺序存储。 根节点至少有两个子节点（如果不是叶节点）。 内部节点的子节点数受限：一个内部节点至少有$$[m/2]$$个子节点，最多有 $$m$$个子节点（这里的$m$是B树的阶）。 所有叶子节点处于同一层：B树的所有叶子节点都在同一层，保证树的平衡性。 B树的性质如下： 平衡性：B树是自平衡的，所有叶子节点处在同一层，树的高度通常较小，因而能够保证较快的搜索、插入和删除操作。 高效的磁盘I/O操作：由于节点可以包含多个键和子节点，B树通常用于磁盘存储中，减少磁盘I/O操作的次数。 时间复杂度：搜索、插入和删除操作的时间复杂度均为$O(\\log n)$，其中$n$是树中的键的总数。 B树的操作如下： 搜索：从根节点开始，根据当前节点中的键范围，递归或迭代地选择相应的子节点进行搜索，直到找到目标键或到达叶子节点。 插入： 在叶子节点插入新键。 如果叶子节点已满，则进行分裂操作，将中间键提升到父节点，并将叶子节点分裂为两个节点。 如果父节点也满，则递归进行分裂，直到树根。 删除： 从树中删除键。 如果删除键导致节点下溢（键数少于$[m/2]$），则进行合并或借用操作，以保持B树的平衡性。 ","date":"2024-06-01","objectID":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/:9:0","tags":[null],"title":"数据结构与算法 面试题目总结","uri":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","数据结构与算法"],"content":"10 Trie 树 Trie 树，又称前缀树，字典树， 是一种有序树，用于保存关联数组，其中的键通常是字符串。与二叉查找树不同，键不是直接保存在节点中，而是由节点在树中的位置决定。一个节点的所有子孙都有相同的前缀，也就是这个节点对应的字符串，而根节点对应空字符串。一般情况下，不是所有的节点都有对应的值，只有叶子节点和部分内部节点所对应的键才有相关的值。 Trie 树查询和插入时间复杂度都是 O(n)，是一种以空间换时间的方法。当节点树较多的时候，Trie 树占用的内存会很大。 Trie 树常用于搜索提示。如当输入一个网址，可以自动搜索出可能的选择。当没有完全匹配的搜索结果，可以返回前缀最相似的可能。 ","date":"2024-06-01","objectID":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/:10:0","tags":[null],"title":"数据结构与算法 面试题目总结","uri":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","数据结构与算法"],"content":"11 B+树 B+树通常用于数据库和操作系统的文件系统中，B+树的结构如下： 根节点（Root Node）：B+树的根节点可以是叶子节点，也可以是内部节点。 内部节点（Internal Nodes）：存储键值用于导航，不存储实际数据。每个内部节点包含若干个键和指向子节点的指针。 叶子节点（Leaf Nodes）：存储所有的实际数据，并且包含指向相邻叶子节点的指针，形成一个双向链表。 B+树的性质： 有序性：所有键按升序排列。 平衡性：树的所有叶子节点处于同一层级，保证了平衡性。 多路性：每个节点可以有多个子节点，具体数量由树的阶（order）决定。 B+树的操作： 查找（Search）：从根节点开始，依次比较键值，沿着指向子节点的指针递归查找，直到找到目标叶子节点。 插入（Insert）：将新键插入适当的叶子节点，如果叶子节点满了，则分裂叶子节点并将中间键上移到父节点，递归进行分裂直到树恢复平衡。 删除（Delete）：从叶子节点删除键，如果删除导致节点键数目不足，则进行节点合并或键重新分配，直到树恢复平衡。 B+树的优点： 高效的范围查询：由于所有数据都存储在叶子节点中，并且叶子节点形成双向链表，B+树能够高效地进行范围查询（range query）。 高存储利用率：内部节点只存储键，数据存储在叶子节点中，节点分裂和合并更加高效。 低树高（Tree Height）：B+树的多路性使得其树高较低，查找、插入和删除操作的时间复杂度为$O(\\log_mn$，其中$m$为树的阶。 ","date":"2024-06-01","objectID":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/:11:0","tags":[null],"title":"数据结构与算法 面试题目总结","uri":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","数据结构与算法"],"content":"12 什么是红黑树？ 红黑树（为了解决平衡树在插入、删除等操作需要频繁调整的情况）是一种自平衡的二叉查找树（BST），广泛用于计算机科学中实现高效的数据存储和检索。它通过在每个节点上附加一个颜色属性（红或黑）来保持树的平衡，从而确保树的高度在对数级别，提供较好的时间复杂度性能。 红黑树的性质： 每个结点不是红色就是黑色； 根节点是黑色的； 叶子节点（NIL节点）是黑色：红黑树中的叶子节点，即树尾端的所有NULL节点，都是黑色的。 红色节点的父节点和子节点必须是黑色的，即不能有两个连续的红色节点。 从任一节点到其每个叶子的所有路径包含相同数量的黑色节点：这保证了没有一条路径会比其他路径长出太多，从而确保了树的平衡。 红黑树的操作：红黑树的操作包括插入、删除和查找，基本的操作步骤与普通的二叉查找树类似，但在维护平衡性方面有所不同。 插入操作 普通BST插入：按二叉查找树的插入规则，将新节点插入适当位置。 节点染色为红色：新插入的节点初始为红色。 调整平衡：通过旋转和重新染色来保持红黑树的性质。 情况1：插入节点的父节点是黑色：不需要进一步操作。 情况2：插入节点的父节点是红色：根据叔节点的颜色，有不同的调整方法，包括重新染色和旋转。 删除操作 普通BST删除：按二叉查找树的删除规则，找到并删除节点。 调整平衡：删除节点后可能破坏红黑树的性质，需要通过旋转和重新染色来恢复平衡。 情况1：删除节点是红色：不需要进一步操作。 情况2：删除节点是黑色：通过双重黑色节点的概念和调整，包括重新染色和旋转，来恢复红黑树的平衡。 红黑树的优点： 自平衡：通过颜色属性和旋转操作，红黑树可以保持平衡，确保基本操作的时间复杂度为$$O(\\log n)$$。 高效查找：由于平衡性，红黑树在最坏情况下的高度为$$2\\log(n+1)$$，保证了查找操作的高效性。 高效插入和删除：插入和删除操作在进行平衡调整时，旋转和重新染色的成本较低，确保了高效性。 红黑树广泛应用于许多计算机系统和软件中，包括： 关联容器：C++的STL中的map和set，Java的TreeMap和TreeSet都基于红黑树实现。 内存管理：Linux内核中的内存管理使用红黑树来管理空闲内存块。 数据库索引：一些数据库系统使用红黑树作为索引结构，实现高效的数据检索。 ","date":"2024-06-01","objectID":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/:12:0","tags":[null],"title":"数据结构与算法 面试题目总结","uri":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","数据结构与算法"],"content":"13 什么是哈希表？哈希表的实现方式？怎么避免哈希冲突 哈希表（Hash Table，也叫散列表），是根据键值 (Key-Value) 而直接进行访问的数据结构。也就是说，它通过把键值映射到表中一个位置来访问记录，以加快查找的速度。哈希表的实现主要需要解决两个问题，哈希函数和冲突解决。 哈希函数也称为散列函数，它接受一个键作为输入，并将其映射到哈希表的一个位置上。理想的哈希函数应该能够将键均匀地分布到哈希表的不同位置上，同时具有良好的计算效率。常见的哈希函数包括取余法、乘法哈希法、MD5、SHA等。选择合适的哈希函数取决于应用场景和性能要求。 当两个不同的键经过哈希函数映射后得到相同的位置时，就会发生哈希冲突。为了解决这个问题，常见的冲突解决方法包括： 开放定址法（Open Addressing）：当发生冲突时，顺序地查找下一个可用的位置，直到找到一个空槽位。常见的开放定址法包括线性探测、二次探测、双重哈希等。 链地址法（Chaining）（最常用）：将哈希表的每个槽位都连接一个链表（或其他数据结构），当发生冲突时，将冲突的元素插入到对应位置的链表中。这样，相同哈希值的元素都存储在同一个链表中。 再哈希法（Rehashing）：使用另一个哈希函数计算新的哈希值，然后再次查找空槽位。这样可以减少冲突的概率，提高哈希表的性能。 建立公共溢出区：将哈希表的一部分空间作为溢出区，当发生冲突时，将冲突的元素存储在溢出区中。这样，哈希表的主要部分仍然保持较低的负载因子，提高了性能。 ","date":"2024-06-01","objectID":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/:13:0","tags":[null],"title":"数据结构与算法 面试题目总结","uri":"/posts/02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/"},{"categories":["面试","技术基础"],"content":" const知道吗？解释其作用 修饰变量，说明该变量不可以被改变； 修饰指针，分为指向常量的指针（pointer to const）和自身是常量的指针（常量指针，const pointer）； 修饰引用，指向常量的引用（reference to const），用于形参类型，既避免了拷贝，又避免了函数对值的修改； 修饰成员函数，说明该成员函数内不能修改成员变量。 宏定义 #define 和 const 常量 宏定义 #define const 常量 宏定义，相当于字符替换 | 常量声明 | 预处理器处理 | 编译器处理 | 无类型安全检查 | 有类型安全检查 | 不分配内存 | 要分配内存 | 存储在代码段 | 存储在数据段 | 可通过 #undef 取消 | 不可取消 | static的作用 修饰普通变量，修改变量的存储区域和生命周期，使变量存储在静态区，在 main 函数运行前就分配了空间，如果有初始值就用初始值初始化它，如果没有初始值系统用默认值初始化它。 修饰普通函数，表明函数的作用范围，仅在定义该函数的文件内才能使用。在多人开发项目时，为了防止与他人命名空间里的函数重名，可以将函数定位为 static。 修饰成员变量，修饰成员变量使所有的对象只保存一个该变量，而且不需要生成对象就可以访问该成员。 修饰成员函数，修饰成员函数使得不需要生成对象就可以访问该函数，但是在 static 函数内不能访问非静态成员。 说说this指针 this 指针是一个隐含于每一个非静态成员函数中的特殊指针。它指向调用该成员函数的那个对象。 当对一个对象调用成员函数时，编译程序先将对象的地址赋给 this 指针，然后调用成员函数，每次成员函数存取数据成员时，都隐式使用 this 指针。 当一个成员函数被调用时，自动向它传递一个隐含的参数，该参数是一个指向这个成员函数所在的对象的指针。 this 指针被隐含地声明为: ClassName *const this，这意味着不能给 this 指针赋值；在 ClassName 类的 const 成员函数中，this 指针的类型为：const ClassName* const，这说明不能对 this 指针所指向的这种对象是不可修改的（即不能对这种对象的数据成员进行赋值操作）； this 并不是一个常规变量，而是个右值，所以不能取得 this 的地址（不能 \u0026this）。 在以下场景中，经常需要显式引用this指针： 为实现对象的链式引用； 为避免对同一对象进行赋值操作； 在实现一些数据结构时，如 list。 说说inline内联函数 相当于把内联函数里面的内容写在调用内联函数处，即不用执行进入函数的步骤，直接执行函数体；相当于宏，却比宏多了类型检查，真正具有函数特性；编译器一般不内联包含循环、递归、switch 等复杂操作的内联函数；在类声明中定义的函数，除了虚函数的其他函数都会自动隐式地当成内联函数（但虚函数也可以是内联函数，但是当虚函数表现出多态性时不能内联）。 优点： 内联函数同宏函数一样将在被调用处进行代码展开，省去了参数压栈、栈帧开辟与回收，结果返回等，从而提高程序运行速度。 在类中声明同时定义的成员函数，自动转化为内联函数，因此内联函数可以访问类的成员变量，宏定义则不能。 内联函数在运行时可调试，而宏定义不可以。 缺点： 代码膨胀。内联是以代码膨胀（复制）为代价，消除函数调用带来的开销。如果执行函数体内代码的时间，相比于函数调用的开销较大，那么效率的收获会很少。另一方面，每一处内联函数的调用都要复制代码，将使程序的总代码量增大，消耗更多的内存空间。 inline 函数无法随着函数库升级而升级。inline函数的改变需要重新编译，不像 non-inline 可以直接链接。 是否内联，程序员不可控。内联函数只是对编译器的建议，是否对函数内联，决定权在于编译器。 说说volatile关键字 volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素（操作系统、硬件、其它线程等）更改。所以使用 volatile 告诉编译器不应对这样的对象进行优化。 volatile 关键字声明的变量，每次访问时都必须从内存中取出值（没有被 volatile 修饰的变量，可能由于编译器的优化，从 CPU 寄存器中取值） const 可以是 volatile （如只读的状态寄存器） 指针可以是 volatile 说说assert() 断言，是宏，而非函数。assert 宏的原型定义在 \u003cassert.h\u003e（C）、\u003ccassert\u003e（C++）中，其作用是如果它的条件返回错误，则终止程序执行。可以通过定义 NDEBUG 来关闭 assert，但是需要在源代码的开头，include \u003cassert.h\u003e 之前。 static_assert 是一个编译时断言，用于在编译期间检查常量表达式是否为 true。它定义在 C++11 及更高版本的标准中。static_assert 通常用于模板编程和常量表达式中，以确保某些编译时条件成立。与 assert 不同的是，static_assert 在编译时进行检查，因此它不会影响运行时性能。 说说sizeof() sizeof 对数组，得到整个数组所占空间大小。 sizeof 对指针，得到指针本身所占空间大小。 #pragma pack(n) 设定结构体、联合以及类成员变量以 n 字节方式对齐，#pragma pack(pop) 恢复对齐状态 extern \"C\" 被 extern 限定的函数或变量是 extern 类型的，被 extern “C” 修饰的变量和函数是按照 C 语言方式编译和链接的 C++ 中 struct 和 class 总的来说，struct 更适合看成是一个数据结构的实现体，class 更适合看成是一个对象的实现体。 最本质的一个区别就是默认的访问控制，struct 默认的数据访问控制是 public 的，class 默认的成员变量访问控制是 private 的。 union 联合 联合（union）是一种节省空间的特殊的类，一个 union 可以有多个数据成员，但是在任意时刻只有一个数据成员可以有值。当某个成员被赋值后其他成员变为未定义状态。联合有如下特点： 默认访问控制符为 public 可以含有构造函数、析构函数 不能含有引用类型的成员 不能继承自其他类，不能作为基类 不能含有虚函数 匿名 union 在定义所在作用域可直接访问 union 成员 匿名 union 不能包含 protected 成员或 private 成员 全局匿名联合必须是静态（static）的 C 实现 C++ 类 C 实现 C++ 的面向对象特性（封装、继承、多态） 封装：使用函数指针把属性与方法封装到结构体中 继承：结构体嵌套 多态：父类与子类方法的函数指针不同 explicit（显式）关键字 explicit 修饰构造函数时，可以防止隐式转换和复制初始化 explicit 修饰转换函数时，可以防止隐式转换，但 按语境转换 除外 friend 友元类和友元函数 能访问私有成员 破坏封装性 友元关系不可传递 友元关系的单向性 友元声明的形式及数量不受限制 谈谈using using 关键字在 C++ 中有多种用途，主要包括类型别名、引入命名空间中的标识符。并且C++11 引入了别名模板，可以使用 using 创建模板的别名。 尽量少使用 using 指示：using namespace std;，会污染命名空间 :: 范围解析运算符 全局作用域符（::name）：用于类型名称（类、类成员、成员函数、变量等）前，表示作用域为全局命名空间 int count = 11; // 全局（::）的 count ::count = 12; // 测试 1：设置全局的 count 的值为 12 类作用域符（class::name）：用于表示指定类型的作用域范围是具体某个类的 class A { public: static int count; // 类 A 的 count（A::count） }; int A::count = 21; 命名空间作用域符（namespace::name）:用于表示指定类型的作用域范围是具体某个命名空间的 std::cout \u003c\u003c \"Hello, World!\" \u003c\u003c std::endl; 谈谈decltype关键字 decltype 关键字用于检查实体的声明类型或表达式的类型及值分类，返回值为所属类型。语法：decltype ( expression ) 谈谈引用 在 C++ 中，引用（reference）是一种为已存在的变量创建别名的机制。引用可以让你通过另一个名字访问同一个变量。C++ 中的引用主要分为以下几种类型： 左值引用（L-value References）：左值引用用于引用内存中已经存在的对象，通常用于函数参数传递和返回值。 右值引用（R-value References）：右值引用在 C++11 引入（int\u0026\u0026 rvalueRef = 10），主要用于引用临时对象（右值），支持移动语义和完美转发，优化性能。 引用折叠（Reference Collapsing）：引用折叠是一种复杂的规则，决定了多层引用的结果。它在模板编程和完美转发中非常重要。 X\u0026 \u0026、X\u0026 \u0026\u0026、X\u0026\u0026 \u0026 可折叠成 X\u0026 X\u0026\u0026 \u0026\u0026 可折叠成 X\u0026\u0026 成员初始化列表 好处 更高效：少了一次调用默认构造函数的过程。 有些场合必须要用初始化列表： 常量成员，因为常量只能初始化","date":"2024-06-01","objectID":"/posts/01.c-%E9%9D%A2%E7%BB%8F/:0:0","tags":["C++"],"title":"C/C++ 面试题目总结","uri":"/posts/01.c-%E9%9D%A2%E7%BB%8F/"},{"categories":["系统架构"],"content":"1 分布式存储系统难点 在设计大型分布式系统或存储系统时，初衷通常是为了获得显著的性能提升，通过数百台计算机的资源来并行完成大量工作。因此，性能问题成为最初的关注点。一个自然的想法是将数据分片（Sharding），分布到大量服务器上，从而并行读取数据。 当你在成百上千台服务器上进行分片时，服务器故障将成为常态。如果你有数千台服务器，每天甚至每小时都可能有服务器宕机。因此，需要自动化的方法来修复错误，而不是依赖人工介入。为此，自动容错系统至关重要，这引出了容错（fault tolerance）的概念。 实现容错最有效的方法之一是使用数据复制，只需维护2-3个数据副本，当其中一个故障时，可以使用另一个。因此，要实现容错，必须进行数据复制（replication）。 然而，数据复制带来了不一致性（inconsistency）问题。拥有多个数据副本，如果管理不当，副本之间可能不一致。理想情况下，可以任意使用任一副本进行容错，但如果副本不一致，应用程序将面临麻烦。因此，数据复制不可避免地会引发不一致性问题。 通过精巧的设计，可以减少甚至避免不一致性，使数据表现得符合预期。但要实现这一点，服务器之间需要进行额外的网络交互，这会降低性能。因此，如果追求一致性（consistency），必须付出性能的代价，这与最初的高性能目标相悖。 尽管可以构建高性能系统，但不可避免地会陷入性能与一致性的权衡之中。在实际应用中，为了获得良好的一致性，必须付出相应的代价。如果不愿付出代价，就需要忍受一定程度的不确定性。很多系统中都存在这种权衡，人们往往不愿为高一致性牺牲性能。 ","date":"2024-05-28","objectID":"/posts/04.gfs/:1:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】GFS","uri":"/posts/04.gfs/"},{"categories":["系统架构"],"content":"2 错误的设计 对于强一致性系统，应用程序或客户端感受到的就像在与一台服务器通信。尽管系统由数百台计算机组成，但理想的强一致模型让它看起来像只有一台服务器，一份数据，并且一次只处理一个请求。这种设计确保了每个请求能看到之前所有请求按顺序执行的结果。 对于存储服务器来说，它通常包含一块磁盘。执行写请求可能意味着向磁盘写入数据或对数据进行自增操作。如果是一次修改操作，并且我们有一个以 key-value 为索引的数据表单，那么我们会更新这个表单。如果是读取操作，只需从表单中取出之前写入的数据即可。为了保证这个简单服务的行为可预期，需要遵循一个规则：每次只执行一个请求。这样，每个请求都能看到之前所有请求按顺序执行后的结果。如果服务器按某种顺序依次处理写请求，当你读取数据时，你就能看到预期的数据。 举例来说，客户端 C1 发起写请求将 X 设置为 1，同时客户端 C2 发起写请求将 X 设置为 2。待 C1 和 C2 的写请求都执行完毕后，客户端 C3 发送读取 X 的请求，得到一个结果；客户端 C4 也发送读取 X 的请求，得到另一个结果。此时，问题是这两个客户端看到的结果会是什么。 即使在一个非常简单的系统中，仍会出现一些模糊场景，使你无法确定系统的执行过程及其输出结果。你只能根据结果判断系统是否保持了一致性。 如果 C3 读取 X 得到 2，那么 C4 也应该读取到 2，因为这表明写 X 为 2 的请求是第二个执行的写请求。当 C4 读取 X 时，写 X 为 2 应该仍然是第二个写请求。 然而，单服务器设计存在容错能力差的问题。如果服务器故障或磁盘损坏，系统将无法使用。因此，现实中我们会构建多副本的分布式系统，这引发了一系列新的问题。 假设我们有两台服务器，每台服务器都有数据的一份完整拷贝，并在磁盘上存储一个 key-value 表单。我们希望这两个表单完全一致，这样当一台服务器故障时，可以切换到另一台服务器继续读写操作。 两个表单完全一致意味着，每一个写请求都必须在两台服务器上执行，而读请求只需要在一台服务器上执行，否则就没有容错性了。因为如果读请求也需要从两台服务器读数据，那么一台服务器故障我们就没法提供服务了。现在问题来了，假设客户端C1和C2都想执行写请求，其中一个要写X为1，另一个写X为2。C1会将写X为1的请求发送个两个服务器，因为我们想要更新两台服务器上的数据。C2也会将写X为2的请求发送给两个服务器。 这里会出现什么错误呢？是的，我们没有做任何事情来保障两台服务器以相同的顺序处理这2个请求。如果服务器1（S1）先处理C1的请求，那么在它的表单里面，X先是1，之后S1看到了来自C2的请求，会将自己表单中的X覆盖成2。但是，如果S2恰好以不同的顺序收到客户端请求，那么S2会先执行C2的请求，将X设置为2，之后收到C1的请求，将X设置为1。 之后，如果另外一些客户端，假设C3从S1读数据，C4从S2读数据，我们就会面临一个可怕的场景：这两个客户端读取的数据不一样。但是从前一个例子中的简单模型可以看出，相连的读请求应该读出相同的数据。 这里的问题可以以另一种方式暴露出来。假设我们尝试修复上面的问题，我们让客户端在S1还在线的时候，只从S1读取数据，S1不在线了再从S2读取数据。这样最开始所有的客户端读X都能得到2。但是突然，如果S1故障了，尽管没有写请求将X改成1，客户端读X得到的数据将会从2变成1。因为S1故障之后，所有的客户端都会切换到S2去读数据。这种数据的神奇变化与任何写操作都没有关联，并且也不可能在前一个例子的简单模型中发生。 当然，这里的问题是可以修复的，修复需要服务器之间更多的通信，并且复杂度也会提升。由于获取强一致会带来不可避免的复杂性的提升，有大量的方法可以在好的一致性和一些小瑕疵行为之间追求一个平衡。 ","date":"2024-05-28","objectID":"/posts/04.gfs/:2:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】GFS","uri":"/posts/04.gfs/"},{"categories":["系统架构"],"content":"3 GFS设计目标 Google的目标是构建一个大型且快速的文件系统（GFS），以便各种应用程序都能全局访问数据。传统的方法是为每个应用程序构建特定的存储系统，但这会导致重复建设。GFS 作为一个全局通用的存储系统，允许不同应用程序共享和访问数据。例如，存储了大量互联网抓取数据后，其他用户可以通过申请权限查看这些数据，因为大家使用的是同一个存储系统。这样，Google 内部的人员可以根据名字读取 GFS 中可共享的内容。 为了实现大容量和高速性能，GFS 将数据文件自动分割并存储在多台服务器上，这样可以并行读取同一个文件，从而获得更高的聚合吞吐量。文件分割存储还允许存储比单个磁盘更大的文件。由于存储系统分布在数百台服务器上，GFS 具备自动故障修复功能，不需要人工干预来修复服务器或迁移数据。 GFS 的一些特征并非设计目标。例如，GFS 只在一个数据中心内运行，多个副本并未分布在全球各地。理论上，数据副本应该地理分散，但实现起来很难，所以 GFS 局限于单个数据中心内。 此外，GFS 面向 Google 内部使用，供工程师开发应用程序，并不直接面向普通用户。虽然 Google 可能会出售基于 GFS 的服务，但 GFS 本身并不对外提供。 最后，GFS 专注于对大型顺序文件的读写优化。例如，银行账户系统需要能够读写小数据块的数据库，而 GFS 针对 TB 级别的文件进行优化，只支持顺序处理而非随机访问。某种程度上，它更像批处理系统，注重巨大的吞吐量而非低延迟，每次操作都涉及 MB 级别的数据。 ","date":"2024-05-28","objectID":"/posts/04.gfs/:3:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】GFS","uri":"/posts/04.gfs/"},{"categories":["系统架构"],"content":"4 Master节点 假设我们有上百个客户端和一个Master节点。虽然实际中可以有多台机器作为Master节点，但GFS中Master采用Active-Standby模式（系统包含两个或多个实例，其中一个实例（Active）正在运行并处理所有的请求，而其他实例（Standby）则处于待命状态，准备在Active实例发生故障时立即接管工作。），所以只有一个Master节点在工作。Master节点保存了文件名和存储位置的对应关系。除此之外，还有大量的Chunk服务器，每个Chunk服务器上都有1-2块磁盘。 Master节点管理文件和Chunk的信息，而Chunk服务器存储实际数据。这种设计将管理和存储分开处理，提高了系统效率。在GFS中，Master节点知道每个文件对应的所有Chunk handle，这些Chunk每个是64MB大小，共同构成一个文件。例如，一个1GB的文件会分成多个Chunk，Master节点知道每个Chunk存储在哪。读取文件时，需要先向Master节点查询Chunk位置，然后从对应的Chunk服务器读取数据。 我们需要了解Master节点内保存的数据内容，这里我们关心的主要是两个表单： 文件名到Chunk handle的对应关系：Master节点有一个表单记录了文件名到Chunk handle数组的对应关系。 Chunk handle到Chunk数据的对应关系：另一个表单记录了Chunk handle和它们的数据的对应关系，包括每个Chunk的服务器列表、当前版本号、主Chunk（Primary Chunk）和租约过期时间。 这些数据都存储在内存中，但为了防止数据丢失，Master节点也将部分数据存储在磁盘上。Master节点的写操作会记录到磁盘的日志（log）中，并定期生成检查点（CheckPoint）。 有些数据需要存在磁盘上，而有些不用。它们分别是： Chunk Handle数组（非易失性，NV）：保存到磁盘上。 Chunk服务器列表（易失性，V）：不用写入磁盘，重启后可重新获取。 版本号（非易失性，NV）：写入磁盘，确保数据一致性。 主Chunk的handle（易失性，V）：不写入磁盘，重启后可重新分配。 租约过期时间（易失性，V）：不写入磁盘。 当文件扩展到新的64MB或主Chunk变更时，Master节点会向磁盘日志中追加记录。这种日志追加方式比数据库高效，因为它只需顺序写入，不涉及磁盘的随机访问。 Master节点故障重启时，会从最近的检查点开始恢复状态，然后通过执行日志中的记录恢复到最新状态。这种方式避免了从日志最开始重建状态的低效问题。 ","date":"2024-05-28","objectID":"/posts/04.gfs/:4:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】GFS","uri":"/posts/04.gfs/"},{"categories":["系统架构"],"content":"5 读文件 对于读请求来说，应用程序或GFS客户端会提供一个文件名和读取的偏移量（offset）。首先，客户端将这些信息发送给Master节点。Master节点从自己的文件表单中查找文件名，获取对应的Chunk handle数组。每个Chunk大小为64MB，因此可以通过偏移量除以64MB来确定对应的Chunk handle。接着，Master节点从Chunk表单中找到包含该Chunk的服务器列表，并将这个列表返回给客户端。 具体步骤如下： 客户端（或应用程序）将文件名和偏移量发送给Master节点。 Master节点将Chunk Handle（即Chunk ID）和服务器列表发送给客户端。 客户端接下来可以从服务器列表中选择一个服务器来读取数据。根据GFS论文的描述，客户端会选择一个在网络上最近的服务器（在Google的数据中心中，通过IP地址的差异可以判断网络位置的远近），然后将读请求发送到这个服务器。由于客户端每次可能只读取1MB或64KB的数据，它可能会多次读取同一个Chunk的不同部分。为此，客户端会缓存Chunk和服务器的对应关系，这样在后续读取相同Chunk数据时，不需要每次都向Master请求相同的信息。 接下来，客户端会与选定的Chunk服务器通信，将Chunk Handle和偏移量发送给该服务器。Chunk服务器在本地硬盘上将每个Chunk存储为独立的Linux文件，并通过普通的Linux文件系统进行管理。可以推测，Chunk文件会按照Handle（即ID）命名。因此，Chunk服务器需要做的就是根据文件名找到对应的Chunk文件，从文件中读取相应的数据段，并将数据返回给客户端。 ","date":"2024-05-28","objectID":"/posts/04.gfs/:5:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】GFS","uri":"/posts/04.gfs/"},{"categories":["系统架构"],"content":"6 写文件 对于应用程序来说，写文件的过程与读文件的接口非常类似，都是通过调用GFS的库函数进行操作。在写文件时，应用程序会告诉库函数，要将缓冲区中的数据追加到指定文件中。为了简化讨论，我们只考虑GFS论文中的记录追加（Record Append）的情况。 所以再次描述一下，对于写文件，客户端会向Master节点发送请求说：我想向这个文件名对应的文件追加数据，请告诉我文件中最后一个Chunk的位置。 当有多个客户端同时写同一个文件时，一个客户端并不能知道文件究竟有多长。因为如果只有一个客户端在写文件，客户端自己可以记录文件长度，而多个客户端时，一个客户端没法知道其他客户端写了多少。例如，不同客户端写同一份日志文件，没有一个客户端会知道文件究竟有多长，因此也就不知道该往什么样的偏移量，或者说向哪个Chunk去追加数据。这个时候，客户端可以向Master节点查询哪个Chunk服务器保存了文件的最后一个Chunk。 对于读操作，可以从任何最新的Chunk副本读取数据，但写操作必须通过Chunk的主副本（Primary Chunk）进行。Master节点需要确保Chunk的主副本存在。如果不存在，Master节点会查找所有存有该Chunk最新副本的Chunk服务器。Master节点确定哪些副本是最新的（副本中保存的版本号与Master中记录的Chunk的版本号一致），并从中选择一个作为Primary，其余作为Secondary。 之后，Master节点增加Chunk的版本号，并将新的版本号写入磁盘。Master节点通知Primary和Secondary服务器新的Chunk版本号，并指定它们的角色。Primary和Secondary服务器将新版本号存储在本地磁盘中，以便在重启时报告给Master。 所以客户端将要追加的数据发送给Primary和Secondary服务器，这些服务器将数据写入临时位置。所以最开始，这些数据不会追加到文件中。当所有服务器确认数据已写入临时位置后，客户端向Primary发送消息，要求将数据追加到文件中。Primary按照顺序处理来自多个客户端的并发请求，确保每次只执行一个请求。Primary将数据写入Chunk的末尾，并通知所有Secondary服务器也将数据写入它们的Chunk末尾。 Secondary服务器将数据写入本地磁盘后，向Primary发送确认消息。如果所有Secondary服务器成功写入数据并回复“yes”，Primary向客户端返回写入成功。如果任何Secondary服务器写入失败，Primary向客户端返回写入失败。 如果客户端接到写入失败的消息，应重新发起整个追加过程。首先，客户端再次与Master节点交互，找到文件末尾的Chunk，然后重新向Primary和Secondary发起追加操作。 ","date":"2024-05-28","objectID":"/posts/04.gfs/:6:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】GFS","uri":"/posts/04.gfs/"},{"categories":["系统架构"],"content":"7 GFS的一致性 在GFS中，追加数据的过程相对复杂。我们通过一个例子来解释这一过程。 **数据追加请求：**客户端发送一个追加数据的请求，例如数据A，要将数据A追加到文件末尾。Chunk的三个副本（一个Primary和两个Secondary）都成功将数据A追加到了Chunk中，因此Chunk中的第一个记录是A。 **网络问题导致的部分写入：**第二个客户端加入，想要追加数据B。但由于网络问题，消息只被Primary和一个Secondary收到并处理。因此，两个副本追加了数据B，而另一个副本没有。 **后续写入：**第三个客户端想要追加数据C，并且Primary选择了偏移量并通知Secondary。三个副本都成功追加了数据C。 **处理写入失败：**由于网络问题，第二个客户端会收到写入失败的回复，并重新发起追加数据B的请求。假设这次数据B没有丢包，三个副本都成功追加了数据B。现在，三个副本都在线，并且都有最新的版本号。 **读取数据的影响：**客户端读取文件时，读取的内容取决于读取的是哪个副本。例如： 读取第一个副本时，可能会看到数据A、B、C，然后是重复的B。 读取第三个副本时，可能会看到数据A、一个空白数据、然后是C、B。 所以不同的读请求可能得到不同的结果，具体取决于读取的是哪个副本。 **处理写入失败的复杂情况：**在最坏情况下，某个Secondary未能成功执行数据追加操作，客户端从Primary收到写入失败的回复。在客户端重新发送写文件请求之前，客户端可能故障，导致数据D只存在于某些副本中，而其他副本完全没有。 在GFS的这种工作方式下，如果Primary返回写入成功，一切正常。如果Primary返回写入失败，不同副本的数据可能不同。GFS的设计简单，但可能会暴露一些奇怪的数据顺序问题。应用程序需要容忍数据乱序，或通过在文件中写入序列号来识别顺序。如果应用程序对数据顺序敏感，可以避免并发写入，例如，电影文件的写入应使用一个客户端顺序追加数据。 如果要将GFS升级为强一致系统，需要考虑以下几点： **检测重复请求：**Primary需要能够检测重复的请求，确保数据不会重复写入。 **Secondary的强制执行：**Secondary必须执行Primary的请求，而不能简单地返回错误。对于永久性故障的Secondary，需要有机制将其移除。 **两阶段提交：**写请求需要两个阶段：首先Primary向Secondary发出请求并等待确认；如果所有Secondary都确认，Primary再指示实际执行操作。 **处理Primary崩溃：**当Primary崩溃时，新Primary需要与Secondary同步，确保操作历史一致。 **Secondary的租约系统：**Secondary需要一个类似Primary的租约系统，确保在合法时间内响应客户端请求。 总体而言，GFS取得了巨大的成功，许多Google的应用都依赖于它。例如，BigTable和MapReduce等关键基础架构都是构建在GFS之上的，因此GFS在Google内部得到了广泛应用。然而，GFS也有其局限性，最严重的问题在于它只有一个Master节点，这带来了以下几个问题： **内存限制：**Master节点必须为每个文件和每个Chunk维护表单。随着使用量的增加，文件数量不断上升，最终Master节点会耗尽内存来存储这些表单。虽然可以增加内存，但单台计算机的内存总有上限，这成为了早期遇到的一个显著问题。 **处理能力：**单个Master节点需要处理数千个客户端的请求，而其CPU每秒只能处理数百个请求。尤其当Master节点还需要将部分数据写入磁盘时，这个问题变得更加严重，导致客户端数量很快超过了单个Master的处理能力。 **复杂的语义：**应用程序发现很难处理GFS复杂的语义，特别是副本数据同步问题（或不同步问题），这在一定程度上增加了开发难度。 **故障切换：**从GFS论文中可以了解到，Master节点的故障切换不是自动的。当Master节点永久故障时，需要人工干预来更换新的服务器，这可能需要几十分钟甚至更长时间来处理。对于某些应用程序来说，这样的停机时间是不可接受的。 ","date":"2024-05-28","objectID":"/posts/04.gfs/:7:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】GFS","uri":"/posts/04.gfs/"},{"categories":["系统架构"],"content":"8 FAQ 应用程序如何知道Chunk的哪些部分由填充和重复记录组成？ 为了检测填充，应用程序可以在有效记录的开头放置一个可预测的幻数，或者包含一个校验和，该校验和可能仅在记录有效时才有效。应用程序可以通过在记录中包含唯一 ID 来检测重复项。然后，如果它读取的记录与之前的记录具有相同的 ID，它就知道它们是彼此的重复项。 GFS 为处理这些情况的应用程序提供了一个库。 GFS 设计的这一方面有效地将复杂性从 GFS 转移到了应用程序，但这可能并不理想。 怎样知道一个文件存储在哪台机器上？ 根据master中文件到chunk再到chunk位置的映射来定位具体的chunkserver。 论文提到了引用计数——它们是什么？ 它们是快照写时复制实现的一部分。当GFS创建快照时，它不会复制块，而是增加每个块的引用计数器。这使得创建快照的成本很低。如果客户端写入一个chunk并且主服务器注意到引用计数大于 1，则主服务器首先创建一个副本，以便客户端可以更新该副本（而不是属于快照一部分的块）。您可以将此视为延迟复制，直到绝对必要为止。希望并非所有块都会被修改，并且可以避免制作一些副本。 什么是租约？ 对于 GFS，租约是master授予 chunkserver 充当特定 chunk 的主chunkserver的能力的一段时间。master保证在租约期间不会分配不同的主chunkserver，并且主服务器同意在租约到期之前停止充当主chunkserver（除非主chunkserver要求master延长租约）。租约是避免主chunkserver必须反复询问master是否仍然是主chunkserver的一种方法—它知道它可以在下一分钟（或无论租约间隔是多少）充当主chunkserver，而无需再次与master通信。 什么是内部碎片？为什么惰性分配有帮助？ 内部碎片是当系统使用大于所请求分配所需的分配单元时浪费的空间。如果 GFS 以 64MB 为单位分配磁盘空间，那么一个 1 字节的文件将浪费近 64MB 的磁盘空间。 GFS 通过延迟分配磁盘空间来避免这个问题。每个块都是一个Linux文件，Linux文件系统使用的块大小为几十KB；因此，当应用程序创建一字节 GFS 文件时，该文件的块仅消耗 1 个 Linux 磁盘块，而不是 64 MB。 Google 还在使用 GFS 吗？ 有传言称 GFS 已被 Colossus 所取代，总体目标相同，但在主性能和容错性方面有所改进。此外，Google内部的许多应用程序已经转向更多类似数据库的存储系统，例如BigTable和Spanner。然而，GFS 的大部分设计仍然存在于 HDFS（Hadoop 开源 MapReduce 的存储系统）中。 ","date":"2024-05-28","objectID":"/posts/04.gfs/:8:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】GFS","uri":"/posts/04.gfs/"},{"categories":["系统架构"],"content":"Testing Distributed Systems for Linearizability 原文 ","date":"2024-05-22","objectID":"/posts/03.%E6%B5%8B%E8%AF%95%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7/:0:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】 测试分布式系统的线性一致性","uri":"/posts/03.%E6%B5%8B%E8%AF%95%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7/"},{"categories":["系统架构"],"content":"1 引言 正确实现一个分布式系统是非常有挑战的一件事情，因为需要很好的处理并发和失败这些问题。网络包可能被延迟，重复，乱序或者丢弃，机器可能在任何时候宕机。即使一些计被论文证明是正确的，也仍然很难再实现中避免 bug。 除非我们使用形式方法，不然，即使我们假设实现是正确的，我们也需要去测试系统。测试分布式系统也是一件非常有挑战的事情。并发和不确定性使得我们在测试的时候非常难抓住 bug，尤其是在一些极端情况下面才会出现的 bug，譬如同时机器宕机或者极端网络延迟。 ","date":"2024-05-22","objectID":"/posts/03.%E6%B5%8B%E8%AF%95%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7/:1:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】 测试分布式系统的线性一致性","uri":"/posts/03.%E6%B5%8B%E8%AF%95%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7/"},{"categories":["系统架构"],"content":"2 正确性 在讨论测试分布式系统的正确性之前，我们首先定义下什么是 “正确性”。即使对于一些简单的系统，要完全的确定系统符合预期也是一件相当复杂的事情。 考虑一个简单的 key-value store，譬如 etcd，支持两个操作：Put(key, value) 和 Get(key)，首先，我们需要考虑它在顺序情况下面的行为。 ","date":"2024-05-22","objectID":"/posts/03.%E6%B5%8B%E8%AF%95%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7/:2:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】 测试分布式系统的线性一致性","uri":"/posts/03.%E6%B5%8B%E8%AF%95%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7/"},{"categories":["系统架构"],"content":"2.1 顺序规范 通常对于一个 key-value store，我们对于它在顺序操作下面的行为都能有一个直观的认识：Get 操作如果在 Put 的后面，那么一定能得到 Put 的结果。譬如，如果 Put(\"x\", \"y\") ，那么后面的 Get(\"x\") 就能得到 “y”，如果得到了 “z”，那么这就是不对的。 我们使用 Python 定义一个简单的 key-value store： 上面的代码比较简单，但包含了足够的信息，包括初始状态是怎样的，内部状态是如何被操作的结果改变的，从 key-value存储里面操作返回的结果是怎样的。这里需要留意下 Get() 对于不存在的 key 的处理，通常会返回一个空字符串。 ","date":"2024-05-22","objectID":"/posts/03.%E6%B5%8B%E8%AF%95%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7/:2:1","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】 测试分布式系统的线性一致性","uri":"/posts/03.%E6%B5%8B%E8%AF%95%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7/"},{"categories":["系统架构"],"content":"3 线性一致性 接下来，我们来考虑我们的 key-value store在并发下面会有怎样的行为。需要注意顺序规范并没有指明在并发操作下面会发生什么。譬如，顺序规范并没有说 key-value store 在下面这个场景下可以允许的操作。 我们并不能立刻知道 Get(\"x\") 这个操作会允许返回怎样的结果。直觉上，我们可以说Get(\"x\") 是跟 Put(\"x\", \"y\") 和 Put(\"x\", \"z\") 一起执行的，所以它能可能返回一个值，甚至也可能返回 \"\"。 如果有另一个 Get(\"x\") 的操作在更后面执行，我们可以说这个一定能返回 \"z\"，因为它是最后一次写入的值，而且那个时候并没有其他的并发写入。 对于一个基于顺序规范的并发操作来说，我们会用一个一致性模型，也就是线性一致性来说明它的正确性。在一个线性一致性的系统里面，任何操作都可能在调用或者返回之间原子和瞬间执行。除了线性一致性，还有一些其他一致性的模型，但多数分布式系统都提供了线性一致性的操作：线性一致性是一个强的一致性模型，并且基于线性一致性系统，很容易去构建其他的系统。考虑到如下对 key-value store 操作的历史例子： 这个历史是一个线性的。在下面图片的蓝色地方，我们现实的标明了线性一致的点。这个顺序历史 Put(\"x\", \"0\"), Get(\"x\") -\u003e \"0\", Put(\"x\", \"1\"), Get(\"x\") -\u003e \"1\"，对于顺序规范来说就是一个正确的历史。 对应的，下面的历史就不是线性一致的。 对于顺序规范来说，这个历史并不是线性一致的：我们并不能在这个历史的操作里面指定出线性一致的点。我们可以画出 client 1，2 和 3 的，但我们并不能画出 client 4 的，因为这明显是一个过期的值。类似的，我们可以画出 client 1，2 和 4 的，那么 client 2 的操作一定会在 4 的操作开始的后面，但这样我们就不能处理 client 3，它只可能合法的返回 \"\"或者 \"0\"。 ","date":"2024-05-22","objectID":"/posts/03.%E6%B5%8B%E8%AF%95%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7/:3:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】 测试分布式系统的线性一致性","uri":"/posts/03.%E6%B5%8B%E8%AF%95%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7/"},{"categories":["系统架构"],"content":"4 测试 有了一个正确性的定义，我们就可以考虑如何去测试分布式系统了。通常的做法就是对于正确的操作，不停的进行随机的错误注入，类似机器宕机，网络隔离等。我们甚至能模拟整个网络，这样我们就能做长时间的网络延迟等。因为测试时随机的，我们需要跑很多次从而确定一个系统的实现是正确的。 ","date":"2024-05-22","objectID":"/posts/03.%E6%B5%8B%E8%AF%95%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7/:4:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】 测试分布式系统的线性一致性","uri":"/posts/03.%E6%B5%8B%E8%AF%95%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7/"},{"categories":["系统架构"],"content":"4.1 临时测试 我们实际如何做正确操作的测试呢？在最简单的软件里面，我们可以使用输入输出测试，譬如 assert(expected_output == f(input))，我们也可以在分布式系统上面使用一个类似的方法，譬如，对于 key-value store，当多个 client 开始执行操作的时候，我们可以有如下的测试： 如果测试挂掉了，那么这个系统一定不是线性一致性的，当然，这个测试并不是很完备，因为有可能不是线性一致的系统也可能通过这个测试。 ","date":"2024-05-22","objectID":"/posts/03.%E6%B5%8B%E8%AF%95%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7/:4:1","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】 测试分布式系统的线性一致性","uri":"/posts/03.%E6%B5%8B%E8%AF%95%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7/"},{"categories":["系统架构"],"content":"4.2 线性一致性 一个更好的办法就是并发的客户端完全跑随机的操作。譬如，循环的去调用 kvstore.put(rand(), rand()) 和 kvstore.get(rand())，有可能会只用很少的 key 去增大冲突的概率。但在这种情况下，我们如何定义什么是正确的操作呢？在上面的简单的测试里面，因为每个 client 都操作的是一个独立的 key，所以我们可以非常明确的知道输出结果。 但是 clients 并发的操作同一堆 keys，事情就变得复杂了。我们并不能预知每个操作的返回值因为这并没样一个唯一的答案。但我们可以用另一个办法：我们可以记录整个操作的历史，然后去验证这个操作历史是线性一致的。 4.2.1 线性一致性验证 一个线性一致性验证器会使用一个顺序规范和一个并发操作的历史，然后执行一个判定程序去检查这个历史在规范下面是否线性一致。 4.2.2 NP 完备 但不幸的是，线性一致性验证是 NP 完备的。这个证明非常简单：我们能说明线性一致性验证是 NP 问题，并且也能展示一个 NP 困难问题能被简化成线性一致性验证。明显的，线性一致性验证是 NP 问题，譬如，所有操作的线性一致性点，根据相关的顺序规范，我们可以在多项式时间里验证。 为了说明线性一致性验证是 NP 困难的，我们可以将子集合问题简化成线性一致性验证。对于子集合问题，我们给出非负数的集合 $S={s_1,s_2,…,s_n}$ 和目标结果 $t$，然后我们必须确定是否存在一个子集 $S$ 的和等于 $t$。我们可以将这个问题简化成如下的线性一致性验证。考虑顺序规范： 以及历史： 当且仅当子集和问题的答案为“是”时，该历史才可线性化。如果历史是可线性化的，那么我们可以采用在 Get() 操作之前具有线性化点的所有操作 Add(s_i) ，并且这些操作对应于中的元素 $s_i$总和为 $t$ 的子集。如果该集合确实有一个总和为$t$的子集，那么我们可以通过与子集中的元素$s_i$对应的操作 Add(s_i) 来构造线性化放置在 Get() 操作之前，并使其余操作发生在 Get() 操作之后。 4.2.3 实现 即使线性一致性验证是 NP 完全的，在实际中，它仍然能在一些小的历史上面很好的工作。线性一致性验证器的实现会用一个可执行的规范，加上一个历史，执行一个搜索过程去构造一个线性化，并使用一些技巧来限制减少搜索的空间。 现有的线性化检查器如 Knossos，用于 Jepsen 测试系统。但不幸的是，在测试一些分布式 key-value store 的时候，Knossos 并不能很好的工作，它可能只能适用于一些少的并发 clients，以及只有几百的事件的历史。但在一些测试里面，有很多的 clients，以及会生成更多的历史事件。 为了解决 Knossos 的问题，作者开发了 Procupine，一个用 Go 写的更快的线性一致性验证工具。Porcupine 使用一个用 Go 开发的执行规范去验证历史是否是线性的。根据实际测试的情况，Porcupine 比 Knossos 快很多倍。 Procupine Github 4.2.4 效果 使用故障注入和线性化检查来测试可线性化分布式系统是一种有效的方法。 作为对比，在使用专门的测试用 Porcupine 测试 key-value store 的时候，作者使用了这两种方式。作者在实现它自己的 key-value store 的时候引入不同的设计错误，譬如在修改之后会出现过期读，来看这些测试是否会挂掉。专门测试会捕捉到很多 bugs，但并没有能力去捕捉到更多的狡猾的 bugs。相对而言，作者现在还没找到一个正确性的 bug 是线性一致性测试不能抓住的。 形式方法能够保证一个分布式系统的正确性。例如，UM PLSE 研究小组最近使用 Coq proof assistnt 来验证了 Raft 一致性协议。但不幸的的是，验证需要特定的知识，另外验证实际的系统需要做大量的工作。没准有一天，验证能被用在实际系统上面，但现在，主要还是测试，而不是验证。 理论上，所有的生产系统都会有一个形式规范，而且一些系统也已经有了，譬如 Raft 就有一个用 TLA+ 写的形式规范。但不幸的是，大部分的系统是没有的。 ","date":"2024-05-22","objectID":"/posts/03.%E6%B5%8B%E8%AF%95%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7/:4:2","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】 测试分布式系统的线性一致性","uri":"/posts/03.%E6%B5%8B%E8%AF%95%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7/"},{"categories":["系统架构"],"content":"1 为什么选择Go 在实现分布式系统时，选择合适的编程语言非常重要。Go有以下特点： 优秀的线程支持； 便捷的RPC机制、类型； 内存安全以及垃圾回收机制。 这使Go成为了一个理想的选择。Go不仅相对简单，而且其垃圾回收机制使线程管理更加容易，避免了使用后释放问题。由于这些优势，Go在分布式系统中被广泛应用。 Go Tutorial ","date":"2024-05-15","objectID":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/:1:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】使用Go进行线程和RPC编程","uri":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/"},{"categories":["系统架构"],"content":"2 线程与Go中的Goroutine 线程是一种有用的结构工具，允许一个程序同时执行多项任务，每个线程串行执行，就像非线程程序一样。Go中称线程为Goroutine，每个Goroutine在执行时包含自己的程序计数器、寄存器和栈，但共享内存。使用线程可以提高I/O并发性和多核性能，同时也方便后台任务的处理。 ","date":"2024-05-15","objectID":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/:2:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】使用Go进行线程和RPC编程","uri":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.1 为什么使用线程？ I/O并发性：客户端可以并行向多个服务器发送请求并等待回复，服务器可以同时处理多个客户端请求。 多核性能：在多核处理器上并行执行代码，提高计算效率。 便捷性：后台线程可以定期检查各个worker线程是否仍然活跃。 ","date":"2024-05-15","objectID":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/:2:1","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】使用Go进行线程和RPC编程","uri":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.2 线程的替代方案 事件驱动编程（Event-driven programming）是一种替代传统多线程编程的方式，通过在单线程中显式交错处理活动来实现I/O并发性。这种编程模型常用于处理大量I/O操作的场景，例如网络服务器和图形用户界面（GUI）应用。 在事件驱动编程中，系统维护一个事件循环（event loop），不断检查并处理事件队列中的事件。每个事件通常对应某种外部输入或状态变化，如网络请求到达、用户点击按钮或定时器到期。事件处理程序（event handler）被注册到特定事件上，当相应事件发生时，处理程序被调用来执行预定义的操作。 ","date":"2024-05-15","objectID":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/:2:2","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】使用Go进行线程和RPC编程","uri":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.3 线程编程挑战 安全共享数据：多个线程同时访问共享数据时可能导致竞争条件，常用的解决方案是使用锁（如Go的sync.Mutex）或者避免共享可变数据。 线程间协调：一个线程生产数据，另一个线程消费数据，需要使用Go的通道（channel）或条件变量（sync.Cond）或等待组（sync.WaitGroup）进行协调。 死锁：线程之间通过锁或channel或RPC相互等待资源时可能导致死锁，需要小心避免。 ","date":"2024-05-15","objectID":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/:2:3","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】使用Go进行线程和RPC编程","uri":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/"},{"categories":["系统架构"],"content":"3 以网络爬虫为例的线程应用 网络爬虫的目标是抓取所有网页内容，常见的实现方式有串行和并发两种。并发爬虫利用线程提高抓取效率，但也需要解决避免重复抓取和循环依赖的问题。 在本例中，我们使用一个填充的Fetcher来模拟抓取。fetcher结构如下： type fakeResult struct { body string urls []string } func (f fakeFetcher) Fetch(url string) ([]string, error) { if res, ok := f[url]; ok { fmt.Printf(\"found: %s\\n\", url) return res.urls, nil } fmt.Printf(\"missing: %s\\n\", url) return nil, fmt.Errorf(\"not found: %s\", url) } // fetcher is a populated fakeFetcher. var fetcher = fakeFetcher{ \"http://golang.org/\": \u0026fakeResult{ \"The Go Programming Language\", []string{ \"http://golang.org/pkg/\", \"http://golang.org/cmd/\", }, }, \"http://golang.org/pkg/\": \u0026fakeResult{ \"Packages\", []string{ \"http://golang.org/\", \"http://golang.org/cmd/\", \"http://golang.org/pkg/fmt/\", \"http://golang.org/pkg/os/\", }, }, \"http://golang.org/pkg/fmt/\": \u0026fakeResult{ \"Package fmt\", []string{ \"http://golang.org/\", \"http://golang.org/pkg/\", }, }, \"http://golang.org/pkg/os/\": \u0026fakeResult{ \"Package os\", []string{ \"http://golang.org/\", \"http://golang.org/pkg/\", }, }, } ","date":"2024-05-15","objectID":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/:3:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】使用Go进行线程和RPC编程","uri":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/"},{"categories":["系统架构"],"content":"3.1 串行爬虫 串行爬虫通过递归调用实现深度优先搜索，使用一个共享的map记录已抓取的URL，防止重复抓取。然而，这种方式只能一次抓取一个页面，速度较慢。代码如下： func Serial(url string, fetcher Fetcher, fetched map[string]bool) { // Use a map to keep track of fetched URLs if fetched[url] { return } fetched[url] = true urls, err := fetcher.Fetch(url) if err != nil { return } // Recursively fetch URLs for _, u := range urls { Serial(u, fetcher, fetched) } return } 我们是否可以在Serial()调用前面放一个go呢 在 Serial() 调用前添加 go 关键字会导致并发执行多个爬虫任务，从而可能导致重复抓取相同的页面。这是因为每个爬虫任务都会尝试从未抓取过的页面开始递归抓取，而并发执行可能导致多个爬虫同时选择相同的页面作为起始点，进而重复抓取。 ","date":"2024-05-15","objectID":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/:3:1","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】使用Go进行线程和RPC编程","uri":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/"},{"categories":["系统架构"],"content":"3.2 并发爬虫 ","date":"2024-05-15","objectID":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/:3:2","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】使用Go进行线程和RPC编程","uri":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/"},{"categories":["系统架构"],"content":"3.3 使用锁 每个页面的抓取在独立的线程中进行，为了确保抓取过程的正确性，我们使用了互斥锁来保护共享的 fetchState 结构体，避免了重复抓取和并发冲突的问题。在抓取过程中，我们使用了递归调用 ConcurrentMutex 函数来处理当前页面的所有子链接。每当发现一个新的子链接时，我们启动一个新的 Goroutine 来并发地抓取该链接，从而实现了多个页面的并行抓取。使用 sync.WaitGroup 来等待所有的子链接抓取任务完成，确保主线程在所有任务完成后才返回，以避免提前结束抓取过程。代码如下： type fetchState struct { mu sync.Mutex // protect concurrent crawls fetched map[string]bool // Used to store crawled URLs. The key is URL and the value is whether it has been crawled. } func (fs *fetchState) testAndSet(url string) bool { fs.mu.Lock() defer fs.mu.Unlock() r := fs.fetched[url] fs.fetched[url] = true return r // Return to previous crawling status } func ConcurrentMutex(url string, fetcher Fetcher, fs *fetchState) { if fs.testAndSet(url) { return } urls, err := fetcher.Fetch(url) if err != nil { return } var done sync.WaitGroup // Create a wait group that waits for all subtasks to complete for _, u := range urls { done.Add(1) // Increase the counter of the waiting group go func(u string) { // Start a Go coroutine to concurrently crawl sub-links defer done.Done() ConcurrentMutex(u, fetcher, fs) // Recursive call ConcurrentMutex, fetching sub-links. }(u) } done.Wait() // Wait for all subtasks to complete return } ","date":"2024-05-15","objectID":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/:3:3","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】使用Go进行线程和RPC编程","uri":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/"},{"categories":["系统架构"],"content":"3.4 使用通道 每个worker线程将抓取到的URL发送到一个通道，coordinator从通道中读取URL并启动新的worker线程。这种方式避免了锁的使用，但需要小心避免通道阻塞导致的死锁。代码如下： func worker(url string, ch chan []string, fetcher Fetcher) { urls, err := fetcher.Fetch(url) if err != nil { ch \u003c- []string{} } else { ch \u003c- urls } } func coordinator(ch chan []string, fetcher Fetcher) { n := 1 // 记录正在处理的任务数量，初始值为 1，因为最开始只有一个初始 URL fetched := make(map[string]bool) // 记录已经抓取的 URL for urls := range ch { // 不断从通道中接收抓取到的链接列表，直到通道被关闭 for _, u := range urls { // 遍历接收到的链接列表 if fetched[u] == false { fetched[u] = true n += 1 go worker(u, ch, fetcher) // 启动一个新的 worker 协程抓取该链接的子链接 } } n -= 1 if n == 0 { // 如果当前没有正在处理的任务，则退出循环，结束并发抓取过程 break } } } // ConcurrentChannel 函数是并发抓取的入口函数，利用通道协调并发抓取的过程。 func ConcurrentChannel(url string, fetcher Fetcher) { ch := make(chan []string) // 创建一个字符串切片类型的通道 go func() { // 启动一个匿名函数的 Go 协程，用于向通道发送 URL ch \u003c- []string{url} // 向通道发送包含初始 URL 的字符串切片 }() coordinator(ch, fetcher) // 调用 coordinator 函数，开始并发抓取的协调过程 } 在 worker 函数中，每个worker线程会尝试抓取指定的URL，并将抓取到的子链接发送到通道中。如果抓取失败，则发送一个空的字符串切片到通道，以便通知coordinator任务失败。 在 coordinator 函数中，coordinator不断从通道中读取抓取到的链接列表，然后遍历这些链接，如果发现之前未抓取过的新链接，则将其标记为已抓取并启动一个新的worker线程进行抓取。同时，coordinator会维护一个计数器 n 来记录当前正在处理的任务数量，当所有任务都处理完成后，coordinator结束并发抓取的过程。 在 ConcurrentChannel 函数中，我们首先创建了一个字符串切片类型的通道，并启动了一个匿名的 Goroutine 来向通道发送初始的 URL。然后，调用 coordinator 函数开始并发抓取的协调过程。 coordinator如何知道它已经完成？ coordinator知道它已完成的条件是 n 计数器的值归零。coordinator通过维护 n 计数器来跟踪当前正在处理的任务数量，每个worker线程处理完成后会将 n 减一。当 n 计数器的值为零时，表示所有的任务都已经完成，coordinator就知道自己的工作已经完成。 通道在这里有两个作用： - 通信值：worker线程将抓取到的链接列表发送到通道中，以便coordinator可以读取并处理。 - 事件通知：通道的关闭可作为事件通知，当通道关闭时，coordinator会知道所有的worker线程都已完成，并且没有新的任务需要处理。 ","date":"2024-05-15","objectID":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/:3:4","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】使用Go进行线程和RPC编程","uri":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/"},{"categories":["系统架构"],"content":"4 远程过程调用（RPC） ","date":"2024-05-15","objectID":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/:4:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】使用Go进行线程和RPC编程","uri":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/"},{"categories":["系统架构"],"content":"4.1 介绍 ","date":"2024-05-15","objectID":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/:4:1","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】使用Go进行线程和RPC编程","uri":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/"},{"categories":["系统架构"],"content":"4.2 远程过程调用（RPC） 远程过程调用（RPC）是分布式系统中的关键技术之一，它使得客户端和服务器之间的通信变得简单而直观。在分布式系统中，不同的节点可能分布在不同的物理机器上，RPC允许这些节点之间进行远程通信，就像调用本地函数一样，无需了解底层的网络协议细节。 RPC的目标是实现易于编程的客户端/服务器通信，它隐藏了底层网络通信的复杂性，为开发人员提供了简单的接口。通过RPC，开发人员可以专注于业务逻辑的实现，而无需担心网络通信的细节。 在RPC中，数据在客户端和服务器之间通过网络传输，因此需要将数据转换为“有线格式”（wire format）。RPC库负责处理数据的序列化和反序列化，以确保数据可以在网络上传输并在另一端正确解析。 RPC消息的基本结构是请求-响应模式。客户端发送请求给服务器，服务器处理请求并发送响应给客户端。这种简单的请求-响应模式使得RPC成为了一种非常有效的通信方式。 在RPC的软件结构中，通常会有以下几个组件： 客户端应用程序：负责发起RPC请求的应用程序。 存根函数（Stub functions）：客户端应用程序调用的接口函数，实际上是一个本地代理，负责将RPC调用转发给远程服务器。 服务器处理函数（Handler functions）：服务器端实际执行业务逻辑的函数。 调度器（Dispatcher）：负责将RPC请求分发给正确的处理函数。 RPC库：提供了RPC通信所需的基本功能，例如序列化、网络通信等。 通过RPC，不同语言编写的客户端和服务器可以进行通信，实现了跨语言的可移植性和互操作性。 ","date":"2024-05-15","objectID":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/:4:2","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】使用Go进行线程和RPC编程","uri":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/"},{"categories":["系统架构"],"content":"4.3 Go的RPC实现 在Go中，实现RPC需要定义请求和回复的结构体，并使用Go的RPC库来处理通信。下面是一个示例，展示了如何在Go中实现一个简单的键值存储服务器（key/value storage server），并使用RPC进行通信。 请求回复结构体 在键值存储服务器的示例中，我们定义了用于Put和Get操作的请求和回复结构体： type PutArgs struct { Key string Value string } type PutReply struct { } type GetArgs struct { Key string } type GetReply struct { Value string } 服务器端（Server） 在服务器端，首先需要定义一个对象，并在该对象上注册处理函数作为RPC处理程序。这些处理函数将处理客户端发送的RPC请求。服务器接受TCP连接并将其传递给RPC库。RPC库负责读取每个请求，并为每个请求创建一个新的Goroutine进行处理。处理函数会读取请求参数，并根据请求调用相应的方法。处理完请求后，服务器将回复信息进行序列化，并通过TCP连接发送回客户端。服务器端的处理函数必须使用锁进行同步，因为RPC库为每个请求创建了一个新的Goroutine。处理函数需要读取请求参数并修改回复信息，因此需要确保并发访问的安全性。 type KV struct { mu sync.Mutex // 互斥锁，保护数据并发访问 data map[string]string } func server() { kv := \u0026KV{data: map[string]string{}} // 创建键值存储服务器实例 rpcs := rpc.NewServer() // 创建一个 RPC 服务器 rpcs.Register(kv) // 注册 kv 为 RPC 服务器的服务对象 l, e := net.Listen(\"tcp\", \":1234\") // 监听 TCP 端口 1234 if e != nil { log.Fatal(\"listen error:\", e) } go func() { // 启动一个协程来处理客户端连接 for { conn, err := l.Accept() // 接受客户端连接 if err == nil { go rpcs.ServeConn(conn) // 启动一个协程来为客户端提供服务 } else { break } } l.Close() // 关闭监听器 }() } // Get 方法用于处理客户端发送的 Get 请求，获取指定键的值。 func (kv *KV) Get(args *GetArgs, reply *GetReply) error { kv.mu.Lock() defer kv.mu.Unlock() reply.Value = kv.data[args.Key] return nil } // Put 方法用于处理客户端发送的 Put 请求，存储键值对。 func (kv *KV) Put(args *PutArgs, reply *PutReply) error { kv.mu.Lock() defer kv.mu.Unlock() kv.data[args.Key] = args.Value return nil } 客户端（Client） 在客户端，首先需要使用Dial函数建立与服务器的TCP连接。然后，客户端需要定义RPC请求的参数结构体和回复结构体，并实现对应的处理函数。客户端通过调用Call函数发起RPC调用，指定连接、函数名称、参数以及存放回复的位置。RPC库负责对参数进行序列化，并将请求发送给服务器。然后，客户端等待并接收服务器的回复，并将回复反序列化为指定的回复结构体。Call函数的返回值指示是否成功接收到了回复，通常还包括服务级别的错误信息。 // connect 函数用于与键值存储服务器建立连接，并返回一个 RPC 客户端对象。 func connect() *rpc.Client { client, err := rpc.Dial(\"tcp\", \":1234\") // 使用 TCP 协议连接服务器 if err != nil { log.Fatal(\"dialing:\", err) // 如果连接失败，则记录错误并终止程序 } return client } func get(key string) string { client := connect() // 建立连接 args := GetArgs{key} // 构造 Get 请求的参数 reply := GetReply{} // 准备接收服务器的响应 err := client.Call(\"KV.Get\", \u0026args, \u0026reply) // 调用远程方法 Get，并传递参数 args，将响应写入 reply if err != nil { log.Fatal(\"error:\", err) } client.Close() // 关闭连接 return reply.Value // 返回服务器返回的值 } // put 函数用于向键值存储服务器发送 Put 请求，存储键值对。 func put(key string, val string) { client := connect() args := PutArgs{key, val} reply := PutReply{} err := client.Call(\"KV.Put\", \u0026args, \u0026reply) if err != nil { log.Fatal(\"error:\", err) } client.Close() } 其他细节： 绑定（Binding）：客户端如何知道要与哪台服务器通信？ 在Go的RPC中，服务器的名称和端口是Dial函数的参数。在大型系统中，通常会有一种名称或配置服务器来管理这些信息。 序列化（Marshalling）：数据格式化为数据包。Go的RPC库可以传递字符串、数组、对象、映射等类型的数据。Go通过复制指向的数据来传递指针，但不能传递通道或函数。RPC库只序列化导出字段（即大写字母开头的字段）。 ","date":"2024-05-15","objectID":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/:4:3","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】使用Go进行线程和RPC编程","uri":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/"},{"categories":["系统架构"],"content":"4.4 处理RPC中的失败 在分布式系统中，网络故障和服务器故障是不可避免的。简单的解决方案是“尽力而为”的RPC，即在超时后重试请求，但这可能导致重复操作。 这种方法的缺点是，重试请求可能导致操作被重复执行。例如： client.Put(\"k\", 10) client.Put(\"k\", 20) 如果第二个Put请求因网络故障重试多次，可能会导致不一致的结果： 更好的解决方案是“至多一次”的RPC，“至多一次”的RPC通过以下机制实现更可靠的行为： 客户端在未收到响应时重新发送请求。 服务器检测重复请求，并返回之前的响应，而不是重新执行处理函数。 为了检测重复请求，客户端在每个请求中包含一个唯一的ID（XID）。每个请求使用相同的 XID 重新发送服务器： if seen[xid] { reply = old[xid] } else { reply = handler() old[xid] = reply seen[xid] = true } 一些“至多一次”复杂性问题： 如果两个客户端使用相同的XID？ 解决方案：使用大随机数生成唯一ID。 如何避免seen[xid]表过大？ 每个客户端有一个唯一ID，使用序列号。 客户端在每次RPC中包含“已见到的最大回复”信息，类似于TCP序列号和确认号。 服务器崩溃和重启： 如果“至多一次”信息保存在内存中，服务器重启后将忘记这些信息，可能会接受重复请求。 解决方案：将重复检测信息写入磁盘，或使用复制服务器同步这些信息。 Go的RPC库是“至多一次”策略的简单实现： 打开TCP连接。 将请求写入TCP连接。 Go RPC从不重发请求，因此服务器不会看到重复请求。 如果未收到回复，Go RPC代码返回错误（可能是由于TCP超时）。 关于“恰好一次”的RPC “恰好一次”的RPC包括无限重试、重复检测和容错服务，这种方法更复杂，在实际系统中需要实现容错机制。 例如，lab 4中将探讨“恰好一次”RPC的实现。 ","date":"2024-05-15","objectID":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/:4:4","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】使用Go进行线程和RPC编程","uri":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/"},{"categories":["系统架构"],"content":"5 FAQ Go通道是如何工作的？Go如何确保它们在多个goroutines之间同步？ 可以在这里查看源码，尽管不易理解。高层次上，通道是一个包含缓冲区和锁的结构体。发送到通道涉及获取锁，等待（可能释放CPU）直到某个线程接收，并交付消息。接收涉及获取锁并等待发送者。可以使用Go的sync.Mutex和sync.Cond自己实现通道。 我使用通道唤醒另一个goroutine，通过在通道上发送一个虚拟的bool值。但如果另一个goroutine已经在运行（因此没有在通道上接收），发送goroutine会阻塞。我应该怎么做？ 尝试使用条件变量（Go的sync.Cond）而不是通道。条件变量非常适合通知可能（或可能不）等待某事的goroutines。由于通道是同步的，如果不确定通道另一端是否有goroutine在等待，使用通道会显得很尴尬。 如何让一个goroutine等待来自多个不同通道的输入？如果没有任何内容可读取，则尝试在任何一个通道上接收都会阻塞，从而阻止 goroutine 检查其他通道。 尝试为每个通道创建一个单独的goroutine，每个goroutine阻塞在其通道上。这不是总能实现，但在可行时通常是最简单的方法。否则，尝试使用Go的select。 什么时候应该使用sync.WaitGroup而不是通道？反之亦然？ WaitGroup用途较为特殊；它仅在等待一堆活动完成时有用。通道用途更广泛；例如，可以通过通道传递值。尽管比WaitGroup需要多写几行代码，但也可以使用通道等待多个goroutines。 如何创建一个通过互联网连接的Go通道？如何指定用于发送消息的协议？ Go通道仅在单个程序内工作；通道不能用于与其他程序或计算机通信。可以查看Go的RPC包，它允许你通过互联网与其他Go程序通信： https://golang.org/pkg/net/rpc/ 一些重要/有用的Go特定并发模式有哪些？ 这是一个关于该主题的幻灯片，由Go专家编写： https://talks.golang.org/2012/concurrency.slide 切片是如何实现的？ 切片是一个对象，包含指向数组的指针以及该数组的开始和结束索引。这种安排允许多个切片共享一个底层数组，每个切片可能暴露数组元素的不同范围。这里有一个更详细的讨论： https://blog.golang.org/go-slices-usage-and-internals Go切片比Go数组更灵活，因为数组的大小是其类型的一部分，而以切片作为参数的函数可以接受任何长度的切片。 什么时候使用同步RPC调用，什么时候使用异步RPC调用？ 大多数代码需要在继续执行前获得RPC回复；在这种情况下，使用同步RPC是合理的。但有时客户端希望启动许多并发RPC；在这种情况下，异步可能更好。或者客户端希望在等待RPC完成时做其他工作，可能是因为服务器很远（所以光速时间很高）或因为服务器可能不可达，从而RPC经历长时间的超时。我(Robert)从未在Go中使用异步RPC。当我想发送RPC但不必等待结果时，我创建一个goroutine，并让这个goroutine进行同步Call()。 开发人员在开始使用Go时常见的问题有哪些？ 以下是一些常见问题： - 未在并发访问时使用锁保护映射。使用Go的竞态检测器！ - 使用通道时的死锁。 - 在创建goroutine时未捕获变量。 - 泄漏的goroutines。 Go是否支持继承？（像Java/C++那样的“扩展”方式？） Go不支持C++风格的继承，但有接口和嵌入结构体，可以完成在C++中使用继承的许多事情。这是Go设计中备受争议的部分；可以搜索“golang generics”。 我对选择值接收器或指针接收器仍有些困惑。能否提供一些具体的实际例子说明我们应该选择哪一个？ 当你想修改接收器的状态时，必须使用指针接收器。如果结构体非常大，你可能想使用指针接收器，因为值接收器操作的是一个副本。如果两者都不适用，可以使用值接收器。然而，要小心使用值接收器；例如，如果结构体中有一个互斥锁，你不能将其作为值接收器，因为互斥锁会被复制，从而失去其作用。 ","date":"2024-05-15","objectID":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/:5:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】使用Go进行线程和RPC编程","uri":"/posts/02.%E4%BD%BF%E7%94%A8go%E8%BF%9B%E8%A1%8C%E7%BA%BF%E7%A8%8B%E5%92%8Crpc%E7%BC%96%E7%A8%8B/"},{"categories":["系统架构"],"content":"1 实验要求 在本次 Lab 中，你将在单机上构建一个键/值服务器，以确保即使网络出现故障，每个操作也只能执行一次，并且操作是可线性化的。 客户端可以向键/值服务器发送三个不同的 RPC： Put(key, value) 、 Append(key, arg) 和 Get(key) 。服务器在内存中维护键/值对的map。键和值是字符串。 Put(key, value) 设置或替换map中给定键的值， Append(key, arg) 将 arg 附加到键的值并返回旧值， Get(key) 获取键的当前值。不存在的键的 Get请求应返回空字符串；对于不存在的键的 Append 请求应该表现为现有值是零长度字符串。每个客户端都通过Clerk的 Put/Append/Get 方法与服务器进行通信。 Clerk 管理与服务器的 RPC 交互。 你的服务器必须保证应用程序对Clerk Get/Put/Append 方法的调用是线性一致的。 如果客户端请求不是并发的，每个客户端 Get/Put/Append 调用时能够看到之前调用序列导致的状态变更。 对于并发的请求来说，返回的结果和最终状态都必须和这些操作顺序执行的结果一致。如果一些请求在时间上重叠，则它们是并发的：例如，如果客户端 X 调用 Clerk.Put() ，并且客户端 Y 调用 Clerk.Append() ，然后客户端 X 的调用 返回。 一个请求必须能够看到已完成的所有调用导致的状态变更。 一个应用实现线性一致性就像一台单机服务器一次处理一个请求的行为一样简单。 例如，如果一个客户端发起一个更新请求并从服务器获取了响应，随后从其他客户端发起的读操作可以保证能看到改更新的结果。在单台服务器上提供线性一致性是相对比较容易的。 Lab 在 src/kvsrv 中提供了框架代码和单元测试。你需要更改 kvsrv/client.go、kvsrv/server.go 和 kvsrv/common.go 文件。 ","date":"2024-05-15","objectID":"/posts/06.mit-6.58406.824-lab2-kv-server/:1:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824) 】Lab2:Key/Value Server 设计实现","uri":"/posts/06.mit-6.58406.824-lab2-kv-server/"},{"categories":["系统架构"],"content":"2 无网络故障的KV Server ","date":"2024-05-15","objectID":"/posts/06.mit-6.58406.824-lab2-kv-server/:2:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824) 】Lab2:Key/Value Server 设计实现","uri":"/posts/06.mit-6.58406.824-lab2-kv-server/"},{"categories":["系统架构"],"content":"2.1 任务要求 此任务需要实现一个在没有丢失消息的情况下有效的解决方案。你需要在 client.go 中，在 Clerk 的 Put/Append/Get 方法中添加 RPC 的发送代码；并且实现 server.go 中 Put、Append、Get 三个 RPC handler。 当你通过了前两个测试 case：one client、many clients 时表示完成该任务。 ","date":"2024-05-15","objectID":"/posts/06.mit-6.58406.824-lab2-kv-server/:2:1","tags":["分布式系统"],"title":"【MIT 6.5840(6.824) 】Lab2:Key/Value Server 设计实现","uri":"/posts/06.mit-6.58406.824-lab2-kv-server/"},{"categories":["系统架构"],"content":"2.2 设计实现 这个任务比较简单，我们只需要根据实验要求的逻辑进行实现即可。 server.go 使用map保存键值信息，三种操作都需要通过锁来保证互斥访问共享map。 func (kv *KVServer) Get(args *GetArgs, reply *GetReply) { kv.mu.Lock() defer kv.mu.Unlock() reply.Value = kv.data[args.Key] } func (kv *KVServer) Put(args *PutAppendArgs, reply *PutAppendReply) { kv.mu.Lock() defer kv.mu.Unlock() kv.data[args.Key] = args.Value } func (kv *KVServer) Append(args *PutAppendArgs, reply *PutAppendReply) { kv.mu.Lock() defer kv.mu.Unlock() oldValue := kv.data[args.Key] kv.data[args.Key] = oldValue + args.Value reply.Value = oldValue } client.go 只需要添加RPC的发送代码。 func (ck *Clerk) Get(key string) string { args := \u0026GetArgs{ Key: key, } reply := \u0026GetReply{} ck.server.Call(\"KVServer.Get\", args, reply) return reply.Value } func (ck *Clerk) PutAppend(key string, value string, op string) string { arg := \u0026PutAppendArgs{ Key: key, Value: value, } reply := \u0026PutAppendReply{} ck.server.Call(\"KVServer.\"+op, arg, reply) return reply.Value } func (ck *Clerk) Put(key string, value string) { ck.PutAppend(key, value, \"Put\") } ","date":"2024-05-15","objectID":"/posts/06.mit-6.58406.824-lab2-kv-server/:2:2","tags":["分布式系统"],"title":"【MIT 6.5840(6.824) 】Lab2:Key/Value Server 设计实现","uri":"/posts/06.mit-6.58406.824-lab2-kv-server/"},{"categories":["系统架构"],"content":"3 可能丢弃消息的KV Server ","date":"2024-05-15","objectID":"/posts/06.mit-6.58406.824-lab2-kv-server/:3:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824) 】Lab2:Key/Value Server 设计实现","uri":"/posts/06.mit-6.58406.824-lab2-kv-server/"},{"categories":["系统架构"],"content":"3.1 任务要求 现在，您应该修改您的解决方案，以便在遇到丢失的消息（例如 RPC 请求和 RPC 回复）时继续工作。如果消息丢失，则客户端的 ck.server.Call() 将返回 false （更准确地说， Call() 等待响应直至超市，如果在此时间内没有响应就返回false）。您将面临的一个问题是 Clerk 可能需要多次发送 RPC，直到成功为止。但是，每次调用 Clerk.Put() 或 Clerk.Append() 应该只会导致一次执行，因此您必须确保重新发送不会导致服务器执行请求两次。 你的任务是在 Clerk 中添加重试逻辑，并且在 server.go 中来过滤重复请求。 Hint 您需要唯一地标识client操作，以确保KV Server仅执行每个操作一次。 您必须仔细考虑server必须维持什么状态来处理重复的 Get() 、 Put() 和 Append() 请求（如果有的话）。 您的重复检测方案应该快速释放服务器内存，例如让每个 RPC 暗示client已看到其前一个 RPC 的回复。可以假设client一次只向Clerk发起一次调用。 ","date":"2024-05-15","objectID":"/posts/06.mit-6.58406.824-lab2-kv-server/:3:1","tags":["分布式系统"],"title":"【MIT 6.5840(6.824) 】Lab2:Key/Value Server 设计实现","uri":"/posts/06.mit-6.58406.824-lab2-kv-server/"},{"categories":["系统架构"],"content":"3.2 方案设计 根据提示，我们可以为Put和Append消息添加标识ID（Get消息只需不断重试，不会有影响），这里我们还需要用到sync.Map用于在键/值服务器中跟踪处理过的请求ID，以防止重复处理请求。每当服务器接收到一个新的RPC请求时，它会检查请求ID是否已存在于sync.Map中。如果存在，则表明该请求已经处理过，服务器可以跳过重复的处理，直接返回之前处理过的值。否则，服务器会记录该请求ID处理请求，并将回复结果记录。这种机制确保了操作的幂等性，避免了由于网络故障或重试机制导致的重复执行。 当然，还需要考虑一个问题，就是服务器会不断积压处理过的请求ID信息，所以我们需要快速释放服务器内存，即让Client通知Server这个任务操作已经完成，删除相关的记录信息。故我们还需要给消息结构添加一个Type字段标识为Modify还是Report。 整个流程图如下所示： ","date":"2024-05-15","objectID":"/posts/06.mit-6.58406.824-lab2-kv-server/:3:2","tags":["分布式系统"],"title":"【MIT 6.5840(6.824) 】Lab2:Key/Value Server 设计实现","uri":"/posts/06.mit-6.58406.824-lab2-kv-server/"},{"categories":["系统架构"],"content":"3.3 代码实现 实验代码实现仓库：https://github.com/unique-pure/MIT6.5840/tree/main/src/kvsrv，实验代码已通过实验测试。 common.go type MessageType int const ( Modify = iota Report ) // Put or Append type PutAppendArgs struct { Key string Value string MessageType MessageType // Modify or Report MessageID int64 // Unique ID for each message } server.go type KVServer struct { mu sync.Mutex data map[string]string record sync.Map } func (kv *KVServer) Get(args *GetArgs, reply *GetReply) { kv.mu.Lock() defer kv.mu.Unlock() reply.Value = kv.data[args.Key] } func (kv *KVServer) Put(args *PutAppendArgs, reply *PutAppendReply) { if args.MessageType == Report { kv.record.Delete(args.MessageID) } res, ok := kv.record.Load(args.MessageID) if ok { reply.Value = res.(string) // 重复请求，返回之前的结果 return } kv.mu.Lock() old := kv.data[args.Key] kv.data[args.Key] = args.Value reply.Value = old kv.mu.Unlock() kv.record.Store(args.MessageID, old) // 记录请求 } func (kv *KVServer) Append(args *PutAppendArgs, reply *PutAppendReply) { if args.MessageType == Report { kv.record.Delete(args.MessageID) } res, ok := kv.record.Load(args.MessageID) if ok { reply.Value = res.(string) // 重复请求，返回之前的结果 return } kv.mu.Lock() old := kv.data[args.Key] kv.data[args.Key] = old + args.Value reply.Value = old kv.mu.Unlock() kv.record.Store(args.MessageID, old) // 记录请求 } client.go func (ck *Clerk) Get(key string) string { args := \u0026GetArgs{ Key: key, } reply := \u0026GetReply{} for !ck.server.Call(\"KVServer.Get\", args, reply) { } // keep trying forever return reply.Value } func (ck *Clerk) PutAppend(key string, value string, op string) string { MessageID := nrand() arg := \u0026PutAppendArgs{ Key: key, Value: value, MessageID: MessageID, MessageType: Modify, } reply := \u0026PutAppendReply{} for !ck.server.Call(\"KVServer.\"+op, arg, reply) { } arg = \u0026PutAppendArgs{ MessageType: Report, MessageID: MessageID, } for !ck.server.Call(\"KVServer.\"+op, arg, reply) { } return reply.Value } ❯ go test Test: one client ... Passed -- t 3.3 nrpc 20037 ops 13359 Test: many clients ... ... Passed -- t 3.7 nrpc 85009 ops 56718 Test: unreliable net, many clients ... ... Passed -- t 3.3 nrpc 1161 ops 632 Test: concurrent append to same key, unreliable ... ... Passed -- t 0.4 nrpc 131 ops 52 Test: memory use get ... ... Passed -- t 0.6 nrpc 8 ops 0 Test: memory use put ... ... Passed -- t 0.3 nrpc 4 ops 0 Test: memory use append ... ... Passed -- t 0.5 nrpc 4 ops 0 Test: memory use many put clients ... ... Passed -- t 36.7 nrpc 200000 ops 0 Test: memory use many get client ... ... Passed -- t 22.6 nrpc 100002 ops 0 Test: memory use many appends ... 2024/05/15 12:48:26 m0 411000 m1 1550088 ... Passed -- t 2.6 nrpc 2000 ops 0 PASS ok 6.5840/kvsrv 75.329s ","date":"2024-05-15","objectID":"/posts/06.mit-6.58406.824-lab2-kv-server/:3:3","tags":["分布式系统"],"title":"【MIT 6.5840(6.824) 】Lab2:Key/Value Server 设计实现","uri":"/posts/06.mit-6.58406.824-lab2-kv-server/"},{"categories":["系统架构"],"content":"1 介绍 本次实验是实现一个简易版本的MapReduce，你需要实现一个工作程序（worker process）和一个调度程序（coordinator process）。工作程序用来调用Map和Reduce函数，并处理文件的读取和写入。调度程序用来协调工作任务并处理失败的任务。你将构建出跟 MapReduce论文 里描述的类似的东西。（注意：本实验中用\"coordinator\"替代里论文中的\"master\"。） 实验先决条件： 阅读MapReduce论文 阅读lab文档 理解MapReduce框架 理解原框架代码，理清所需完成任务 实验代码实现仓库：https://github.com/unique-pure/MIT6.5840/tree/main/src/mr，实验代码已通过实验测试，并在以下清单中列出了实现的功能及待办事项。 Complete the basic requirements for MapReduce Handling worker failures No data competition, a big lock ensures safety Pass lab test Communicate over TCP/IP and read/write files using a shared file system ","date":"2024-05-14","objectID":"/posts/05.mit-6.58406.824-lab1mapreduce-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/:1:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)】Lab1:MapReduce 设计实现","uri":"/posts/05.mit-6.58406.824-lab1mapreduce-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"2 原框架解析 src/mrapps/wc.go 这是一个用于 MapReduce 的字数统计（Word Count）插件。该插件包含 Map 和 Reduce 函数，用于统计输入文本中的单词频率。 func Map(filename string, contents string) []mr.KeyValue { // function to detect word separators. ff := func(r rune) bool { return !unicode.IsLetter(r) } // split contents into an array of words. words := strings.FieldsFunc(contents, ff) kva := []mr.KeyValue{} for _, w := range words { kv := mr.KeyValue{w, \"1\"} kva = append(kva, kv) } return kva } func Reduce(key string, values []string) string { // return the number of occurrences of this word. return strconv.Itoa(len(values)) } src/main/mrcoordinator.go mrcoordinator.go 定义了调度器（Coordinator）的主要逻辑。调度器通过 MakeCoordinator 启动一个 Coordinator 实例 c，并在 c.server() 中通过协程 go http.Serve(l, nil) 启动一个 HTTP 服务器来接收和处理 RPC 调用。 func (c *Coordinator) server() { rpc.Register(c) rpc.HandleHTTP() //l, e := net.Listen(\"tcp\", \":1234\") sockname := coordinatorSock() os.Remove(sockname) l, e := net.Listen(\"unix\", sockname) if e != nil { log.Fatal(\"listen error:\", e) } go http.Serve(l, nil) } func MakeCoordinator(files []string, nReduce int) *Coordinator { c := Coordinator{} c.server() return \u0026c } 注意：在 Go 的 net/http 包中，使用 http.Serve(l, nil) 启动 HTTP 服务器时，服务器会为每个传入的请求自动启动一个新的协程。这意味着每个 RPC 调用都是在独立的协程中处理的，从而允许并发处理多个请求。因此，在设计时可能需要使用锁等同步原语来保护共享资源。此外，Coordinator 不会主动与 Worker 通信（除非额外实现），只能通过 Worker 的 RPC 通信来完成任务。同时，当所有任务完成时，Done 方法将返回 false，从而关闭 Coordinator。 src/main/mrworker.go mrworker.go 通过 Worker 函数运行。因此，Worker 函数需要完成请求任务、执行任务、报告任务状态等多个任务。可以推测，Worker 需要在这个函数中不断地轮询 Coordinator，并根据 Coordinator 的不同回复来驱动当前 Worker 完成各种任务。 src/main/mrsequential.go mrsequential.go 实现了一个简单的顺序 MapReduce 应用程序。该程序读取输入文件，执行 Map 和 Reduce 操作，并将结果写入输出文件。 ","date":"2024-05-14","objectID":"/posts/05.mit-6.58406.824-lab1mapreduce-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/:2:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)】Lab1:MapReduce 设计实现","uri":"/posts/05.mit-6.58406.824-lab1mapreduce-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"3 设计实现 ","date":"2024-05-14","objectID":"/posts/05.mit-6.58406.824-lab1mapreduce-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/:3:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)】Lab1:MapReduce 设计实现","uri":"/posts/05.mit-6.58406.824-lab1mapreduce-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"3.1 任务分析 总体而言，Worker通过RPC轮询Coordinator请求任务，例如Map或者Reduce任务，Coordinator将剩余任务分配给Worker处理（先处理完Map任务才能处理Reduce任务）。 其中，在此实验中Map任务数量就是输入文件数量，每个Map Task的任务就是处理一个.txt文件；Reduce任务的数量是nReduce。 由于Map任务会将文件的内容分割为指定的nReduce份，每一份应当由序号标明，拥有这样的序号的多个Map任务的输出汇总起来就是对应的Reduce任务的输入。 请求完任务后，Worker需要根据任务类型进行处理，这段处理过程跟mrsequential.go基本一致，但需要注意的就是论文中提到的，如果同一个任务被多个Worker执行，针对同一个最终的输出文件将有多个重命名操作执行。我们这就依赖底层文件系统提供的重命名操作的原子性来保证最终的文件系统状态仅仅包含一个任务产生的数据。即通过os.Rename()。 处理完任务后，Worker通过RPC告知Coordinator任务结果。 所以，我们可以知道Coordinator管理着任务状态和任务分配，而无需记录Worker的信息，Worker实现任务处理。 整个任务流程如下图所示： MapReduce处理WordCount程序的流程如下图所示： ","date":"2024-05-14","objectID":"/posts/05.mit-6.58406.824-lab1mapreduce-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/:3:1","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)】Lab1:MapReduce 设计实现","uri":"/posts/05.mit-6.58406.824-lab1mapreduce-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"3.2 RPC 通信时首先需要确定这个消息是什么类型, 通过前述分析可知： 对于Worker发送消息，Worker需要跟Coordinator报告Map或Reduce任务的执行情况(成功或失败) type TaskCompletedStatus int const ( MapTaskCompleted = iota MapTaskFailed ReduceTaskCompleted ReduceTaskFailed ) 对于Coordinator回复消息，Coordinator需要分配Reduce或Map任务，告知任务的类型，或者告知Worker休眠（暂时没有任务需要执行）、Worker退出（所有任务执行成功） type TaskType int const ( MapTask = iota ReduceTask Wait Exit ) 同时，消息还需要附带额外的信息，我这里的设计是发送消息包含任务ID，以便Coordinator更新任务状态，结构如下： type MessageSend struct { TaskID int // task id TaskCompletedStatus TaskCompletedStatus // task completed status } 回复消息结构如下： type MessageReply struct { TaskID int // task id TaskType TaskType // task type, map or reduce or wait or exit TaskFile string // task file name NReduce int // reduce number, indicate the number of reduce tasks NMap int // map number, indicate the number of map tasks } 这些字段都是为了辅助Worker进行任务处理，如NMap是为了提供Map任务的数量，以便生成中间文件名，TaskFile是保存Map任务需要处理的输入文件。 对于通信，原框架已提供Unix套接字通信，如果有想法，我们可以将 RPC 设置为通过 TCP/IP 而不是 Unix 套接字进行通信（请参阅 Coordinator.server() 中注释掉的行），并使用共享文件系统读/写文件。 ","date":"2024-05-14","objectID":"/posts/05.mit-6.58406.824-lab1mapreduce-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/:3:2","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)】Lab1:MapReduce 设计实现","uri":"/posts/05.mit-6.58406.824-lab1mapreduce-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"3.3 Coordinator 3.3.1 结构 如前所述，Coordinator需要管理任务的状态信息，对于一个任务而言，我们这里定义它的状态为：未分配、已分配、完成、失败。 type TaskStatus int const ( Unassigned = iota Assigned Completed Failed ) 那么，任务结构应该包括任务状态，同时，如论文中提到的，可能有Worker成为落伍者，所以我们还需要考虑一个任务是否执行了很长时间还没结束，故这里需要记录任务分配时的时间戳，以便计算运行时间。另外，我们还需要一个字段来存储需要处理的任务文件名。故任务信息结构如下： type TaskInfo struct { TaskStatus TaskStatus // task status TaskFile string // task file TimeStamp time.Time // time stamp, indicating the running time of the task } 对于Coordinator结构，首先肯定是需要两个数据结构来存储所有的Map任务状态和Reduce任务状态，我这里使用的列表；然后由于是并发执行，更新共享任务状态数据，需要一把大锁保平安；最后需要一些额外变量存储任务数量（也可以直接len(list)）以及标志某阶段任务是否完成（如在Reduce任务进行之前Map任务是否已经完成）。 type Coordinator struct { NMap int // number of map tasks NReduce int // number of reduce tasks MapTasks []TaskInfo // map task ReduceTasks []TaskInfo // reduce task AllMapTaskCompleted bool // whether all map tasks have been completed AllReduceTaskCompleted bool // whether all reduce tasks have been completed Mutex sync.Mutex // mutex, used to protect the shared data } 3.3.2 初始化 我们需要对Coordinator初始化，其中最重要的是更新任务初始状态，一开始都是未分配， func (c *Coordinator) InitTask(file []string) { for idx := range file { c.MapTasks[idx] = TaskInfo{ TaskFile: file[idx], TaskStatus: Unassigned, TimeStamp: time.Now(), } } for idx := range c.ReduceTasks { c.ReduceTasks[idx] = TaskInfo{ TaskStatus: Unassigned, } } } func MakeCoordinator(files []string, nReduce int) *Coordinator { c := Coordinator{ NReduce: nReduce, NMap: len(files), MapTasks: make([]TaskInfo, len(files)), ReduceTasks: make([]TaskInfo, nReduce), AllMapTaskCompleted: false, AllReduceTaskCompleted: false, Mutex: sync.Mutex{}, } c.InitTask(files) c.server() return \u0026c } 3.3.3 RequestTask函数 这部分比较复杂，根据我们之前的分析，处理逻辑如下： 如果有未分配的任务、之前执行失败、已分配但已经超时（10s）的Map任务，则选择这个任务进行分配； 如果以上的Map任务均不存在，但Map又没有全部执行完成，告知Worker先等待； Map任务全部执行完成的情况下，按照1和2相同的逻辑进行Reduce任务的分配； 所有的任务都执行完成了, 告知Worker退出。 因此，处理代码如下： func (c *Coordinator) RequestTask(args *MessageSend, reply *MessageReply) error { // lock c.Mutex.Lock() defer c.Mutex.Unlock() // assign map task if !c.AllMapTaskCompleted { // count the number of completed map tasks NMapTaskCompleted := 0 for idx, taskInfo := range c.MapTasks { if taskInfo.TaskStatus == Unassigned || taskInfo.TaskStatus == Failed || (taskInfo.TaskStatus == Assigned \u0026\u0026 time.Since(taskInfo.TimeStamp) \u003e 10*time.Second) { reply.TaskFile = taskInfo.TaskFile reply.TaskID = idx reply.TaskType = MapTask reply.NReduce = c.NReduce reply.NMap = c.NMap c.MapTasks[idx].TaskStatus = Assigned // mark the task as assigned c.MapTasks[idx].TimeStamp = time.Now() // update the time stamp return nil } else if taskInfo.TaskStatus == Completed { NMapTaskCompleted++ } } // check if all map tasks have been completed if NMapTaskCompleted == len(c.MapTasks) { c.AllMapTaskCompleted = true } else { reply.TaskType = Wait return nil } } // assign reduce task if !c.AllReduceTaskCompleted { // count the number of completed reduce tasks NReduceTaskCompleted := 0 for idx, taskInfo := range c.ReduceTasks { if taskInfo.TaskStatus == Unassigned || taskInfo.TaskStatus == Failed || (taskInfo.TaskStatus == Assigned \u0026\u0026 time.Since(taskInfo.TimeStamp) \u003e 10*time.Second) { reply.TaskID = idx reply.TaskType = ReduceTask reply.NReduce = c.NReduce reply.NMap = c.NMap c.ReduceTasks[idx].TaskStatus = Assigned // mark the task as assigned c.ReduceTasks[idx].TimeStamp = time.Now() // update the time stamp return nil } else if taskInfo.TaskStatus == Completed { NReduceTaskCompleted++ } } // check if all reduce tasks have been completed if NReduceTaskCompleted == len(c.ReduceTasks) { c.AllReduceTaskCompleted = true } else { reply.TaskType = Wait return nil } } // all tasks have been completed reply.TaskType = Exit return nil } 3.3.4 ReportTask函数 这个函数则是根据Worker发送的消息任务完成状态来更新任务状态信息即可，记住，一把大锁保平安。 func (c *Coordinator) ReportTask(args *MessageSend, reply *MessageReply) error { c.Mutex.Lock() defer c.Mutex.Unlock() if args.TaskCompletedStatus == MapTaskCompleted { c.MapTasks[args.TaskID].TaskStatus = Completed return nil } else if args.TaskC","date":"2024-05-14","objectID":"/posts/05.mit-6.58406.824-lab1mapreduce-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/:3:3","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)】Lab1:MapReduce 设计实现","uri":"/posts/05.mit-6.58406.824-lab1mapreduce-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"3.4 Worker 3.4.1 Worker轮询 Worker需要通过RPC轮询Coordinator请求任务，然后根据返回的任务类型进行处理（即调用相应函数）： func Worker(mapf func(string, string) []KeyValue, reducef func(string, []string) string) { for { args := MessageSend{} reply := MessageReply{} call(\"Coordinator.RequestTask\", \u0026args, \u0026reply) switch reply.TaskType { case MapTask: HandleMapTask(\u0026reply, mapf) case ReduceTask: HandleReduceTask(\u0026reply, reducef) case Wait: time.Sleep(1 * time.Second) case Exit: os.Exit(0) default: time.Sleep(1 * time.Second) } } } 3.4.2 处理Map任务 跟mrsequential.go处理基本一致，处理完成后需要通过RPC告知Coordinator结果。但需要注意的是，我们需要通过os.Rename()原子重命名来保证最终的文件系统状态仅仅包含一个任务产生的数据。 func HandleMapTask(reply *MessageReply, mapf func(string, string) []KeyValue) { // open the file file, err := os.Open(reply.TaskFile) if err != nil { log.Fatalf(\"cannot open %v\", reply.TaskFile) return } // read the file, get the content content, err := io.ReadAll(file) if err != nil { log.Fatalf(\"cannot read %v\", reply.TaskFile) return } file.Close() // call the map function to get the key-value pairs kva := mapf(reply.TaskFile, string(content)) // create intermediate files intermediate := make([][]KeyValue, reply.NReduce) for _, kv := range kva { r := ihash(kv.Key) % reply.NReduce intermediate[r] = append(intermediate[r], kv) } // write the intermediate files for r, kva := range intermediate { oname := fmt.Sprintf(\"mr-%v-%v\", reply.TaskID, r) ofile, err := os.CreateTemp(\"\", oname) if err != nil { log.Fatalf(\"cannot create tempfile %v\", oname) } enc := json.NewEncoder(ofile) for _, kv := range kva { // write the key-value pairs to the intermediate file enc.Encode(kv) } ofile.Close() // Atomic file renaming：rename the tempfile to the final intermediate file os.Rename(ofile.Name(), oname) } // send the task completion message to the coordinator args := MessageSend{ TaskID: reply.TaskID, TaskCompletedStatus: MapTaskCompleted, } call(\"Coordinator.ReportTask\", \u0026args, \u0026MessageReply{}) } 3.4.3 处理Reduce任务 这里利用我们生成的中间文件名特点，对于每个Reduce任务，它的输入文件（中间文件）名为mr-MapID-ReduceID，所以我们构造出输入文件数组，将其解码得到键值对，再进行处理。 // generate the intermediate files for reduce tasks func generateFileName(r int, NMap int) []string { var fileName []string for TaskID := 0; TaskID \u003c NMap; TaskID++ { fileName = append(fileName, fmt.Sprintf(\"mr-%d-%d\", TaskID, r)) } return fileName } func HandleReduceTask(reply *MessageReply, reducef func(string, []string) string) { // load the intermediate files var intermediate []KeyValue // get the intermediate file names intermediateFiles := generateFileName(reply.TaskID, reply.NMap) // fmt.Println(intermediateFiles) for _, filename := range intermediateFiles { file, err := os.Open(filename) if err != nil { log.Fatalf(\"cannot open %v\", filename) return } // decode the intermediate file dec := json.NewDecoder(file) for { kv := KeyValue{} if err := dec.Decode(\u0026kv); err == io.EOF { break } intermediate = append(intermediate, kv) } file.Close() } // sort the intermediate key-value pairs by key sort.Slice(intermediate, func(i, j int) bool { return intermediate[i].Key \u003c intermediate[j].Key }) // write the key-value pairs to the output file oname := fmt.Sprintf(\"mr-out-%v\", reply.TaskID) ofile, err := os.Create(oname) if err != nil { log.Fatalf(\"cannot create %v\", oname) return } for i := 0; i \u003c len(intermediate); { j := i + 1 for j \u003c len(intermediate) \u0026\u0026 intermediate[j].Key == intermediate[i].Key { j++ } var values []string for k := i; k \u003c j; k++ { values = append(values, intermediate[k].Value) } // call the reduce function to get the output output := reducef(intermediate[i].Key, values) // write the key-value pairs to the output file fmt.Fprintf(ofile, \"%v %v\\n\", intermediate[i].Key, output) i = j } ofile.Close() // rename the output file to the final output file os.Rename(ofile.Name(), oname) // send the task completion message to the coordinator args := MessageSend{ TaskID: reply.TaskID, TaskCompletedStatus: ReduceTaskCompleted, } call(\"Coordinator.ReportTask\", \u0026args, \u0026MessageReply{}) } ","date":"2024-05-14","objectID":"/posts/05.mit-6.58406.824-lab1mapreduce-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/:3:4","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)】Lab1:MapReduce 设计实现","uri":"/posts/05.mit-6.58406.824-lab1mapreduce-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"4 测试和常见问题 test-mr.sh为测试脚本，也可以通过运行sh test-mr-many.sh n来运行$n$次测试。 ❯ bash test-mr.sh *** Starting wc test --- wc test: PASS *** Starting indexer test. --- indexer test: PASS *** Starting map parallelism test. --- map parallelism test: PASS *** Starting reduce parallelism test. --- reduce parallelism test: PASS *** Starting job count test. --- job count test: PASS *** Starting early exit test. --- early exit test: PASS *** Starting crash test. --- crash test: PASS *** PASSED ALL TESTS 常见的问题如下： 不能通过job-count测试 *** Starting job count test. --- map jobs ran incorrect number of times (10 != 8) --- job count test: FAIL 因为多次处理同一个任务，且任务没有异常。这是因为在分配任务后没有更新任务的状态，例如标记为已分配和记录当前时间戳。 ","date":"2024-05-14","objectID":"/posts/05.mit-6.58406.824-lab1mapreduce-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/:4:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)】Lab1:MapReduce 设计实现","uri":"/posts/05.mit-6.58406.824-lab1mapreduce-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"1 概念 当我们谈论分布式系统时，我们指的是一组通过网络连接的计算机，它们协同工作以完成某种共同的任务或目标。 在分布式系统中，通信是通过消息传递进行的。这意味着各个计算节点之间通过发送和接收消息来进行通信，而不是通过共享内存。这种消息传递模型使得分布式系统的设计和实现更为灵活，因为每个节点可以独立地运行，并通过消息传递来进行协作。 尽管消息传递模型具有很多优点，但也需要注意到它引入了一些复杂性。例如，需要考虑消息的传递延迟、顺序和可靠性等问题。因此，在设计分布式系统时，需要仔细考虑如何有效地管理消息传递，以确保系统的正确性和性能。 TIP：在设计系统或解决问题时，应该始终优先考虑在单台计算机上解决。只有在问题规模超出单台计算机的处理能力，或者需要满足高可用性、容错性等需求时，才需要考虑采用分布式系统。因此，深入了解问题的性质和需求，以及权衡利弊，是设计分布式系统的关键。 ","date":"2024-05-14","objectID":"/posts/01.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:1:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】 分布式系统介绍","uri":"/posts/01.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["系统架构"],"content":"2 驱动力和挑战 当人们构建分布式系统时，驱动力主要包括以下几个方面： 追求更高的计算性能：分布式系统能够利用大量的计算资源，实现并行运算，充分利用多个CPU、大容量内存和磁盘资源。 实现容错性：即使在其中一台计算机发生故障时，系统仍然能够保持正常运行。 解决空间分布性问题：某些问题天然具有空间分布性，需要跨越不同地理位置的计算资源和数据进行协同处理。例如，银行跨地域的资金转移需要协调不同地点的数据和操作，这就需要分布式系统来实现数据的同步和协调，以确保交易的准确性和可靠性。 提高安全性：分布式系统可以通过将系统分散在多个计算机上来提高安全性。不信任的代码或系统可能存在潜在的安全风险，通过在分布式环境中运行代码并采用加密通信等安全措施，可以有效降低风险，并限制错误和攻击的影响范围。 分布式系统的挑战源自其驱动力： 并发执行和复杂交互：分布式系统中存在大量并发执行的部分，以及复杂的交互关系。这导致了在并发编程中遇到各种问题，例如同步、异步操作的管理以及处理时间依赖性。 意外故障：分布式系统由多个组成部分和计算机网络组成，因此容易受到意外故障的影响。与单个计算机不同，这些组件可能在工作或停止状态之间切换，同时还受到网络中断或不稳定性的影响。 性能预期：分布式系统的设计旨在实现更高的性能，例如利用大量计算资源实现并行处理。但实际评估多台计算机或磁盘臂的性能存在一定挑战，需要仔细的设计和调整以实现预期的性能水平。 ","date":"2024-05-14","objectID":"/posts/01.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:2:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】 分布式系统介绍","uri":"/posts/01.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["系统架构"],"content":"3 抽象和实现工具 分布式系统基础架构主要包括存储、通信（网络）和计算这三种类型。我们的目标是设计简单的接口，使第三方应用程序能够轻松使用这些分布式存储和计算功能，这样才能简单的在这些基础架构之上，构建第三方应用程序。 通过这种抽象接口，我们可以将分布式系统的复杂性隐藏在系统内部，使用户专注于应用程序的开发。举例来说，在存储方面，用户可以将整个系统视为非分布式系统，类似于一个文件系统或者常规的编程模型，而不必担心分布式系统的细节。我们的目标是构建一个接口，使其看起来像一个非分布式存储和计算系统，但实际上却具备了分布式系统的高性能和容错性。 但实际上，很难能找到一个抽象来描述分布式的存储或者计算，使得它们能够像非分布式系统一样有简单易懂的接口。 抽象的实际实现是我们首先要考虑的问题。在构建分布式系统时，人们使用了许多工具： RPC（Remote Procedure Call）：RPC旨在掩盖在不可靠网络上通信的复杂性，使得远程调用过程更为简单直接。 线程：线程是一种重要的编程技术，可用于充分利用多核心计算机。它不仅仅是为了提高计算机的利用率，更重要的是提供了结构化的并发操作方式，简化了程序员对并发操作的处理。 分布式文件系统：分布式文件系统是分布式系统中常用的存储工具之一，它提供了分布式的数据存储和访问接口。通过分布式文件系统，可以实现数据的分布式存储和管理，从而支持大规模数据处理和分布式计算任务的执行。 ","date":"2024-05-14","objectID":"/posts/01.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:3:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】 分布式系统介绍","uri":"/posts/01.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["系统架构"],"content":"4 分布式系统特性 ","date":"2024-05-14","objectID":"/posts/01.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:4:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】 分布式系统介绍","uri":"/posts/01.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["系统架构"],"content":"4.1 可扩展性 分布式系统的主要特性是可扩展性（Scalability）。可扩展性指的是，增加计算资源后系统能够以相应的方式提高性能或吞吐量。举例来说，如果一台计算机能够解决一定量的问题，那么增加第二台计算机后，系统能够以更快的速度解决相同数量的问题，或者在相同时间内处理更多的问题。如果由两台计算机组成的系统能够实现两倍的性能或吞吐量，那就达到了可扩展性的标准。 这是一个极为强大的特性，因为只需花钱就可以购买计算机。如果构建的系统能够通过增加计算机数量来提高性能或吞吐量，那将是一个巨大的成就。相比之下，通过雇佣程序员来优化系统或应用更优的算法通常是一种昂贵的方法。我们希望通过增加计算机数量，从十台提升到一千台，来应对一百倍的流量。 例如在构建一个常规网站时，通常会有一个HTTP服务器、一些用户和浏览器以及基于Python或PHP的Web服务器，它们与数据库进行交互。 在初始阶段，一台计算机可以运行Web服务器和数据库，或者将Web服务器和数据库分别部署在两台计算机上。但是，当网站突然迎来数以亿计的用户登录请求时，单一服务器显然无法满足需求。 为了应对高流量，第一步是购买更多的Web服务器，并将用户分配到不同的服务器上。这样，不同的用户可以访问不同的Web服务器，但它们需要访问相同的数据，因此所有的Web服务器都需要与后端数据库通信。在这个阶段，通过添加更多的Web服务器来提高代码效率是一个有效的方法，前提是单个服务器不会给数据库带来过大的压力。 然而，可扩展性并非无限的。随着Web服务器数量的增加，数据库很可能成为性能的瓶颈。即使增加更多的Web服务器也无法解决问题。在某个临界点，系统中添加更多计算机将不再有效，而瓶颈将转移到其他地方，比如从Web服务器转移到数据库。 在这种情况下，必须进行一些重构工作。然而，重构一个单一的数据库是困难的，尽管可以将数据库拆分为多个来提高性能，但这需要大量的工作。 ","date":"2024-05-14","objectID":"/posts/01.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:4:1","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】 分布式系统介绍","uri":"/posts/01.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["系统架构"],"content":"4.2 可用性 在构建系统时，使用单台计算机往往具有较高的可靠性。单台计算机通常可以长时间稳定运行，这是因为计算机和操作系统都很可靠，而且电源也很稳定。然而，如果系统由数千台计算机构成，即使每台计算机都能稳定运行一年，每天也会有多台计算机发生故障。 因此，大型分布式系统面临的一个主要问题是放大一些罕见问题的影响。在这样的系统中，总会有一些机器故障、运行错误、执行缓慢或执行错误任务的情况发生。网络问题也是一个常见的挑战，比如网线踩断或交换机故障。这些小问题在大规模系统中会变成持续不断的问题。 因此，在设计系统时必须考虑系统的容错性，即使发生错误也要能够继续运行。同时，为了简化应用开发人员的工作，需要构建一个基础架构，能够尽可能屏蔽和掩盖错误。 容错有多种概念和表述方式，其中一个重要思想是可用性（Availability）。通过精心设计，系统可以在特定类型的错误发生时继续提供服务，就像没有错误一样。某些系统通过多副本的方式实现可用性。比如，构建一个有两个拷贝的多副本系统，其中一个故障了，另一个仍然可以正常运行。可用性意味着在特定的故障范围内，系统仍能提供服务。 另一种容错特性是自我可恢复性（Recoverability），即在出现问题后系统停止工作，不再响应请求，等待修复，然后恢复正常运行。 可恢复性是一个重要的需求，尽管它比可用性更弱。在故障发生到修复期间，系统将完全停止工作。但修复后，系统应能正确运行，因此可恢复性至关重要。对于可恢复的系统，通常需要采取一些措施，如将最新数据存储在磁盘中，以便在供电恢复后检索。甚至对于具备可用性的系统，在实际应用中，也需要具备可恢复性。 为了实现这些特性，有两个关键工具。 一个是非易失存储（Non-volatile storage），如硬盘或闪存，用于存储系统状态的checkpoint或日志。这样，即使出现电源故障，系统也能从存储中读取最新状态，并继续运行。 另一个重要工具是复制（Replication），即通过多副本系统实现容错。管理复制的多副本系统可能会面临同步偏移等问题，这在容错系统中是一个挑战。 ","date":"2024-05-14","objectID":"/posts/01.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:4:2","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】 分布式系统介绍","uri":"/posts/01.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["系统架构"],"content":"4.3 一致性 最后一个很重要的特性是一致性（Consistency）。一致性定义了操作的行为，特别是在分布式系统中。在分布式存储系统中，例如键值（KV）服务，put操作将一个值存储到一个键中，而get操作从键中获取值。在分布式系统中，多个副本可能存在不同版本的数据，因此一致性变得至关重要。 强一致性（Strong Consistency）要求get请求总是返回最近一次完成的put请求写入的值，这确保了数据的完全一致。然而，实现强一致性需要大量的通信和延迟。弱一致性（Weak Consistency）不保证get请求获取到最新的数据，但通常可以提供更高的性能。 因此，为了尽可能减少通信，特别是当副本相距很远时，人们会构建弱一致性系统，只需要更新最近的数据副本，并且只需要从最近的副本获取数据，并允许读取旧数据。当然，为了使弱一致性更具实际意义，人们会定义更多的规则。 ","date":"2024-05-14","objectID":"/posts/01.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:4:3","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】 分布式系统介绍","uri":"/posts/01.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["系统架构"],"content":"5 MapReduce论文阅读笔记 MapReduce论文阅读笔记 ","date":"2024-05-14","objectID":"/posts/01.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:5:0","tags":["分布式系统"],"title":"【MIT 6.5840(6.824)学习笔记】 分布式系统介绍","uri":"/posts/01.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["系统架构","论文阅读"],"content":"1 概念 MapReduce 是一种用于在大型集群上进行简化数据处理的编程模型和计算框架。它最初由 Google 公司设计用于解决大规模数据处理问题，后来被广泛应用于各种大数据处理场景。 MapReduce 模型的核心思想是将大规模的数据集分解成多个小的数据块，然后分配给集群中的多个计算节点进行并行处理，最终将结果合并成最终的输出。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:1:0","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"2 编程模型 MapReduce 编程模型由两个主要阶段组成：map 阶段和 reduce 阶段。 map 阶段：在 map 阶段，输入数据被分割成若干个数据块，并由不同的计算节点进行并行处理。每个计算节点都会执行用户定义的 map 函数，将输入数据转换为键值对的形式，并发出中间结果。 reduce 阶段：在 reduce 阶段，会将中间结果按照键进行分组，并由不同的计算节点进行并行处理。每个计算节点都会执行用户定义的 reduce 函数，对相同键的数据进行合并和处理，最终生成最终的输出结果。 对于用户(MapReduce的使用者)而言：MapReduce是一种抽象化的编程模型，它隐藏了分布式数据处理的细节，仅对外暴露map和reduce的抽象，用户来实现具体的map和reduce功能。MapReduce自身关注的是并行计算、容错、分布式数据、负载均衡等一系列问题，并且保证分布计算的结果和无错误的串形计算的结果一致。 形式化地说，由用户提供的 map 函数和 reduce 函数应有如下类型： $$ \\begin{align*} \\text{map} \u0026\\quad (k_1, v_1)\\quad\\quad\\quad\\rightarrow\\quad\\text{list}(k_2, v_2)\\ \\text{reduce} \u0026\\quad (k_2,\\text{list}(v_2))\\quad\\rightarrow\\quad\\text{list}(v_2) \\end{align*} $$ 其中，输入的 key 和 value 值与输出的 key 和 value 值在类型上推导的域不同。此外，中间结果 key 和 value 值与输出 key 和 value 值在类型上推导的域相同。 例如，计算一个大的文档集合中每个单词出现的次数，下面是伪代码段： map(String key, String value): // key: document name // value: document contents for each word w in value: EmitIntermediate(w, “1″); reduce(String key, Iterator values): // key: a word // values: a list of counts int result = 0; for each v in values: result += ParseInt(v); Emit(AsString(result)); map 函数输出文档中的每个词、以及这个词的出现次数(在这个简单的例子里就是 1)。reduce 函数把 map 函数产生的每一个特定的词的计数累加起来。 值得注意的是，在实际的实现中 MapReduce 框架使用 Iterator 来代表作为输入的集合，主要是为了避免集合过大，无法被完整地放入到内存中。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:2:0","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"3 实现 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:3:0","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"3.1 MapReduce执行流程 下图展示了MapReduce操作的全部流程。当用户调用 MapReduce 函数时，将发生下面的一 系列动作（下面的序号和图中的序号一一对应）： 用户程序首先调用的 MapReduce 库将输入文件分成 $M$ 个数据片度，每个数据片段的大小一般从 $16\\text{ MB}$ 到$64\\text{ MB}$(可以通过可选的参数来控制每个数据片段的大小)。然后用户程序在集群中创建大量的程序副本。 这些程序副本中的有一个特殊的程序—master。副本中其它的程序都是 worker 程序，由 master 分配 任务。有 $M$ 个 map 任务和 $R$ 个 reduce 任务将被分配，master 将一个 map 任务或 reduce 任务分配给一个空闲的 worker。 被分配了 map 任务的 worker 程序读取相关的输入数据片段，从输入的数据片段中解析出键值对，然后把键值对传递给用户自定义的 Map 函数，由 Map 函数生成并输出的中间结果键值对，并缓存在内存中。 缓存中的键值对通过分区函数（可由用户指定，默认为hasy(key) mod R）分成 $R$ 个区域，之后周期性的写入到本地磁盘上。缓存的键值对在本地磁盘上的存储位置将被回传给 master，由 master 负责把这些存储位置再传送给 reduce worker。 当 reduce worker 程序接收到 master 程序发来的数据存储位置信息后，使用 RPC 从 Map worker 所在主机的磁盘上读取这些缓存数据。当 reduce worker 读取了所有的中间数据后，通过对 key 进行排序后使得具有相同 key 值的数据聚合在一起。由于许多不同的 key 值会映射到相同的 reduce 任务上， 因此必须进行排序。如果中间数据太大无法在内存中完成排序，那么就要在外部进行排序。 reduce worker 程序遍历排序后的中间数据，对于每一个唯一的中间 key 值，reduce worker 程序将这 个 key 值和它相关的中间结果value 值的集合传递给用户自定义的 reduce 函数。reduce 函数的输出被追加到所属分区的输出文件。 当所有的 map 和 reduce 任务都完成之后，master 唤醒用户程序。在这个时候，在用户程序里的对 MapReduce 调用才返回。 在成功完成任务之后，MapReduce 的输出存放在 $R$ 个输出文件中（对应每个 reduce 任务产生一个输出文件，文件名由用户指定）。一般情况下，用户不需要将这 $R$ 个输出文件合并成一个文件—他们经常把这些文件作为另外一个 MapReduce 的输入，或者在另外一个可以处理多个分割文件的分布式应用中使用。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:3:1","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"3.2 master数据结构 master 持有一些数据结构，它存储每一个 map 和 reduce 任务的状态（空闲、工作中或完成)，以及 worker 机器(非空闲任务的机器)的标识。 master 就像一个数据管道，中间文件存储区域的位置信息通过这个管道从 map 传递到 reduce。因此， 对于每个已经完成的 map 任务，master 存储了 map 任务产生的 $R$ 个中间文件存储区域的大小和位置。当 map 任务完成时，master 接收到位置和大小的更新信息，这些信息被逐步递增的推送给那些正在工作的 reduce 任务。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:3:2","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"3.3 容错机制 3.3.1 worker故障 故障判定 master 周期性的 ping 每个 worker。如果在一个约定的时间范围内没有收到 worker 返回的信息，master 将 把这个 worker 标记为失效。 故障处理 正在运行：正在运行的 map 或 reduce 任务将被重新置为空闲状态，等待重新调度。 已完成：所有由这个故障的worker 完成的 map 任务也会被重设为初始的空闲状态，等待重新调度，因为该 worker 不可用也意味着存储在该 worker 本地磁盘上的中间结果也不可用了；已经完成的 reduce 任务的输出存储在全局文件系统（eg. Google File System）上，因此不需要重新执行。 当一个 map 任务首先被 worker A 执行，之后由于 worker A 故障了又被调度到 worker B 执行，这个“重新执行”的动作会被通知给所有执行 reduce 任务的 worker。任何还没有从 worker A 读取数据的 reduce 任务 将从 worker B读取数据。 3.3.2 master故障 一个简单的解决办法是让 master 周期性的将上面描述的master数据结构的写入磁盘，即检查点（checkpoint）。如果这个 master 任务失败了，可以从最后一个检查点（checkpoint）开始启动另一个 master 进程。 然而，由于只有一个 master 进程，master 失效后再恢复是比较麻烦的，因此现在的实现是如果 master 故障，就中止MapReduce 运算。用户可以检查到这个状态，并且可以根据需要重新执行 MapReduce 操作。 3.3.3 出现故障时的语义 当用户提供的 map 和 reduce 操作是输入确定性函数（即相同的输入产生相同的输出）时，MapReduce保证任何情况下的输出都和所有程序没有出现任何错误、顺序的执行产生的输出是一样的。 这依赖对 map 和 reduce 任务的输出是原子提交的来完成这个特性。 每个工作中的任务把它的输出写到私有的临时文件中。 每个 reduce 任务生成一个这样的文件，而每个 map 任务则生成 $R$ 个这样的文件（一 个 reduce 任务对应一个文件）。 当一个 map 任务完成的时，worker 发送一个包含 R 个临时文件名的完成消息给master。如果 master 从一个已经完成的 map 任务再次接收到到一个完成消息，master 将忽略这个消息；否 则，master 将这 $R$ 个文件的名字记录在数据结构里。 当 reduce 任务完成时，reduce worker 进程以原子的方式把临时文件重命名为最终的输出文件。如果同一个 reduce 任务在多台机器上执行，针对同一个最终的输出文件将有多个重命名操作执行。这就依赖底层文件系统提供的重命名操作的原子性来保证最终的文件系统状态仅仅包含一个 reduce任务产生的数据。 使用 MapReduce 模型的程序员可以很容易的理解他们程序的行为，因为我们绝大多数的 map 和 reduce 操作是确定性的，而且存在这样的一个事实：我们的语义（也可以理解为处理机制）等价于一个顺序的执行的操作。 当 map and/or reduce 操作是不确定性的时候，MapReduce提供虽然较弱但是依然合理的语义。当使用非确定操作的时候， 一个 reduce 任务 $R_1$ 的输出等价于一个非确定性程序顺序执行产生时的输出。但是，另一个 reduce 任务 $R_2$的输出也许符合一个不同的非确定程序顺序执行产生的 $R_2$ 的输出。 考虑 map 任务 $M$ 和 reduce 任务 $R_1$、$R_2$ 的情况。我们设定 $e(R_i)$是 $R_i$ 已经提交的执行过程（有且仅有一个这样的执行过程）。出现较弱语义是因为 $e(R_1)$可能读取了$M$ 一次执行产生的输出，而 $e(R_2)$可能读取了 $M$ 的另一次执行产生的输出。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:3:3","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"3.4 存储位置 核心思想：尽量把输入数据(由 GFS 管理)存储在集群中机器的本地磁盘上来节省网络带宽。 GFS 把每个文件按 64MB 一个 Block 分隔，每个 Block 保存 在多台机器上，环境中就存放了多份拷贝(一般是 3 个拷贝)。MapReduce 的 master 在调度 map 任务时会考虑输入文件的位置信息，尽量将一个 map 任务调度在包含相关输入数据拷贝的机器上执行； 如果上述努力失败 了，master 将尝试在保存有输入数据拷贝的机器附近的机器上执行 map 任务(例如，分配到一个和包含输入数据的机器在一个 switch 里的 worker 机器上执行)。当在一个足够大的 cluster 集群上运行大型 MapReduce 操作的时候，大部分的输入数据都能从本地机器读取，因此消耗非常少的网络带宽。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:3:4","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"3.5 任务粒度 理想情况下，$M$ 和 $R$ 应当比集群中 worker 的机器数量要多得多。在每台 worker 机器都执行大量的不同任务能够提高集群的动态的负载均衡能力，并且能够加快故障恢复的速度：失效机器上执行的大量 map 任务都可以分布到所有其他的 worker 机器上去执行。 但是实际上，在具体实现中对 $M$ 和 $R$ 的取值都有一定的客观限制，因为 master 必须执行 $O(M+R) $次调度，并且在内存中保存 $O(M\\times R)$个状态（对影响内存使用的因素还是比较小的：$O(M\\times R)$块状态，大概每对 map 任务/reduce 任务 1 个字节就可以了）。 更进一步，$R$ 值通常是由用户指定的，因为每个 reduce 任务最终都会生成一个独立的输出文件。实际使用时我们也倾向于选择合适的 $M$ 值，以使得每一个独立任务都是处理大约 16M 到 64M 的输入数据（这样， 上面描写的输入数据本地存储优化策略才最有效），另外，我们把 $R$ 值设置为我们想使用的 worker 机器数量的小的倍数。 所以我们通常会用这样的比例来执行 MapReduce：$M=200000$，$R=5000$，使用 $2000$ 台 worker 机器。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:3:5","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"3.6 备用任务 如果集群中有某个 worker 花了特别长的时间来完成最后的几个 map 或 reduce 任务，整个 MapReduce 计算任务的耗时就会因此被拖长，这样的 worker 也就成了落后者（Straggler）。 因此，论文提出一个通用的机制来减少“落伍者”出现的情况。当一个 MapReduce 操作接近完成的时候，master 会调度备用（backup）任务进程来执行剩下的、处于处理中状态（in-progress）的任务。无论是最初的执行、还是备用（backup）任务进程完成了任务，我们都把这个任务标记成为已经完成。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:3:6","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"4 扩展技巧 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:4:0","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"4.1 分区函数 MapReduce 的使用者通常会指定 reduce 任务和 reduce 任务输出文件的数量（$R$）。我们在中间结果key 上使用分区函数来对数据进行分区，之后再输入到后续任务执行进程。 一个缺省的分区函数是使用 hash 方法(比如， hash(key) mod R)进行分区。hash 方法能产生非常平衡的分区。然而，有的时候，其它的一些分区函数对 key 值进行的分区将非常有用。 比如，输出的 key 值是 URLs，我们希望每个主机的所有条目保持在同一个输出文件中。为了支持类似的情况，MapReduce库的用户需要提供专门的分区函数。例如，使用hash(Hostname(urlkey)) mod R作为分区函数就可以把所有来自同一个主机的 URLs 保存在同一个输出文件中。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:4:1","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"4.2 顺序保证 在给定的分区$R$中，MapReduce保证所有中间键值对数据的处理顺序是按照 key 值增量顺序处理的。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:4:2","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"4.3 Combiner函数 在某些情况下，map 函数产生的中间 key 值的重复数据会占很大的比重，并且，用户自定义的 reduce 函数满足结合律和交换律。词数统计程序是个很好的例子。由于词频率倾向于一个 zipf 分布，每个 map 任务将产生成千上万个这样的记录。所有的这些记录将通过网络被发送到一个单独的 reduce 任务，然后由这个reduce 任务把所有这些记录累加起来产生一个数字。 MapReduce允许用户指定一个可选的 combiner 函数，combiner 函数首先在本地将这些记录进行一次合并，然后将合并的结果再通过网络发送出 去。 combiner 函数在每台执行 Map 任务的机器上都会被执行一次。一般情况下，combiner 和 reduce 函数是 一样的。combiner 函数和 Reduce 函数之间唯一的区别是 MapReduce 库怎样控制函数的输出。 reduce 函数的输出被保存在最终的输出文件里，而 combiner 函数的输出被写到中间文件里，然后被发送给 reduce 任务。 部分的合并中间结果可以显著的提高一些 MapReduce 操作的速度。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:4:3","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"4.4 输入和输出的类型 MapReduce库支持几种不同的格式的输入数据。比如文本模式中，key是文件的偏移量，value是该行内容。 程序员可以定义Reader接口来适应不同的输入类型，程序员需要保证必须能把输入数据切分成数据片段，且这些数据片段能够由单独的Map任务来处理就行了。Reader的数据源可能是数据库，可能是文本文件，甚至是内存等。 同样，用户采用类似添加新的输入数据类型的方式增加新的输出类型（定义Writer接口）。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:4:4","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"4.5 副作用 程序员在写map和/或reduce操作的时候，可能会因为方便，定义很多额外功能，比如增加辅助的输出文件等。但应当时刻记住，map和reduce操作应当保证原子性和幂等性。 比如，一个任务生成了多个输出文件，但是我们没有原子化多段commit的操作。这就需要程序员自己保证生成多个输出的任务是确定性任务。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:4:5","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"4.6 跳过损坏的记录 有时候，用户程序中的 bug 导致 map 或者 reduce 函数在处理某些记录的时候 crash 掉，MapReduce 操作 无法顺利完成。相较于修复无法执行的 Bug，跳过引发 Bug 的记录可能更为明智。因此，我们希望 MapReduce 检测哪些记录导致确定性的crash， 并且跳过这些记录不处理。 MapReduce 如何自动检测这种情况呢？首先，每个worker进程都设置了信号处理函数捕获内存段异常（segmentation violation）和总线错误（bus error）。 在执行 map 或者 reduce 操作之前，MapReduce 库通过全局变量保存记录序号。如果用户程序触发了一个系统信号，信号处理函数将用“最后一口气”通过 UDP 包向 master 发送处理的最后一条记录的序号。当 master 看到在处理某条特定记录不止失败一次时，master 就标志这条记录需要被跳过，并且在下次重新执行相关的map 或者 reduce 任务的时候跳过这条记录。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:4:6","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"4.7 本地执行 调试 map 和 reduce 函数的 bug 非常困难，因为它们在分布式系统中执行，并且通常跨多台计算机执行，由 master 动态调度。为了简化调试、性能分析和小规模测试，Google开发了本地版本的 MapReduce 库。这个本地版本可以让 MapReduce 操作在单台计算机上顺序执行。用户可以控制操作的执行，并且可以将其限制在特定的 map 任务上。通过设置特殊标志，用户可以在本地执行他们的程序，并且轻松使用本地调试和测试工具（如 gdb）。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:4:7","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"4.8 状态信息 在 master 内部，设有一个内置的 HTTP 服务器，用于展示一系列状态信息页面。这些页面会显示计算进度，例如已完成的任务数量、正在执行的任务数量、输入、中间数据和输出的字节数，以及处理速率等。 这些页面还包含了指向每个任务的stderr和stdout文件的链接。用户可以利用这些数据来预测计算完成所需的时间，以及是否需要增加更多资源。当计算花费的时间超过预期时，这些页面还可以帮助用户找出执行速度缓慢的原因。 另外，顶层状态页面还会显示出现故障的worker及其故障时正在执行的 map 和 reduce 任务。这些信息对于调试用户代码中的 bug 非常有帮助。 很多分布式系统架构都会提供可视化监控界面，这是提升分布式系统的可维护性的重要手段。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:4:8","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"4.9 计数器 MapReduce 库提供计数器机制，用来统计不同操作发生次数。比如，用户可能想统计已经处理了多少个单词、已经索引的多少篇 German 文档等等。 要想使用这个特性，用户需要创建Counter对象，然后在map和reduce函数中以正确的方式增加counter。这些计数器的值周期性的从各个单独的worker机器上传递给master（附加在ping的应答包中传递）。master 把执行成功的 map 和 reduce 任务的计数器值进行累计，当 MapReduce 操作完成之后，返回给用户代码。 计数器当前的值也会显示在 master 的状态页面上，这样用户就可以看到当前计算的进度。 当累加这些counter的值时，master会去掉那些重复执行的相同map或者reduce操作的次数，以此避免重复计数（之前提到的备用任务和故障后重新执行任务，这两种情况会导致相同的任务被多次执行）。 有些counter值是由MapReduce库自动维护的，例如已经处理过的输入键值对的数量以及生成的输出键值对的数量等等。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:4:9","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"5 应用场景 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:5:0","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"5.1 论文中提出的应用场景 分布式的 Grep：map 函数输出匹配某个模式的一行，reduce 函数是一个恒等函数，即把中间数据复制到输出。 计算 URL 访问频率：map 函数处理日志中 web 页面请求的记录，然后输出 (URL,1)。reduce 函数把相同 URL 的 value 值都累加起来，产生 (URL, 记录总数）结果。 倒转网络链接图：map 函数在源页面（source）中搜索所有的链接目标（target）并输出为(target,source)。 reduce 函数把给定链接目标（target）的链接组合成一个列表，输出(target,list(source))。 每个主机的检索词向量：检索词向量用一个(词,频率)列表来概述出现在文档或文档集中的最重要的一些词。map 函数为每一个输入文档输出(主机名,检索词向量)，其中主机名来自文档的 URL。reduce 函数接收给定主机的所有文档的检索词向量，并把这些检索词向量加在一起，丢弃掉低频的检索词，输出一个最终的(主机名,检索词向量)。 倒排索引：map 函数分析每个文档输出一个(词,文档号)的列表，reduce 函数的输入是一个给定词的所有 （词，文档号），排序所有的文档号，输出(词,list(文档号))。所有的输出集合形成一个简单的倒排索引，它以一种简单的算法跟踪词在文档中的位置。 分布式排序：map 函数从每个记录提取 key，输出(key,record)。reduce 函数不改变任何的值。这个运算依赖分区机制和排序属性。 重建索引系统：重写了 Google 网络搜索服务所使用的索引系统。这个索引系统的输入数据是网络爬虫抓取回来的大量文档，这些文档数据保存在 GFS 文件系统中，其原始内容超过了 20TB。通过一系列的 MapReduce 操作（大约 5 到 10 次），来建立索引。使用 MapReduce（替换上一个特别设计的、分布式处理的索引程序）带来这些好处： 简化的代码：索引部分的代码变得简单、小巧、易于理解； 灵活性：MapReduce 库的性能已经足够好，因此可以将概念上不相关的计算步骤分开处理，减少数据传递的额外开销； 操作管理的简化：因为由机器失效、机器处理速度缓慢、以及网络的瞬间阻塞等引起的绝大部分问题都已经由 MapReduce 库解决了，不再需要操作人员的介入了。另外，我们可以通过在索引系统集群中增加机器的简单方法提高整体处理性能。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:5:1","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"5.2 其他应用场景 数据清洗和预处理：MapReduce 可以用于处理大规模数据集的清洗和预处理，包括数据去重、数据过滤、数据格式转换等操作； 日志分析和异常检测：MapReduce 可以用于分析大规模日志数据，检测异常行为、故障事件和系统性能问题； 图算法和社交网络分析：MapReduce 可以应用于图算法和社交网络分析，包括图的遍历、最短路径计算、社区发现等操作； 文本挖掘和信息抽取：MapReduce 可以用于处理文本数据，进行信息抽取、实体识别、主题建模等自然语言处理任务。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:5:2","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"6 FAQ 当你调用emit时，数据会发生什么变化？emit函数在哪运行？ 首先看，这些函数在哪运行。这里可以看MapReduce论文的图1。现实中，MapReduce运行在大量的服务器之上，我们称之为worker服务器或者worker。同时，也会有一个Master节点来组织整个计算过程。这里实际发生的是，Master服务器知道有多少输入文件，例如5000个输入文件，之后它将Map函数分发到不同的worker。所以，它会向worker服务器发送一条消息说，请对这个输入文件执行Map函数吧。之后，MapReduce框架中的worker进程会读取文件的内容，调用Map函数并将文件名和文件内容作为参数传给Map函数。worker进程还需要实现emit，这样，每次Map函数调用emit，worker进程就会将数据写入到本地磁盘的文件中。所以，Map函数中调用emit的效果是在worker的本地磁盘上创建文件，这些文件包含了当前worker的Map函数生成的所有的key和value。 所以，Map阶段结束时，我们看到的就是Map函数在worker上生成的一些文件。之后，MapReduce的worker会将这些数据移动到Reduce所需要的位置。对于一个典型的大型运算，Reduce的入参包含了所有Map函数对于特定key的输出。通常来说，每个Map函数都可能生成大量key。所以通常来说，在运行Reduce函数之前。运行在MapReduce的worker服务器上的进程需要与集群中每一个其他服务器交互来询问说，看，我需要对key=a运行Reduce，请看一下你本地磁盘中存储的Map函数的中间输出，找出所有key=a，并通过网络将它们发给我。所以，Reduce worker需要从每一个worker获取特定key的实例。这是通过由Master通知到Reduce worker的一条指令来触发。一旦worker收集完所有的数据，它会调用Reduce函数，Reduce函数运算完了会调用自己的emit，这个emit与Map函数中的emit不一样，它会将输出写入到一个Google使用的共享文件服务中。 有关输入和输出文件的存放位置，这是我之前没有提到的，它们都存放在文件中，但是因为我们想要灵活的在任意的worker上读取任意的数据，这意味着我们需要某种网络文件系统（network file system）来存放输入数据。所以实际上，MapReduce论文谈到了GFS（Google File System）。GFS是一个共享文件服务，并且它也运行在MapReduce的worker集群的物理服务器上。GFS会自动拆分你存储的任何大文件，并且以64MB的块存储在多个服务器之上。所以，如果你有了10TB的网页数据，你只需要将它们写入到GFS，甚至你写入的时候是作为一个大文件写入的，GFS会自动将这个大文件拆分成64MB的块，并将这些块平均的分布在所有的GFS服务器之上，而这是极好的，这正是我们所需要的。如果我们接下来想要对刚刚那10TB的网页数据运行MapReduce Job，数据已经均匀的分割存储在所有的服务器上了。如果我们有1000台服务器，我们会启动1000个Map worker，每个Map worker会读取1/1000输入数据。这些Map worker可以并行的从1000个GFS文件服务器读取数据，并获取巨大的读取吞吐量，也就是1000台服务器能提供的吞吐量。 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:6:0","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"7 参考 paper:MapReduce MIT 6.824 知乎 【分布式】MapReduce论文笔记 知乎 Google MapReduce 论文详解 ","date":"2024-05-12","objectID":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/:7:0","tags":["分布式系统","MapReduce"],"title":"【论文阅读笔记】MapReduce: Simplified Data Processing on Large Clusters","uri":"/posts/01.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0mapreduce/"},{"categories":["系统架构","论文阅读"],"content":"1 简介 Google File System (GFS) 是一个可扩展的分布式文件系统，专为快速增长的Google数据处理需求而设计。这篇论文发表于2003年，此前已在Google内部大规模应用。 GFS不仅追求性能、可伸缩性、可靠性和可用性等传统分布式文件系统的设计目标，还基于对自身应用负载情况和技术环境的深入观察，提出了独特的设计思路，与早期文件系统的假设明显不同。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:1:0","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"2 设计概述 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:2:0","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"2.1 设计目标 GFS 在设计的时候有一些假想，即预期要实现的目标。 系统由许多廉价的普通组件组成，因此组件失效是一种常态。GFS必须能够持续监控自身的状态，将组件失效作为一种常态事件，并能够迅速侦测、冗余和恢复失效的组件。 系统能存储一定数量的大文件。Google预期会存储几百万个文件，这些文件通常大小在100MB以上，数GB大小的文件也是普遍存在的。系统必须能够高效管理这些大文件，同时，系统也必须支持小文件，但不需要针对小文件进行专门优化。 工作负载主要包括两类读操作： 大规模流式读取：单个读操作一般读几百 KB，更常见的是读 1MB 甚至更多。来自同一个客户端的连续操作通常是读取同一个文件中连续的一个区域。 小规模随机读取：一般是在文件的某个随机位置读几个 KB 数据。注重性能的应用程序通常会将小规模随机读取操作合并并排序，之后按顺序批量读取，避免在文件中前后移动读取位置。 系统的工作负载也会有很多大规模的、顺序的、数据追加方式的写操作。一般这种操作的大小和大规模读类似。一旦写入操作完成，这个文件很少会被修改。小规模的随机写也支持，但是不太高效。 系统必须高效的、行为定义明确的实现多客户端并行追加数据到同一个文件里的语意。GFS 中的文件通常用作“生产者—消费者”队列或其他多路文件合并操作。系统中通常有数百个生产者，每个机器上运行一个，这些生产者并发地追加修改一个文件，因此以最小的同步开销来实现原子性是必不可少的。这些文件可能随后被读取，也可能是消费者在追加的操作的同时读取文件。 高性能的稳定网络带宽远比低延迟重要。GFS 的大多数目标应用程序都重视以高速率的、大批量的处理数据，而很少有应用程序对单个读或写有严格的响应时间要求。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:2:1","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"2.2 接口 GFS 提供了一套类似传统文件系统的 API 接口函数，虽然并不是严格按照 POSIX 等标准 API 的形式实现的。文件以分层目录的形式组织，用路径名来标识。GFS 支持常用操作以创建(create)、删除(delete)、打开(open)、关闭(close)、读(read)和写(write)文件。 另外，GFS 提供了快照和记录追加操作。 快照以很低的成本创建一个文件或者目录树的拷贝。 记录追加操作允许多个客户端同时对一个文件进行数据追加操作，同时保证每个客户端的追加操作都是原子性的。这对于实现多路结果合并、“生产者-消费者”队列非常有用，多个客户端可以同时追加写入，而不需要额外的同步锁。Google 发现在构建大型分布式应用时，这些类型的文件是非常有用的。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:2:2","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"2.3 架构 一个 GFS 集群包含一个单独的master节点和多个chunk服务器，允许多个客户端访问，如下图所示。 所有这些机器通常是普通的 Linux 机器，运行用户级别的服务进程。可以将 chunkserver和客户端部署在同一台机器上，前提是机器资源允许，并能接受稳定性降低的风险。 其中GFS存储的文件都被分割成固定大小的chunk。在chunk 创建的时候，master会给每个 chunk 分 配一个不变的、全局唯一的 64 位的 chunk 句柄来标识。chunkserver把 chunk 以 Linux 文件的形式保存在本地硬盘上，并且根据指定的 chunk 句柄和字节范围来读写块数据。出于可靠性的考虑，每个chunk都会复制到多个chunk服务器上。默认使用3 个存储复制节点，不过用户可以为不同的文件命名空间设定不同的复制级别。 master节点管理所有的文件系统元数据。这些元数据包括命名空间、访问控制信息、文件和chunk 的映射信息、以及chunk当前的位置信息。Master 节点还管理着系统范围内的活动，比如，chunk 租用管理、孤儿 chunk的回收、以及 chunk 在 chunkserver之间的迁移。master 节点使用心跳信息周期地和每个 chunkserver通讯，发送指令到各个 chunkserver并接收 chunkserver的状态信息。 链接到每个应用程序的 GFS 客户端代码中实现了文件系统 API，这个 GFS 客户端代表应用程序与 master 和 chunk服务器通信以读写数据。客户端与 master 交互只进行元数据操作，所有的数据操作都是由客户端直接和 chunkserver进行交互的。GFS 没有提供 POSIX标准的API，因此不需要深入到 Linux 的 vnode 层。 客户端和 chunk服务器都不缓存文件数据。 客户端缓存文件数据几乎没什么好处，因为大多数应用程序通过巨大的文件进行流式传输，或者工作集太大而无法缓存。不缓存文件数据使得客户端代码和总体系统的代码得以简化，因为无需编写代码解决缓存一致性的问题（不过客户端是缓存元数据的）。 chunk服务器不需要缓存文件数据是因为 chunk 以本地文件的方式保存，Linux 操作系统的文件系统缓存会把经常访问的数据缓存在内存中。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:2:3","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"2.4 单个Master 单一的 Master 节点策略大大简化了系统设计。单一的 Master 节点能够通过全局信息精确定位 chunk 的位置，并做出复制决策。不过必须最小化在读写中 master 的调用次数，防止 master 成为 GFS 系统的性能瓶颈。客户端永远不通过 Master 节点直接读写文件数据，而是向 master 节点请求应联系的 chunkserver，并将这些元数据缓存一段时间，后续操作直接与 chunkserver进行。 以上图GFS架构为例，在一次简单读取操作中： 客户端将文件名和字节偏移量转换成文件的 chunk索引（chunk_index = offset / chunk_size），并将文件名和 chunk 索引发送给 master 节点。 master 节点返回相应的 chunk 句柄和副本的位置信息，客户端将这些信息缓存。 客户端将请求发送给一个副本，通常选择最近的副本，请求包含 chunk 句柄和字节范围。在后续对该 chunk 的读取操作中，客户端无需再次与 master 节点通讯，除非缓存的元数据信息过期或文件被重新打开。 客户端通常会在一次请求中查询多个 chunk 信息，master 节点的回复可能包含后续 chunk 的信息，这些额外信息在避免未来多次通讯的同时，不增加额外代价。这种设计保证了系统的高效性，减少了 master 节点的负担，提高了整体性能。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:2:4","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"2.5 chunk大小 chunk 的大小是 GFS 的关键设计参数之一，GFS 选择了 64MB 的 chunk 大小，这远大于一般文件系统的 block 大小。每个 chunk 的副本都以普通 Linux 文件的形式保存在 chunkserver上，并且只有在需要时才扩大，采用惰性空间分配策略避免了内部碎片造成的空间浪费。 将 chunk 设置为 64MB 这么大，有以下几个有点： 它减少了客户端和 master 节点之间的通信需求。因为一次与 master 节点通信即可获取 chunk 的位置信息，之后可以对同一个 chunk 进行多次读写操作。 较大的 chunk大小使客户端能够对同一个 chunk 进行多次操作，通过与 chunkserver保持较长时间的 TCP 连接来减少网络负载。 较大的 chunk大小减少了 master 节点需要保存的元数据数量，允许将所有元数据放在内存中，从而提高访问速度。 然而，较大的 chunk 大小也有缺点。小文件包含的 chunk 较少，甚至只有一个 chunk。当多个客户端频繁访问同一个小文件时，存储这些 chunk 的服务器容易成为热点。在实际应用中，这种情况较少发生，因为程序通常是连续读取包含多个 chunk 的大文件。 但将GFS应用于批处理队列系统中，热点问题曾经出现过：一个可执行文件保存在一个单一 chunk 中，当数百台机器同时启动这个文件时，存储这个 chunk 的服务器因并发请求导致系统局部过载。为解决这个问题，GFS通过增加可执行文件的复制参数和错开程序启动时间来缓解。此外，一个长效解决方案是允许客户端在这种情况下从其他客户端读取数据。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:2:5","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"2.6 元数据 master 中主要存储三种类型的元数据： 文件和 chunk 的命名空间； 文件和 chunk 的映射； 每个 chunk 的副本的位置。 所有的元数据都存储在 master 的内存里。前两种类型也会通过在操作日志(operation log)上记录修改来持久化，操作日志文件存储在 master 的本地磁盘上，同时日志会被复制到其它的远程master服务器上。使用日志使得我们能够简单可靠的更新 master 的状态，，而不用担心 master 崩溃导致的不一致性的风险。master 不会持久的存储 chunk 位置信息，而是会在 master 启动时或一个 chunkserver加入集群时向 chunkserver轮询其 chunk 信息。 2.6.1 内存中的数据结构 GFS 的设计将所有元数据保存在内存中，使 master 的操作速度非常快。这种设计允许 master 在后台简单而高效地周期性扫描所有状态信息，实现如 chunk 垃圾收集、在 chunkserver失效的时重新复制数据、通过 chunk 的迁移实现跨 chunkserver的负载均衡以及磁盘使用状况统计等功能。 虽然将元数据保存在内存中会使 chunk 的数量和系统的承载能力受限于 master 的内存大小，但在实际应用中，这并不是严重问题。具体而言，master 管理每个 64MB 的 chunk 只需不到 64字节的元数据。由于大多数文件包含多个 chunk，绝大多数chunk 都是满的，只有最后一个 chunk 可能部分填充。同样，每个文件在命名空间中的数据大小通常在 64 字节以下，因为文件名经过前缀压缩。 即便需要支持更大的文件系统，增加 master 的内存成本也相对较低。通过增加少量内存，可以使元数据全部保存在内存中，从而增强系统的简洁性、可靠性、高性能和灵活性。 2.6.2 chunk位置信息 master 不持久化存储哪个 chunkserver包含指定 chunk 副本的信息，master 只是在启动时会轮询 chunkserver以获取这些信息，并通过控制 chunk 位置分配和定期的心跳信息监控chunk服务器状态保持最新。 Google起初尝试将 chunk 位置信息持久化保存在 master 上，但发现启动时轮询 chunkserver并定期更新更为简便。这种设计简化了在 chunkserver加入、离开、更名、故障和重启时的数据同步问题，适应了大规模集群中频繁发生的事件。 这个设计的另一个理解思路：只有 chunkserver才能最终确定一个 chunk 是否在其硬盘上。在 master 上维护全局视图是不现实的，因为 chunkserver的错误可能导致 chunk 自动消失，或者操作人员可能重命名 chunkserver。这种方法确保了系统的简洁性和可靠性。 2.6.3 操作日志 操作日志包含关键的元数据变更历史记录，是元数据唯一的持久化存储和判断同步操作顺序的逻辑时间基线。每个文件和 chunk，还有它们的版本， 都由它们创建的逻辑时间唯一的、永久的标识。 日志文件必须确保完整性。只有在元数据变更被持久化后，日志才对客户端可见，以防止丢失文件系统或最近的客户端操作。为此，日志会被复制到多台远程机器，只有在本地和远程机器都写入日志后，master 才响应客户端请求。master 会收集多个日志记录后批量处理，以减少写入和复制对系统性能的影响。 在灾难恢复时，master 通过重演操作日志恢复文件系统。为了缩短启动时间，日志必须足够小。当日志增长到一定量时，master 会进行 checkpoint，将所有状态数据写入 checkpoint 文件。恢复时，master读取 Checkpoint 文件并重演之后的日志文件即可。Checkpoint 文件以压缩 B-树形式存储，可以直接映射到内存，在用于命名空间查询时无需额外的解析，提高了恢复速度和系统可用性。 创建 Checkpoint 文件时，master 确保不会阻塞正在进行的操作，通过独立线程切换到新的日志文件和创建新的 Checkpoint 文件。生成一个 Checkpoint 文件大约需要一分钟，完成后Checkpoint会被写入本地和远程硬盘。 master 恢复仅需最新的 Checkpoint 文件和后续日志文件。虽然旧的 Checkpoint 文件和日志文件可以删除，但通常会保留一些历史文件以应对灾难性故障。Checkpoint 失败不会对正确性产生任何影响，因为恢复功能的代码可以检测并跳过没有完成的 Checkpoint 文件（使用前一个完整的 Checkpoint 文件和之后的操作日志来恢复系统）。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:2:6","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"2.7 一致性模型 GFS 有一个宽松的一致性模型，很好地支持我们的高度分布式应用程序，但是实现起来依然简单且高效。 我们现在讨论 GFS 如何保证一致性，以及这对应用程序来说有何意义。我们也会强调 GFS 如何维护这些保证，但是更详细的内容将在本文的其他部分来说。 2.7.1 GFS一致性保障机制 文件命名空间的修改（例如，文件创建）是原子性的，且仅由 master 控制。命名空间锁保证了操作的原子性和正确性（详见4.1），而操作日志定义了这些操作的全局顺序（详见2.6.3）。 数据修改后的文件区域状态取决于操作类型、成功与否以及是否同步修改。下表总结了各种操作的结果。 如果所有客户端，无论从哪个副本读取，读到的数据都一样，那么我们认为文件区域是consistent； 如果对文件的数据修改之后，文件区域是一致的，并且客户端能够看到写入操作全部的内容，那么这个 region 是defined。 其中，对于一个文件区域，只要所有客户端看到的数据都是一样的，那这个区域就是 consistent 的。在 consistent 的前提下，如果所有修改都已经被写入，就是 defined 的。consistent 是 defined 的子集。即 defined 的一定是 consistent 的，但 consistent 的不一定是 defined 的。 当一个数据修改操作成功执行，并且没有受到同时执行的其它写入操作的干扰（即串行修改），那么受影响的区域就是 defined（隐含了 consistent ）：所有的客户端都可以看到写入的内容。 当多个并行修改操作成功完成后，文件区域处于consistent但undefined的状态：即所有的客户端看到的数据是一样的，但这并不意味着每个修改都已经被写入。一般来说，写入的内容由多个修改的混合片段组成。 失败的修改操作导致文件区域inconsistent (因此也是 undefined )：不同客户端在不同时间看到的数据不同。后面我们将描述应用如何区分 defined 和 undefined 的区域。应用程序没有必要再去细分 undefined 区域的不同类型。 数据修改操作分为写入或者记录追加两种： 写入操作：数据写在应用程序指定的文件偏移位置上。 记录追加操作：数据（记录）原子性追加到文件中至少一次（即使是并发修改），但偏移位置由 GFS 选择（3.3）。 作为对比，一个普通的追加操作仅仅是一个在客户端认为是当前文件末尾的偏移处的写入操作。GFS 返回给客户端一个偏移量，表示包含写入记录的 defined 区域的起点。另外，GFS 可能会在文件中间插入填充数据或者重复记录。这些数据占据的文件区域被认定是 inconsistent（即上表 中的 defined interspersed with inconsistent，即 defined 区域中穿插了 inconsistent 区域，但这些区域不会影响读取数据的结果，因为会被过滤掉）， 这些数据通常比用户数据小的多。 经过一系列成功的修改操作后，GFS 确保被修改的文件区域是defined的，并包含最后一次修改操作写入的数据。GFS 通过以下措施确保这一点： 对chunk的所有副本的修改操作顺序一致。 使用 chunk 版本号检测副本是否因其所在的 chunkserver宕机而错过了修改操作导致失效。失效的副本不再进行修改操作，master 也不会返回该副本的位置信息给客户端，失效副本会被垃圾收集系统尽快回收。 由于 chunk 位置信息会被客户端缓存，在信息刷新前，客户端可能从失效的副本读取数据。只有当缓存条目超时，或文件被重新打开时，这个问题才能解决，因为条目超时或重新打开文件会清除客户端缓存中的所有跟这个文件有关的 chunk 信息。此外，大多数文件只进行追加操作，因此失效副本通常返回一个提前结束的 chunk 而不是过期的数据（也就是说，数据还是有效的数据，只是返回的偏移位置不对）。当 Reader 程序 重新尝试联络 master 时，会立刻得到最新的 chunk 位置信息。 即使修改操作成功执行后很长时间，组件故障仍可能损坏或删除数据。GFS 通过 master 和所有 chunkserver的定期“握手”找到失效的 chunkserver，并使用校验和检测数据是否损坏。一旦发现问题，数据将尽快利用有效副本进行恢复。只有当一个 chunk 的所有副本在 GFS 检测到错误并采取应对措施之前全部丢失，chunk 才会不可逆转地丢失。通常，GFS 的反应时间（master 节点检测到错误并采取应对措施）为几分钟。即便如此，chunk 也只是不可用而非损坏，应用程序会收到明确的错误信息而非损坏的数据。 2.7.2 对应用程序的影响 使用 GFS 的应用程序可以利用一些简单的技术来实现宽松的一致性模型，也可以实现其他目标功能，包括尽量采用追加写入而不是覆盖、Checkpoint、写入自验证和自识别的记录。 在实际应用中，我们所有的应用程序对文件的写入操作都尽量采用追加方式而不是覆盖方式。例如，应用程序从头到尾写入数据生成一个文件，写入完成后自动将文件改名为一个永久文件名，或者定期进行 Checkpoint，记录成功写入的数据量。Checkpoint 文件可以包含程序级别的校验和。Readers 仅校验并处理上个 Checkpoint 之后的文件区域，这些区域的状态是defined的。这种方法满足了我们的一致性和并发处理需求。追加写入比随机写入更加高效，对应用程序的失败处理更具弹性。Checkpoint 允许 Writer 以渐进方式重新开始，并防止 Reader 处理已成功写入但从应用程序的角度来看未完成的数据。 另一个典型的应用场景是，许多应用程序并行追加数据到同一个文件，例如进行结果合并或者是一个生产者-消费者队列。记录追加方式的“至少一次追加”特性保证了 Writer 的输出。Readers 可以通过以下方法处理偶然性的填充数据和重复内容：Writers 在每条写入记录中包含额外信息，例如 Checksum，用来验证有效性。Reader 可以利用 Checksum 识别并丢弃额外的填充数据和记录片段。如果应用不能容忍偶尔的重复内容，可以使用记录的唯一标识符来过滤重复数据，这些唯一标识符通常用于命名程序中处理的实体对象，如 web 文档。这些记录 I/O 功能都包含在我们共享的程序库中，并适用于 Google 内部的其他文件接口实现。这样，相同序列的记录，加上偶尔出现的重复数据，都能正确分发给 Reader。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:2:7","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"3 系统交互 Google 设计 GFS 系统一个重要的原则是最小化所有操作和 master 的交互（因为 master 只有一个，必须减轻 master 的压力）。在这个背景下，我们现在来说客户端、master 和 chunk服务器如何互动以实现数据修改、原子记录追加(append)，以及快照(snapshot)。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:3:0","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"3.1 租约（lease）和变更顺序 变更是一个会改变 chunk 内容或者元数据的操作（如写入或记录追加），会在 chunk 的所有副本上执行。为了保持多个副本间变更顺序的一致性，GFS 采用了租约（lease）机制。master 节点为 chunk 的一个副本（主 chunk）建立租约，初始租期为 60 秒。主 chunk 对所有更改操作进行序列化，所有副本遵从这个序列进行修改。因此，修改操作全局的顺序首先由 master 选择的租约的顺序决定，然后由租约中主 chunk 分配的序列号决定。 只要 chunk 被修改了，主 chunk 就可以申请更长的租期，通常会得到 master 的确认并收到租约延长的时间。 这些租约延长请求和批准的信息通常都是附加在 master 和 chunkserver之间的心跳消息中来传递。有时 master 会试图提前取消租约（例如，master 想取消在一个已经被改名的文件上的修改操作）。即使 master 和主chunk失去联系，它仍然可以安全地在旧的租约到期后和另外一个chunk副本签订新的租约。 在下图中，我们通过列出 写入操作的控制流描述了这个过程，并且用数字标记了步骤顺序。 客户端向master询问哪个chunk服务器持有当前的租约，以及其他副本的位置。如果没有一个chunk服务器持有租约，master则会选择其中一个副本建立一个租约（图中没有显示此步骤）； master将主chunk的标识符以及其他副本（又称二级副本）的位置返回给客户端。客户端缓存这些数据以便后续的操作。只有在主 chunk 不可用，或者主 chunk 回复信息表明它已不再持有租约的时候，客户端才需要重新跟 master 联系。 客户端把数据 push 给所有的副本，客户端可以以任意的顺序 push。chunkserver接收到数据并保存在它的内部 LRU 缓存中，一直到数据被使用或者过期交换出去。通过将数据流与控制流解耦，我们可以基于网络拓扑情况调度昂贵的数据流来提高性能，而不管哪个 chunk服务器是主 chunk。 当所有的副本都确认接收到了数据，客户端发送写请求到主chunk服务器。这个请求标识了之前推送到所有副本的数据。主 chunk 为接收到的所有操作分配连续的序列号，这些操作可能来自不同的客户端，序列号保证了操作顺序执行。它以序列号的顺序把操作应用到它自己的本地状态中。 主chunk把写请求传递到所有的二级副本。每个二级副本依照主chunk分配的序列号以相同的顺序执行这些操作。 所有完成了操作的二级副本向主chunk 回复，表明它们已经完成了操作。 主 chunk 回复客户端。任何副本产生的任何错误都会返回给客户端。在出现错误的情况下，写入操作可能在主chunk和一些二级副本执行成功（因为是主chunk 先成功完成修改后，才会让二级副本开始应用修改，如果主 chunk 失败了，二级副本就不会收到序列号以及应用更改的命令）。客户端的请求被确认为失败，被修改的区域处于inconsistent的状态。我们的客户端代码通过重复执行失败的操作来处理这样的错误。在从头开始重复执行之前，客户端会先从步骤（3）到步骤（7） 做几次尝试。（Q：已经完成操作或部分完成操作的副本，接收到重试的数据后，如何处理？A：直接在文件末尾（最后一个 chunk 末尾）继续写入，之前成功的二级副本会重复写入，去重任务由读取数据的客户端来完成。） 如果应用程序一次写入的数据量很大，或者数据跨越了多个 chunk，GFS 客户端代码会把它们分成多个写操作。这些操作都遵循前面描述的控制流程，但是可能会被其它客户端上同时进行的操作打断或者覆盖。 因此，共享的文件区域的尾部可能包含来自不同客户端的数据片段，尽管如此，由于这些分解后的写入操作在所有的副本上都以相同的顺序执行完成，chunk 的所有副本都是一致的。这使文件 region 处于 2.7 节描述 的consistent但是undefined的状态。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:3:1","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"3.2 数据流 为了提高网络效率，GFS采取了将数据流和控制流分开的措施。在控制流从客户端到主 chunk再到所有二级副本的同时，数据以管道方式顺序沿着精心选择的 chunkserver链推送，充分利用每台机器的带宽，避免网络瓶颈和高延时连接，最小化数据推送延时。 数据顺序沿着一个 chunkserver链推送，而不是分散推送（如树型拓扑结构），以充分利用每台机器的出口带宽，实现最快速度的传输，而不分散带宽。为避免网络瓶颈和高延迟连接，每台机器尽量选择网络拓扑中离自己最近且尚未接收到数据的机器作为目标推送数据。例如，客户端将数据推送到最近的 chunkserver S1，S1 推送到 S2，以此类推，基于 IP 地址计算节点距离。 利用基于 TCP 连接的管道式数据推送方式最小化延迟。chunkserver接收到数据后立即向前推送，利用全双工交换网络的优势，传输不会减慢接收速度。在无网络拥塞情况下，传送 $B$ 字节的数据到 $R$ 个副本的理想时间为 $\\frac{B}{T} + RL$（$T$ 是网络吞吐量，$L$ 是传输延迟）。通常，我们的网络连接速度是 100Mbps，传输 1MB 数据的理想时间约为 80ms。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:3:2","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"3.3 原子的记录追加 GFS 提供了一种原子的记录追加操作，客户端只需指定要写入的数据，GFS 保证至少一次原子写入成功执行（即写入一个顺序的byte流），写入数据追加到 GFS 指定的偏移位置，并返回该偏移量给客户端。类似于 Unix 的 O_APPEND 模式，多个并发写操作无竞态条件。 记录追加在分布式应用中频繁使用，特别是在多个客户端并行追加数据的情况下。传统写入需要复杂的同步机制，如分布式锁管理器，而记录追加简化了这种需求，常用于生产者/消费者队列系统或数据合并文件。 记录追加遵循 3.1 节描述的控制流程，主 chunk 有额外控制逻辑。客户端将数据推送到最后一个 chunk 的所有副本，然后发送请求给主 chunk。主 chunk 检查是否超出最大大小（64MB），如果超出，则填充到最大大小并通知二级副本做同样的操作，然后回复客户端要求其对下一个chunk重新进行记录追加。通常情况下，主 chunk 追加数据并通知二级副本写入相同位置，最后回复客户端操作成功。 如果记录追加在任何副本上失败，客户端需要重新操作，可能导致同一个chunk的不同副本包含不同数据。GFS 只保证数据整体原子性写入至少一次，而不保证字节级别一致。成功执行操作的数据区域是defined的（且consistent的），否则是inconsistent的（且undefined义的）。程序可以处理这些inconsistent区域。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:3:3","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"3.4 快照 快照操作在 GFS 中几乎瞬间完成，且不干扰其他操作。用户可以用快照快速创建数据集的分支拷贝或在实验前备份当前状态，方便之后提交或回滚。 就像AFS（Andrew File System，一种分布式文件系统），GFS 使用标准的“写时复制”（copy-on-write）技术实现快照。当 master 收到快照请求时，它会取消作快照的文件的所有 chunk 的租约，确保后续写操作必须与 master 交互，使 master 有机会先创建 chunk 的新拷贝。 租约取消或过期后，master 将操作记录到硬盘日志，并通过复制源文件或目录的元数据将变化反映到内存中。新创建的快照文件与源文件共享相同的 chunk 地址。 快照操作后，当客户端首次写入 chunk C 时，会先请求 master 查询当前租约持有者。master 发现 chunk C 的引用计数超过 1（写时复制方法创建快照时是给这个chunk加一个引用计数，没有立刻真的拷贝，一个 chunk 的引用计数大于 1 的话就代表这个 chunk 是某个快照的一部分，要保留原样数据的。当这个 chunk 上有新的写入的时候，这个 chunk 才会真的被复制，客户端在新复制的 chunk 上写入，而原来的旧 chunk 被快照继续引用），不立即回复客户端，而是选择新的 chunk 句柄 C'，并要求所有持有 chunk C 副本的服务器创建 C'。通过在本地创建新的 chunk 避免了网络复制，提高了效率。master 确保新 chunk C'的一个副本拥有租约后回复客户机，客户机即可正常写入该 chunk。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:3:4","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"4 Master操作 master 执行所有的命名空间操作。此外，它还管理着整个系统里所有 Chunk 的副本： master 决定 chunk 副本的存储位置； 创建新的 chunk 和它的副本； 协调各种各样的系统范围内的活动以保证 chunk 被完全拷贝； 在所有的 chunkserver上做负载均衡； 回收不再使用的存储空间。 下面我们深入讨论下上述的几点。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:4:0","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"4.1 命名空间管理和锁 在 GFS 中，master 节点的操作可能耗时较长，例如快照操作需取消所有相关 chunk 的租约。为避免延缓其他操作，GFS 允许多个操作同时进行，并通过命名空间的区域锁保证顺序正确。 GFS 命名空间是一个全路径与元数据映射的查找表，采用前缀压缩高效存储在内存中。不同于传统文件系统，GFS 不支持列出目录下所有文件的结构，也不支持文件或目录的链接。每个节点（绝对路径的文件名或目录名）有一个关联的读写锁。 每个 master 操作开始前都要获得相关锁。通常，涉及路径/d1/d2/.../dn/leaf 的操作需要获得/d1，/d1/d2，…，/d1/d2/.../dn 的读锁，以及/d1/d2/.../dn/leaf 的读写锁。根据操作不同，leaf 可以是文件或目录。例如，在/home/user 快照到/save/user 时，锁机制防止创建文件/home/user/foo。快照操作获得/home 和/save 的读锁及/home/user 和/save/user 的写锁；文件创建操作获得/home 和/home/user 的读锁及/home/user/foo 的写锁。由于/home/user 锁冲突，这两个操作顺序执行。文件创建操作不需要获取父目录的写入锁，因为这里没有“目录”，或者类似 inode 等用来 禁止修改的数据结构。文件名的读取锁足以防止父目录被删除。 这种锁方案支持对同一目录的并行操作。例如，可在同一目录下同时创建多个文件：每个操作获取目录名的读锁和文件名的写锁。目录名的读锁防止目录被删除、改名或快照；文件名的写锁序列化文件创建操作，确保不会多次创建同名文件。 由于命名空间节点众多，读写锁采用惰性分配策略，不再使用时立刻删除。锁的获取依据全局一致的顺序避免死锁：首先按命名空间层次排序，在同一层次内按字典顺序排序。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:4:1","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"4.2 副本放置 GFS 集群采用高度分布的多层布局结构，典型拓扑包括数百个 chunkserver分布在多个机架上，由来自同一或不同机架的数百个客户机访问。通信可能跨越一个或多个网络交换机，且机架出入带宽可能较小。多层分布架构带来数据灵活性、可靠性和可用性挑战。 chunk 副本位置选择旨在最大化数据可靠性和可用性，以及网络带宽利用率。仅在多台机器上存储副本不足以达到目标，需在多个机架间分布储存 chunk 的副本。这保证即使整个机架故障或掉线，某些副本仍可用，且网络流量尤其读操作可利用多个机架的带宽。尽管写操作需与多个机架设备通信，但这是值得的。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:4:2","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"4.3 创建、重新复制、重新平衡 chunk 副本在 GFS 中有三个主要用途：chunk 创建、重新复制和重新平衡。 Master 节点在创建 chunk 时选择存放初始空副本的位置，考虑以下因素： 优先选择硬盘使用率低于平均值的 chunkserver，以平衡硬盘使用率。 限制每个 chunkserver上最近 chunk 创建操作的次数，以减少写入操作的集中度。 分布在多个机架之间，以提高可靠性。 当有效副本数量低于指定复制因数时，master 节点会重新复制 chunk，可能原因包括： chunkserver不可用或报告副本损坏。 磁盘错误或复制因数增加。 重新复制优先级基于现有副本数量与复制因数的差异、chunk 活跃状态及其对客户端的影响。 master 选择优先级最高的chunk，命令 chunkserver克隆副本，选择新副本的位置的策略类似于 chunk 创建。为防止克隆操作超载网络，master会限制克隆操作数量及其读请求频率。 master 周期性检查副本分布，移动副本以优化硬盘空间利用和平衡。在这个过程中，master 渐进式填充新 chunkserver，避免短期内填充过载。副本位置选择策略同上，并优先移走剩余空间低于平均值的服务器上的副本，以平衡整体硬盘使用率。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:4:3","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"4.4 垃圾回收 GFS 在文件删除后不会立即回收物理空间，而是采用惰性垃圾回收策略，仅在文件和 chunk 级的常规垃圾收集中进行。这样简化了系统设计，提高了可靠性。 4.4.1 机制 当一个文件被应用程序删除时，master立刻把删除操作以日志的方式记录下来。但是，master 并不马上回收资源，而是把文件名改为一个包含删除时间戳的、隐藏的名字。当 master 对文件系统命名空间做常规扫描的时候，它会删除所有三天前的隐藏文件（这个时间间隔是可以设置的）。在文件被真正删除之前，它们仍旧可以用新的特殊的名字（即被重命名后的带有删除时间戳的名字）读取，也可以通过把隐藏文件改名为正常显示的文件名的方式“取消删除”。当隐藏文件被从命名空间中删除，master 内存中保存的这个文件的相关元数据才会被删除。这也有效的切断了文件和它包含的所有 chunk 的连接。 在对 chunk 命名空间做类似的常规扫描时，master 找到孤儿 chunk（不被任何文件包含的 Chunk） 并删除它们的元数据。chunkserver在和 master 交互的心跳信息中，报告它拥有的 chunk 子集的信息， master 回复 chunkserver哪些 chunk 在 master 保存的元数据中已经不存在了。chunkserver可以任意删除这些 chunk 的副本。 4.4.2 讨论 GFS 的垃圾回收方案简单可靠。可以轻易得到chunk 的引用：存储在 master 的文件到chunk的映射表中；也可以轻松得到chunk所有副本：以Linux文件的形式存储在 chunkserver指定目录下。所有master 不能识别的副本即为“垃圾”。 垃圾回收在空间回收方面相比直接删除有几个优势。 在大规模分布式系统中，组件失效是常态。chunk 可能在某些服务器上创建成功，但在其他服务器上失败，失败的副本处于无法被 master 识别的状态。副本删除消息可能丢失，master 必须重新发送失败的删除消息， 包括自身的（元数据）和 chunkserver的。垃圾回收提供了一致的、可靠的清除无用副本的方法。 垃圾回收将存储空间回收操作合并到 master 的规律性后台活动中，如例行扫描和与 chunkserver的握手。因此操作被批量执行，减少开销。回收在 master 相对空闲时进行，提高了响应速度。 延迟回收为意外、不可逆转的删除操作提供了安全保障，防止误删。 虽然延迟回收可能阻碍存储优化，尤其在空间紧缺时。但可以通过显式再次删除文件可以加速回收。用户可以为不同命名空间设置不同的复制和回收策略，以优化存储使用。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:4:4","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"4.5 过期副本检测 当 chunkserver失效时，chunk 的副本可能因错失一些修改操作而过期。master 通过保存每个 Chunk 的版本号来区分当前副本和过期副本。每次与 chunk 签订新租约时，master 都会增加 chunk 的版本号，并通知最新的副本，且这些副本会将新的版本号记录在其持久化存储中。这个过程在任何客户端得到通知前完成，因此也是在对这个 chunk 开始写之前完成的。如果某个副本所在的 chunkserver正好失效，那么其版本号就不会被更新。待该 chunkserver重新启动并向 master 报告其持有的 chunk 及相应版本号时，master 会检测出其包含过期的 chunk。若 master 发现一个比其记录的版本号更高的版本号，会认为之前签订租约的操作失败，并选择更高的版本号作为当前版本号。 master 在例行垃圾回收过程中移除所有过期副本。在此之前，master 在回复客户端的 chunk 信息请求时，master 实际上会认为根本不存在一个过期的副本（也就是说，给客户端返回的 chunk 列表中可能包含过期的 chunk，客户端有可能去读过期的 chunk。GFS 是弱一致性的）。另外一重保障措施是，master 在通知客户端哪个 chunkserver持有租约或指示 chunkserver从哪个 chunkserver进行克隆时，消息中都会附带 chunk 的版本号。客户端或 chunkserver在执行操作时会验证版本号，以确保总是访问当前版本的数据。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:4:5","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"5 容错和诊断 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:5:0","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"5.1 高可用性 在 GFS 集群中，高可用性的策略主要包括快速恢复和复制。 首先，对于快速恢复，无论是 master 还是 chunkserver，它们都能在数秒内恢复状态并重新启动。系统不区分正常关闭和异常关闭，通常通过直接终止进程来关闭服务器。 其次，对于 chunk 复制，每个 chunk 都被复制到不同机架上的不同 chunkserver上，并可以根据需要设定不同的复制级别。当有 chunkserver 离线或发现数据损坏时，master 通过克隆已有的副本来确保每个 chunk 都被完整复制。 最后，master 的状态也需要复制以保证其可靠性。master 的所有操作日志和 checkpoint 文件都被复制到多台机器上，确保操作日志写入备用节点和本机磁盘，以支持失败后的快速重新启动。此外，还存在“影子”master，用于提供文件系统的只读访问。这些“影子”服务器能够保持状态最新，并通过与主 master 相同的方式处理数据结构的更改。它们定期从 chunkserver拉取数据，并与其握手以确定状态，从而确保系统的高可用性。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:5:1","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"5.2 数据完整性 每个 Chunkserver使用 checksum 来检查保存的数据是否损坏。由于 GFS 集群通常包含数百台机器和数千块硬盘，磁盘损坏导致的数据丢失或损坏在读写过程中是常见的。虽然可以通过其他副本恢复数据，但跨服务器比较副本以检查数据完整性并不实际。此外，由于 GFS 允许存在有歧义的副本，特别是在原子记录追加操作中，副本并不总是完全一致的（副本不是 byte-wise 完全一致的）。因此，每个 chunkserver必须独立维护 checksum 来校验自己的副本完整性。 每个 chunk 被分为 64KB 的块，每个块对应一个 32 位的 checksum，存储在内存和硬盘上，并记录在操作日志中。在读取数据之前，chunkserver会校验与读取范围重叠的数据块的checksum。如果 checksum 不匹配，服务器返回错误信息并通知 master，之后从其他副本读取数据并进行克隆恢复。一旦新的副本就绪，master 通知 chunkserver删除错误的副本。 checksum 对读操作性能影响很小，因为大部分读操作涉及多个块，而只需读取少量额外数据进行校验。通过对齐读操作到 checksum块的边界，可以进一步减少额外读取操作的影响。此外，checksum 的查找和比较不需要额外的 I/O 操作，计算可以与 I/O 操作并行进行。 针对追加写入操作，checksum 的计算进行了优化，因为这种操作在 GFS 工作中占很大比例。只需增量更新最后一个不完整块的 checksum，并使用新写入的数据计算新的 checksum。如果最后一个checksum块损坏，问题会在下次读取时被发现。 相比之下，覆盖写操作需要读取和校验被覆盖范围内的第一个和最后一个块，操作完成后重新计算和写入新的 checksum。如果不校验第一个和最后一个被写的块，新的 checksum 可能会隐藏未覆盖区域内的数据错误。 当 chunkserver空闲时，会扫描和校验每个不活动 chunk 的内容，以发现很少被读取的 chunk 是否完整。一旦发现数据损坏，master 可以创建新的正确副本并删除损坏的副本，避免非活动的损坏 chunk 误导 master，使其认为副本数量足够。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:5:2","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"5.3 诊断工具 详尽的、深入细节的诊断日志在问题隔离、调试和性能分析等方面提供了极大的帮助，而所需开销却很小。没有日志，我们很难理解短暂的、不重复的机器间消息交互。GFS 服务器会生成大量日志，记录关键事件（如 chunkserver 的启动和关闭）以及所有 RPC 请求和回复。这些日志可以随时删除，不影响系统的正确运行，但我们在存储空间允许的情况下尽量保留这些日志。 RPC 日志详细记录了网络上的所有请求和响应，但不包括读写的文件数据。通过匹配请求与回应，并收集不同机器上的 RPC 日志，我们可以重现所有消息交互来诊断问题。这些日志还用于跟踪负载测试和进行性能分析。 日志对性能的影响很小，因为日志写入是顺序且异步的。最近的事件日志保存在内存中，用于持续的在线监控。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:5:3","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["系统架构","论文阅读"],"content":"6 经验 在构建和部署 GFS 的过程中，Google 遇到了许多问题，包括操作和技术方面的挑战。最初，GFS 主要作为生产系统的后端文件系统，后来逐渐支持研究和开发任务，增加了权限和配额等功能。 最大的难题是磁盘和 Linux 相关问题。许多磁盘声称支持 Linux IDE 驱动，但实际应用中情况不一，导致协议不匹配，数据可能因内核问题而被破坏。为此，Google 使用校验和来验证数据，并修改内核处理这些问题。 早期使用 Linux 2.2 内核时，fsync() 效率与文件大小相关而非修改部分大小相关，导致操作日志文件过大时出现问题，尤其是在尚未实现checkpoint 的时候。Google费了很大的力气用同步写来解决这个问题，但是最后还是移植到了 Linux2.4 内核上。 另一个问题是单个读写锁，导致系统偶尔超时。Google 通过用 pread() 替代 mmap() 并增加额外复制操作解决了这个问题。 在任意地址空间的线程在磁盘读入（读锁）时或 mmap() 调用（写锁）时必须持有锁。即使系统负载很轻，也会偶尔超时。Google花费大量精力查找资源瓶颈或硬件问题，最终发现磁盘线程在交换数据到磁盘时，锁住了当前网络线程，阻止其将新数据映射到内存。由于性能主要受限于网络接口而非内存复制带宽，Google用 pread() 替代 mmap()，通过额外复制操作解决了问题。 ","date":"2024-05-12","objectID":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/:6:0","tags":["分布式系统","GFS","文件系统"],"title":"【论文阅读笔记】The Google File System","uri":"/posts/02.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0gfs/"},{"categories":["知识科普"],"content":"翻译原文地址 ","date":"2024-05-12","objectID":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/:0:0","tags":["GPU"],"title":"AI时代下的GPU生存工具包：每个开发人员必须了解的最基本知识","uri":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/"},{"categories":["知识科普"],"content":"1 CPU知识为何不再足够 在当今的人工智能时代，大多数开发者都是按照CPU的方式进行训练。这种认知也已经成为我们学术中的一部分，因此很自然地会以CPU为导向来思考和解决问题。 然而，CPU 的问题在于它们依赖于串行架构。在当今世界中，我们依赖大量并行任务的情况下，CPU 无法很好地处理这些场景。 因此，开发者面临着如下问题。 执行并行任务 CPU 传统上是线性运行的，一次执行一条指令。这种限制源于这样一个事实：CPU 通常具有一些针对单线程性能进行优化的强大内核。当面临多个任务时，CPU会分配其资源来逐个处理每个任务，从而导致指令的顺序执行。在需要同时关注众多任务的情况下，这种方法变得低效。 尽管我们通过诸如多线程等技术来提高CPU性能，但CPU的基本设计理念是优先考虑顺序执行。 高效运行AI模型 AI 模型采用 Transformer 等先进架构，利用并行处理来增强性能。与顺序运行的旧递归神经网络 (RNN) 不同，GPT 等现代 Transformer 可以同时处理多个单词，从而提高训练效率和能力。因为当我们并行训练时，会产生更大的模型，而更大的模型会产生更好的输出。 并行的概念已从自然语言处理扩展到图像识别等其他领域。例如，图像识别架构 AlexNet 通过同时处理图像的不同部分，展示了并行处理的威力，从而实现准确的模式识别。 然而，CPU 的设计侧重于单线程性能，很难充分挖掘并行处理的潜力。它们难以有效分配和执行复杂AI模型所需的大量并行计算。 ","date":"2024-05-12","objectID":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/:1:0","tags":["GPU"],"title":"AI时代下的GPU生存工具包：每个开发人员必须了解的最基本知识","uri":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/"},{"categories":["知识科普"],"content":"2 GPU驱动开发如何解决这些问题 GPU 核心的大规模并行性 与 CPU 中更大、更强大的内核相比，工程师设计的 GPU 具有更小、高度专业化的内核。该架构允许 GPU 同时执行多个并行任务。 GPU 中的大量核心非常适合依赖于并行性的工作负载，例如图形渲染和复杂的数学计算。 如下图所示，5.3.2使用 GPU 并行性来减少复杂任务所需的时间。 AI 模型中使用的并行性 人工智能模型，特别是基于 TensorFlow 等深度学习框架构建的模型，表现出高度的并行性。神经网络训练涉及大量矩阵运算，而 GPU 凭借其庞大的核心数量，擅长并行化这些运算。 TensorFlow 与其他流行的深度学习框架一起进行优化，以利用 GPU 的能力来加速模型训练和推理。 如下图所示，5.3.3使用 GPU 的强大功能来训练神经网络。 ","date":"2024-05-12","objectID":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/:2:0","tags":["GPU"],"title":"AI时代下的GPU生存工具包：每个开发人员必须了解的最基本知识","uri":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/"},{"categories":["知识科普"],"content":"3 GPU和CPU有什么区别 CPU 串行架构 中央处理单元 (CPU) 的设计重点是顺序处理。它们擅长线性执行一组指令。CPU 针对需要高单线程性能的任务进行了优化，例如： 通用计算 系统操作 处理涉及条件分支的复杂算法 并行任务的核心数量有限 CPU 的核心数量较少，在消费级处理器中通常为 2-16 个核心。每个内核都能够独立处理自己的指令集。 GPU 并行架构 图形处理单元（GPU）采用并行架构设计，使其能够高效地执行并行处理任务。这有利于： 渲染图形 执行复杂的数学计算 运行可并行算法 GPU 通过将多个任务分解为更小的并行子任务来同时处理多个任务。 数千个内核用于并行任务 与 CPU 不同，GPU 拥有更多的核心，通常有数千个。这些内核被组织成流式多处理器 (SM) 或类似的结构。丰富的内核使 GPU 能够同时处理大量数据，非常适合并行任务，例如图像和视频处理、深度学习和科学模拟。 ","date":"2024-05-12","objectID":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/:3:0","tags":["GPU"],"title":"AI时代下的GPU生存工具包：每个开发人员必须了解的最基本知识","uri":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/"},{"categories":["知识科普"],"content":"4 GPU类型 通用 Gpu 通用 GPU 实例（P3 和 P4 实例）适用于广泛的工作负载，包括机器学习训练和推理、图像处理和视频编码。它们的平衡性能使它们成为各种计算任务的理想选择。 推理优化的 GPU 推理是运行已经训练好的 AI 模型并对实时数据进行预测或任务求解的过程。推理优化的 GPU 实例（P5 和 Inf1 实例）在低延迟和成本效率至关重要的情况下表现出色，特别适用于机器学习推理任务。 图形优化的 GPU 图形优化的 GPU 实例（G4 实例）专门设计用于处理图形密集型任务，如视频游戏开发中的 3D 图形渲染。这些实例非常适合需要处理大量图形数据的应用程序。 托管 GPU Amazon SageMaker 是一种托管服务，为机器学习提供了易于使用的 GPU 实例。它提供对多种 GPU 实例（包括 P3、P4 和 P5 实例）的访问，适用于想要轻松开始机器学习而无需管理底层基础设施的组织。 ","date":"2024-05-12","objectID":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/:4:0","tags":["GPU"],"title":"AI时代下的GPU生存工具包：每个开发人员必须了解的最基本知识","uri":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/"},{"categories":["知识科普"],"content":"5 使用 Nvidia 的 CUDA 进行 GPU 驱动开发 CUDA 是 NVIDIA 开发的并行计算平台和编程模型，使开发人员能够利用 GPU 加速器的强大功能来加速其应用程序。 ","date":"2024-05-12","objectID":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/:5:0","tags":["GPU"],"title":"AI时代下的GPU生存工具包：每个开发人员必须了解的最基本知识","uri":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/"},{"categories":["知识科普"],"content":"5.1 Linux安装CUDA 下载CUDA 从上面的链接下载基本安装程序以及驱动程序安装程序 转到主文件夹中的 .bashrc（如果使用其他shell则使用对应的配置文件） 在配置文件中添加以下行： export PATH=\"/usr/local/cuda-12.3/bin:$PATH\" export LD_LIBRARY_PATH=\"/usr/local/cuda-12.3/lib64:$LD_LIBRARY_PATH\" 然后执行以下命令： sudo apt-get install cuda-toolkit sudo apt-get install nvidia-gds ","date":"2024-05-12","objectID":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/:5:1","tags":["GPU"],"title":"AI时代下的GPU生存工具包：每个开发人员必须了解的最基本知识","uri":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/"},{"categories":["知识科普"],"content":"5.2 基本命令 lspci | grep VGA 识别并列出系统中的 GPU。 nvidia-smi “NVIDIA 系统管理界面”，它提供有关系统中 NVIDIA GPU 的详细信息，包括利用率、温度、内存使用情况等。 sudo lshw -C display 提供有关系统中显示控制器（包括显卡）的详细信息。 inxi -G 提供有关图形子系统的信息，包括有关 GPU 和显示器的详细信息。 sudo hwinfo --gfxcard ","date":"2024-05-12","objectID":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/:5:2","tags":["GPU"],"title":"AI时代下的GPU生存工具包：每个开发人员必须了解的最基本知识","uri":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/"},{"categories":["知识科普"],"content":"5.3 开始使用CUDA框架 当我们安装了 CUDA 框架后，让我们开始执行展示其功能的操作。 5.3.1 数组加法问题 数组加法问题是演示 GPU 并行化的一个合适问题。考虑以下数组： 数组 $A = [1,2,3,4,5,6]$ 数组 $B = [7,8,9,10,11,12]$ 我们需要存储每个元素的和并将其存储在数组$C$中。我们需要存储每个元素的和并将其存储在数组$C$中。 就像 $C = [1+7,2+8,3+9,4+10,5+11,6+12] = [8,10,12,14,16,18]$ 如果CPU要执行这样的操作，它将执行如下代码所示的操作。 #include \u003cstdio.h\u003e int a[] = {1,2,3,4,5,6}; int b[] = {7,8,9,10,11,12}; int c[6]; int main() { int N = 6; // Number of elements for (int i = 0; i \u003c N; i++) { c[i] = a[i] + b[i]; } for (int i = 0; i \u003c N; i++) { printf(\"c[%d] = %d\", i, c[i]); } return 0; } 这种方法是逐个遍历数组元素并依次执行加法。然而，当处理大量数字时，这种方法由于其顺序性质而变得缓慢。 为了解决这个限制，GPU 通过并行化加法过程提供了一种解决方案。与依次执行运算的 CPU 不同，GPU 可以同时执行多项加法。例如，运算$1+7、2+8、3+9、4+10、5+11$和$6+12$可以借助GPU并行化同时执行。 利用CUDA，我们将使用内核文件 (.cu) 进行展示。实现并行加法的代码如下： __global__ void vectorAdd(int* a, int* b, int* c) { int i = threadIdx.x; c[i] = a[i] + b[i]; return; } __global__ 说明符表明该函数是一个内核函数，将在 GPU 上调用。 vectorAdd 采用三个整数指针（$a$、$b$ 和 $c$）作为参数，表示要相加的向量。 threadIdx.x 检索当前线程的索引（在一维网格中）。 向量 $a$ 和 $b$ 的相应元素之和存储在向量 $c$ 中。 现在我们来看看主要功能。创建指针 cudaA 、 cudaB 和 cudaC 来指向 GPU 上的内存。 // 利用 CUDA 使用并行计算加法的函数 int main() { int a[] = {1,2,3}; int b[] = {4,5,6}; int c[sizeof(a) / sizeof(int)] = {0}; // 创建指向 GPU 的指针 int* cudaA = 0; int* cudaB = 0; int* cudaC = 0; 使用 cudaMalloc ，在 GPU 上为向量 cudaA、cudaB 和 cudaC 分配内存。 // 在GPU中分配内存 cudaMalloc(\u0026cudaA,sizeof(a)); cudaMalloc(\u0026cudaB,sizeof(b)); cudaMalloc(\u0026cudaC,sizeof(c)); 内核函数 vectorAdd 使用一个块和等于向量大小的多个线程启动。 // 用一个程序块和与向量大小相等的线程数启动内核 vectorAdd \u003c\u003c\u003c1, sizeof(a) / sizeof(a[0])\u003e\u003e\u003e (cudaA, cudaB, cudaC); 结果向量 cudaC 从GPU复制回主机。 // 将结果向量复制回主机 cudaMemcpy(c, cudaC, sizeof(c), cudaMemcpyDeviceToHost); 然后我们可以照常打印结果 // 打印结果 for (int i = 0; i \u003c sizeof(c) / sizeof(int); i++) { printf(\"c[%d] = %d\", i, c[i]); } return 0; } 为了执行此代码，我们将使用 nvcc 命令。我们将得到输出为： 这是完整的代码供读者参考。 5.3.2 使用 GPU 在 Python 中优化图像生成 本节探讨使用 GPU 处理来优化性能密集型任务，例如图像生成。 Mandelbrot 集是一种数学构造，它根据规定方程中特定数字的行为形成复杂的视觉模式。生成一个这样的图案需要耗费大量资源。在下面的代码片段中，您可以观察到使用 CPU 处理生成 Mandelbrot 集的传统方法，该方法速度很慢。 # 导入必要的库 from matplotlib import pyplot as plt import numpy as np from pylab import imshow, show from timeit import default_timer as timer # 计算给定点 (x, y) 的 Mandelbrot 集的函数 def mandel(x, y, max_iters): c = complex(x, y) z = 0.0j # 迭代检查该点是否在 Mandelbrot 集中 for i in range(max_iters): z = z*z + c if (z.real*z.real + z.imag*z.imag) \u003e= 4: return i # 如果在最大迭代次数内，则将其视为集合的一部分 return max_iters # 在指定区域内创建 Mandelbrot 分形的函数 def create_fractal(min_x, max_x, min_y, max_y, image, iters): height = image.shape[0] width = image.shape[1] # 根据指定区域计算像素大小 pixel_size_x = (max_x - min_x) / width pixel_size_y = (max_y - min_y) / height # 在图像中迭代每个像素并计算Mandelbrot值 for x in range(width): real = min_x + x * pixel_size_x for y in range(height): imag = min_y + y * pixel_size_y color = mandel(real, imag, iters) image[y, x] = color # 为 Mandelbrot 集创建一个空白图像数组 image = np.zeros((1024, 1536), dtype=np.uint8) # 记录性能测量的开始时间 start = timer() # 在指定的区域和迭代次数内生成Mandelbrot集合 create_fractal(-2.0, 1.0, -1.0, 1.0, image, 20) # 计算创建 Mandelbrot 集所需的时间 dt = timer() - start # 打印生成 Mandelbrot 集所需的时间 print(\"Mandelbrot created in %f s\" % dt) # 使用 matplotlib 显示 Mandelbrot 集 imshow(image) show() 上面的代码在 4.07 秒内生成输出。 为了加快速度，我们可以使用 Numba 库将代码与 GPU 并行化，具体操作如下： 我们将从 numba 导入即时编译、用于 GPU 加速的 CUDA 以及其他工具库 import numpy as np from numba import jit, cuda, uint32, f8, uint8 from pylab import imshow, show from timeit import default_timer as timer @jit 装饰器指示 Numba 执行即时编译，将 Python 代码转换为机器代码以提高执行速度。 @jit def mandel(x, y, max_iters): c = complex(x, y) z = 0.0j for i in range(max_iters): z = z*z + c if (z.real*z.real + z.imag*z.imag) \u003e= 4: return i return max_iters mandel_gpu 是使用 cuda.jit 创建的 mandel 函数的 GPU 兼容版本。这允许将 mandel 逻辑卸载到 GPU。这是通过使用 @cuda.jit 装饰器并指定函数参数的数据类型（f8 表示浮点数，``uint32 表示无符号32位整数）来完成的。device=True` 参数指示该函数将在 GPU 上运行。 mandel_gpu = cuda.jit((f8, f8, uint32), device=True)(mandel) mandel_kernel 函数被定义为在 CUDA GPU 上执行。它负责跨 GPU 线程并行生成 Mandelbrot 集。 @cuda.jit((f8, f8, f8, f8, uint8[:,:], uint32)) def mandel_kernel(min_x, max_x, min_y, max_y, image, iters): height = image.shape[0] width = ima","date":"2024-05-12","objectID":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/:5:3","tags":["GPU"],"title":"AI时代下的GPU生存工具包：每个开发人员必须了解的最基本知识","uri":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/"},{"categories":["知识科普"],"content":"6 结论 在即将到来的AI时代，GPU是一个不容忽视的东西，我们应该更加了解它的能力。随着我们从传统的串行算法过渡到日益流行的并行算法，GPU 成为加速复杂计算不可或缺的工具。 GPU 的并行处理能力在处理人工智能和机器学习任务固有的海量数据集和复杂的神经网络架构方面特别有优势。此外，GPU 的作用超出了传统的机器学习领域，在科学研究、模拟和数据密集型任务中找到了应用。事实证明，GPU 的并行处理能力有助于解决从药物发现、气候建模到金融模拟等各个领域的挑战。 ","date":"2024-05-12","objectID":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/:6:0","tags":["GPU"],"title":"AI时代下的GPU生存工具包：每个开发人员必须了解的最基本知识","uri":"/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/"},{"categories":["资源收藏"],"content":"1 操作系统 ","date":"2024-05-11","objectID":"/posts/01.%E8%AF%BE%E7%A8%8B%E7%BD%91%E7%AB%99/:1:0","tags":["学习"],"title":"优秀的CS学习网站","uri":"/posts/01.%E8%AF%BE%E7%A8%8B%E7%BD%91%E7%AB%99/"},{"categories":["资源收藏"],"content":"1.1 NJU操作系统：设计与实现 先修要求： C语言 一些汇编语言基础 计算机基础 这是NJU jyy老师的操作系统课程，每年都会在B站更新最新的操作系统课程视频，当然过往课程也可以找到。 2022年OS 网站 2022年OS 视频 课程教程OSTEP 2022年OS Lab ","date":"2024-05-11","objectID":"/posts/01.%E8%AF%BE%E7%A8%8B%E7%BD%91%E7%AB%99/:1:1","tags":["学习"],"title":"优秀的CS学习网站","uri":"/posts/01.%E8%AF%BE%E7%A8%8B%E7%BD%91%E7%AB%99/"},{"categories":["资源收藏"],"content":"1.2 MIT6.S081: Operating System Engineering 先修要求： C语言 一些汇编语言基础 计算机基础 课程网站 课程视频 课程视频翻译文档 课程教材 课程作业 ","date":"2024-05-11","objectID":"/posts/01.%E8%AF%BE%E7%A8%8B%E7%BD%91%E7%AB%99/:1:2","tags":["学习"],"title":"优秀的CS学习网站","uri":"/posts/01.%E8%AF%BE%E7%A8%8B%E7%BD%91%E7%AB%99/"},{"categories":["资源收藏"],"content":"2 分布式系统 ","date":"2024-05-11","objectID":"/posts/01.%E8%AF%BE%E7%A8%8B%E7%BD%91%E7%AB%99/:2:0","tags":["学习"],"title":"优秀的CS学习网站","uri":"/posts/01.%E8%AF%BE%E7%A8%8B%E7%BD%91%E7%AB%99/"},{"categories":["资源收藏"],"content":"2.1 MIT6.824(after 2022, 6.5840): Distributed System 先修要求： Go语言 操作系统 并发编程 计算机体系结构 课程网站 课程视频-中文字幕 课程中文文档 课程作业 ","date":"2024-05-11","objectID":"/posts/01.%E8%AF%BE%E7%A8%8B%E7%BD%91%E7%AB%99/:2:1","tags":["学习"],"title":"优秀的CS学习网站","uri":"/posts/01.%E8%AF%BE%E7%A8%8B%E7%BD%91%E7%AB%99/"},{"categories":["系统架构"],"content":"1 引言 Andrew 文件系统是卡内基梅隆大学 (CMU) 于 1980 年代引入的。该项目由CMU著名教授 M. Satyanarayanan（简称“Satya”）领导，其主要目标很简单：扩展性。具体来说，如何设计一个分布式文件系统，使得服务器可以支持尽可能多的客户端？ 有趣的是，设计和实现的许多方面都会影响可扩展性。最重要的是客户端和服务器之间的协议设计。例如，在 NFS 中，协议强制客户端定期检查服务器以确定缓存的内容是否已更改；由于每次检查都会占用服务器资源（包括CPU和网络带宽），因此频繁进行这样的检查将限制服务器可以响应的客户端数量，从而限制可扩展性。 AFS 与 NFS 的不同之处还在于，从一开始，合理的用户可见行为就是首要关注的问题。在 NFS 中，缓存一致性很难描述，因为它直接取决于低级实现细节，包括客户端缓存超时间隔。在AFS中，缓存一致性很简单且易于理解：当文件被打开时，客户端通常会从服务器接收到最新的一致副本。 我们将讨论两个版本的 AFS。第一个版本（我们称之为 AFSv1，但实际上最初的系统被称为 ITC 分布式文件系统有一些基本设计，但扩展性不尽如人意，这导致了重新设计和最终协议（我们称之为 AFSv2，或简称 AFS）。 ","date":"2024-05-11","objectID":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:1:0","tags":["OS"],"title":"Andrew文件系统","uri":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"2 AFSv1 ","date":"2024-05-11","objectID":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:2:0","tags":["OS"],"title":"Andrew文件系统","uri":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"2.1 基本介绍 AFS 所有版本的基本原则之一是在访问文件的客户端计算机的本地磁盘上缓存整个文件。当您 open() 文件时，将从服务器获取整个文件（如果存在）并将其存储在本地磁盘上的文件中。后续应用程序的read()和write()操作将被重定向到存储文件的本地文件系统；因此，这些操作不需要网络通信并且速度很快。最后，在 close() 时，文件（如果已被修改）被刷新回服务器。请注意与 NFS 的明显对比，NFS 缓存块（不是整个文件，尽管 NFS 当然可以缓存整个文件的每个块）并在客户端内存（而不是本地磁盘）中进行缓存。 让我们进一步了解细节。当客户端应用程序第一次调用 open() 时，AFS 客户端代码（AFS 设计者称之为 Venus）将向服务器发送一条 Fetch 协议消息。 Fetch 协议消息会将所需文件的整个路径名（例如，/home/zfhe/notes.txt）传递到文件服务器（他们称之为 Vice 的组），然后文件服务器将遍历路径名，找到所需的文件，并将整个文件发回给客户端。然后，客户端代码会将文件缓存在客户端的本地磁盘上（通过将其写入本地磁盘）。正如我们上面所说，后续的 read() 和 write() 系统调用在 AFS 中严格是本地的（不发生与服务器的通信）；它们只是重定向到文件的本地副本。由于 read() 和 write() 调用的行为就像对本地文件系统的调用一样，因此一旦访问了一个块，它也可能会缓存在客户端内存中。因此，AFS 还使用客户端内存来缓存其本地磁盘中的块副本。最后，完成后，AFS 客户端检查文件是否已被修改（即，它已被打开用于写入）；如果是，它将使用存储协议消息将新版本刷新回服务器，并将整个文件和路径名发送到服务器进行持久存储。 下次访问文件时，AFSv1 的效率会更高。具体来说，客户端代码首先联系服务器（使用 TestAuth 协议消息）以确定文件是否已更改。如果没有，客户端将使用本地缓存的副本，从而通过避免网络传输来提高性能。下面展示了AFSv1中的一些协议消息。请注意，该协议的早期版本仅缓存文件内容；例如，目录仅保存在服务器上。 TestAuth Test whether a file has changed (used to validate cached entries) GetFileStat Get the stat info for a file Fetch Fetch the contents of file Store Store this file on the server SetFileStat Set the stat info for a file ListDir List the contents of a directory ","date":"2024-05-11","objectID":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:2:1","tags":["OS"],"title":"Andrew文件系统","uri":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"2.2 存在的问题 AFS 第一个版本的一些关键问题促使设计人员重新考虑他们的文件系统。为了详细研究这些问题，AFS 的设计者花费了大量时间测量他们现有的原型，以找出问题所在。这样的实验是一件好事，因为测量是理解系统如何工作以及如何改进系统的关键；因此，获得具体、良好的数据是系统建设的必要组成部分。在他们的研究中，作者发现 AFSv1 的两个主要问题： 路径遍历成本太高：当执行 Fetch 或 Store 协议请求时，客户端将整个路径名（例如 /home/zfhe/notes.txt）传递给服务器。服务器为了访问该文件，必须执行完整的路径名遍历，首先在根目录中查找home，然后在home中查找zfhe，依此类推，一直沿着路径遍历，直到最后找到所需的文件。由于许多客户端同时访问服务器，AFS 的设计者发现服务器花费了大量的 CPU 时间只是沿着目录路径查找。 客户端发出过多的TestAuth 协议消息：与NFS 及其过多的GETATTR 协议消息非常相似，，AFSv1 也产生了大量流量，用于通过 TestAuth 协议信息检查本地文件（或其状态信息）是否有效。因此，服务器要花费大量时间告诉客户端是否可以使用其缓存的文件副本。大多数情况下，答案是文件没有变化。 AFSv1 实际上还存在两个问题：服务器之间的负载不均衡，并且服务器对每个客户端使用单独的进程，从而导致上下文切换和其他开销。通过引入卷解决了负载不均衡问题，管理员可以跨服务器移动卷以均衡负载； AFSv2 中通过使用线程而不是进程构建服务器来解决上下文切换问题。然而，我们在这里重点关注上面限制系统规模的两个主要协议问题。 上述两个问题限制了AFS的可扩展性；服务器CPU成为系统的瓶颈，每台服务器只能服务20个客户端而不至于过载。服务器接收到太多 TestAuth 消息，并且当它们接收到 Fetch 或 Store 消息时，会花费太多时间遍历目录层次结构。因此，AFS 设计者面临着一个问题： 如何设计可扩展的文件协议 应如何重新设计协议以最大限度地减少服务器交互的数量，即如何减少 TestAuth 消息的数量？此外，他们如何设计协议以使这些服务器交互高效？通过解决这两个问题，新协议将产生更具可扩展性的 AFS 版本。 ","date":"2024-05-11","objectID":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:2:2","tags":["OS"],"title":"Andrew文件系统","uri":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3 AFSv2 ","date":"2024-05-11","objectID":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:0","tags":["OS"],"title":"Andrew文件系统","uri":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3.1 基本介绍 AFSv2 引入了回调的概念，以减少客户端/服务器交互的次数。回调只是服务器对客户端的一个承诺，即当客户端缓存的文件被修改时，服务器将通知客户端。在系统中添加这种状态后，客户端就不再需要联系服务器来了解缓存文件是否仍然有效。相反，它会假定文件是有效的，直到服务器告诉它否则；请注意轮询与中断之间的类比。 AFSv2 还引入了**文件标识符（FID）**的概念（类似于 NFS 文件句柄），而不是路径名来指定客户端感兴趣的文件。AFS 中的 FID 由一个卷标识符、一个文件标识符和一个 “唯一标识符 “组成（以便在删除文件时重复使用卷和文件标识符）。因此，客户端不再向服务器发送整个路径名，并让服务器遍历路径名以找到所需的文件，而是逐步遍历路径名，缓存结果，并希望减少对服务器的负载。 例如，如果客户端访问文件/home/zfhe/notes.txt，而 home 是挂载在 / 上的 AFS 目录（即 / 是本地根目录，但 home 及其子目录在 AFS 中），客户端将首先获取 home 的目录内容，将其放入本地磁盘缓存，并在 home 上设置回调。然后，客户机将取回 zfhe 目录，将其放入本地磁盘缓存，并在 zfhe 上设置回调。最后，客户端会获取notes.txt，将这个常规文件缓存到本地磁盘，并设置回调，最后向调用应用程序返回一个文件描述符。这个过程如下图所示。 不过，与 NFS 的主要区别在于，每次获取目录或文件时，AFS 客户端都会与服务器建立回调，从而确保服务器会通知客户端其缓存状态的变化。这样做的好处显而易见：虽然对/home/zfhe/notes.txt 的首次访问会产生许多客户端-服务器信息（如上所述），但同时也会为所有目录以及notes.txt 文件建立回调，因此后续访问完全是本地操作，根本不需要与服务器交互。因此，在客户端缓存文件的常见情况下，AFS 的行为几乎与本地磁盘文件系统相同。如果访问一个文件不止一次，那么第二次访问的速度应该与本地访问文件的速度一样快。 ","date":"2024-05-11","objectID":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:1","tags":["OS"],"title":"Andrew文件系统","uri":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3.2 缓存一致性 缓存一致性不是万能的 在讨论分布式文件系统时，很多人都会提到文件系统提供的缓存一致性。然而，这种基本一致性并不能解决多个客户端访问文件的所有问题。例如，如果你正在建立一个代码库，有多个客户端执行代码的检入和检出，你就不能简单地依赖底层文件系统来为你完成所有工作；相反，你必须使用显式文件级锁定，以确保在发生这种并发访问时发生 “正确 “的事情。事实上，任何真正关心并发更新的应用程序都会增加额外的机制来处理冲突。基本一致性主要适用于临时使用，也就是说，当用户登录到不同的客户端时，他们希望在客户端上显示其文件的合理版本。如果对这些协议抱有更高的期望，就会让自己陷入失败、失望和充满泪水的沮丧之中。 当我们讨论 NFS 时，我们考虑了缓存一致性的两个方面：更新可见性和缓存陈旧性。 对于更新可见性，问题是：服务器何时会使用新版本的文件进行更新？ 对于缓存陈旧性，问题是：一旦服务器有了新版本，客户端多久才能看到新版本而不是旧的缓存副本？ 由于回调和全文件缓存，AFS 提供的缓存一致性很容易描述和理解。有两个重要的情况需要考虑：不同机器上的进程之间的一致性，以及同一机器上的进程之间的一致性。 在不同的计算机之间，AFS 使更新在服务器上可见，并在同一时间（即更新的文件关闭时）使缓存的副本失效。客户端打开一个文件，然后写入（可能重复）。当它最终关闭时，新文件将刷新到服务器（因此可见）。此时，服务器会“中断”任何具有缓存副本的客户端的回调；**中断是通过联系每个客户端并通知它对文件的回调不再有效来完成的。**此步骤确保客户端将不再读取文件的过时副本；这些客户端上的后续打开将需要从服务器重新获取文件的新版本（并且还将用于在文件的新版本上重新建立回调）。 AFS 对同一台机器上的进程之间的这种简单模型进行了例外处理。在这种情况下，对文件的写入对其他本地进程立即可见（即，进程不必等到文件关闭才能查看其最新更新）。这使得使用单台机器的行为完全符合您的预期，因为此行为基于典型的 UNIX 语义。只有当切换到不同的机器时，你才能检测到更通用的AFS一致性机制。 有一个有趣的跨机器案例值得进一步讨论。具体来说，在不同机器上的进程同时修改文件的罕见情况下，AFS 自然会采用所谓的“最后写入者获胜”方法（也许应该称为“最后关闭者获胜”）。具体来说，最后调用 close() 的客户端将最后更新服务器上的整个文件，因此将成为“获胜”文件，即保留在服务器上供其他人查看的文件。结果是一个由一个客户端或另一个客户端完整生成的文件。请注意与 NFS 等基于块的协议的区别：在 NFS 中，当每个客户端更新文件时，各个块的写入可能会被刷新到服务器，因此服务器上的最终文件可能是两个客户端更新的混合体。在许多情况下，这种混合文件输出没有多大意义，即想象一下 JPEG 图像被两个客户端分段修改；由此产生的写入组合不太可能构成有效的 JPEG。 下图中显示了其中一些不同场景的时间线。这些列显示了 $Client_1$ 上的两个进程（$P_1$ 和 $P_2$）及其缓存状态、$Client_2$ 上的一个进程 ($P_3$) 及其缓存状态以及服务器 (Server) 的行为，所有这些都在一个名为 $F$ 的文件上进行操作。对于服务器来说，图中只是显示了左边操作完成后的文件内容。 ","date":"2024-05-11","objectID":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:2","tags":["OS"],"title":"Andrew文件系统","uri":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3.3 崩溃恢复 从上面的描述中，你可能会感觉到崩溃恢复比 NFS 更复杂。你是对的。例如，假设服务器 (S) 在短时间内无法与客户端(C1) 取得联系，比如客户端 C1 正在重启。当 C1 不可用时，S 可能已尝试向其发送一条或多条回调召回消息；例如，假设 C1 在本地磁盘上缓存了文件 F，然后 C2（另一个客户端）更新了 F，从而导致 S 向所有缓存该文件的客户端发送消息，要求它们从本地缓存中删除该文件。由于 C1 在重启时可能会错过这些关键信息，因此在重新加入系统时，C1 应将其所有缓存内容视为可疑内容。因此，在下一次访问文件 F 时，C1 应首先询问服务器（通过 TestAuth 协议消息）其缓存的文件 F 副本是否仍然有效；如果有效，C1 可以使用它；如果无效，C1 应从服务器获取更新的版本。 服务器崩溃后的恢复也比较复杂。由此产生的问题是，回调是保存在内存中的；因此，当服务器重启时，它不知道哪台客户机拥有哪些文件。因此，服务器重启后，服务器的每个客户端都必须意识到服务器已经崩溃，并将其所有缓存内容视为可疑内容，并且（如上所述）在使用文件之前重新确定其有效性。 因此，服务器崩溃是一件大事，因为必须确保每个客户端都能及时意识到服务器崩溃，否则客户端就有可能访问过期文件。实现这种恢复的方法有很多，例如，当服务器重新启动并运行时，让服务器向每个客户端发送一条消息（说 “不要相信你的缓存内容！\"），或者让客户端定期检查服务器是否还活着（即所谓的 “心跳消息”）。正如你所看到的，建立一个可扩展性更强、更合理的缓存模型是有代价的；在 NFS 中，客户端几乎不会注意到服务器崩溃。 ","date":"2024-05-11","objectID":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:3","tags":["OS"],"title":"Andrew文件系统","uri":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3.4 可扩展性和性能 采用新协议后，对 AFSv2 进行了测量，发现其可扩展性远远超过原始版本。事实上，每台服务器可以支持大约 50 个客户端（而不是 20 个）。另一个好处是，客户端的性能往往非常接近本地性能，因为在普通情况下，所有文件访问都是本地的；文件读取通常会进入本地磁盘缓存（也可能进入本地内存）。只有在客户端创建新文件或写入现有文件时，才需要向服务器发送存储信息，从而用新内容更新文件。 我们还可以通过比较常见的文件系统访问情况和 NFS 来了解 AFS 的性能。下图显示了定性比较的结果。 在图中，我们分析了不同大小文件的典型读写模式。小文件有 $N_s$ 个块；中等文件有 $N_m$ 个块；大文件有 $N_L$ 个块。我们假定，小型和中型文件适合放在客户端内存中；大型文件适合放在本地磁盘上，但不适合放在客户端内存中。 为便于分析，我们还假设，通过网络访问远程服务器的文件块需要 $L_{net}$ 时间单位。访问本地内存需要 $L_{mem}$，访问本地磁盘需要 $L_{disk}$。一般假设是$L_{net} \u003e L_{disk} \u003e L_{mem}$。 最后，我们假设对文件的首次访问不在任何缓存中发生。如果相关缓存有足够的容量容纳文件，我们假设对文件的后续访问（即 “重读”）会在缓存中命中。 图中各列显示了特定操作（如小文件顺序读取）在 NFS 或 AFS 上大致花费的时间。最右边一列显示的是 AFS 与 NFS 的比例。 我们得出以下结论。首先，在许多情况下，每个系统的性能大致相当。例如，在首次读取文件时（如工作负载 1、3、5），从远程服务器获取文件的时间占主导地位，而且在两个系统上的时间相似。在这种情况下，您可能会认为 AFS 的速度会慢一些，因为它必须将文件写入本地磁盘；但是，本地（客户端）文件系统缓存会对这些写入进行缓冲，因此上述成本很可能是隐性的。同样，你可能会认为 AFS 从本地缓存副本读取文件的速度会更慢，这也是因为 AFS 将缓存副本存储在磁盘上。然而，AFS 也能从本地文件系统缓存中获益；AFS 上的读取可能会在客户端内存缓存中进行，性能与 NFS 类似。 其次，在大文件顺序重读（工作负载 6）过程中出现了一个有趣的差异。由于 AFS 有一个很大的本地磁盘缓存，当文件再次被访问时，它会从本地磁盘缓存中访问文件。相比之下，NFS 只能缓存客户端内存中的数据块；因此，如果重新读取大文件（即大于本地内存的文件），NFS 客户端将不得不从远程服务器重新获取整个文件。因此，假设远程访问确实比本地磁盘慢，在这种情况下，AFS 比 NFS 快 $\\frac{L_{net}}{L_{disk}}$ 的系数。我们还注意到，在这种情况下，NFS 会增加服务器负载，这也会对扩展性产生影响。 第三，我们注意到，顺序写入（新文件）在两个系统上的执行情况类似（工作负载 8、9）。在这种情况下，AFS 会将文件写入本地缓存副本；当文件关闭时，AFS 客户端会根据协议强制将文件写入服务器。NFS 会在客户端内存中缓冲写入，也许会因为客户端内存压力而强制将某些块写入服务器，但在文件关闭时肯定会将它们写入服务器，以保持 NFS 的关闭时刷新一致性。你可能会认为 AFS 的速度会更慢，因为它会将所有数据写入本地磁盘。但是，你要知道，它是在向本地文件系统写入数据；这些写入的数据首先提交到页面缓存，然后才（在后台）提交到磁盘，因此 AFS 可以利用客户端操作系统内存缓存基础架构的优势来提高性能。 第四，我们注意到 AFS 在顺序文件覆盖（工作负载 10）上的性能更差。到目前为止，我们假定写入的工作负载也在创建新文件；在这种情况下，文件存在，然后被覆盖写入。对于 AFS 来说，重写可能是一种特别糟糕的情况，因为客户端首先会完整地获取旧文件，然后再将其重写。与此相反，NFS 只需覆盖块，从而避免了最初的（无用的）读取。 最后，访问大文件中一小部分数据的工作负载在 NFS 上的表现要比 AFS 好得多（工作负载 7、11）。在这些情况下，AFS 协议会在打开文件时获取整个文件；但不幸的是，只会执行少量的读取或写入操作。更糟糕的是，如果文件被修改，整个文件都会被写回服务器，对性能的影响会加倍。NFS 作为基于块的协议，执行的 I/O 与读取或写入的大小成正比。总之，我们看到 NFS 和 AFS 的假设不同，因此实现的性能结果也不同，这并不奇怪。这些差异是否重要，始终是一个工作负载问题。 工作负载的重要性 评估任何系统的一大挑战是工作负载的选择。由于计算机系统的使用方式多种多样，因此有多种工作负载可供选择。存储系统设计人员应如何确定哪些工作负载是重要的，以便做出合理的设计决策？ AFS 的设计者根据衡量文件系统使用方式的经验，做出了某些工作负载假设；特别是，他们假设大多数文件不经常共享，并且整体上按顺序访问。考虑到这些假设，AFS 设计就非常有意义了。 然而，这些假设并不总是正确的。例如，假设有一个应用程序定期将信息附加到日志中。这些小日志写入会将少量数据添加到现有的大文件中，这对于 AFS 来说是相当有问题的。还存在许多其他困难的工作负载，例如事务数据库中的随机更新。 ","date":"2024-05-11","objectID":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:4","tags":["OS"],"title":"Andrew文件系统","uri":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"4 AFS：其他改进 就像我们在引入 Berkeley FFS（添加了符号链接和许多其他功能）时看到的那样，AFS 的设计者在构建系统时抓住了机会添加了许多功能，使系统更易于使用和管理。例如，AFS 为客户端提供了真正的全局命名空间，从而确保所有文件在所有客户端计算机上都以相同的方式命名。相比之下，NFS 允许每个客户端以他们喜欢的任何方式安装 NFS 服务器，因此只有按照约定（以及大量的管理工作），文件才能在客户端之间以类似的方式命名。 AFS 还非常重视安全性，并采用了对用户进行身份验证的机制，并确保如果用户愿意，可以将一组文件保持私有。相比之下，NFS 多年来对安全性的支持相当原始。 AFS 还包括用于灵活的用户管理访问控制的设施。因此，在使用 AFS 时，用户可以很好地控制谁可以访问哪些文件。 NFS 与大多数 UNIX 文件系统一样，对此类共享的支持要少得多。 最后，如前所述，AFS 添加了一些工具，使系统管理员能够更简单地管理服务器。在系统管理方面，AFS 遥遥领先于该领域。 ","date":"2024-05-11","objectID":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:4:0","tags":["OS"],"title":"Andrew文件系统","uri":"/posts/39.andrew%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"1 基本的分布式文件系统 分布式客户端/服务器计算最早应用于分布式文件系统领域。在这种环境中，有多台客户机和一台（或几台）服务器；服务器将数据存储在磁盘上，客户机通过格式良好的协议信息请求数据。下图描述了基本设置。 从图中可以看出，服务器拥有磁盘，客户端通过网络发送消息来访问这些磁盘上的目录和文件。我们为什么要费心这样的安排呢？ （即，为什么我们不让客户端使用他们的本地磁盘？）嗯，主要是这种设置允许在客户端之间轻松共享数据。因此，如果您访问一台计算机（客户端 0）上的文件，然后使用另一台计算机（客户端 2），您将拥有相同的文件系统视图。您的数据自然会在这些不同的机器之间共享。第二个好处是集中管理；例如，备份文件可以从少数服务器计算机而不是多个客户端完成。另一个优势可能是安全性。将所有服务器放在上锁的机房中可以防止出现某些类型的问题。 因此关键问题是： 如何构建分布式文件系统？需要考虑哪些关键方面？什么容易出错？我们可以从现有系统中学到什么？ 我们现在将研究简化的分布式文件系统的架构。一个简单的客户端/服务器分布式文件系统比我们迄今为止研究的文件系统具有更多的组件。在客户端，有一些客户端应用程序通过客户端文件系统访问文件和目录。客户端应用程序向客户端文件系统发出系统调用（例如 open()、read()、write()、close()、mkdir() 等），以便访问存储在服务器上的文件。因此，对于客户端应用程序来说，除了性能之外，文件系统似乎与本地（基于磁盘的）文件系统没有任何不同。这样，分布式文件系统提供了对文件的透明访问，这是一个显而易见的目标；毕竟，谁会愿意使用一个需要不同的应用程序接口或者使用起来很麻烦的文件系统呢？ 客户端文件系统的作用是执行服务这些系统调用所需的操作。例如，如果客户端发出 read() 请求，客户端文件系统可能会向服务器端文件系统（或者通常称为文件服务器）发送消息以读取特定块；然后，文件服务器将从磁盘（或其自己的内存缓存）读取该块，并将包含请求数据的消息发送回客户端。然后，客户端文件系统会将数据复制到提供给 read() 系统调用的用户缓冲区中，从而完成请求。请注意，客户端上同一块的后续 read() 可能会缓存在客户端内存中，甚至缓存在客户端磁盘上；在最好的情况下，不需要产生网络流量。 从这个简单的概述中，您应该了解到客户端/服务器分布式文件系统中有两个重要的软件部分：客户端文件系统和文件服务器。它们的行为共同决定了分布式文件系统的行为。现在是时候研究一个特定的系统了：Sun 的网络文件系统 (NFS)。 ","date":"2024-05-11","objectID":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:1:0","tags":["OS"],"title":"网络文件系统","uri":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"2 网络文件系统（NFS） Sun Microsystems 公司开发的分布式系统是最早也是相当成功的分布式系统之一，被称为 Sun 网络文件系统（或 NFS）。在定义 NFS 时，Sun 采用了一种不同寻常的方法：Sun 没有构建一个专有的封闭系统，而是开发了一个开放协议，简单地规定了客户机和服务器用于通信的确切信息格式。不同的团体可以开发自己的 NFS 服务器，从而在 NFS 市场上竞争，同时保持互操作性。这种做法取得了成功：如今有许多公司都在销售 NFS 服务器（包括 Oracle/Sun、NetApp、EMC、IBM 和其他公司），NFS 的广泛成功很可能归功于这种 “开放市场 “方法。 ","date":"2024-05-11","objectID":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:2:0","tags":["OS"],"title":"网络文件系统","uri":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"2.1 重点：简单快速的服务器崩溃恢复 在本章中，我们将讨论经典的 NFS 协议（版本 2，又称 NFSv2），该协议是多年来的标准；在向 NFSv3 迁移时进行了一些小改动，在向 NFSv4 迁移时进行了更大规模的协议改动。然而，NFSv2 既精彩又令人沮丧，因此成为我们关注的焦点。在 NFSv2 中，协议设计的主要目标是简单快速地恢复服务器崩溃。在多客户端、单服务器的环境中，这一目标是非常合理的；服务器宕机（或不可用）的任何一分钟都会让所有客户端机器（及其用户）不高兴，并影响工作效率。因此，服务器垮了，整个系统也就垮了。 2.1.1 快速崩溃恢复的关键：无状态 NFSv2 通过设计无状态协议实现了这一简单目标。根据设计，服务器不会跟踪每个客户端正在发生的任何事情。例如，服务器不知道哪些客户端正在缓存哪些数据块，也不知道每个客户端当前打开了哪些文件，更不知道文件的当前文件指针位置等。简而言之，服务器不会跟踪客户端正在做的任何事情；相反，协议的设计目的是在每个协议请求中提供完成请求所需的所有信息。 有状态（非无状态）协议的一个例子是 open() 系统调用。给定一个路径名，open() 返回一个文件描述符（整数）。该描述符将用于后续的 read() 或 write() 请求，以访问各种文件块，如下面这段代码所示： char buffer[MAX]; int fd = open(\"foo\", O_RDONLY); // get descriptor \"fd\" read(fd, buffer, MAX); // read MAX bytes from foo (via fd) read(fd, buffer, MAX); // read MAX bytes from foo ... read(fd, buffer, MAX); // read MAX bytes from foo close(fd); // close file 现在想象一下，客户端文件系统通过向服务器发送一条协议消息“打开文件‘foo’并给我返回一个描述符”来打开文件。然后，文件服务器在其本地打开该文件并将描述符发送回客户端。在后续读取中，客户端应用程序使用该描述符来调用 read() 系统调用；然后，客户端文件系统将消息中的描述符传递给文件服务器，表示“从我传递给您的描述符所引用的文件中读取一些字节”。 在这个例子中，文件描述符是客户端和服务器之间的一段共享状态（Ousterhout 称之为分布式状态）。正如我们上面所暗示的，共享状态使崩溃恢复变得复杂。想象一下，服务器在第一次读取完成后、客户端发出第二次读取之前崩溃了。服务器重新启动并运行后，客户端会发出第二次读取。不幸的是，服务器不知道 fd 引用的是哪个文件；该信息是短暂的（即在内存中），因此当服务器崩溃时就会丢失。为了处理这种情况，客户端和服务器必须参与某种恢复协议，客户端将确保在其内存中保留足够的信息，以便能够告诉服务器它需要知道什么（在这种情况下 ，该文件描述符 fd 引用文件 foo) 当您考虑有状态服务器必须处理客户端崩溃这一事实时，情况会变得更糟。例如，想象一下，一个客户端打开一个文件然后崩溃了。 open() 使用了服务器上的文件描述符；服务器如何知道可以关闭给定文件？在正常操作中，客户端最终会调用 close() ，从而通知服务器应该关闭文件。然而，当客户端崩溃时，服务器永远不会收到 close()，因此必须注意到客户端已崩溃才能关闭文件。 出于这些原因，NFS 的设计者决定采用无状态方法：每个客户端操作都包含完成请求所需的所有信息。不需要花哨的崩溃恢复；服务器刚刚重新开始运行，而客户端在最坏的情况下可能必须重试请求。 2.1.2 NFSv2 协议 由此，我们得出了 NFSv2 协议的定义。我们的问题陈述很简单： 如何定义无状态文件协议 如何定义网络协议以实现无状态操作？显然，像 open() 这样的有状态调用不能作为讨论的一部分（因为这需要服务器跟踪打开的文件）；但是，客户端应用程序会希望调用 open()、read()、write()、close() 和其他标准 API 调用来访问文件和目录。因此，作为一个细化的问题，我们该如何定义协议才能既无状态又支持 POSIX 文件系统 API 呢？ 理解 NFS 协议设计的关键之一是理解文件句柄。文件句柄用于唯一描述特定操作要操作的文件或目录；因此，许多协议请求都包含一个文件句柄。 你可以认为文件句柄有三个重要组成部分：卷标识符、inode号和生成号；这三者共同构成了客户端希望访问的文件或目录的唯一标识符。 卷标识符告知服务器该请求指向哪个文件系统（一个 NFS 服务器可以导出多个文件系统）； Inode号告诉服务器该请求访问的是该分区中的哪个文件。 最后，在重复使用inode号时需要使用生成号；每当重复使用一个inode号时，服务器就会递增生成号，以确保使用旧文件句柄的客户端不会意外访问新分配的文件。 以下是协议中一些重要部分的摘要；完整的协议可从其他地方获得。 NFSPROC_GETATTR: # 期望：文件句柄 # 返回：属性 expects: file handle returns: attributes NFSPROC_SETATTR: # 期望：文件句柄，属性 # 返回：无 expects: file handle, attributes returns: nothing NFSPROC_LOOKUP: # 期望：目录文件句柄，要查找的文件/目录的名称 # 返回：文件句柄 expects: directory file handle, name of file/directory to look up returns: file handle NFSPROC_READ: # 期望：文件句柄，偏移量，计数 # 返回：数据，属性 expects: file handle, offset, count returns: data, attributes NFSPROC_WRITE: # 期望：文件句柄，偏移量，计数，数据 # 返回：属性 expects: file handle, offset, count, data returns: attributes NFSPROC_CREATE: # 期望：目录文件句柄，文件名，属性 # 返回：无 expects: directory file handle, name of file, attributes returns: nothing NFSPROC_REMOVE: # 期望：目录文件句柄，要移除的文件名 # 返回：无 expects: directory file handle, name of file to be removed returns: nothing NFSPROC_MKDIR: # 期望：目录文件句柄，目录名，属性 # 返回：文件句柄 expects: directory file handle, name of directory, attributes returns: file handle NFSPROC_RMDIR: # 期望：目录文件句柄，要移除的目录名 # 返回：无 expects: directory file handle, name of directory to be removed returns: nothing NFSPROC_READDIR: # 期望：目录句柄，要读取的字节数，标识符 # 返回：目录条目，标识符（以获取更多条目） expects: directory handle, count of bytes to read, cookie returns: directory entries, cookie (to get more entries) 我们简要介绍一下协议的重要组成部分。首先，LOOKUP 协议报文用于获取文件句柄，然后使用该句柄访问文件数据。客户端传递一个目录文件句柄和要查找的文件名，服务器会将该文件（或目录）的句柄及其属性传回客户端。 例如，假设客户端已经拥有文件系统根目录 (/) 的目录文件句柄（实际上，这可以通过 NFS 挂载协议获得，这是客户端和服务器首次连接的方式；为简洁起见，我们在此不讨论挂载协议）。如果在客户端运行的应用程序打开文件 /foo.txt，客户端文件系统就会向服务器发送一个查找请求，将根文件句柄和文件名 foo.txt 传递给服务器；如果请求成功，就会返回 foo.txt 的文件句柄（和属性）。 如果你想知道，属性只是文件系统跟踪每个文件的元数据，包括文件创建时间、最后修改时间、大小、所有权和权限信息等字段，也就是在文件上调用 stat() 时会返回的信息。 一旦有了文件句柄，客户端就可以对文件发出 READ 和 WRITE 协议消息，分别读取或写入文件。读取协议消息要求传递文件句柄、文件偏移量和要读取的字节数。然后，服务器就能发出读取命令（毕竟，句柄会告诉服务器要从哪个卷和哪个 inode 读取，偏移量和字节数会告诉服务器要读取文件的哪个字节），并将数据返回给客户端（如果读取失败，则返回错误信息）。写入（WRITE）的处理方式与此类似，只是数据从客户端传递到服务器，并只返回一个成功代码。 最后一个有趣的协议信息是 GETATTR 请求；给定一个文件句柄后，它只需获取该文件的属性，包括文件的最后修改时间。在下文讨论缓存时，我们将看到该协议请求在 NFSv2 中的重要性。 ","date":"2024-05-11","objectID":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:2:1","tags":["OS"],"title":"网络文件系统","uri":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"2.2 从协议到分布式文件系统 希望您现在已经了解如何将该协议转变为跨客户端文件系统和文件服务器的文件系统。客户端文件系统跟踪打开的文件，并且通常将应用程序请求转换为相关的协议消息集。服务器只是响应协议消息，每个消息都包含完成请求所需的所有信息。 例如，让我们考虑一个读取文件的简单应用程序。在下图中，我们显示了应用程序进行了哪些系统调用，以及客户端文件系统和文件服务器响应此类调用时执行的操作。 首先，注意客户端如何跟踪文件访问的所有相关状态，包括整数文件描述符到 NFS 文件句柄的映射以及当前文件指针。这使得客户端能够将每个读取请求（您可能已经注意到，没有明确指定要读取的偏移量）转换为格式正确的读取协议消息，该消息准确地告诉服务器要读取文件中的哪些字节。成功读取后，客户端更新当前文件位置；后续读取将使用相同的文件句柄但偏移量不同。 其次，您可能会注意到服务器交互发生的位置。当文件第一次打开时，客户端文件系统会发送一个LOOKUP请求消息。事实上，如果必须遍历长路径名（例如，/home/zfhe/foo.txt），客户端将发送三个 LOOKUP：一个在目录 / 中查找 home，一个在 home 中查找 zfhe，最后一个在 zfhe 中查找 foo.txt。 第三，您可能会注意每个服务器请求都包含完成请求所需的全部信息。这个设计要点对于从服务器故障中从容恢复至关重要，我们现在将详细讨论；它确保服务器不需要状态就能响应请求。 ","date":"2024-05-11","objectID":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:2:2","tags":["OS"],"title":"网络文件系统","uri":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"2.3 使用幂等操作处理服务器故障 客户端向服务器发送信息时，有时会收不到回复。造成这种无法回复的原因有很多。在某些情况下，信息可能被网络丢弃；网络确实会丢失信息，因此请求或回复都可能丢失，这样客户端就永远不会收到回复。 也有可能是服务器崩溃了，因此目前没有响应信息。一段时间后，服务器将重新启动并重新开始运行，但在此期间，所有请求都已丢失。在所有这些情况下，客户端都会遇到一个问题：当服务器未能及时回复时该怎么办？ 在 NFSv2 中，客户端以一种单一、统一和优雅的方式处理所有这些故障：只需重试请求即可。具体来说，在发送请求后，客户端会设置一个计时器，在指定时间段后关闭。如果在定时器关闭前收到了回复，定时器就会被取消，一切正常。但是，如果在收到任何回复之前计时器就关闭了，客户端就会认为请求没有被处理，并重新发送请求。如果服务器回复了，则一切正常，客户端也顺利地解决了问题。 客户端之所以能简单地重试请求（不管失败的原因是什么），是因为大多数 NFS 请求都有一个重要特性：它们都是幂等的。当多次执行该操作的效果等同于单次执行该操作的效果时，我们就称该操作为幂等操作。例如，如果将一个值存储到内存位置三次，与存储一次的效果相同；因此，“将值存储到内存 “就是一个幂等操作。但是，如果将一个计数器递增三次，其结果与只递增一次的结果不同，因此 “递增计数器 “不是幂等操作。更一般地说，任何只读取数据的操作显然都是幂等的，而更新数据的操作则必须更仔细地考虑，以确定它是否具有这种特性。 NFS 崩溃恢复设计的核心是大多数常见操作的幂等性。LOOKUP 和 READ 请求具有微不足道的幂等性，因为它们只从文件服务器读取信息，而不更新信息。更有趣的是，WRITE 请求也是幂等的。例如，如果 WRITE 失败，客户端只需重试即可。WRITE 消息包含数据、计数和（重要的）要写入数据的准确偏移量。因此，只要知道多次写入的结果与单次写入的结果相同，就可以重复写入。 这样，客户端就能以统一的方式处理所有超时。 如果只是丢失了 WRITE 请求（上述情况 1），客户端将重试，服务器将执行写入操作，一切正常。 同样的情况也会发生，如果在发送请求时服务器碰巧宕机，但在发送第二个请求时又恢复运行，那么一切都会如愿以偿（情况 2）。 最后，服务器可能会接收到写入请求，向磁盘发出写入操作，并发送回复。这个回复可能会丢失（情况 3），再次导致客户机重新发送请求。当服务器再次收到请求时，它只会做完全相同的事情：将数据写入磁盘并回复说已经写入。如果这次客户端收到了回复，那么一切又都正常了，这样客户端就以统一的方式处理了信息丢失和服务器故障。 不过有些操作很难做到幂等。例如，当你试图创建一个已经存在的目录时，你会被告知 mkdir 请求失败。因此，在 NFS 中，如果文件服务器接收到 MKDIR 协议信息并成功执行，但却丢失了回复，那么客户端可能会重复该操作并遭遇失败，而实际上该操作一开始是成功的，只是在重试时失败了。因此，生活并不完美。 TIP：幂等性非常强大 在构建可靠系统时，幂等性是一个有用的属性。当一个操作可以多次发出时，处理操作失败就容易得多；你可以重试。如果操作不是幂等的，生活就会变得更加困难。 ","date":"2024-05-11","objectID":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:2:3","tags":["OS"],"title":"网络文件系统","uri":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3 提高性能：客户端缓存 ","date":"2024-05-11","objectID":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:0","tags":["OS"],"title":"网络文件系统","uri":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3.1 基本介绍 分布式文件系统的优点有很多，但通过网络发送所有读写请求可能会导致很大的性能问题：网络通常速度不快，尤其是与本地内存或磁盘相比。那么，又一个问题：如何提高分布式文件系统的性能？ 答案是客户端缓存。 NFS 客户端文件系统将从服务器读取的文件数据（和元数据）缓存在客户端内存中。因此，虽然第一次访问的成本很高（即，它需要网络通信），但后续访问很快就会从客户端内存中得到服务。 高速缓存还充当写入的临时缓冲区。当客户端应用程序首次写入文件时，客户端会先将数据缓冲在客户端内存中（与从文件服务器读取的数据位于同一缓存中），然后再将数据写出到服务器。这种写入缓冲非常有用，因为它将应用程序 write() 延迟与实际写入性能解耦，即应用程序对 write() 的调用立即成功（并且只是将数据放入客户端文件系统的缓存中）；只有稍后数据才会被写出到文件服务器。 因此，NFS 客户端缓存数据并且性能通常很好，我们就完成了，对吗？不幸的是，不完全是。将缓存添加到具有多个客户端缓存的任何类型的系统中都会带来一个巨大且有趣的挑战，我们将其称为缓存一致性问题。 ","date":"2024-05-11","objectID":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:1","tags":["OS"],"title":"网络文件系统","uri":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3.2 缓存一致性问题 缓存一致性问题最好用两个客户端和一个服务器来说明。假设客户端 C1 读取文件 F，并在其本地缓存中保留该文件的副本。现在想象一个不同的客户端 C2 覆盖文件 F，从而更改其内容；我们将文件的新版本称为 F（版本 2）或 F[v2]，将旧版本称为 F[v1]，这样我们就可以保持两者不同（当然，文件具有相同的名称，只是内容不同）。最后，还有第三个客户端 C3，它尚未访问文件 F。 您可能会看到即将出现的问题，如下图所示。 事实上，有两个子问题。 第一个子问题是客户端 C2 在将其写入传播到服务器之前可能会在其缓存中缓冲一段时间；在这种情况下，虽然 F[v2] 位于 C2 的内存中，但来自另一个客户端（例如 C3）对 F 的任何访问都将获取文件的旧版本 (F[v1])。因此，通过在客户端缓冲写入，其他客户端可能会获得该文件的过时版本，这可能是不合需要的；事实上，想象一下这样的情况：您登录到机器 C2，更新 F，然后登录到 C3 并尝试读取文件，结果却得到旧副本！当然，这可能会令人沮丧。因此，我们将这方面的缓存一致性问题称为更新可见性；一个客户端的更新何时对其他客户端可见？ 缓存一致性的第二个子问题是陈旧的缓存；在这种情况下，C2 最终将其写入刷新到文件服务器，因此服务器具有最新版本（F[v2]）。然而，C1 的缓存中仍然有 F[v1]；如果在 C1 上运行的程序读取文件 F，它将获得陈旧版本 (F[v1])，而不是最新副本 (F[v2])，这（通常）是不可取的。 NFSv2 实现通过两种方式解决这些缓存一致性问题。 首先，为了解决更新可见性，客户端实现有时称为“关闭时刷新”（也称为“关闭到打开”）一致性语义；具体来说，当客户端应用程序写入文件并随后关闭文件时，客户端会将所有更新（即缓存中的脏页）刷新到服务器。通过关闭时刷新一致性，NFS 可确保后续从另一个节点打开时将看到最新的文件版本。 其次，为了解决陈旧缓存问题，NFSv2 客户端在使用其缓存内容之前首先检查文件是否已更改。具体来说，在使用缓存块之前，客户端文件系统将向服务器发出 GETATTR 请求以获取文件的属性。重要的是，属性包括有关文件最后一次在服务器上修改的时间的信息；如果修改时间比文件被提取到客户端缓存的时间更新，则客户端会使该文件无效，从而将其从客户端缓存中删除，并确保后续读取将转到服务器并检索最新的文件的版本。另一方面，如果客户端发现它具有该文件的最新版本，它将继续使用缓存的内容，从而提高性能。 当 Sun 的原始团队针对陈旧缓存问题实施此解决方案时，他们意识到了一个新问题：突然，NFS 服务器被 GETATTR 请求淹没。遵循的一个良好的工程原则是针对常见情况进行设计，并使其运行良好；在这里，尽管常见情况是仅从单个客户端访问文件（可能重复），**但客户端始终必须向服务器发送 GETATTR 请求以确保没有其他人更改该文件。**因此，客户端轰炸服务器，不断询问“有人更改了这个文件吗？”，而大多数时候没有人更改过。 为了（在某种程度上）解决这种情况，每个客户端都添加了属性缓存。客户端在访问文件之前仍然会验证文件，但大多数情况下只会查看属性缓存以获取属性。特定文件的属性在第一次访问该文件时被放置在缓存中，然后在一定时间（例如 3 秒）后超时。因此，在这三秒钟内，所有文件访问都将确定可以使用缓存的文件，从而在与服务器没有网络通信的情况下执行此操作。 ","date":"2024-05-11","objectID":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:2","tags":["OS"],"title":"网络文件系统","uri":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3.3 评估 NFS 缓存一致性 关于 NFS 缓存一致性的最后几句话。添加关闭时刷新行为是为了“有意义”，但引入了一定的性能问题。具体来说，如果在客户端上创建了临时或短暂的文件，然后很快将其删除，它仍然会被强制发送到服务器。更理想的实现可能会将这些短暂的文件保留在内存中，直到它们被删除，从而完全消除服务器交互，也许会提高性能。 更重要的是，在 NFS 中添加属性缓存使得人们很难理解或推断到底获得的文件版本是什么。有时你会得到最新版本；有时，您会得到旧版本，只是因为您的属性缓存尚未超时，因此客户端很乐意为您提供客户端内存中的内容。尽管这在大多数情况下都很好，但它偶尔会（而且仍然如此！）导致奇怪的行为。这样我们就描述了 NFS 客户端缓存的奇怪之处。它是一个有趣的例子，其中实现的细节用于定义用户可观察的语义，而不是相反。 ","date":"2024-05-11","objectID":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:3","tags":["OS"],"title":"网络文件系统","uri":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"4 对服务器端写缓冲的影响 到目前为止，我们的重点一直放在客户端缓存上，这也是最有趣的问题所在。不过，NFS 服务器往往也是拥有大量内存的装备精良的机器，因此它们也有缓存问题。当从磁盘读取数据（和元数据）时，NFS 服务器会将其保存在内存中，随后对数据（和元数据）的读取将不会转到磁盘，这有可能（小幅）提高性能。 更有趣的是写缓冲。NFS 服务器在强制写入稳定存储（如磁盘或其他持久性设备）之前，绝对不会返回成功的 WRITE 协议请求。虽然它们可以在服务器内存中放置数据副本，但向客户端返回 WRITE 协议请求成功可能会导致不正确的行为。 答案就在于我们对客户端如何处理服务器故障的假设。想象一下客户端发出的以下写入序列： write(fd, a_buffer, size); // fill first block with a’s write(fd, b_buffer, size); // fill second block with b’s write(fd, c_buffer, size); // fill third block with c’s 这些写入会先用 a 块、b 块和 c 块覆盖文件的三个块。因此，如果文件最初看起来像这样： xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz 我们可能期望这些写入后的最终结果是这样的，其中 x、y 和 z 将分别被 a、b 和 c 覆盖。 aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc 现在，为了举例，我们假设这三个客户端写入作为三个不同的 WRITE 协议消息发送到服务器。假设服务器收到第一个 WRITE 消息并将其发送到磁盘，并且客户端通知其成功。现在假设第二次写入只是缓冲在内存中，并且服务器在将其强制写入磁盘之前也会向客户端报告其成功；不幸的是，服务器在将其写入磁盘之前崩溃了。服务器很快重启，收到第三个写请求，也成功了。 因此，对于客户端来说，所有请求都成功了，但令我们惊讶的是文件内容如下所示： aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy \u003c--- oops cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc 因为服务器在将第二次写入提交到磁盘之前告诉客户端第二次写入成功，所以文件中会留下旧的块，这可能是灾难性的，具体取决于应用程序。 为了避免这个问题，NFS 服务器必须将每次写入提交到稳定（持久）存储，然后再通知客户端成功；这样做使客户端能够在写入期间检测到服务器故障，从而重试直到最终成功。这样做可以确保我们永远不会像上面的示例一样最终出现文件内容混合的情况。 这一要求在 NFS 服务器实现中引起的问题是，如果不小心的话，写入性能可能会成为主要的性能瓶颈。事实上，一些公司（例如 Network Appliance）的成立只是为了构建一个可以快速执行写入的 NFS 服务器；他们使用的一个技巧是首先将写入操作放入电池支持的内存中，从而能够快速回复写入请求，而不必担心丢失数据，并且无需立即写入磁盘；第二个技巧是使用专门设计的文件系统设计，以便在最终需要时快速写入磁盘。 ","date":"2024-05-11","objectID":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:4:0","tags":["OS"],"title":"网络文件系统","uri":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"5 总结 在 NFS 中实现快速、简单的崩溃恢复这一主要目标的关键在于无状态协议的设计。崩溃后，服务器可以快速重新启动并再次开始服务请求；客户端只需重试请求，直到成功为止。 使请求具有幂等性是NFS 协议的一个核心方面。当多次执行某个操作的效果与执行一次相同时，该操作就是幂等的。在NFS中，幂等性使客户端能够无忧重试，并统一客户端丢失消息重传以及客户端处理服务器崩溃的方式。 性能问题决定了对客户端缓存和写缓冲的需求，但会带来缓存一致性问题。 NFS 实现提供了一种通过多种方式实现缓存一致性的工程解决方案：**关闭时刷新（关闭到打开）**方法可确保当文件关闭时，其内容被强制传输到服务器，从而使其他客户端能够观察到文件的更新。属性缓存减少了向服务器检查文件是否已更改的频率（通过 GETATTR 请求）。 NFS 服务器必须在返回成功之前向持久介质提交写入；否则，可能会导致数据丢失。 为了支持NFS 集成到操作系统中，Sun 引入了VFS/Vnode 接口，使多个文件系统实现能够在同一操作系统中共存。 ","date":"2024-05-11","objectID":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:5:0","tags":["OS"],"title":"网络文件系统","uri":"/posts/38.%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"1 引言 分布式系统改变了世界的面貌。当您的网络浏览器连接到地球上其他地方的网络服务器时，它正在参与看似简单形式的客户端/服务器（CS）分布式系统。然而，当您联系 Google 或 Facebook 等现代网络服务时，您不仅仅是在与一台机器进行交互。在幕后，这些复杂的服务是由大量（即数千台）机器构建的，每台机器相互协作以提供站点的特定服务。 构建分布式系统时会出现许多新的挑战。我们主要关注的是失败；机器、磁盘、网络和软件都会时不时地出现故障，因为我们不（并且可能永远不会）知道如何构建“完美”的组件和系统。然而，当我们构建现代 Web 服务时，我们希望它对客户来说似乎永远不会失败；我们怎样才能完成这个任务呢？ 关键：如何构建在组件出现故障时仍能正常工作的系统？ 有趣的是，虽然失败是构建分布式系统的主要挑战，但它也代表着机遇。是的，机器会出故障；但一台机器发生故障并不意味着整个系统一定会发生故障。通过将一组机器集合在一起，我们可以构建一个似乎很少发生故障的系统，尽管它的组件经常发生故障。这一事实是分布式系统的核心魅力和价值，也是为什么它们成为您使用的几乎所有现代网络服务（包括 Google、Facebook 等）的基础。 TIP：通信本质上是不可靠的 在几乎所有情况下，最好将通信视为一种本质上不可靠的活动。bit损坏、链路和机器瘫痪或无法工作，以及传入数据包缺乏缓冲空间，都会导致同样的结果：数据包有时无法到达目的地。要在这种不可靠的网络之上建立可靠的服务，我们必须考虑能够应对数据包丢失的技术。 还存在其他重要问题。系统性能往往至关重要；由于网络将我们的分布式系统连接在一起，系统设计者往往必须仔细考虑如何完成既定任务，尽量减少发送信息的数量，并进一步提高通信效率（低延迟、高带宽）。 最后，安全也是一个必要的考虑因素。确保远程方的真实身份成为一个核心问题。此外，确保第三方无法监视或改变两个人之间正在进行的通信也是一个挑战。 在本介绍中，我们将讨论分布式系统中最基本的新问题：通信。也就是说，分布式系统中的机器应该如何相互通信？？我们将从最基本的可用原语（消息）开始，并在它们之上构建一些更高级别的原语。正如我们上面所说，故障将成为焦点：通信层应如何处理故障？ ","date":"2024-05-11","objectID":"/posts/37.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/:1:0","tags":["OS"],"title":"分布式系统","uri":"/posts/37.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"2 通信基础 现代网络的核心原则是通信从根本上来说是不可靠的。无论是在广域互联网中，还是在 Infiniband 等局域高速网络中，数据包经常会丢失、损坏或无法到达目的地。 造成数据包丢失或损坏的原因有很多。有时，在传输过程中，某些位会由于电气或其他类似问题而翻转。有时，系统中的某个元件（例如网络链路或数据包路由器甚至远程主机）会因某种原因损坏或无法正常工作；网络电缆确实会被意外切断，至少有时是这样。 然而，更根本的是由于网络交换机、路由器或端点内缺乏缓冲而导致的数据包丢失。具体来说，即使我们可以保证所有链路正常工作，并且系统中的所有组件（交换机、路由器、终端主机）都按预期启动并运行，但由于以下原因，仍然有可能发生丢失。 想象一下一个数据包到达路由器；要处理数据包，必须将其放置在路由器内存中的某个位置。如果许多此类数据包同时到达，则路由器内的内存可能无法容纳所有数据包。此时路由器唯一的选择是丢弃一个或多个数据包。同样的行为也发生在终端主机上；当你向一台机器发送大量消息时，机器的资源很容易被淹没，从而再次出现丢包。 因此，数据包丢失是网络中的基础。那么问题就变成了：我们该如何应对？ ","date":"2024-05-11","objectID":"/posts/37.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/:2:0","tags":["OS"],"title":"分布式系统","uri":"/posts/37.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3 不可靠通信层 一种简单的方法是：我们不去处理它。因为某些应用程序知道如何处理数据包丢失，所以有时让它们与基本的不可靠消息传递层进行通信是有用的，这是人们经常听到的端到端论点的一个例子。UDP/IP 网络协议栈就是这种不可靠层的一个很好的例子，目前几乎所有的现代系统都有这种协议栈。使用 UDP 时，进程使用socket API 创建通信端点；其他机器（或同一机器）上的进程向原始进程发送 UDP 数据报（数据报是固定大小的报文，最大不超过某个最大值）。 端到端论点 端到端论点认为，系统的最高层，即通常位于 “端 “的应用程序，最终是分层系统中唯一能真正实现某些功能的地方。在具有里程碑意义的论文中，Saltzer 等人通过一个极好的例子论证了这一点：两台机器之间的可靠文件传输。如果要将文件从机器 A 传输到机器 B，并确保最终到达机器 B 的字节与开始到达机器 A 的字节完全相同，就必须进行 “端到端 “检查；而网络或磁盘等较低级别的可靠机制则无法提供这种保证。 与此形成鲜明对比的是一种试图通过在系统较低层增加可靠性来解决可靠文件传输问题的方法。例如，我们建立了一个可靠的通信协议，并用它来建立可靠的文件传输。该通信协议保证发送方发送的每个字节都能被接收方按顺序接收，例如使用超时/重试、确认和序列号。不幸的是，使用这样的协议并不能实现可靠的文件传输；试想一下，在通信开始之前，发送方内存中的字节就已经损坏，或者接收方将数据写入磁盘时发生了什么不好的事情。在这种情况下，即使字节在网络上可靠地传输，我们的文件传输最终也是不可靠的。要建立可靠的文件传输，必须包括端到端的可靠性检查，例如，在整个传输完成后，读回接收方磁盘上的文件，计算校验和，并将校验和与发送方的文件进行比较。 这句格言的推论是，有时让下层提供额外功能确实可以提高系统性能或优化系统。因此，你不应该排除在系统中的较低层次使用这种机制；相反，你应该仔细考虑这种机制的效用，考虑到它在整个系统或应用程序中的最终用途。 下面这两段代码显示了构建在 UDP/IP 之上的简单客户端和服务器。客户端可以向服务器发送消息，然后服务器做出响应。通过这么少量的代码，您就拥有了开始构建分布式系统所需的一切！ // client.c #include \u003cstdio.h\u003e #include \"udp.h\" #define BUFFER_SIZE 1024 int main() { struct sockaddr_in addrSend, addrRecv; int fd = UDP_Open(CLIENT_PORT); int rc = UDP_FillSockAddr(\u0026addrSend, \"localhost\", SERVER_PORT); char message[BUFFER_SIZE]; sprintf(message, \"hello world\"); printf(\"client:: sending message [%s]\\n\", message); rc = UDP_Write(fd, \u0026addrSend, message, BUFFER_SIZE); if (rc \u003c 0) { fprintf(stderr, \"Client:: Failed to send message\\n\"); return -1; } printf(\"client:: waiting for reply...\\n\"); rc = UDP_Read(fd, \u0026addrRecv, message, BUFFER_SIZE); if (rc \u003c 0) { fprintf(stderr, \"Client:: Failed to read message\\n\"); return -1; } printf(\"client:: read %d bytes (message: %s)\\n\", rc, message); return 0; } //server.c #include \u003cstdio.h\u003e #include \"udp.h\" #define BUFFER_SIZE 1024 int main(int argc, char **argv) { int fd = UDP_Open(SERVER_PORT); if (fd \u003c 0) { fprintf(stderr, \"Failed to create socket\\n\"); return -1; } while (1) { struct sockaddr_in addr; char buffer[BUFFER_SIZE]; printf(\"server:: waiting for data...\\n\"); int rc = UDP_Read(fd, \u0026addr, buffer, 1024); printf(\"server:: read %d bytes (message: %s)\\n\", rc, buffer); if (rc \u003e 0) { char reply[BUFFER_SIZE]; sprintf(reply, \"goodbye world\"); rc = UDP_Write(fd, \u0026addr, reply, BUFFER_SIZE); printf(\"server:: reply\\n\"); } } return 0; } UDP 是不可靠通信层的一个很好的例子。而发送方从不会因此被告知数据包丢失。但是，这并不意味着 UDP 完全不防范任何故障。例如，UDP 包含一个校验和来检测某些形式的数据包损坏。 然而，由于许多应用程序只是想将数据发送到目的地而不担心数据包丢失，因此我们需要更多。具体来说，我们需要在不可靠的网络上进行可靠的通信。 ","date":"2024-05-11","objectID":"/posts/37.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/:3:0","tags":["OS"],"title":"分布式系统","uri":"/posts/37.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"4 可靠的通信层 为了构建可靠的通信层，我们需要一些新的机制和技术来处理丢包。让我们考虑一个简单的示例，其中客户端通过不可靠的连接向服务器发送消息。我们必须回答的第一个问题：发送者如何知道接收者确实收到了消息？ 我们将使用的技术称为确认，简称 ack。想法很简单：发送者向接收者发送消息；然后接收者发回一条短消息以确认其收到。下图描述了该过程。 当发送方收到消息的确认时，它就可以放心，接收方确实收到了原始消息。但是，如果发送方没有收到确认，该怎么办？ 为了处理这种情况，我们需要一个额外的机制，称为超时。当发送者发送消息时，发送者现在设置一个计时器在一段时间后关闭。如果此时未收到确认，则发送方断定消息已丢失。然后，发送者只需重试发送，再次发送相同的消息，希望这次能够成功。为了使这种方法发挥作用，发送者必须保留消息的副本，以备需要再次发送时使用。超时和重试的结合导致一些人将这种方法称为超时/重试，下图显示了一个示例。 不幸的是，这种形式的超时/重试还不够。下图显示了可能导致问题的数据包丢失示例。 在此示例中，丢失的不是原始消息，而是确认消息。从发送方的角度来看，情况似乎是一样的：没有收到确认，因此需要超时和重试。但从接收者的角度来看，情况就大不一样了：现在同一条消息已经收到两次了！虽然在某些情况下这可能是可以的，但一般来说是不行的；想象一下当您下载文件并且在下载过程中重复额外的数据包时会发生什么。因此，当我们的目标是建立一个可靠的消息层时，我们通常还希望保证接收者只接收每条消息一次。 为了使接收方能够检测到重复的消息传输，发送方必须以某种独特的方式识别每条消息，并且接收方需要某种方式来跟踪它之前是否已经看过每条消息。当接收方看到重复传输时，它只是确认消息，但（关键）不会将消息传递给接收数据的应用程序。因此，发送方收到 ack，但消息不会被接收两次，从而保留了上述的恰好一次语义。有多种方法可以检测重复消息。例如，发送者可以为每条消息生成一个唯一的ID；接收者可以追踪它所见过的每一个ID。这种方法可行，但成本高昂，需要无限的内存来跟踪所有 ID。 有一种更简单的方法可以解决这个问题，只需要很少的内存，这种机制被称为序列计数器。使用序列计数器时，发送方和接收方商定一个计数器的起始值（如 $1$），由双方共同维护。每当发送一条信息时，计数器的当前值就会随信息一起发送；这个计数器值（$N$）就是信息的 ID。信息发送后，发送方会递增计数器值（到 $N + 1$）。 接收方使用其计数器值作为该发送方发来信息的 ID 的预期值。如果接收到的信息 ID（N）与接收者的计数器（也是 N）相匹配，接收者就会接收该信息并将其上传给应用程序；在这种情况下，接收者就会断定这是第一次收到该信息。然后，接收方递增计数器（到 $N + 1$），等待下一条信息。 如果丢失了应答，发送方将超时并重新发送信息 $N$。这一次，接收方的计数器更高（$N + 1$），因此接收方知道自己已经收到了这条信息。因此，它会接收信息，但不会将其上传给应用程序。通过这种简单的方式，序列计数器可用于避免重复。 最常用的可靠通信层被称为 TCP/IP，简称 TCP。TCP 比我们上面描述的要复杂得多，包括处理网络拥塞、多个未处理请求以及数百种其他小调整和优化的机制。 TIP：小心设置超时值 正如您可能从讨论中猜到的那样，正确设置超时值是使用超时重试消息发送的一个重要方面。 如果超时太小，发送方将不必要地重新发送消息，从而浪费发送方的CPU时间和网络资源。 如果超时太大，则发送方等待太长时间才能重新发送，从而降低发送方的感知性能。 因此，从单个客户端和服务器的角度来看，“正确”值是等待足够长的时间来检测数据包丢失，但不再等待。 然而，正如我们将在以后的章节中看到的那样，分布式系统中通常不仅仅只有一个客户端和服务器。在许多客户端向单个服务器发送数据的情况下，服务器上的数据包丢失可能表明服务器过载。如果为真，客户端可能会以不同的自适应方式重试；例如，在第一次超时后，客户端可能会将其超时值增加到更高的值，可能是原始值的两倍。这种指数退避方案在早期的 Aloha 网络中首创并在早期以太网中采用，避免了因过度重发而导致资源过载的情况。稳健的系统努力避免这种性质的过载。 ","date":"2024-05-11","objectID":"/posts/37.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/:4:0","tags":["OS"],"title":"分布式系统","uri":"/posts/37.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"5 通信抽象 给定了基本的消息传递层，我们现在讨论本章中的下一个问题：在构建分布式系统时我们应该使用什么通信抽象？ 多年来，系统界开发了许多方法。其中一项工作是将操作系统的抽象概念扩展到分布式环境中运行。例如，分布式共享内存（DSM）系统能让不同机器上的进程共享一个大型虚拟地址空间。这种抽象将分布式计算变成了类似于多线程应用程序的东西；唯一的区别是，这些线程运行在不同的机器上，而不是同一机器上的不同处理器上。 大多数 DSM 系统的工作方式是通过操作系统的虚拟内存系统。在一台机器上访问一个页面时，可能会发生两种情况。 在第一种（最佳）情况下，页面已经在本地计算机上，因此可以快速获取数据。 第二种情况是，页面当前在其他机器上。页面故障发生后，页面故障处理程序会向其他机器发送信息，以获取页面，并将其安装到请求进程的页表中，然后继续执行。 由于多种原因，这种方法目前并未得到广泛应用。DSM 面临的最大问题是如何处理故障。例如，设想一下，如果一台机器发生故障，那么这台机器上的页面会发生什么情况？如果分布式计算的数据结构遍布整个地址空间怎么办？在这种情况下，这些数据结构的一部分将突然不可用。当部分地址空间丢失时，处理故障是非常困难的；想象一下，在一个链表中，“下一个 “指针指向的地址空间部分已经消失。 另一个问题是性能。在编写代码时，我们通常会假设访问内存的成本很低。在 DSM 系统中，有些访问是廉价的，但有些访问却会导致页面故障，并从远程机器上获取昂贵的数据。因此，这种 DSM 系统的程序员必须非常小心地组织计算，使其几乎不发生任何通信，这在很大程度上违背了这种方法的初衷。尽管在这一领域进行了大量研究，但几乎没有产生实际影响；如今，没有人使用 DSM 构建可靠的分布式系统。 ","date":"2024-05-11","objectID":"/posts/37.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/:5:0","tags":["OS"],"title":"分布式系统","uri":"/posts/37.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"6 远程过程调用 (RPC) 操作系统抽象对于构建分布式系统来说是一个糟糕的选择，而编程语言（PL）抽象则更有意义。最主要的抽象基于**远程过程调用（简称 RPC）**的思想。 远程过程调用包都有一个简单的目标：使在远程机器上执行代码的过程像调用本地函数一样简单明了。因此，对客户端来说，只需进行一次过程调用，一段时间后就会返回结果。服务器只需定义一些它希望导出的例程。RPC 系统一般由两部分组成：存根生成器（有时称为协议编译器）和运行时库。下面我们将详细介绍其中的每一部分。 ","date":"2024-05-11","objectID":"/posts/37.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/:6:0","tags":["OS"],"title":"分布式系统","uri":"/posts/37.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"6.1 存根生成器 存根生成器的工作很简单：通过自动化来消除将函数参数和结果打包到消息中的一些痛苦。这样做会带来许多好处：通过设计可以避免手工编写此类代码时出现的简单错误；此外，存根编译器也许可以优化此类代码，从而提高性能。 这种编译器的输入只是服务器希望导出到客户端的一组调用。从概念上讲，它可能像这样简单： interface { int func1(int arg1); int func2(int arg1, int arg2); }; 存根生成器采用这样的接口并生成一些不同的代码片段。 对于客户端，生成一个客户端存根，其中包含接口中指定的各个功能；希望使用此 RPC 服务的客户端程序将与此客户端存根链接并调用它以进行 RPC。在内部，客户端存根中的每个函数都执行执行远程过程调用所需的所有工作。对于客户端来说，代码只是显示为函数调用（例如，客户端调用 func1(x)）；在内部，func1() 的客户端存根中的代码执行以下操作： **创建消息缓冲区。**消息缓冲区通常只是某个大小的连续字节数组。 将所需信息打包到消息缓冲区中。该信息包括要调用的函数的某种标识符，以及函数需要的所有参数（例如，在上面的示例中，func1 是一个整数）。将所有这些信息放入单个连续缓冲区的过程有时称为参数的编组或消息的序列化。 **将消息发送到目标RPC 服务器。**与 RPC 服务器的通信以及使其正确运行所需的所有细节均由 RPC 运行时库处理，如下所述。 **等待回复。**由于函数调用通常是同步的，因此调用将等待其完成。 解压返回代码和其他参数。如果函数仅返回单个返回码，则此过程很简单；然而，更复杂的函数可能会返回更复杂的结果（例如，列表），因此存根可能也需要解压这些结果。此步骤也称为解组或反序列化。 返回调用者。最后，只需从客户端存根返回到客户端代码即可。 对于服务器，也会生成代码。在服务器上采取的步骤如下： 解压消息。此步骤称为解组或反序列化，从传入消息中取出信息，提取函数标识符和参数。 调用实际函数。最后！我们已经到达了实际执行远程函数的阶段。 RPC 运行时调用 ID 指定的函数并传入所需的参数。 **将结果打包。**返回参数被打包回单个回复缓冲区。 发送回复。回复最终发送给调用者。 存根编译器还需要考虑其他一些重要问题。 首先是复杂参数，即如何打包和发送复杂的数据结构？例如，当调用 write() 系统调用时，需要传递三个参数：一个整数文件描述符、一个指向缓冲区的指针和一个表示要写入多少字节（从指针开始）的大小。如果一个 RPC 程序包传递了一个指针，它就需要知道如何解释该指针，并执行正确的操作。通常，这可以通过两种方式实现：一种是众所周知的类型（例如，用于传递给定大小的数据块的buffer_t，RPC 编译器可以理解），另一种是为数据结构注释更多信息，使编译器知道哪些字节需要序列化。 另一个重要问题是服务器的并发组织。简单的服务器只是在一个简单的循环中等待请求，并一次处理一个请求。但是，正如你可能已经猜到的那样，这样做的效率会非常低：如果一个 RPC 调用阻塞（例如，在 I/O 上），服务器资源就会被浪费。 因此，大多数服务器都是以某种并发方式构建的。一种常见的组织方式是线程池。在这种组织结构中，服务器启动时会创建一组有限的线程；当消息到达时，它会被分派到这些工作线程中的一个，然后工作线程会执行 RPC 调用的工作，并最终回复；在此期间，主线程会不断接收其他请求，并可能将其分派给其他工作线程。这种组织方式可以在服务器内实现并发执行，从而提高服务器的利用率；同时也会产生标准成本，主要是编程复杂度，因为 RPC 调用现在可能需要使用锁和其他同步原语，以确保其正确运行。 ","date":"2024-05-11","objectID":"/posts/37.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/:6:1","tags":["OS"],"title":"分布式系统","uri":"/posts/37.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"6.2 运行时库 运行时库负责处理 RPC 系统中的大部分繁重工作；大部分性能和可靠性问题都由运行时库处理。下面我们将讨论构建这样一个运行时库所面临的一些主要挑战。 我们必须克服的首要挑战之一是如何定位远程服务。这个命名问题是分布式系统中的常见问题，在某种意义上超出了我们当前讨论的范围。最简单的方法是利用现有的命名系统，例如当前互联网协议提供的主机名和端口号。在这种系统中，客户端必须知道运行所需的 RPC 服务的机器的主机名或 IP 地址，以及它正在使用的端口号（端口号只是一种识别机器上正在进行的特定通信活动的方法，允许同时使用多个通信通道）。然后，协议套件必须提供一种机制，将数据包从系统中的任何其他机器路由到特定地址。 一旦客户端知道应该与哪台服务器通信以获取特定的远程服务，下一个问题就是 RPC 应该基于哪种传输级协议。具体来说，RPC 系统应该使用 TCP/IP 这样可靠的协议，还是建立在 UDP/IP 这样不可靠的通信层之上？ 天真地认为，选择似乎很容易：显然，我们希望请求能可靠地传送到远程服务器，显然，我们希望能可靠地收到回复。因此，我们应该选择可靠的传输协议，如 TCP，对吗？ 不幸的是，在可靠通信层之上构建 RPC 会导致性能严重低下。回想一下上文讨论的可靠通信层的工作原理：确认加超时/重试。因此，当客户端向服务器发送 RPC 请求时，服务器会以确认的方式作出响应，以便调用者知道请求已收到。同样，当服务器发送回复给客户端时，客户端也会发出确认响应，以便服务器知道它已收到。在可靠的通信层之上建立请求/响应协议（如 RPC），需要发送两条 “额外 “信息。 因此，许多 RPC 程序包都建立在不可靠的通信层（如 UDP）之上。这样做可以提高 RPC 层的效率，但却增加了为 RPC 系统提供可靠性的责任。RPC 层通过使用超时/重试和确认来达到所需的责任水平，这一点与我们上面所描述的非常相似。通过使用某种形式的序列号，通信层可以保证每个 RPC 恰好发生一次（在无故障的情况下），或最多发生一次（在出现故障的情况下）。 ","date":"2024-05-11","objectID":"/posts/37.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/:6:2","tags":["OS"],"title":"分布式系统","uri":"/posts/37.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"6.3 其他问题 RPC 运行时还必须处理一些其他问题。例如，当远程调用需要很长时间才能完成时会发生什么？考虑到我们的超时机制，长时间运行的远程调用可能会对客户端显示为失败，从而触发重试，因此这里需要注意。一种解决方案是在未立即生成回复时使用显式确认（从接收方到发送方）；这让客户端知道服务器收到了请求。然后，经过一段时间后，客户端可以定期询问服务器是否仍在处理该请求；如果服务器一直说“是”，客户端应该很高兴并继续等待（毕竟，有时过程调用可能需要很长时间才能完成执行）。 运行时还必须处理带有大参数的过程调用，这些参数大于单个数据包所能容纳的参数。一些较低级别的网络协议提供此类发送方分段（将较大的数据包分解为一组较小的数据包）和接收方重组（将较小的部分分解为一个较大的逻辑整体）；如果没有，RPC 运行时可能必须自己实现此类功能。 许多系统处理的一个问题是字节排序问题。您可能知道，某些机器以所谓的大端顺序存储值，而其他机器则使用小端顺序。大端存储从最高有效位到最低有效位的字节（例如，整数），很像阿拉伯数字；小端则相反。两者都是存储数字信息的同等有效的方式；这里的问题是如何在不同字节序的机器之间进行通信。 RPC 包通常通过在其消息格式中提供明确定义的字节顺序来处理此问题。在Sun的RPC包中，XDR（外部数据表示）层提供了此功能。如果发送或接收消息的机器与 XDR 的字节顺序匹配，则消息将按预期发送和接收。但是，如果通信的机器具有不同的字节顺序，则必须转换消息中的每条信息。因此，字节顺序的差异可能会带来很小的性能成本。 最后一个问题是是否向客户端公开通信的异步特性，从而实现一些性能优化。具体来说，典型的 RPC 是同步进行的，即当客户端发出过程调用时，它必须等待过程调用返回才能继续。由于等待时间可能很长，并且客户端可能还有其他工作要做，因此某些 RPC 包允许您异步调用 RPC。当发出异步RPC时，RPC包发送请求并立即返回；然后客户端可以自由地执行其他工作，例如调用其他 RPC 或其他有用的计算。客户端有时会希望看到异步 RPC 的结果；因此，它回调 RPC 层，告诉它等待未完成的 RPC 完成，此时可以访问返回参数。 ","date":"2024-05-11","objectID":"/posts/37.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/:6:3","tags":["OS"],"title":"分布式系统","uri":"/posts/37.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"1 磁盘故障模式 磁盘并不完美，并且可能会出现故障（有时）。在早期的 RAID 系统中，故障模型非常简单：要么整个磁盘正常工作，要么完全故障，并且检测此类故障非常简单。这种磁盘故障的故障停止模型使得构建 RAID 相对简单。 但现代磁盘所表现出的还有其他类型的故障模式。具体来说，如 Bairavasundaram 等人经过详细研究 ，现代磁盘有时看起来大部分工作正常，但在成功访问一个或多个块时遇到问题。具体来说，有两种类型的单块故障很常见且值得考虑：静默扇区错误 (LSE) 和块损坏。我们现在将更详细地讨论每一个。 当磁盘扇区（或扇区组）受到某种损坏时，就会出现 LSE。例如，如果磁盘磁头由于某种原因（磁头撞击，正常运行中不应该发生的情况）接触到磁盘表面，可能会损坏磁盘表面，导致位无法读取。宇宙射线也会使位翻转，导致内容错误。幸运的是，硬盘会使用磁盘内纠错码 (ECC) 来确定块中的磁盘位是否正确，并在某些情况下对其进行修复；如果位不正确，而硬盘又没有足够的信息来修复错误，则在请求读取时磁盘会返回错误信息。 还有一种情况是，磁盘块损坏的方式无法被磁盘本身检测到。例如，存在漏洞的磁盘固件可能会将块写入错误位置；在这种情况下，磁盘 ECC 显示块内容正常，但从客户端的角度来看，随后访问时会返回错误的块。同样，当数据块通过故障总线从主机传输到磁盘时，也可能会损坏数据块；磁盘会存储损坏的数据，但这些数据并不是客户想要的。这类故障特别隐蔽，因为它们是静默故障；磁盘在返回故障数据时不会显示问题。 Prabhakaran 等人将这种更现代的磁盘故障观点称为部分故障磁盘故障模型。在这种观点中，磁盘仍有可能全部失效（就像传统的故障-停止模型中的情况一样）；但是，磁盘也有可能看似正常工作，但有一个或多个区块变得不可访问（即 LSE）或包含错误的内容（即损坏）。因此，在访问看似正常工作的磁盘时，偶尔会在尝试读取或写入给定块时返回错误（非静默部分故障），偶尔也会简单地返回错误数据（静默部分故障）。 这两类故障都比较罕见，但究竟有多罕见呢？下图总结了两份 Bairavasundaram 研究报告的部分结论。 该图显示了在研究过程中（约 3 年，超过 150 万台硬盘）至少出现过一次 LSE 或块损坏的硬盘百分比。该图将结果进一步细分为 “廉价 “硬盘（通常为 SATA 硬盘）和 “昂贵 “硬盘（通常为 SCSI 或光纤通道硬盘）。正如您所看到的，虽然购买更好的硬盘降低了这两类问题的发生频率（大约降低了一个数量级），但它们仍然经常发生，因此您需要仔细考虑如何在存储系统中处理它们。 关于 LSE 的一些其他发现包括： 具有多个 LSE 的昂贵驱动器与较便宜的驱动器一样可能产生额外错误； 对于大多数驱动器，第二年的年错误率会增加； LSE 数量随着磁盘大小的增加而增加； 大多数磁盘具有LSE 少于 50 个； 具有 LSE 的磁盘更有可能产生额外的 LSE； 存在大量的空间和时间局部性； 磁盘清理很有用（大多数 LSE 都是通过这种方式找到的） 。 关于损坏的一些发现： 同一驱动器类别中不同驱动器型号的损坏几率差异很大； 型号之间的老化影响不同； 工作负载和磁盘大小对损坏影响很小 大多数损坏的磁盘只有少数损坏； 损坏在磁盘内或 RAID 中的磁盘之间不是独立的； 存在空间局部性和一些时间局部性 与LSE 的相关性很弱 一个可靠的存储系统，需要有检测和恢复 LSE 和块损坏的机制 ","date":"2024-05-11","objectID":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/:1:0","tags":["OS"],"title":"数据完整性和保护","uri":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/"},{"categories":["系统架构"],"content":"2 处理静默扇区错误（LSE） 考虑到这两种新的部分磁盘故障模式，我们现在应该尝试看看我们可以对它们做些什么。让我们首先解决两者中较容易的一个，即静默扇区错误。 关键问题：存储系统应如何处理静默扇区错误？需要多少额外的机制来处理这种形式的部分故障？ 事实证明，静默扇区错误的处理相当简单，因为它们（根据定义）很容易检测到。当存储系统尝试访问块并且磁盘返回错误时，存储系统应该简单地使用它所拥有的任何冗余机制来返回正确的数据。例如， 在镜像 RAID 中，系统应该访问备用副本； 在基于奇偶校验的 RAID-4 或 RAID-5 系统中，系统应从奇偶校验组中的其他块重建该块。 因此，诸如 LSE 等容易检测到的问题可以通过标准冗余机制轻松恢复。 LSE的不断增多影响了多年来RAID设计。在RAID-4/5系统中，当整个磁盘故障和LSE同时发生时，会出现一个特别有趣的问题。具体而言，在整个磁盘失败时，RAID尝试通过读取奇偶校验组中所有其他磁盘并重新计算缺失值来重建该磁盘（比如说，到一个热备用上）。如果在重建过程中，在任何其他一块磁盘上遇到LSE，则会出现问题：无法成功完成重建。 为了解决这个问题，一些系统增加了额外的冗余度。例如，NetApp的RAID-DP相当于两块奇偶校验硬盘而不是一块。当在重建过程中发现LSE时，额外的奇偶校验有助于重构丢失的数据块。正如始终如此地存在成本那样，在每条条带保持两块奇偶校验硬盘更昂贵；然而，NetApp WAFL文件系统的日志结构化性质在许多情况下可以减轻这种成本。剩下的成本是空间方面，在第二个奇偶校验区块形式上需要额外一块硬盘。 ","date":"2024-05-11","objectID":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/:2:0","tags":["OS"],"title":"数据完整性和保护","uri":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/"},{"categories":["系统架构"],"content":"3 检测损坏：校验和 ","date":"2024-05-11","objectID":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/:3:0","tags":["OS"],"title":"数据完整性和保护","uri":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/"},{"categories":["系统架构"],"content":"3.1 基本介绍 现在让我们解决更具挑战性的问题，即通过数据损坏导致的静默故障。当数据损坏导致磁盘返回坏数据时，我们如何防止用户获得坏数据？ 关键问题：鉴于此类故障的隐匿性，存储系统可以采取哪些措施来检测何时发生损坏？需要什么技术？如何有效地实施它们？ 与静默扇区错误不同，损坏检测是一个关键问题。客户端如何知道某个块已经坏了？一旦知道某个特定块损坏，恢复就与以前相同：您需要该块的其他副本（希望是一个未损坏的副本！）。因此，我们在这里重点关注检测技术。 现代存储系统用于保持数据完整性的主要机制称为校验和。校验和只是一个函数的结果，该函数将一块数据（例如 4KB 块）作为输入，并根据所述数据计算函数，生成数据内容的小摘要（例如 4 或 8 字节），该摘要称为校验和。这种计算的目标是使系统能够通过将校验和与数据一起存储来检测数据是否已被损坏或更改，然后在以后访问时确认数据的当前校验和与原始存储值相匹配。 ","date":"2024-05-11","objectID":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/:3:1","tags":["OS"],"title":"数据完整性和保护","uri":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/"},{"categories":["系统架构"],"content":"3.2 常用校验和函数 许多不同的函数用于计算校验和，它们的强度（即，它们在保护数据完整性方面的能力）和速度（即，它们的计算速度）各不相同。这里出现了系统中常见的权衡：通常，获得的保护越多，成本就越高。 有些人使用的一种简单的校验和函数是基于异或 (XOR) 的。对于基于 XOR 的校验和，校验和是通过对正在校验和的数据块的每个块进行异或来计算的，从而生成表示整个块的 XOR 的单个值。 为了更具体地说明这一点，假设我们正在 16 字节的块上计算 4 字节的校验和（这个块当然太小，不能真正成为磁盘扇区或块，但它将用于示例）。 16 个数据字节（十六进制）如下所示： 365e c4cd ba14 8a92 ecef 2c3a 40be f666 如果用二进制表示，我们会得到以下结果： 0011 0110 0101 1110 1100 0100 1100 1101 1011 1010 0001 0100 1000 1010 1001 0010 1110 1100 1110 1111 0010 1100 0011 1010 0100 0000 1011 1110 1111 0110 0110 0110 由于我们以每行 4 个字节为一组排列数据，因此很容易看出校验和的结果：在每列上执行 XOR 即可得到最终的校验和值： 0010 0000 0001 1011 1001 0100 0000 0011 结果（十六进制）为0x201b9403。 XOR 是一种合理的校验和方法，但有其局限性。例如，如果每个校验和单元中同一位置的两个位发生变化，则校验和将无法检测到损坏。为此，人们研究了其他校验和函数。 另一种基本的校验函数是加法。这种方法的优点是速度快；计算时只需对每块数据执行 2 的补码加法，忽略溢出。它可以检测到数据的许多变化，但如果数据发生移位等情况，则效果不佳。 Fletcher校验和是一种略微复杂的算法，以John G. Fletcher的名字命名。它的计算非常简单，只需计算两个校验字节 $s_1$ 和 $s_2$。具体来说，假设数据块 $D$ 由字节 $d_1 \\dots d_n$ 组成；$s_1$ 的定义如下：$s_1 = (s_1 + d_i) \\mod 255$（对所有 $d_i$ 进行计算）；$s_2$ 的定义如下：$s_2 = (s_2 + s_1) \\mod 255$（同样对所有 $d_i$ 进行计算）。Fletcher 校验和与 CRC 几乎一样强（见下文），能检测出所有单bit、双bit错误和许多突发错误。 最后一种常用的校验和称为循环冗余校验（CRC）。假设要计算数据块 D 的校验和，只需将 D 视为一个大的二进制数（毕竟只是一串bit），然后除以一个约定的值（$k$）。除数的余数就是 CRC 的值。事实证明，我们可以相当高效地实现这种二进制模运算，因此 CRC 在网络中也很流行。 无论使用哪种方法，显而易见的是，没有完美的校验和：两个内容不相同的数据块有可能具有完全相同的校验和，这就是所谓的冲突。这个事实应该是直观的：毕竟，计算校验和是把一个大的东西（如 4KB），生成一个小得多的摘要（如 4 或 8 字节）。因此，在选择一个好的校验和函数时，我们试图找到一个既能尽量减少冲突几率，又能保持计算简便的函数。 ","date":"2024-05-11","objectID":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/:3:2","tags":["OS"],"title":"数据完整性和保护","uri":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/"},{"categories":["系统架构"],"content":"3.3 校验和布局 现在您已经了解了如何计算校验和，接下来我们来分析如何在存储系统中使用校验和。我们必须解决的第一个问题是校验和的布局，即校验和应该如何存储在磁盘上？ 最基本的方法只是存储每个磁盘扇区（或块）的校验和。给定一个数据块 D，让我们调用该数据的校验和 C(D)。因此，如果没有校验和，磁盘布局如下所示： 使用校验和时，布局会为每个块添加一个校验和： 由于校验和通常很小（如 8 字节），而磁盘只能以扇区大小的块（512 字节）或其倍数写入，因此出现的一个问题是如何实现上述布局。硬盘制造商采用的一种解决方案是用 520 字节扇区格式化硬盘；每个扇区额外的 8 字节可用于存储校验和。 对于不具备这种功能的磁盘，文件系统必须想办法将校验和存储到 512 字节的块中。其中一种方法如下： 在此方案中，$n$ 个校验和一起存储在一个扇区中，后面是 $n$ 个数据块，然后是下一个的 $n$ 个块的另一个校验和扇区，依此类推。这种方法的优点是可以在所有磁盘上工作，但效率可能较低；例如，如果文件系统想要覆盖块D1，则必须读入包含C(D1)的校验和扇区，更新其中的C(D1)，然后写出校验和扇区和新的数据块D1（因此，一次读取和两次写入）。早期的方法（每个扇区一个校验和）仅执行一次写入。 ","date":"2024-05-11","objectID":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/:3:3","tags":["OS"],"title":"数据完整性和保护","uri":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/"},{"categories":["系统架构"],"content":"3.4 使用校验和 在确定了校验和布局之后，我们就可以着手了解如何使用校验和了。读取数据块 D 时，客户端（即文件系统或存储控制器）也会从磁盘读取其校验和$C_s(D)$，我们称之为存储校验和（因此使用了下标 $C_s$）。然后，客户端对检索到的数据块 D 计算校验和，我们称之为计算校验和 $C_c(D)$。此时，客户端会比较存储的校验和与计算的校验和；如果两者相等（即 $C_s(D) == C_c(D)$），则数据很可能没有损坏，因此可以安全地返回给用户。如果它们不匹配（即 $C_s(D) != C_c(D)$），这意味着数据在存储后发生了变化（因为存储的校验和反映的是数据当时的值）。在这种情况下，我们的校验和帮助我们检测到了数据损坏。 有了损坏，我们自然会问该如何处理？如果存储系统有冗余副本，答案很简单：尝试使用它。如果存储系统没有这样的副本，答案很可能是返回错误。不管是哪种情况，都要认识到损坏检测并不是灵丹妙药；如果没有其他办法获取未损坏的数据，那就只能走霉运了。 ","date":"2024-05-11","objectID":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/:3:4","tags":["OS"],"title":"数据完整性和保护","uri":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/"},{"categories":["系统架构"],"content":"4 一个新问题：错误写入 上述基本方案在一般的块损坏情况下效果很好。然而，现代磁盘有几种不同寻常的故障模式，需要不同的解决方案。 第一种故障模式称为误写。磁盘和 RAID 控制器会出现这种情况，它们会将数据正确写入磁盘，只是写错了位置。在单磁盘系统中，这意味着磁盘将数据块 $D_x$ 写入的地址不是 $x$，而是 $y$（从而 “破坏 “了 $D_y$）；此外，在多磁盘系统中，控制器也可能将 $D_{i,x}$ 写入的地址不是磁盘 $i$ 的 $x$，而是其他磁盘 $j$。因此关键问题是： 存储系统或磁盘控制器应如何检测错误写入？校验和需要哪些附加功能？ 答案很简单：在每个校验和中增加一点信息。在这种情况下，增加一个**物理标识符（物理 ID）**是非常有用的。例如，如果现在存储的信息包含校验和 $C(D)$以及块的磁盘编号和扇区编号，那么客户端就很容易确定正确的信息是否存在于特定位置。具体来说，如果客户端读取的是磁盘 $10$ 上的块 $4$（$D_{10,4}$），则存储的信息应包括该磁盘编号和扇区偏移量，如下图所示。如果信息不匹配，就说明发生了错误写入，此时就会检测到损坏。下面是双磁盘系统中添加信息的示例。请注意，该图和之前的其他图一样，并不是按比例绘制的，因为校验和通常很小（如 8 字节），而数据块却大得多（如 4 KB 或更大）： 从磁盘上的格式可以看出，磁盘上现在有相当多的冗余信息：对于每个块，磁盘编号在每个数据块内重复出现，而相关块的偏移量也保留在数据块本身旁边。冗余信息的存在不足为奇，因为冗余是错误检测（在本例中）和恢复（在其他情况下）的关键。虽然完美的磁盘并不严格需要一点额外的信息，但如果出现问题，这些信息却能帮助检测出问题所在。 ","date":"2024-05-11","objectID":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/:4:0","tags":["OS"],"title":"数据完整性和保护","uri":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/"},{"categories":["系统架构"],"content":"5 最后一个问题：写入丢失 不幸的是，错误写入并不是我们要解决的最后一个问题。具体来说，一些现代存储设备还存在一个称为写入丢失的问题，当设备通知上层写入已完成但实际上从未被持久化时，就会发生这种情况；因此，剩下的是块的旧内容而不是更新的新内容。 这里明显的问题是：上面的任何校验和策略（例如基本校验和或物理标识）是否有助于检测丢失的写入？不幸的是，答案是否定的：旧块可能有匹配的校验和，并且上面使用的物理 ID（磁盘号和块偏移量）也将是正确的。 因此，我们的最后一个关键问题是： 存储系统或磁盘控制器应如何检测丢失的写入？校验和还需要哪些附加功能？ 有许多可能的解决方案可以帮助。一种经典方法是执行写入验证或写入后读取；通过在写入后立即读回数据，系统可以确保数据确实到达磁盘表面。然而，这种方法非常慢，完成写入所需的 I/O 数量会增加一倍。 有些系统在系统的其他地方添加校验和来检测丢失的写入。例如，Sun 的 Zettabyte 文件系统 (ZFS) 在每个文件系统inode中包含一个校验和，并为文件中包含的每个块提供间接块。因此，即使对块本身的写入丢失，inode 内的校验和也不会与旧数据匹配。只有当对inode和数据的写入同时丢失时，这种方案才会失败，这是一种不太可能（但不幸的是，有可能！）的情况。 ","date":"2024-05-11","objectID":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/:5:0","tags":["OS"],"title":"数据完整性和保护","uri":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/"},{"categories":["系统架构"],"content":"6 扫描 说了这么多，你可能会问：这些校验和什么时候会被检查？当然，在应用程序访问数据时会进行一定量的校验，但大多数数据很少被访问，因此会保持未校验状态。对于可靠的存储系统来说，未校验的数据是有问题的，因为bit损坏最终会影响特定数据的所有副本。 为了解决这个问题，许多系统都采用了各种形式的磁盘扫描。通过定期读取系统中的每个块，并检查校验和是否仍然有效，磁盘系统可以降低某个数据项的所有副本损坏的几率。典型的系统每晚或每周安排一次扫描。 ","date":"2024-05-11","objectID":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/:6:0","tags":["OS"],"title":"数据完整性和保护","uri":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/"},{"categories":["系统架构"],"content":"7 校验和的开销 在结束之前，我们现在讨论使用校验和进行数据保护的一些开销。正如计算机系统中常见的那样，有两种不同类型的开销：空间和时间。 空间开销有两种形式。 第一个是在磁盘（或其他存储介质）本身上；每个存储的校验和都会占用磁盘空间，无法再用于存储用户数据。典型的比率可能是每 4 KB 数据块 8 字节校验和，磁盘空间开销为 0.19%。 第二种类型的空间开销来自系统的内存。访问数据时，内存中必须有空间用于存放校验和以及数据本身。但是，如果系统只是检查校验和，然后在完成后将其丢弃，则这种开销是短暂的，不必担心。只有当校验和保存在内存中（为了防止内存损坏的额外保护级别），这个小开销才会被观察到。 虽然空间开销很小，但校验和引起的时间开销可能非常明显。至少，CPU 必须计算每个块的校验和，无论是在存储数据时（以确定存储的校验和的值）还是在访问数据时（再次计算校验和并将其与存储的校验和进行比较）。许多使用校验和（包括网络栈）的系统采用的一种减少 CPU 开销的方法是将数据复制和校验和合并为一项简化的活动；因为无论如何都需要复制（例如，将数据从内核页缓存复制到用户缓冲区），因此组合复制/校验和可能非常有效。 除了 CPU 开销之外，某些校验和方案还会产生额外的 I/O 开销，特别是当校验和与数据分开存储时（因此需要额外的 I/O 来访问它们），以及后台扫描所需的任何额外 I/O。前者可以通过设计来减少；后者可以进行调整，从而限制其影响，或许可以通过控制此类扫描活动的发生时间来实现（如半夜）。 ","date":"2024-05-11","objectID":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/:7:0","tags":["OS"],"title":"数据完整性和保护","uri":"/posts/36.%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E5%92%8C%E4%BF%9D%E6%8A%A4/"},{"categories":["系统架构"],"content":"1 引言 在硬盘驱动器占据主导地位数十年后，一种新型的持久存储设备最近在世界上占据了重要地位。这种设备一般被称为固态存储设备，它不像硬盘驱动器那样有机械或移动部件，而是由晶体管构成，就像内存和处理器一样。然而，与典型的随机存取存储器（如 DRAM）不同，这种固态存储设备（又称 SSD）在断电的情况下仍能保留信息，因此是持久存储数据的理想选择。 我们将重点讨论的技术是闪存（更具体地说，是基于 NAND 的闪存，它具有更好的成本效益，即每存储容量单位的成本较低。这使得 NAND 型闪存在大容量存储设备中得到广泛应用，如固态硬盘（SSD）和闪存卡等），它是由 Fujio Masuoka 在 20 世纪 80 年代发明的，。我们将看到，闪存具有一些独特的特性。 例如，要写入闪存的某一大块（即一个闪存页），首先必须擦除更大的一块（即一个闪存块），而擦除的代价可能相当昂贵。 此外，过于频繁地写入页面会导致页面磨损。 这两个特性使得构建基于闪存的固态硬盘成为一项有趣的挑战： 如何构建基于闪存的固态硬盘 如何构建基于闪存的固态硬盘？如何处理擦除的昂贵特性？考虑到反复擦写会损耗设备，我们如何才能制造出使用寿命长的设备？技术进步的脚步会停止吗？或者不再令人惊叹？ 闪存芯片设计用于在单个晶体管中存储一个或多个bit；晶体管内捕获的电荷水平被映射为二进制值。在单层单元 (SLC) 闪存中，晶体管内仅存储单个位（即 1 或 0）；对于多层单元 (MLC) 闪存，两个位被编码为不同的电荷级别，例如，00、01、10 和 11 分别由低、稍低、稍高和高电平表示。甚至还有三层单元 (TLC) 闪存以及四层单元(QLC)闪存，每个单元编码 3 位、4位。如下图所示。 总体而言，SLC芯片性能更高，但价格也更高。 ","date":"2024-05-11","objectID":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/:1:0","tags":["OS"],"title":"基于闪存的SSD","uri":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/"},{"categories":["系统架构"],"content":"2 从bit到组/平面 正如古希腊人所说，存储一个bit（或几个bit）并不能构成一个存储系统。因此，闪存芯片被组织成由大量单元组成的组或平面。 一个组以两种不同大小的单位进行访问： 块（有时称为擦除块），通常大小为 128 KB 或 256 KB； 页，大小为几 KB（如 4KB）。 每个存储组内有大量的块，每个块内又有大量的页。在考虑闪存时，你必须记住这个新术语，它不同于我们在磁盘和 RAID 中提到的块，也不同于我们在虚拟内存中提到的页。 下图显示了一个闪存平面的块和页的示例；在这个简单的示例中，有三个块，每个块包含四个页。我们将在下文中了解区分块和页的原因；事实证明，这种区分对于闪存操作（如读写）至关重要，对于设备的整体性能更是如此。你将了解到的最重要（也是最奇怪）的事情是，要写入块中的页面，首先必须擦除整个块；这一棘手的细节使得构建基于闪存的固态硬盘成为一项有趣且值得挑战的任务，也是本章后半部分的主题。 ","date":"2024-05-11","objectID":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/:2:0","tags":["OS"],"title":"基于闪存的SSD","uri":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/"},{"categories":["系统架构"],"content":"3 基本闪存操作 ","date":"2024-05-11","objectID":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/:3:0","tags":["OS"],"title":"基于闪存的SSD","uri":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/"},{"categories":["系统架构"],"content":"3.1 读取、擦除和编程 鉴于这种闪存组织结构，闪存芯片可支持三种低级操作。读取命令用于从闪存中读取一个页面；擦除和编程同时用于写入。详情如下： 读取（一页）：闪存芯片的客户端只需向设备指定读取命令和相应的页码，即可读取任何页面（如 2KB 或 4KB）。这种操作通常相当快，10 微秒左右，与设备上的位置无关，（或多或少）也与上一次请求的位置无关（与磁盘完全不同），能够均匀快速地访问任何位置意味着该设备是随机存取设备。 擦除（一个块）：在写入闪存中的页面之前，设备的特性要求首先擦除页面所在的整个块。重要的是，擦除会破坏块中的内容（通过将每个位设置为 1）；因此，在执行擦除之前，必须确保块中任何您需要的数据都已复制到其他地方（内存或其他闪存块）。擦除命令耗时较长，需要几毫秒才能完成。完成后，整个块将被重置，每一页都可以进行编程。 编程（一页）：擦除块后，可使用编程命令将页面中的部分 1 变为 0，并将页面中的所需内容写入闪存。对页面进行编程的成本比擦除块低，但比读取页面的成本高，在现代闪存芯片上通常需要 100 微秒左右。 对闪存芯片的一种理解是，每个页面都有一个与之相关的状态。页面开始时处于INVALID状态。通过擦除页面所在的块，可以将页面（以及该块中的所有页面）的状态设置为ERASED状态，从而重置块中每个页面的内容，而且（重要的是）还可以对它们进行编程。当你对一个页面进行编程时，它的状态将变为 VALID，这意味着它的内容已被设置并可被读取。读取不会影响这些状态（尽管你只能读取已编程的页面）。一旦页面被编程，更改其内容的唯一方法就是擦除页面所在的整个块。下面是一个 4页块中各种擦除和编程操作后状态转换的示例： ","date":"2024-05-11","objectID":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/:3:1","tags":["OS"],"title":"基于闪存的SSD","uri":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/"},{"categories":["系统架构"],"content":"3.2 详细示例 由于写入过程（即擦除和编程）非常不寻常，让我们通过一个详细的示例来确保其合理性。在这个例子中，假设我们在一个 4 页的块中有以下 4 个 8 位页面（尺寸都很小，但在本例中很有用）；每个页面都是VALID，因为每个页面之前都被编程过。 现在假设我们希望写入第 0 页，并用新内容填充它。要写入任何页，我们必须首先擦除整个块。假设我们这样做了，从而使块处于这种状态： 现在，我们可以继续对页面0进行编程，例如，用内容 00000011 来覆盖旧的第 0 页（内容 00011000）。这样，我们的程序块看起来就像这样了： 现在坏消息来了：第 1、2 和 3 页的内容已经全部丢失！因此，在覆盖块内的任何页面之前，我们必须先将我们关心的任何数据移动到其他位置（如内存或闪存上的其他位置）。擦除的性质将对我们如何设计基于闪存的固态硬盘产生重大影响，我们很快就会了解到这一点。 ","date":"2024-05-11","objectID":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/:3:2","tags":["OS"],"title":"基于闪存的SSD","uri":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/"},{"categories":["系统架构"],"content":"3.3 总结 读取页面很简单：只需读取页面即可。闪存芯片在这方面做得很好，而且速度很快；就性能而言，它们有可能大大超过现代磁盘驱动器的随机读取性能，而现代磁盘驱动器由于机械寻道和旋转成本而速度较慢。 写入页面则比较麻烦；首先必须擦除整个块（注意先将我们关心的任何数据转移到另一个位置），然后对所需页面进行编程。这不仅成本高昂，而且频繁重复这种编程/擦除循环会导致闪存芯片最大的可靠性问题：磨损。在设计使用闪存的存储系统时，写入的性能和可靠性是重点。我们很快就会了解到现代固态硬盘是如何解决这些问题的，尽管存在这些限制，但仍能提供出色的性能和可靠性。 ","date":"2024-05-11","objectID":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/:3:3","tags":["OS"],"title":"基于闪存的SSD","uri":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/"},{"categories":["系统架构"],"content":"4 闪存性能和可靠性 因为我们有兴趣用原始闪存芯片构建存储设备，所以有必要了解它们的基本性能特征。下图粗略总结了 SLC、MLC 和 TLC 闪存（每个单元分别存储 1、2 和 3 位信息）的读取、编程和擦除的基本操作延迟。 从表中可以看出，读取延迟非常好，只需 10 微秒即可完成。编程延迟更高且变化更大，SLC 低至 200 微秒，但当每个单元中装入更多位时，程序延迟会更高；为了获得良好的写入性能，您必须并行使用多个闪存芯片。最后，擦除非常昂贵，通常需要几毫秒。处理这种成本是现代闪存设计的核心。 现在让我们考虑一下闪存芯片的可靠性。与机械磁盘不同，机械磁盘可能会因多种原因而发生故障（包括可怕的物理磁头碰撞，即驱动器磁头实际上与记录表面接触），闪存芯片是纯硅，从这个意义上讲，需要担心的可靠性问题较少，主要担心的是磨损：当闪存块被擦除和编程时，它会慢慢产生一点额外的电荷。随着时间的推移，随着额外电荷的积累，区分 0 和 1 变得越来越困难。当变得不可能时，该块就变得无法使用。 目前，块的典型寿命尚不清楚。制造商将基于 MLC 的模块评价为具有 10,000 次 P/E（编程/擦除）循环寿命；也就是说，每个块在失败之前可以被擦除和编程 10,000 次。基于 SLC 的芯片由于每个晶体管仅存储一位，因此具有较长的使用寿命，通常为 100,000 个 P/E 周期。然而，最近的研究表明，寿命比预期的要长得多。 闪存芯片内的另一个可靠性问题被称为干扰。当访问闪存中的特定页面时，相邻页面中的某些位可能会被翻转；这种位翻转被称为读取干扰或编程干扰，具体取决于页面是被读取还是被编程。 向后兼容性的重要性 向后兼容性始终是分层系统中需要考虑的问题。通过定义两个系统之间的稳定接口，可以在接口的每一侧实现创新，同时确保持续的互操作性。这种方法在许多领域都非常成功：操作系统为应用程序提供相对稳定的 API，磁盘为文件系统提供相同的基于块的接口，IP 网络堆栈中的每一层都为上一层提供固定不变的接口。 毫不奇怪，这种刚性可能有一个缺点，因为在一代中定义的接口可能不适用于下一代。在某些情况下，考虑完全重新设计整个系统可能会很有用。 Sun ZFS 文件系统 就是一个很好的例子；通过重新考虑文件系统和 RAID 的交互，ZFS 的创建者设想（然后实现）了一个更有效的集成整体。 ","date":"2024-05-11","objectID":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/:4:0","tags":["OS"],"title":"基于闪存的SSD","uri":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/"},{"categories":["系统架构"],"content":"5 从原始闪存到基于闪存的 SSD 鉴于我们对闪存芯片的基本了解，我们现在面临下一个任务：如何将一组基本的闪存芯片变成看起来像典型存储设备的东西。标准存储接口是一种简单的基于块的接口，在给定块地址的情况下，可以读取或写入大小为 512 字节（或更大）的块（扇区）。基于闪存的 SSD 的任务是在其内部的原始闪存芯片之上提供标准块接口。 在内部，SSD 由一定数量的闪存芯片（用于持久存储）组成。 SSD 还包含一定量的易失性（即非持久性）内存（例如 SRAM），这样的内存对于数据的缓存和缓冲以及映射表很有用，我们将在下面了解。最后，SSD 包含协调设备操作的控制逻辑。简化框图如下图所示。 该控制逻辑的基本功能之一是满足客户端的读写，根据需要将其转化为内部闪存操作。**闪存转换层（FTL）**正是提供了这种功能。 FTL 接受逻辑块（构成设备接口）上的读写请求，并将其转换为底层物理块和物理页（构成实际闪存设备）上的低级读取、擦除和编程命令。 FTL 应该以提供卓越的性能和高可靠性为目标来完成这项任务。 正如我们将看到的，卓越的性能可以通过技术的组合来实现。一个关键是并行利用多个闪存芯片；虽然我们不会进一步讨论这项技术，但可以说所有现代 SSD 都在内部使用多个芯片来获得更高的性能。另一个性能目标是减少写入放大，写入放大定义为 FTL 向闪存芯片发出的总写入流量（以字节为单位）除以客户端向 SSD 发出的总写入流量（以字节为单位）。正如我们将在下面看到的，简单的 FTL 构建方法将导致高写入放大和低性能。高可靠性将通过几种不同方法的组合来实现。如上所述，一个主要问题是磨损。如果单个块被频繁地擦除和编程，它将变得不可用；因此，FTL 应尝试尽可能均匀地跨闪存块分布写入，确保设备的所有块大致同时磨损；这样做称为磨损均衡，是任何现代 FTL 的重要组成部分。 另一个可靠性问题是编程干扰。为了最大限度地减少这种干扰，FTL 通常会按从低页到高页的顺序对擦除块内的页进行编程。这种顺序编程方法最大限度地减少了干扰并被广泛使用。 ","date":"2024-05-11","objectID":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/:5:0","tags":["OS"],"title":"基于闪存的SSD","uri":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/"},{"categories":["系统架构"],"content":"6 FTL 组织结构 ","date":"2024-05-11","objectID":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/:6:0","tags":["OS"],"title":"基于闪存的SSD","uri":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/"},{"categories":["系统架构"],"content":"6.1 直接映射 最简单的 FTL 组织结构我们称之为直接映射。在这种方法中，逻辑页 $N$ 的读取直接映射到物理页 $N$ 的读取。对逻辑页 N 的写入则更为复杂；FTL 首先要读入页面 $N$ 所在的整个块，然后擦除该块，最后对旧页面和新页面进行编程。 你可能已经猜到，直接映射 FTL 在性能和可靠性方面都存在很多问题。性能问题出现在每次写入时：设备必须读入整个数据块（成本高昂），擦除（成本相当高昂），然后编程（成本高昂）。最终结果是严重的写入放大（与块中的页数成正比），因此写入性能很差，甚至比典型硬盘的机械寻道和旋转延迟还要慢。 更糟糕的是这种方法的可靠性。如果文件系统元数据或用户文件数据被反复覆盖，同一数据块就会被一次又一次地擦除和编程，使其迅速损耗，并可能丢失数据。直接映射方法只是将磨损的控制权过多地交给了客户端工作负载；如果工作负载不能将写入负载均匀地分散到逻辑块中，那么包含常用数据的底层物理块就会很快磨损。出于可靠性和性能方面的考虑，直接映射 FTL 都不是一个好主意。 ","date":"2024-05-11","objectID":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/:6:1","tags":["OS"],"title":"基于闪存的SSD","uri":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/"},{"categories":["系统架构"],"content":"6.2 日志结构的 FTL 6.2.1 基本原理 由于这些原因，如今大多数 FTL 都是日志结构的，这一理念在存储设备（如我们现在看到的）和其上的文件系统（如我们将在日志结构文件系统一章中看到的）中都很有用。在写入逻辑块 $N$ 时，设备会将写入内容附加到当前正在写入的块中的下一个空闲位置；我们称这种写入方式为日志。为方便后续读取块 $N$，设备会保存一个映射表（在内存中，并以某种形式持久存在于设备上）；该表存储了系统中每个逻辑块的物理地址。 让我们举例说明基于日志的基本方法是如何工作的。对于客户端来说，设备看起来就像一个典型的磁盘，可以读写 512 字节的扇区（或扇区组）。为简单起见，假设客户端正在读取或写入 4KB 大小的块。让我们进一步假设SSD包含大量 16KB 大小的块，每个块分为 4 个 4KB 页面（但闪存块通常由更多页面组成）。 假设客户端发出以下操作序列： Write(100) with contents a1 Write(101) with contents a2 Write(2000) with contents b1 Write(2001) with contents b2 SSD 客户端（如文件系统）使用这些逻辑块地址（如 100）来记忆信息的位置。 在内部，设备必须将这些块写入转化为原始硬件支持的擦除和编程操作，并以某种方式记录每个逻辑块地址在固态硬盘的哪个物理页面存储数据。假设固态硬盘的所有块目前都无效，因此必须先擦除这些块，然后才能对任何页面进行编程。这里显示的是固态硬盘的初始状态，所有页面都标记为INVALID(i)： 当SSD收到第一个写入（逻辑块100）时，FTL决定将其写入物理块0，其中包含四个物理页：0、1、2和3。因为该块没有被擦除，所以我们还不能写入；设备必须首先向块 0 发出擦除命令。这样做会导致以下状态： 现在可以对 0 块进行编程了。大多数固态硬盘会按顺序（即从低到高）写入页面，从而减少与程序干扰有关的可靠性问题。然后，固态硬盘将逻辑块 100 写入物理页 0： 但如果客户要读取逻辑块 100 呢？如何找到它的位置？SSD必须将对逻辑块 100 的读取转换为对物理页 0 的读取。为了适应这种功能，当 FTL 将逻辑块 100 写入物理页 0 时，它会在内存映射表中记录这一事实。我们还将在图表中跟踪该映射表的状态： 现在您可以看到当客户端写入 SSD 时会发生什么。 SSD找到写入位置，通常只是选择下一个空闲页面；然后，它使用块的内容对该页进行编程，并将逻辑到物理的映射记录在其映射表中。后续读取只需使用该表将客户端提供的逻辑块地址转换为读取数据所需的物理页号。 现在让我们检查示例写入流中的其余写入：101、2000 和 2001。写入这些块后，设备的状态为： 基于日志的方法从本质上提高了性能（只需偶尔擦除一次，完全避免了直接映射方法中代价高昂的读取-修改-写入），并大大提高了可靠性。FTL 现在可以在所有页面上分散写入，执行所谓的磨损均衡，延长设备的使用寿命；我们将在下文进一步讨论损耗均衡。 FTL 映射信息持久性 您可能想知道：如果设备断电会发生什么？内存映射表消失了吗？显然，此类信息不会真正丢失，否则该设备将无法充当持久存储设备。 SSD 必须具有某种恢复映射信息的方法。 最简单的做法是在每个页面上记录一些映射信息，即所谓的带外 (OOB) 区域。当设备断电并重新启动时，它必须通过扫描 OOB 区域并重建内存中的映射表。这种基本方法也有其问题；扫描大型 SSD 来查找所有必要的映射信息的速度很慢。为了克服这个限制，一些高端设备使用更复杂的日志记录和检查点技术来加速恢复。 不幸的是，这种基本的日志结构方法有一些缺点。 第一个是逻辑块的覆盖会导致我们称之为垃圾的东西，即驱动器周围的旧版本数据并占用空间。设备必须定期执行**垃圾回收（GC）**以找到所述块和可用空间以供将来写入；过多的垃圾回收会增加写入放大并降低性能。 二是内存映射表成本高；设备越大，此类表需要的内存就越多。我们现在依次讨论每一个。 6.2.2 垃圾回收 任何日志结构方法（例如此方法）的第一个成本是创建垃圾，因此必须执行垃圾回收（即死块回收）。让我们用之前例子来理解这一点。回想一下，逻辑块 100、101、2000 和 2001 已写入设备。 现在，我们假设再次写入块 100 和 101，内容为 c1 和 c2。写入操作将写入下一个空闲页（在本例中为物理页 4 和 5），并且映射表也会相应更新。请注意，设备必须首先擦除块 1 才能进行此类编程： 我们现在遇到的问题应该很明显：物理页 0 和 1 虽然标记为 VALID，但其中有垃圾，即旧版本的块 100 和 101。由于设备的日志结构特性，覆盖会产生垃圾块，设备必须回收这些垃圾块，以便为新的写入提供可用空间。 查找垃圾块（也称为死块）并将其回收以备将来使用的过程称为垃圾回收，它是所有现代固态硬盘的重要组成部分。基本过程很简单：找到包含一个或多个垃圾页的块，读入该块中的活（非垃圾）页，将这些活页写入日志，最后回收整个块用于写入。 下面我们举例说明。设备决定要回收上述 0 号块中的所有死页。块 0 有两个死块（第 0 页和第 1 页）和两个活块（第 2 页和第 3 页，分别包含块 2000 和 2001）。为此，设备将： 从块 0 读取有效数据（第 2 页和第 3 页） 将有效数据写入日志末尾 擦除块 0（将其释放供以后使用） 为了让垃圾回收程序发挥作用，每个块内必须有足够的信息，以便固态硬盘确定每个页面是有效还是无效。实现这一目的的一种自然方法是在每个块内的某个位置存储有关每个页面内存储了哪些逻辑块的信息。然后，设备就可以使用映射表来确定块中的每个页面是否保存有效数据。 在我们上面的示例中（垃圾回收之前），块 0 包含逻辑块 100、101、2000 和 2001。通过检查映射表（在垃圾收集之前，映射表包含 100-\u003e4、101-\u003e5、2000-\u003e2、2001-\u003e3），设备可以轻松确定固态硬盘块内的每个页面是否包含有效信息。例如，2000 和 2001 显然仍由映射指向；而 100 和 101 则不是，因此是垃圾回收的候选对象。在我们的示例中，当垃圾回收过程完成后，设备的状态为： 可以看出，垃圾回收的成本很高，需要读取和重写有效数据。最理想的回收对象是只包含死页的块；在这种情况下，数据块可以立即被擦除并用于新数据，而无需进行昂贵的数据迁移。 为了降低 GC 成本，一些固态硬盘对设备进行了超额配置；通过增加额外的闪存容量，可以延迟清理并将其推至后台，或许可以在设备不太忙的时候进行。增加容量还能增加内部带宽，可用于清理，从而不影响客户端的感知带宽。许多现代硬盘都以这种方式进行超额配置，这是实现出色整体性能的关键之一。 一种称为 TRIM 的新存储 API 当我们想到硬盘驱动器时，我们通常只想到最基本的读写接口：读和写（通常还有某种缓存刷新命令，确保写入实际上已被持久化，但为了简单起见，有时我们会忽略这一点）。对于日志结构的 SSD，以及任何保持逻辑到物理块的灵活且不断变化的映射的设备，一个新的接口非常有用，称为修剪操作。 修剪操作采用一个地址（可能还有一个长度），并简单地通知设备该地址（和长度）指定的块已被删除；因此，设备不再需要跟踪有关给定地址范围的任何信息。对于标准硬盘驱动器，修剪并不是特别有用，因为驱动器具有块地址到特定盘片、磁道和扇区的静态映射。 然而，对于日志结构的 SSD，知道不再需要某个块非常有用，因为 SSD 可以从 FTL 中删除此信息，并在垃圾回收期间回收物理空间。 尽管我们有时将接口和实现视为独立的实体，但在这种情况下，我们看到实现塑造了接口。通过复杂的映射，了解不再需要哪些块可以更有效的实现。 6.2.3 映射表大小 日志结构的第二个成本是可能会产生非常大的映射表，设备的每个 4 KB 页都有一个条目。例如，对于大型 1 TB SSD，每 4 KB 页一个 4 字节条目会导致设备需要 1 GB 内存，仅用于这些映射！因此，这种页级 FTL 方案是不切实际的。 6.2.3.1 基于块的映射 降低映射成本的一种方法是只为设备的每个块而不是每个页保留一个指针，从而将映射信息量减少 $\\frac{Size_{block}}{ Size_{page}}$ 倍。这种块级 FTL 类似于在虚拟内存系统中具有更大的页面大小；在这种情况下，您可以为 VPN 使用更少的位，并在每个虚拟地址中使用更大的偏移量。 不幸的是，由于性能原因，在基于日志的 FTL 中使用基于块的映射效果不佳。当发生“小写入”（即小于物理块大小的写入）时，就会出现最大的问题。在这种情况下，FTL 必须从旧块中读取大量有效数据并将其复制到新块中（以及来自小写入的数据）。这种数据复制极大地增加了写放大，从而降低了性能。 为了更清楚地说明这个问题，我们来看一个例子。假设客户端之前写出了逻辑块 2000、2001、2002 和 2003（内容为 a、b、c、d），并且它们位于物理块 1 内的物理页 4、5、6 和 7。对于每页映射，转换表必须记录这些逻辑块的四个映射：2000→4、2001→5、2002→6、2003→7。 相反，如果我们使用块级映射，FTL 只需要记录所有这些数据的单个地址转换。然而，地址映射与我们之前的示例略有不同。具体来说，我们认为设备的逻辑地址空间被分割成闪存中物理块大小的块。因此，逻辑块地址由两部分组成：块号和偏移量。因为我们假设每个物理块中有四个逻辑块，所以逻辑地址的偏移部分需要 2 位；其余（","date":"2024-05-11","objectID":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/:6:2","tags":["OS"],"title":"基于闪存的SSD","uri":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/"},{"categories":["系统架构"],"content":"7 磨损均衡 最后，现代 FTL 必须实现的一项相关背景活动是磨损均衡，如上所述。基本思想很简单：因为多个擦除/编程周期会磨损闪存块，所以 FTL 应尽力将工作均匀地分布到设备的所有块上。通过这种方式，所有块将大致在同一时间磨损，而不是一些“常用”块很快变得无法使用。 基本的日志结构方法在分散写入负载方面做得很好，垃圾回收也有帮助。然而，有时一个块会填充长期存在的数据，这些数据不会被覆盖；在这种情况下，垃圾回收永远不会回收该块，因此它不会收到其公平份额的写入负载。 为了解决这个问题，FTL 必须定期从这些块中读取所有有效数据，并将其重新写入其他地方，从而使该块可再次写入。这种磨损均衡过程会增加 SSD 的写入放大，从而降低性能，因为需要额外的 I/O 来确保所有块以大致相同的速率磨损。 ","date":"2024-05-11","objectID":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/:7:0","tags":["OS"],"title":"基于闪存的SSD","uri":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/"},{"categories":["系统架构"],"content":"8 SSD性能与成本 ","date":"2024-05-11","objectID":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/:8:0","tags":["OS"],"title":"基于闪存的SSD","uri":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/"},{"categories":["系统架构"],"content":"8.1 性能 与硬盘驱动器不同，基于闪存的 SSD 没有机械组件，实际上在很多方面与 DRAM 更相似，因为它们是“随机访问”设备。与磁盘驱动器相比，最大的性能差异是在执行随机读取和写入时实现的；虽然典型的磁盘驱动器每秒只能执行几百次随机 I/O，但 SSD 可以做得更好。在这里，我们使用现代 SSD 的一些数据来看看 SSD 的性能到底有多好；我们特别感兴趣的是 FTL 如何很好地隐藏原始芯片的性能问题。 下表显示了三种不同 SSD 和一种顶级硬盘的一些性能数据。 左边两列显示随机 I/O 性能，右边两列显示顺序I/O性能；前三行显示三种不同 SSD（来自Samsung、Seagate和Intel）的数据，最后一行显示硬盘驱动器（或 HDD）的性能，在本例中为Seagate高端驱动器。 我们可以从表中了解到一些有趣的事实。 首先，也是最引人注目的，是 SSD 和独立硬盘之间随机 I/O 性能的差异。虽然 SSD 在随机 I/O 中获得数十甚至数百 MB/秒，但这种“高性能”硬盘的峰值仅为几 MB/秒（事实上，我们四舍五入为 2 MB/秒） 。 其次，您可以看到，就顺序I/O性能而言，差异要小得多；虽然 SSD 的性能更好，但如果您只需要顺序I/O性能，硬盘驱动器仍然是一个不错的选择。第三，可以看到SSD随机读性能不如SSD随机写性能。随机写入性能如此出人意料的好，得益于很多SSD的日志结构设计，将随机写入转化为顺序写入，提高了性能。 最后，由于 SSD 在顺序 I/O 和随机 I/O 之间表现出一些性能差异，因此如何为硬盘驱动器构建文件系统的许多技术仍然适用于 SSD；尽管顺序 I/O 和随机 I/O 之间的差异幅度较小，但仍有足够的差距需要仔细考虑如何设计文件系统以减少随机 I/O。 ","date":"2024-05-11","objectID":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/:8:1","tags":["OS"],"title":"基于闪存的SSD","uri":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/"},{"categories":["系统架构"],"content":"8.2 成本 正如我们在上面看到的，即使在执行顺序 I/O 时，SSD 的性能也大大超过了现代硬盘驱动器。那么，为什么 SSD 没有完全取代硬盘作为存储介质的选择呢？答案很简单：成本，或更具体地说，是每单位容量的成本。目前，250 GB 驱动器的 SSD 成本约为 150 美元；这样的 SSD 每 GB 成本为 60 美分。传统的硬盘驱动器存储 1 TB 的成本约为 50 美元，这意味着每 GB 成本为 5 美分。这两种存储介质的成本仍然存在10倍以上的差异。 这些性能和成本差异决定了如何构建大规模存储系统。如果性能是主要考虑因素，那么 SSD 是一个很好的选择，特别是在随机读取性能很重要的情况下。另一方面，如果您正在组装一个大型数据中心并希望存储大量信息，那么巨大的成本差异将促使您转向HDD。当然，混合方法是有意义的——一些存储系统同时配备了 SSD 和HDD，使用较少数量的 SSD 来存储更常用的“热”数据并提供高性能，同时存储其余的“冷”数据（较少使用）硬盘上的数据以节省成本。只要价格差距存在，硬盘就会一直存在。 ","date":"2024-05-11","objectID":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/:8:2","tags":["OS"],"title":"基于闪存的SSD","uri":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/"},{"categories":["系统架构"],"content":"9 总结 闪存芯片由许多存储体组成，每个存储体都组织成擦除块（有时简称为块）。每个块进一步细分为一定数量的页面。 块很大（128KB–2MB）并包含许多页，而页相对较小（1KB–8KB）。 要从闪存读取，请发出带有地址和长度的读取命令；这允许客户读取一页或多页。 写入闪存更为复杂。首先，客户端必须擦除整个块（这会删除块内的所有信息）。然后，客户端可以对每个页面精确地编程一次，从而完成写入。 新的修剪操作可用于告诉设备何时不再需要特定块（或块范围）。 闪存可靠性主要由磨损决定；如果一个块被频繁地擦除和编程，它将变得不可用。 基于闪存的固态存储设备（SSD）的行为就像普通的基于块的读/写磁盘一样。通过使用闪存转换层 (FTL)，它将客户端的读取和写入转换为对底层闪存芯片的读取、擦除和编程。 大多数FTL 都是日志结构的，这通过最小化擦除/编程周期来降低写入成本。内存中的转换层跟踪逻辑写入在物理介质中的位置。 日志结构FTL 的一个关键问题是垃圾回收的成本，这会导致写入放大。 另一个问题是映射表的大小，它可能会变得非常大。使用混合映射或仅缓存 FTL 的热门部分是可能的补救措施。 最后一个问题是磨损均衡。 FTL 必须偶尔从主要读取的块中迁移数据，以确保所述块也接收其擦除/编程负载份额。 ","date":"2024-05-11","objectID":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/:9:0","tags":["OS"],"title":"基于闪存的SSD","uri":"/posts/35.%E5%9F%BA%E4%BA%8E%E9%97%AA%E5%AD%98%E7%9A%84ssd/"},{"categories":["系统架构"],"content":"1 引言 20 世纪 90 年代初，伯克利分校的一个由 John Ousterhout 教授和研究生 Mendel Rosenblum 领导的小组开发了一种新的文件系统，称为日志结构文件系统。他们这样做的动机基于以下观察： 系统内存不断增长：随着内存变大，内存中可以缓存更多数据。随着越来越多的数据被缓存，磁盘流量越来越多地由写入组成，因为读取由缓存提供服务。因此，文件系统的性能很大程度上取决于其写入性能。 随机I/O 性能和顺序I/O 性能之间存在很大差距：多年来硬盘传输带宽大幅增加；随着更多的位被封装到驱动器的表面，访问所述位时的带宽增加。然而，寻道和旋转延迟成本却缓慢下降；让廉价的小型电机更快地旋转盘片或更快地移动磁盘臂是一项挑战。因此，如果您能够以顺序方式使用磁盘，那么与导致寻道和旋转的方法相比，您将获得相当大的性能优势。 现有文件系统在许多常见工作负载上表现不佳：例如，FFS将执行大量写入来创建一个大小为一个块的新文件：一个用于新的inode，一个用于更新inode位图，一个用于包含该文件的目录数据块，一个用于更新目录inode，一个用于作为新文件一部分的新数据块，并且还需要对数据位图进行一次写入以标记数据块已被分配。因此，尽管 FFS 将所有这些块放置在同一块组内，但 FFS 需要进行许多短寻道和随后的旋转延迟，因此性能远低于峰值顺序带宽。 文件系统不支持RAID：例如，RAID-4 和RAID-5 都存在小写入问题，即对单个块的逻辑写入会导致发生4 个物理I/O。现有文件系统不会尝试避免这种最坏情况的 RAID 写入行为。 因此，理想的文件系统将关注写入性能，并尝试利用磁盘的顺序带宽。此外，它在常见工作负载上表现良好，这些工作负载不仅写出数据，而且还经常更新磁盘上的元数据结构。最后，它在 RAID 和单个磁盘上都能很好地工作。 Rosenblum 和 Ousterhout 推出的新型文件系统称为 LFS，是日志结构文件系统的缩写。当写入磁盘时，LFS 首先将所有更新（包括元数据！）缓冲在内存段中；当该段已满时，它会通过一次长的、顺序的传输写入未使用的磁盘部分。 LFS 永远不会覆盖现有数据，而是始终将段写入空闲位置。由于段很大，因此磁盘（或 RAID）可以得到有效利用，文件系统的性能也接近顶峰。 关键：如何使所有写入顺序写入？ 文件系统如何将所有写入转换为顺序写入？对于读取，此任务是不可能的，因为要读取的所需块可能位于磁盘上的任何位置。然而，对于写入，文件系统总是有一个选择，而我们希望利用的正是这个选择。 ","date":"2024-05-11","objectID":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:1:0","tags":["OS"],"title":"日志结构文件系统","uri":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"2 按顺序写入磁盘 因此，我们面临的第一个挑战是：如何将文件系统状态的所有更新转化为一系列对磁盘的顺序写入？为了更好地理解这一点，让我们举一个简单的例子。假设我们正在向文件写入一个数据块 D。将数据块写入磁盘可能会导致以下磁盘布局，D 被写入磁盘地址 A0： 然而，当用户写入数据块时，写入磁盘的不仅是数据，还有其他需要更新的元数据。在这种情况下，我们也把文件的 inode (I) 写入磁盘，并让它指向数据块 D。写入磁盘后，数据块和 inode 的如下图所示（注意，inode 看起来和数据块一样大，但一般情况下并非如此；在大多数系统中，数据块的大小为 4 KB，而 inode 则小得多，约为 128 字节）： 这种简单地将所有更新（如数据块、inodes 等）按顺序写入磁盘的基本思想是 LFS 的核心。理解了这一点，你就掌握了基本思想。但正如所有复杂的系统一样，细节决定成败。 ","date":"2024-05-11","objectID":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:2:0","tags":["OS"],"title":"日志结构文件系统","uri":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3 顺序有效地写入 不幸的是，顺序写入磁盘（单独）不足以保证高效写入。例如，想象一下，如果我们在时间 $T$ 向地址 $A$ 写入一个块。然后我们等待一会儿，并在时间 $T + \\delta$ 的地址 $A + 1$（按顺序排列的下一个块地址）写入磁盘。不幸的是，在第一次和第二次写入之间，磁盘发生了旋转；当您发出第二次写入时，它将在提交之前等待大部分旋转（具体来说，如果旋转需要时间 $T_{rotation}$，则磁盘将等待 $T_{rotation}-\\delta$，然后才能将第二次写入提交到磁盘表面）。因此，您可以看到，仅仅按顺序写入磁盘不足以实现峰值性能；相反，您必须向驱动器发出大量连续写入（或一次大型写入）才能获得良好的写入性能。 为了实现这一目标，LFS 使用一种称为写入缓冲的古老技术。在写入磁盘之前，LFS 会跟踪内存中的更新；当它收到足够数量的更新时，它会立即将它们全部写入磁盘，从而确保磁盘的有效使用。 LFS 一次写入的大块更新被称为一个段。尽管这个术语在计算机系统中被滥用，但在这里它只是指 LFS 用来分组写入的一个相对较大的块。因此，当写入磁盘时，LFS 将更新缓冲在内存中的段中，然后将该段全部写入磁盘。只要段足够大，这些写入就会高效。 下面是一个示例，其中 LFS 将两组更新缓冲到一个小段中；实际的段更大（几MB）。第一个更新是对文件 j 的四个块写入；第二个是向文件 k 添加一个块。然后，LFS 将七个块的整个段一次性提交到磁盘。这些块的最终磁盘布局如下： ","date":"2024-05-11","objectID":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:0","tags":["OS"],"title":"日志结构文件系统","uri":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"4 缓冲多大 这就提出了以下问题：在写入磁盘之前，LFS 应该缓冲多少个更新？当然，答案取决于磁盘本身，特别是定位开销与传输速率相比有多高。 例如，假设每次写入之前的定位（即旋转和寻道开销）大约需要 $T_{position}$秒。进一步假设磁盘传输速率为$R_{peak}\\text{ MB/s}$。在这样的磁盘上运行时，LFS 在写入之前应该缓冲多少？ 思考这个问题的方法是，每次写入时，您都会付出固定的定位成本开销。因此，您需要写多少才能摊销该成本？你写的越多越好（显然），并且你越接近达到峰值带宽。 为了获得具体的答案，我们假设我们正在写 $D\\text{ MB}$。写这块数据的时间（$T_{write}$）是定位时间$T_{position}$加上传输时间$\\frac{D}{R_{peak}}$，或者： $$ T_{write}=T_{position}+\\frac{D}{R_{peak}} $$ 因此，有效写入率（$R_{effective}$）就是写入的数据量除以写入的总时间： $$ R_{effective}=\\frac{D}{T_{write}}=\\frac{D}{T_{position}+\\frac{D}{R_{peak}}} $$ 我们感兴趣的是让有效率 ($R_{effective}$) 接近峰值率。具体来说，我们希望有效速率是峰值速率的某个分数 $F$，其中 $0 \u003c F \u003c 1$（典型的 F 可能是 $0.9$，或峰值速率的 $90%$）。在数学形式上，这意味着我们需要$R_{effective}=F\\times R_{peak}$ 。 至此，我们可以求解$D$： $$ R_{effective}=\\frac{D}{T_{write}}=\\frac{D}{T_{position}+\\frac{D}{R_{peak}}} $$ $$ D=F\\times R_{peak}\\times(T_{position}+\\frac{D}{R_{peak}}) $$ $$ D=(F\\times R_{peak}\\times T_{position})+(F\\times R_{peak}\\times \\frac{D}{R_{peak}}) $$ $$ D=\\frac{F}{1-F}\\times R_{peak}\\times T_{position} $$ 举个例子，磁盘的定位时间为$10\\text{ ms}$，峰值传输率为$100\\text{ MB/s}$；假设我们想要峰值的 $90%$ 的有效带宽 ($F = 0.9$)。在本例中，$D = \\frac{0.9}{0.1}\\times 100\\text{ MB/s} \\times 0.01 \\text{ s} = 9\\text{ MB}$。尝试一些不同的值，看看我们需要缓冲多少才能接近峰值带宽。需要多少才能达到峰值的 $95%$？ $99%$？ ","date":"2024-05-11","objectID":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:4:0","tags":["OS"],"title":"日志结构文件系统","uri":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"5 问题：查找 Inode 为了了解如何在 LFS 中查找 inode，让我们简要回顾一下如何在典型的 UNIX 文件系统中查找 inode。在典型的文件系统（例如 FFS）甚至旧的 UNIX 文件系统中，查找 inode 很容易，因为它们被组织在数组中并放置在磁盘上的固定位置。 例如，旧的 UNIX 文件系统将所有inode保存在磁盘的固定部分。因此，给定 inode number和起始地址，要查找特定 inode，只需将 inode number乘以 inode 的大小，然后将其添加到磁盘阵列的起始地址，即可计算出其准确的磁盘地址。 基于数组的索引（给定 inode number）既快速又简单。 在 FFS 中查找给定 inode number的 inode 只是稍微复杂一些，因为 FFS 将 inode 表分割成块，并将一组 inode 放置在每个柱面组中。因此，我们必须知道每个inode块有多大以及每个inode的起始地址。之后的计算类似，也很容易。 在LFS，生活更加困难。为什么？好吧，我们已经成功地将inode分散在整个磁盘上！更糟糕的是，我们永远不会就地覆盖，因此最新版本的索引节点（即我们想要的）不断移动。 ","date":"2024-05-11","objectID":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:5:0","tags":["OS"],"title":"日志结构文件系统","uri":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"6 通过间接解决方案：Inode Map 为了解决这个问题，LFS 的设计者通过一个名为 inode map（imap）的数据结构，在 inode number和 inode 之间引入了一层间接关系。imap 是一种将 inode number作为输入并生成该 inode 最新版本磁盘地址的结构。因此，可以想象它通常是作为一个简单的数组来实现的，每个条目有 4 个字节（磁盘指针）。当 inode 被写入磁盘时，imap 就会根据新的位置进行更新。 不幸的是，imap 需要保持持久性（即写入磁盘），这样做可以让 LFS 在崩溃时跟踪 inode 的位置，从而按预期运行。因此，有一个问题：imap 应该放在磁盘的哪个位置？ 当然，它可以位于磁盘的固定位置。遗憾的是，由于它经常更新，这就需要在更新文件结构后再写入 imap，因此性能会受到影响（也就是说，在每次更新和 imap 的固定位置之间会有更多的磁盘寻道）。 相反，LFS 会在写入所有其他新信息的位置旁边放置 inode 映射块。因此，在向文件 k 添加数据块时，LFS 实际上是将新数据块、其 inode 和 inode 映射的一部分一起写入磁盘，如下所示： 在这张图中，存储在标记为 imap 的块中的 imap 数组的一块告诉 LFS inode k 位于磁盘地址 A1；这个 inode 又告诉 LFS 它的数据块 D 位于地址 A0。 ","date":"2024-05-11","objectID":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:6:0","tags":["OS"],"title":"日志结构文件系统","uri":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"7 完成解决方案：检查点区域 ","date":"2024-05-11","objectID":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:7:0","tags":["OS"],"title":"日志结构文件系统","uri":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"7.1 如何找到inode map 你可能已经注意到这里的问题了。既然inode map的各个部分也分布在磁盘上，我们如何找到inode map呢？归根结底，没有什么神奇的：文件系统必须在磁盘上有一些固定且已知的位置才能开始文件查找。 LFS 在磁盘上为此提供了一个固定位置，称为检查点区域 (CR)。检查点区域包含指向最新的 inode map片段的指针（即地址），因此可以通过首先读取 CR 来找到 inode map片段。请注意，检查点区域仅定期更新（例如每 30 秒左右），因此性能不会受到不良影响。因此，磁盘布局的整体结构包含一个检查点区域（指向 inode map的最新部分）；每个 inode 映射片段都包含 inode 的地址； inode 指向文件（和目录），就像典型的 UNIX 文件系统一样。 下面是检查点区域（注意它位于磁盘的起始位置，地址为 0）以及单个 imap 块、inode 和数据块的示例。一个真正的文件系统当然会有一个大得多的 CR（事实上，它会有两个，我们稍后会了解到）、许多 imap 块，当然还有更多的 inode、数据块等。 ","date":"2024-05-11","objectID":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:7:1","tags":["OS"],"title":"日志结构文件系统","uri":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"7.2 从磁盘读取文件 为了确保你理解 LFS 的工作原理，现在让我们来了解一下从磁盘读取文件的过程。假设内存中什么都没有。我们必须读取的第一个磁盘数据结构是检查点区域。检查点区域包含指向整个 inode map的指针（即磁盘地址），因此 LFS 会读入整个 inode map并缓存在内存中。在此之后，当得到文件的 inode number时，LFS 只需在 imap 中查找 inode number到 inode磁盘地址的映射，然后读入最新版本的 inode。 此时，LFS 会根据需要使用直接指针、间接指针或双向间接指针，完全按照典型 UNIX 文件系统的方式读取文件块。在普通情况下，LFS 从磁盘读取文件时执行的 I/O 次数应与典型文件系统相同；整个 imap 已被缓存，因此 LFS 在读取过程中所做的额外工作就是在 imap 中查找 inode 的地址。 ","date":"2024-05-11","objectID":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:7:2","tags":["OS"],"title":"日志结构文件系统","uri":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"7.3 关于目录 到目前为止，我们已经通过仅考虑inode和数据块来简化了我们的讨论。但是，要访问文件系统中的文件（例如 /home/zfhe/foo），还必须访问某些目录。那么LFS是如何存储目录数据的呢？ 幸运的是，目录结构与经典 UNIX 文件系统基本相同，因为目录只是（名称、inode number）映射的集合。例如，当在磁盘上创建文件时，LFS 必须写入新的 inode、一些数据以及引用该文件的目录数据及其 inode。请记住，LFS 将在磁盘上按顺序执行此操作（在缓冲更新一段时间后）。因此，在目录中创建文件foo 将导致磁盘上出现以下新结构： inode map的片段包含目录文件 dir 以及新创建的文件 f 的位置信息。因此，当访问文件 foo （inode number为 $k$）时，您首先会在inode map（通常缓存在内存中）中查找目录 dir ($A3$) 的inode的位置；然后读取目录 inode，它给出目录数据的位置 ($A2$)；读取此数据块即可获得 (foo, k) 的名称到 inode number的映射。然后再次查阅inode map，找到inode number k（$A1$）的位置，最后在地址$A0$处读取所需的数据块。 LFS 中 inode 映射还解决了另一个严重问题，称为递归更新问题。任何从不就地更新（例如 LFS），而是将更新移动到磁盘上的新位置的文件系统都会出现此问题。 具体来说，每当更新inode时，它在磁盘上的位置就会发生变化。如果我们不小心的话，这也会导致指向该文件的目录的更新，然后会强制要求更改该目录的父目录，依此类推，一直沿着文件系统树向上更新。 LFS通过inode map巧妙地避免了这个问题。尽管inode的位置可能会发生变化，但这种变化永远不会反映在目录本身中；相反，当目录保存相同的名称到inode number映射时，imap 结构会被更新。因此，通过间接，LFS 避免了递归更新问题。 ","date":"2024-05-11","objectID":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:7:3","tags":["OS"],"title":"日志结构文件系统","uri":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"8 新问题：垃圾回收 ","date":"2024-05-11","objectID":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:8:0","tags":["OS"],"title":"日志结构文件系统","uri":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"8.1 基本介绍 您可能已经注意到 LFS 的另一个问题；它将文件的最新版本（包括其inode和数据）重复写入磁盘上的新位置。此过程在保持写入效率的同时，意味着 LFS 会将旧版本的文件结构分散在整个磁盘上。我们称这些旧版本为垃圾。例如，假设我们有一个由inode number $k$ 引用的现有文件，它指向单个数据块 $D0$。我们现在更新该块，生成新的inode和新的数据块。 LFS 的最终磁盘布局看起来像这样（注意，为了简单起见，我们省略了 imap 和其他结构；新的 imap 块也必须写入磁盘以指向新的 inode）： 在图中，您可以看到磁盘上的inode和数据块都有两个版本，一个是旧版本（左侧），另一个是当前的、即时的版本（右侧）。通过（逻辑上）更新数据块这一简单行为，LFS 必须持久化大量新结构，从而在磁盘上留下旧版本的数据块。 举个例子，想象我们将一个块附加到原始文件 k 上。在这种情况下，会生成新版本的 inode，但旧数据块仍由 inode 指向。因此它仍然是有效的，并且完全属于当前文件系统： 那么我们应该如何处理这些旧版本的inode、数据块等呢？可以保留这些旧版本并允许用户恢复旧文件版本（例如，当他们不小心覆盖或删除文件时，这样做可能非常方便）；这种文件系统称为版本控制文件系统，因为它跟踪文件的不同版本。 然而，LFS 仅保留文件的最新实时版本；因此（在后台），LFS 必须定期查找文件数据、inode和其他结构的这些旧的无效版本，并清理它们；因此，清理应该使磁盘上的块再次空闲以供后续写入使用。请注意，清理过程是垃圾回收的一种形式，这是编程语言中出现的一种技术，可以自动释放程序未使用的内存。 前面我们讨论了段的重要性，因为它们是在 LFS 中实现对磁盘进行大量写入的机制。事实证明，它们对于有效清理也是不可或缺的。想象一下，如果 LFS 清理器在清理过程中简单地遍历并释放单个数据块、inode等，会发生什么。结果：文件系统在磁盘上分配的空间之间混合了一定数量的空闲孔。写入性能将大幅下降，因为 LFS 无法找到大的连续区域来顺序且高性能地写入磁盘。 相反，LFS 清理器逐段工作，从而为后续写入清理大块空间。基本清理过程如下。 LFS 清理器定期读取一些旧的（部分使用的）段，确定这些段中哪些块是有效的，然后写出一组新的段，其中仅包含有效的块，从而释放旧的段以供写入。具体来说，我们期望清理程序读取 $M$ 个现有段，将其内容压缩为 $N$ 个新段（其中 $N \u003c M$ ），然后将 $N$ 个段写入磁盘的新位置。然后，旧的 $M$ 段将被释放，可供文件系统用于后续写入。 然而，我们现在面临两个问题。 第一个是机制：LFS 如何判断段内哪些块是有效块，哪些块是无效块？ 第二个是策略：清理程序应该多久运行一次，以及应该选择清理哪些部分？ ","date":"2024-05-11","objectID":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:8:1","tags":["OS"],"title":"日志结构文件系统","uri":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"8.2 确定块有效性 我们首先解决机制问题。给定磁盘段 $S$ 内的数据块 $D$，LFS 必须能够确定 $D$ 是否处于有效状态。为此，LFS 向描述每个块的每个段添加了一些额外信息。具体来说，LFS包括每个数据块$D$包括它的inode number（它属于哪个文件）和它的偏移量（它是文件的哪个块）。该信息记录在段头部的结构中，称为段摘要块。 有了这些信息，就可以很容易地确定一个块是有效的还是无效的。对于位于磁盘上地址 $A$ 的块 $D$，查看段摘要块并找到其inode number $N$ 和偏移量 $T$ 。接下来，在 imap 中查找 $N$ 所在的位置并从磁盘读取 $N$（也许它已经在内存中，这样更好）。最后，使用偏移量 $T$ ，查看 inode（或某个间接块）以查看 inode 认为该文件的第 $T$ 个块位于磁盘上的位置。如果它准确地指向磁盘地址A，LFS可以断定块D是有效的。如果它指向其他地方，LFS 可以断定 D 没有在使用中（即它已失效），从而知道不再需要该版本。这是伪代码摘要： (N, T) = SegmentSummary[A]; inode = Read(imap[N]); if (inode[T] == A) // block D is alive else // block D is garbage 下面是描述该机制的图，其中段摘要块（标记为 $SS$）记录了地址 $A0$ 处的数据块实际上是文件 k 偏移量 0 处的一部分。通过检查 k 的 imap，可以找到 inode，并看到它确实指向该位置。 LFS 会采取一些快捷方式来提高确定有效性过程的效率。例如，当文件被截断或删除时，LFS 会增加其版本号，并在 imap 中记录新的版本号。通过在磁盘段中记录版本号，LFS 只需将磁盘上的版本号与 imap 中的版本号进行比较，就能缩短上述较长时间的检查，从而避免额外的读取。 ","date":"2024-05-11","objectID":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:8:2","tags":["OS"],"title":"日志结构文件系统","uri":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"8.3 策略问题：清理哪些块以及何时清理 除上述机制外，LFS 还必须包含一套策略，以确定何时清理以及哪些块值得清理；确定何时清理比较简单：定期、空闲时或磁盘已满而不得不清理时。 而确定清理哪些块则更具挑战性，这也是许多研究论文的主题。在最初的 LFS 论文中，作者描述了一种试图分离热段和冷段的方法。热段是指内容经常被覆盖的段，因此，对于这样的段，最好的策略是等待很长时间再进行清理，因为越来越多的数据块被覆盖（在新的段中），从而被释放出来以供使用。 相比之下，冷段可能会有一些无效块，但其余内容相对稳定。因此，作者得出结论，应该尽早清理冷段，晚些清理热段，并开发了一种启发式方法来实现这一目标。然而，与大多数策略一样，这种策略并不完美；后来的方法展示了如何做得更好。 ","date":"2024-05-11","objectID":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:8:3","tags":["OS"],"title":"日志结构文件系统","uri":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"9 崩溃恢复和日志 最后一个问题：如果 LFS 写入磁盘时系统崩溃，会发生什么？更新期间的崩溃对于文件系统来说是很棘手的，因此 LFS 也必须考虑这一点。 在正常操作期间，LFS 缓冲段中的写入，然后（当段已满或经过一定时间时）将该段写入磁盘。 LFS 将这些写入组织在日志中，即检查点区域指向头段和尾段，每个段都指向下一个要写入的段。 LFS 还定期更新检查点区域。在这些操作（写入段、写入 CR）期间显然可能会发生崩溃。那么 LFS 如何处理写入这些结构期间的崩溃呢？ 我们先来说第二种情况。为了确保 CR 更新以原子方式发生，LFS 实际上保留了两个 CR，分别位于磁盘的两端，并交替写入。 LFS 在使用指向 inode map的最新指针和其他信息更新 CR 时还实现了谨慎的协议；具体来说，它首先写出一个标头（带有时间戳），然后写出 CR 的主题，最后写出最后一个块（也带有时间戳）。如果系统在 CR 更新期间崩溃，LFS 可以通过查看一对不一致的时间戳来检测到这一情况。 LFS总是会选择使用最新的具有一致时间戳的CR，从而实现CR的一致更新。 现在我们来解决第一种情况。由于 LFS 大约每 30 秒写入一次 CR，因此文件系统的最后一个一致快照可能相当旧。因此，重新启动后，LFS 可以通过简单地读取检查点区域、它指向的 imap 片段以及后续文件和目录来轻松恢复；但是，最后几秒的更新将会丢失。 为了改进这一点，LFS 尝试通过数据库社区中称为前滚的技术来重建许多这些段。基本思想是从最后一个检查点区域开始，找到日志的末尾（包含在 CR 中），然后使用它来读取接下来的段并查看其中是否有任何有效的更新。如果有，LFS 会相应地更新文件系统，从而恢复自上一个检查点以来写入的大部分数据和元数据。 ","date":"2024-05-11","objectID":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:9:0","tags":["OS"],"title":"日志结构文件系统","uri":"/posts/34.%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"1 崩溃一致性 正如我们到目前为止所看到的，文件系统管理一组数据结构来实现预期的抽象：文件、目录以及支持我们期望从文件系统获得的基本抽象所需的所有其他元数据。与大多数数据结构（例如，在正在运行的程序的内存中找到的数据结构）不同，文件系统数据结构必须持久存在，即它们必须长期存在，存储在即使断电也能保留数据的设备上（例如硬盘或基于闪存的 SSD）。 文件系统面临的一项主要挑战是如何在断电或系统崩溃的情况下更新持久数据结构。具体来说，如果在更新磁盘结构的过程中，有人被电源线绊倒并且机器断电，会发生什么情况？或者操作系统遇到bug而崩溃？由于断电和崩溃，更新持久数据结构可能非常棘手，并导致文件系统实现中出现一个新的有趣问题，称为崩溃一致性问题。 这个问题很容易理解。想象一下，您必须更新两个磁盘上的结构 A 和 B，才能完成特定操作。由于磁盘一次仅服务一个请求，因此这些请求之一将首先到达磁盘（A 或 B）。如果系统在一次写入完成后崩溃或断电，磁盘上的结构将处于不一致的状态。因此，我们有一个所有文件系统都需要解决的关键问题： 如何在崩溃的情况下更新磁盘？系统可能会崩溃或在任意两次写入之间断电，因此磁盘上的状态可能只会部分更新。崩溃后，系统启动并希望再次挂载文件系统（以便访问文件等）。鉴于崩溃可能在任意时间点发生，我们如何确保文件系统将磁盘映像保持在合理的状态？ 在本章中，我们将更详细地描述这个问题，并了解文件系统用来克服它的一些方法。我们将首先检查旧文件系统所采用的方法，称为 fsck 或文件系统检查器。然后，我们将注意力转向另一种方法，称为日志记录（也称为预写日志记录），这种技术会为每次写入增加一点开销，但可以更快地从崩溃或断电中恢复。我们将讨论日志记录的基本机制，包括 Linux ext3（一种相对现代的日志文件系统）实现的几种不同风格的日志记录。 ","date":"2024-05-11","objectID":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/:1:0","tags":["OS"],"title":"FSCK和日志","uri":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/"},{"categories":["系统架构"],"content":"2 详细示例 ","date":"2024-05-11","objectID":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/:2:0","tags":["OS"],"title":"FSCK和日志","uri":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/"},{"categories":["系统架构"],"content":"2.1 基本介绍 为了开始我们对日志的研究，让我们来看一个例子。我们需要使用以某种方式更新磁盘结构的工作负载。假设工作负载很简单：向现有文件追加一个数据块。追加的方法是打开文件，调用 lseek() 将文件偏移量移动到文件末尾，然后在关闭文件之前向文件写入一个 4KB 的数据块。 我们还假设磁盘上使用的是标准的简单文件系统结构，类似于我们以前见过的文件系统。这个小例子包括一个 inode 位图（只有 8 位，每个 inode 一个）、一个数据位图（也是 8 位，每个数据块一个）、inodes（共 8 个，编号 0 至 7，分布在 4 个块中）和数据块（共 8 个，编号 0 至 7）。下面是该文件系统的示意图： 观察图片中的结构，可以看到一个已分配的 inode（inode number 2）和一个已分配的数据块（数据块 4），前者已在 inode 位图中标记，后者也在数据位图中标记。该 inode 被标记为 I[v1]，因为它是该 inode 的第一个版本；它将很快被更新（由于上述工作负载）。让我们也来看看这个简化的 inode 内部。在 I[v1] 中，我们可以看到： owner : remzi permissions : read-write size : 1 pointer : 4 pointer : null pointer : null pointer : null 在这个简化的 inode 中，文件的size为 1（分配了一个块），第一个直接指针指向块 4（文件的第一个数据块 Da），所有其他三个直接指针都设置为 null （表明它们没有被使用）。当然，真正的inode还有更多的字段。 当我们追加到文件时，我们向其中添加一个新的数据块，因此必须更新三个磁盘结构：inode（必须指向新块并记录由于追加而产生的新的较大大小）、新的数据块Db，以及新版本的数据位图（称为B[v2]）来指示新的数据块已经被分配。 因此，在系统内存中，我们必须将三个块写入磁盘。更新后的索引节点（inode版本 2，简称 I[v2]）现在如下所示： 为实现这一转换，文件系统必须向磁盘执行三次单独的写入操作，分别写入 inode (I[v2])、bitmap (B[v2]) 和数据块 (Db)。请注意，这些写入通常不会在用户发出 write() 系统调用时立即发生；相反，脏的 inode、位图和新数据会先在主内存（页面缓存或缓冲区缓存）中停留一段时间；然后，当文件系统最终决定将它们写入磁盘时（比如 5 秒或 30 秒后），文件系统会向磁盘发出必要的写入请求。 不幸的是，崩溃可能会发生，从而干扰对磁盘的更新。特别是，如果在写入其中一个或两个而不是全部三个之后发生崩溃，文件系统可能会处于一种奇怪的状态。 ","date":"2024-05-11","objectID":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/:2:1","tags":["OS"],"title":"FSCK和日志","uri":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/"},{"categories":["系统架构"],"content":"2.2 崩溃场景 为了更好地理解这个问题，让我们看一些崩溃场景的例子。想象一下只有一次写入成功；因此存在三种可能的结果，我们在此列出： 仅将数据块 (Db) 写入磁盘。 在这种情况下，数据就在磁盘上，但没有指向它的 inode，也没有位图显示该数据块已分配。因此，写入就好像从未发生过一样。从文件系统崩溃一致性的角度来看，这种情况根本不是问题。 只有更新的 inode（I[v2]）被写入磁盘。 在这种情况下，inode 指向 Db 即将被写入的磁盘地址 (5)，但 Db 尚未被写入。因此，如果我们相信该指针，就会从磁盘读取垃圾数据（磁盘地址 5 的旧内容）。 此外，我们还遇到了一个新问题，我们称之为文件系统不一致。磁盘位图告诉我们，数据块 5 尚未分配，但 inode 却说它已经分配。位图和 inode 之间的不一致是文件系统数据结构的不一致；要使用文件系统，我们必须以某种方式解决这个问题。 只有更新后的位图（B[v2]）被写入磁盘。 在这种情况下，位图显示块 5 已分配，但却没有指向它的 inode。因此，文件系统再次出现不一致；如果不加以解决，这次写入将导致空间泄漏，因为文件系统永远不会使用块 5。 在尝试向磁盘写入三个数据块的过程中，还有三种崩溃情况。在这些情况中，两次写入成功，最后一次写入失败： inode (I[v2]) 和 bitmap (B[v2]) 被写入磁盘，但数据 (Db) 未被写入。 在这种情况下，文件系统元数据是完全一致的：inode 有一个指向块 5 的指针，位图显示 5 正在使用中，因此从文件系统元数据的角度看一切正常。但有一个问题：5 中又出现了垃圾。 写入了 inode (I[v2]) 和数据块 (Db)，但没有写入位图 (B[v2])。在这种情况下，我们的 inode 指向了磁盘上的正确数据，但 inode 和旧版本的位图 (B1) 之间再次出现不一致。因此，我们再次需要在使用文件系统前解决这个问题。 位图 (B[v2]) 和数据块 (Db) 被写入，但 inode (I[v2]) 却没有被写入。在这种情况下，我们又遇到了 inode 和数据位图不一致的问题。然而，尽管块已被写入，位图也显示了它的使用情况，我们却不知道它属于哪个文件，因为没有 inode 指向该文件。 ","date":"2024-05-11","objectID":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/:2:2","tags":["OS"],"title":"FSCK和日志","uri":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/"},{"categories":["系统架构"],"content":"2.3 崩溃一致性问题 希望从这些崩溃场景中，你能看到磁盘上的文件系统映像因崩溃而可能出现的诸多问题：文件系统数据结构不一致；空间泄漏；向用户返回垃圾数据等等。理想情况下，我们希望将文件系统从一种一致的状态（例如，在文件被附加之前）原子地移动到另一种一致的状态（例如，在将 inode、位图和新数据块写入磁盘之后）。遗憾的是，我们无法轻易做到这一点，因为磁盘每次只提交一次写入，而在这些更新之间可能会发生崩溃或断电。我们将这一普遍问题称为崩溃一致性问题（也可称为一致性更新问题）。 ","date":"2024-05-11","objectID":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/:2:3","tags":["OS"],"title":"FSCK和日志","uri":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/"},{"categories":["系统架构"],"content":"3 解决方案#1：文件系统检查器 早期的文件系统采用一种简单的方法来解决崩溃一致性问题。基本上，它们决定任由不一致性发生，然后稍后（重启时）再修复它们。fsck就是这种懒惰方法的典型例子，它是一种 UNIX 工具，用于查找和修复此类不一致性；不同系统上也有类似的工具用于检查和修复磁盘分区。需要注意的是，这种方法并不能解决所有问题；例如，考虑上述文件系统看起来一致，但 inode 指向垃圾数据的情况。唯一真正的目标是确保文件系统元数据的内部一致性。 正如 McKusick 和 Kowalski 的论文所总结的，fsck 工具的运行分为几个阶段。它在文件系统挂载和可用之前运行（fsck 假设运行时没有其他文件系统活动）；一旦完成，磁盘上的文件系统应该是一致的，因此可以让用户访问。以下是 fsck 工作的基本概要： 超级块：fsck 首先检查超级块看起来是否合理，主要是进行健全性检查，如确保文件系统大小大于已分配的块数。这些健全性检查的目的通常是发现可疑（损坏）的超级块；在这种情况下，系统（或管理员）可能会决定使用超级块的替代副本。 空闲块：接下来，fsck 会扫描 inodes、间接块、双间接块等，以了解文件系统中当前分配的块。它利用这些知识生成正确版本的分配位图；因此，如果位图和 inodes 之间有任何不一致，可以通过信任 inodes 中的信息来解决。对所有 inodes 执行相同类型的检查，确保所有看起来正在使用的 inodes 都在 inode 位图中标记为正在使用。 Inode状态：检查每个 inode 是否损坏或存在其他问题。例如，fsck 会确保每个已分配的 inode 都有一个有效的类型字段（如常规文件、目录、符号链接等）。如果 inode 字段存在不易修复的问题，该 inode 就会被视为可疑，并被 fsck 清除；inode 位图也会相应更新。 Inode 链接：fsck 还会验证每个已分配 inode 的链接计数。链接计数表示包含对该特定文件的引用（即链接）的不同目录的数量。为了验证链接计数，fsck 会从根目录开始扫描整个目录树，并为文件系统中的每个文件和目录建立自己的链接计数。如果新计算的链接数与某个 inode 中的链接数不匹配，就必须采取纠正措施，通常是修复 inode 中的链接数。如果发现一个已分配的 inode，但没有目录指向它，它就会被移到lost+found目录\u003c/。 重复：fsck 还会检查重复指针，即两个不同的 inode 指向同一块的情况。如果其中一个 inode 明显有问题，可能会被清除。或者，可以复制指向的块，从而根据需要给每个 inode 提供自己的副本。 坏块：在扫描所有指针列表时，还会对坏块指针进行检查。如果一个指针明显指向超出其有效范围的内容，例如，它的地址指向的块大于分区大小，那么这个指针就被认为是 “坏的”。在这种情况下，fsck 不会做任何太聪明的事情；它只是从 inode 或间接块中删除（清除）指针。 目录检查：fsck 无法理解用户文件的内容；但目录中包含文件系统本身创建的特定格式化信息。因此，fsck 会对每个目录的内容执行额外的完整性检查，确保\". “和”.. “是第一个条目，目录条目中引用的每个 inode 都已分配，并确保在整个层次结构中，没有任何目录被链接超过一次。 如你所见，构建一个有效的 fsck 需要复杂的文件系统知识；要确保这样一段代码在所有情况下都能正确运行，是一项挑战。然而，fsck（以及类似方法）还有一个更大、也许更根本的问题：它们太慢了。在磁盘容量非常大的情况下，扫描整个磁盘以找到所有已分配块并读取整个目录树可能需要数分钟或数小时。随着磁盘容量的增加和 RAID 的普及，fsck 的性能变得令人望而却步。 从更高层次来看，fsck 的基本前提似乎有点不合理。想想我们上面的例子，只有三个数据块被写入磁盘；要扫描整个磁盘来修复在更新三个数据块时出现的问题，成本高得惊人。这种情况就好比你把钥匙掉在卧室的地板上，然后开始搜索整个房子的钥匙恢复算法，从地下室开始，逐个房间搜索。这样做虽然有效，但会造成浪费。因此，随着磁盘（和 RAID）的发展，研究人员和从业人员开始寻找其他解决方案。 ","date":"2024-05-11","objectID":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/:3:0","tags":["OS"],"title":"FSCK和日志","uri":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/"},{"categories":["系统架构"],"content":"4 解决方案#2：日志（或预写日志） ","date":"2024-05-11","objectID":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/:4:0","tags":["OS"],"title":"FSCK和日志","uri":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/"},{"categories":["系统架构"],"content":"4.1 基本介绍 解决一致性更新问题的最流行的解决方案可能是从数据库管理系统领域窃取的一个想法。这种被称为预写日志的想法正是为了解决此类问题而发明的。在文件系统中，由于历史原因，我们通常将其称为预写日志记录。第一个做到这一点的文件系统是 Cedar，尽管许多现代文件系统都使用这个想法，包括 Linux ext3 和 ext4、reiserfs、IBM 的 JFS、SGI 的 XFS 和 Windows NTFS。 基本思路如下：更新磁盘时，在覆盖现有的结构之前，首先写下一个小注释（磁盘上其他某个众所周知的位置）描述您将要执行的操作。写这个注释是“预写”部分，我们将其写入我们组织为“日志”的结构中；因此，预写日志记录。 通过将注释写入磁盘，您可以保证如果在更新（覆盖）正在更新的结构期间发生崩溃，您可以返回并查看您所做的注释并重试；因此，您将确切地知道崩溃后要修复什么（以及如何修复），而不必扫描整个磁盘。根据设计，日志记录会在更新期间增加一些工作量，从而大大减少恢复期间所需的工作量。 现在我们将描述 Linux ext3（一种流行的日志文件系统）如何将日志合并到文件系统中。大多数磁盘结构与 Linux ext2 相同，例如，磁盘分为块组，每个块组包含 inode 位图、数据位图、inode 和数据块。新的关键结构是日志本身，它占用分区内或其他设备上的一些少量空间。因此，ext2 文件系统（没有日志）如下所示： 假设日志放置在同一个文件系统映像中（尽管有时它放置在单独的设备上，或者作为文件系统中的文件），带有日志的 ext3 文件系统如下所示： 真正的区别只是日志的存在，当然还有它的使用方式。 ","date":"2024-05-11","objectID":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/:4:1","tags":["OS"],"title":"FSCK和日志","uri":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/"},{"categories":["系统架构"],"content":"4.2 数据日志 让我们看一个简单的例子来了解数据日志的工作原理。数据日志是 Linux ext3 文件系统的一种模式，本文的大部分讨论都是基于这种模式。 假设我们再次进行典型更新，希望将 inode (I[v2])、位图 (B[v2]) 和数据块 (Db) 再次写入磁盘。在将它们写入最终磁盘位置之前，我们首先要将它们写入日志（又称日记）。这就是日志中的内容： 可以看到，我们在这里写入了 5 个块。事务开始（TxB）告诉我们这次更新的信息，包括文件系统待更新的信息（例如，块 I[v2]、B[v2]和 Db 的最终地址），以及某种事务标识符（TID）。中间三个块只包含块本身的确切内容；这被称为物理日志，因为我们将更新的确切物理内容写入日志（另一种想法是逻辑日志，将更新的逻辑表述更紧凑地写入日志，例如 “此更新希望将数据块 Db 附加到文件 X”，这有点复杂，但可以节省日志空间，也许还能提高性能）。最后一个数据块（TxE）是该事务结束的标记，也包含 TID。 一旦事务安全地存储在磁盘上，我们就可以覆盖文件系统中的旧结构；这个过程称为检查点。因此，为了对文件系统进行检查点（即使其与日志中的待定更新保持同步），我们按照上述方式将I[v2]、B[v2] 和 Db 写入到它们的磁盘位置；如果这些写入成功完成，我们就对文件系统进行了检查点，基本上就完成了。因此，我们的初始操作序列为： 写日志：将事务写入日志，包括事务开始块、所有待处理的数据和元数据更新以及事务结束块；等待这些写入完成。 检查点：将待处理的元数据和数据更新写入文件系统中的最终位置。 在我们的示例中，我们首先将 TxB、I[v2]、B[v2]、Db 和 TxE 写入日志。当这些写入完成后，我们将通过检查点 I[v2]、B[v2] 和 Db 到它们在磁盘上的最终位置来完成更新。 当写入日志期间发生崩溃时，事情会变得有点棘手。在这里，我们尝试将事务中的一组块（例如，TxB、I[v2]、B[v2]、Db、TxE）写入磁盘。一种简单的方法是一次发出每一个，等待每一个完成，然后发出下一个。然而，这很慢。理想情况下，我们希望一次发出所有五个块写入，因为这会将五个写入转换为单个顺序写入，从而速度更快。然而，这是不安全的，原因如下：给定如此大的写入，磁盘内部可能会执行调度并以任何顺序完成大写入的小片段。因此，磁盘内部可以 (1) 写入 TxB、I[v2]、B[v2] 和 TxE，并且仅在稍后 (2) 写入 Db。不幸的是，如果磁盘在 (1) 和 (2) 之间断电，磁盘上的结果如下： 强制写入磁盘 现代文件系统在强制两次磁盘写入之间保持顺序时需要额外的预防措施。过去，简单地等待第一次写入完成再进行第二次写入就足够了。然而，由于写入缓存的使用增加，这种方法不再有效。启用写入缓存后，磁盘可能会在将数据放置在内存缓存中后通知操作系统写入已完成，而不是立即将数据写入磁盘。这使得无法保证先前的写入在后续写入之前到达磁盘。 为了解决这个问题，一种解决方案是禁用写缓存，但这会影响性能。另一种现代方法是明确发出写屏障，确保在屏障之前发出的所有写入在屏障之后发出的任何写入之前到达磁盘。然而，最近的研究表明，一些磁盘制造商为了提高性能，可能会忽略写屏障请求，这可能导致错误操作。 为什么会有这个问题？这个事务看起来是一个有效的事务（它有一个开始和结束，序列号匹配）。此外，文件系统无法查看第四个数据块并知道它是错误的；毕竟，它是任意的用户数据。因此，如果系统现在重启并运行恢复，它就会重放此事务，并无知地将垃圾数据块”?? “的内容复制到 Db 应该存放的位置。这对文件中的任意用户数据来说是很糟糕的；如果发生在文件系统的关键部分，如超级块上，情况就更糟了，可能导致文件系统无法挂载。 优化日志写入 文件系统首先要写出事务开始块和事务内容；只有在这些写入完成后，文件系统才能将事务结束块发送到磁盘，这样写入日志的效率特别低，通常会产生额外的旋转（因为磁盘通常需要等待正确的扇区旋转到磁头下方才能进行写入操作）。 Linux ext4中则提供了这样一个方法：将事务写入日志时，在开始和结束块中包含日志内容的校验和。这样做使文件系统能够一次写入整个事务，而不会产生等待；如果在恢复期间，文件系统发现事务中计算的校验和与存储的校验和不匹配，则可以断定事务写入期间发生了崩溃，从而丢弃文件系统更新。因此，通过对写入协议和恢复系统进行小的调整，文件系统可以实现更快的常见情况性能；最重要的是，系统稍微更可靠，因为从日志中读取的任何内容现在都受到校验和的保护。 为避免这一问题，文件系统分两步进行事务写入。首先，文件系统将除 TxE 块外的所有块写入日志，并一次性完成这些写入操作。当这些写入完成后，日志将显示如下内容： 这些写入完成后，文件系统会发出 TxE 块的写入，从而使日志处于最终安全状态： 这个过程的一个重要方面是磁盘提供的原子性保证。事实证明，磁盘保证任何 512 字节的写入要么发生要么不发生（绝不会写一半）；因此，要确保 TxE 的写入是原子性的，就应该把它变成一个单一的 512 字节块。因此，我们目前更新文件系统的协议分为三个阶段： 日志写入：将事务内容（包括 TxB、元数据和数据）写入日志；等待写入完成。 日志提交：将事务提交块（包含 TxE）写入日志；等待写入完成；事务即被提交。 检查点：将更新内容（元数据和数据）写入磁盘上的最终位置。 ","date":"2024-05-11","objectID":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/:4:2","tags":["OS"],"title":"FSCK和日志","uri":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/"},{"categories":["系统架构"],"content":"4.3 恢复 现在让我们了解文件系统如何使用日志的内容从崩溃中恢复。在此更新序列期间随时可能发生崩溃。 如果崩溃发生在事务安全写入日志之前（即，在上面的步骤 2 完成之前），那么我们的工作就很简单：只需跳过挂起的更新。 如果崩溃发生在事务提交到日志之后、检查点完成之前，文件系统可以按如下方式恢复更新。当系统启动时，文件系统恢复过程将扫描日志并查找已提交到磁盘的事务；因此，这些事务会被重放（按顺序），文件系统再次尝试将事务中的块写出到它们在磁盘上的最终位置。这种形式的日志记录是最简单的形式之一，称为重做日志。通过恢复日志中已提交的事务，文件系统确保磁盘上的结构是一致的，因此可以通过挂载文件系统并为新请求做好准备来继续进行。 请注意，在检查点期间的任何时候发生崩溃都是正常的，即使在对块的最终位置的一些更新已经完成之后也是如此。在最坏的情况下，其中一些更新只是在恢复期间再次执行。由于恢复是一种罕见的操作（仅在意外系统崩溃后发生），因此无需担心一些冗余写入。 ","date":"2024-05-11","objectID":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/:4:3","tags":["OS"],"title":"FSCK和日志","uri":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/"},{"categories":["系统架构"],"content":"4.4 批处理日志更新 您可能已经注意到，基本协议可能会增加大量额外的磁盘流量。例如，假设我们在同一目录中连续创建两个文件，分别称为 file1 和 file2。要创建一个文件，必须更新许多磁盘结构，至少包括：inode 位图（分配新的 inode）、文件新创建的 inode、包含新目录条目的的父目录的数据块和父目录 inode（现在有新的修改时间）。通过日志记录，我们在逻辑上将所有这些信息提交到我们创建的两个文件的日志中；因为这些文件位于同一目录中，并且假设它们甚至在同一 inode 块中具有 inode，这意味着如果我们不小心，我们最终将一遍又一遍地写入这些相同的块，即相同的目录数据块和 inode 可能会被重复写入，造成了额外的磁盘流量和性能开销。。 为了解决这个问题，某些文件系统不会一次将每个更新提交到磁盘（例如，Linux ext3）；相反，我们可以将所有更新缓冲到全局事务中。在上面的例子中，当创建两个文件时，文件系统只是将内存中的 inode 位图、文件的 inode、目录数据和目录 inode 标记为脏，并将它们添加到形成当前事务的块列表中。当最终将这些块写入磁盘时（例如，5 秒超时后），将提交包含上述所有更新的单个全局事务。因此，通过缓冲更新，文件系统在许多情况下可以避免过多的磁盘写入流量。 ","date":"2024-05-11","objectID":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/:4:4","tags":["OS"],"title":"FSCK和日志","uri":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/"},{"categories":["系统架构"],"content":"4.5 限制日志大小 因此，我们已经达成了更新磁盘上文件系统结构的基本协议。文件系统在内存中缓冲更新一段时间；当最终写入磁盘时，文件系统首先仔细地将事务的详细信息写入日志（也称为预写日志）；事务完成后，文件系统将这些块检查点到它们在磁盘上的最终位置。 然而，日志的大小是有限的。如果我们继续向其中添加事务（如下图所示），它很快就会填满。你认为接下来会发生什么？ 日志满时会出现两个问题： 第一个问题比较简单，但不那么关键：日志越大，恢复所需的时间就越长，因为恢复过程必须（按顺序）重放日志中的所有事务才能恢复。 第二个问题更为严重：当日志已满（或接近满）时，就无法再向磁盘提交任何事务，从而使文件系统变得 “不那么有用”（即无用）。 为了解决这些问题，日志文件系统将日志视为循环数据结构，不断重复使用；这就是日志有时被称为循环日志的原因。为此，文件系统必须在检查点之后的一段时间内采取行动。具体来说，一旦事务被检查点化，文件系统就应释放日志中占用的空间，允许日志空间被重复使用。实现这一目的的方法有很多，例如，你可以简单地在日志超级块中标记日志中最旧和最新的非检查点事务，其他所有空间都是空闲的。下面是一个图表说明： 在日志超级块（不要与主文件系统超级块混淆）中，日志系统记录足够的信息以了解哪些事务尚未设置检查点，从而减少恢复时间并允许以循环方式重复使用日志。因此，我们在基本协议中添加了另一个步骤： 日志写入：将事务内容（包含 TxB 和更新内容）写入日志，等待这些写入完成。 日志提交：将事务提交块（包含TxE）写入日志，等待写入完成，事务现已提交。 检查点：将更新内容写入文件系统中的最终位置。 释放：一段时间后，通过更新日志超级块在日志中将事务标记为已释放。 这样我们就有了最终的数据日志协议。但仍然存在一个问题：我们将每个数据块写入磁盘两次，这是一个沉重的成本，特别是对于像系统崩溃这样罕见的情况。 ","date":"2024-05-11","objectID":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/:4:5","tags":["OS"],"title":"FSCK和日志","uri":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/"},{"categories":["系统架构"],"content":"4.6 元数据日志 尽管现在恢复速度很快（扫描日志并重放一些事务，而不是扫描整个磁盘），但文件系统的正常操作比我们期望的要慢。特别是，对于每次写入磁盘，我们现在也首先写入日志，从而使写入流量加倍；在顺序写入工作负载期间，这种加倍尤其令人痛苦，现在该工作负载将以驱动器峰值写入带宽的一半进行。此外，在写入日志和写入主文件系统之间，存在成本高昂的查找，这显着增加了某些工作负载的开销。 由于将每个数据块写入磁盘两次的成本很高，因此人们尝试了一些不同的方法来提高性能。例如，我们上面描述的日志模式通常称为数据日志（如在 Linux ext3 中），因为它记录所有用户数据（除了文件系统的元数据）。一种更简单（也更常见）的日志形式有时称为有序日志（或只是元数据日志），它几乎相同，只是用户数据不写入日志。因此，当执行与上述相同的更新时，以下信息将被写入日志： 之前写入日志的数据块 Db 将被写入文件系统本身，避免了额外的写入；考虑到磁盘的大部分 I/O 流量都是数据，不重复写入数据大大减少了日志的 I/O 负载。不过，这一修改确实提出了一个有趣的问题：我们应该在什么时候将数据块写入磁盘？ 为了更好地理解这个问题，我们再来看看追加文件的例子。更新由三个数据块组成：I[v2]、B[v2] 和 Db。前两个块都是元数据，会被记录下来，然后进行检查点处理；后一个块只会被写入文件系统一次。我们应该何时将 Db 写入磁盘？这重要吗？ 事实证明，对于纯元数据日志，数据写入的顺序确实很重要。例如，如果我们在事务（包含 I[v2] 和 B[v2]）完成后将 Db 写入磁盘，会怎样？不幸的是，这种方法存在一个问题：文件系统是一致的，但 I[v2] 最终可能指向垃圾数据。具体来说，考虑 I[v2] 和 B[v2] 已被写入，但 Db 未被写入磁盘的情况。这时文件系统会尝试恢复。由于 Db 不在日志中，文件系统将重放对 I[v2] 和 B[v2] 的写入，并生成一个一致的文件系统（从文件系统元数据的角度来看）。但是，I[v2] 将指向垃圾数据，即 Db 所在槽中的任何数据。 为了确保这种情况不会发生，一些文件系统（如 Linux ext3）会在将相关元数据写入磁盘之前，先将数据块（常规文件）写入磁盘。 具体来说，协议如下： 数据写入：将数据写入最终位置，等待完成（等待是可选的，详见下文）。 日志元数据写入：将起始块和元数据写入日志，等待写入完成。 日志提交：将事务提交块（包含 TxE）写入日志，等待写入完成，事务（包括数据）现已提交。 检查点元数据：将元数据更新内容写入文件系统中的最终位置。 释放：之后，在日志超级块中标记事务释放。 通过强制先写入数据，文件系统可以保证指针永远不会指向垃圾文件。事实上，\"先写被指向对象，再写指向该对象的对象 “这一规则是崩溃一致性的核心，其他崩溃一致性方案也进一步利用了这一规则（详见下文）。 在大多数系统中，元数据日志（类似于 ext3 的有序日志）比完整数据日志更受欢迎。例如，Windows NTFS 和 SGI 的 XFS 都使用某种形式的元数据日志。 Linux ext3 允许您选择数据、有序或无序模式（在无序模式下，可以随时写入数据）。所有这些模式都保持元数据一致；它们的数据语义各不相同。 最后，请注意，如上述协议所示，在向日志发出写入（步骤 2）之前强制完成数据写入（步骤 1）并不是正确性所必需的。具体来说，最好同时对数据、事务开始块和日志元数据进行写入；唯一真正的要求是步骤 1 和 2 在发布日志提交块（步骤 3）之前完成。 ","date":"2024-05-11","objectID":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/:4:6","tags":["OS"],"title":"FSCK和日志","uri":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/"},{"categories":["系统架构"],"content":"4.7 棘手的情况：块重用 有一些有趣的情况会让日志记录变得更加棘手，因此值得讨论。其中许多情况都与块重用有关；正如Stephen Tweedie（ext3 的主要幕后推手之一）所说： “整个系统最可怕的部分是什么？是删除文件。与删除有关的一切都令人毛骨悚然。所有与删除有关的事情……都会让你做噩梦，因为如果块被删除，然后重新分配，会发生什么？ Tweedie给出的具体例子如下。假设你正在使用某种形式的元数据日志（因此文件的数据块没有日志）。假设有一个名为 foo 的目录。用户向 foo 添加条目（比如创建文件），因此 foo 的内容（因为目录被视为元数据）被写入日志；假设 foo 目录数据的位置是块 1000。日志内容如下 此时，用户删除目录中的所有内容以及目录本身，从而释放块 1000 以供重复使用。最后，用户创建一个新文件（例如 foobar），最终会重用曾经属于 foo 的相同块（1000）。 foobar 的 inode 及其数据都提交到磁盘；但请注意，由于正在使用元数据日志，因此只有 foobar 的 inode 会提交到日志；文件 foobar 中块 1000 中新写入的数据未记录。 现在假设发生了崩溃，并且所有这些信息仍在日志中。在重放期间，恢复过程只是重放日志中的所有内容，包括块 1000 中目录数据的写入；因此，重访会用旧目录内容覆盖当前文件 foobar 的用户数据！显然这不是一个正确的恢复操作，并且当用户读取文件 foobar 时肯定会感到惊讶。 对于这个问题有多种解决方案。例如，人们可以永远不会重用块，直到从日志中检查到删除所述块为止。 Linux ext3 所做的是向日志添加一种新类型的记录，称为撤销记录。在上述情况下，删除目录将导致撤销记录写入日志。重放日志时，系统首先扫描此类撤销记录；任何此类撤销的数据都不会被重放，从而避免了上述问题。 ","date":"2024-05-11","objectID":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/:4:7","tags":["OS"],"title":"FSCK和日志","uri":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/"},{"categories":["系统架构"],"content":"4.8 总结日记：时间轴 在结束对日志的讨论之前，我们用时间轴总结一下我们讨论过的协议。上图显示了记录数据和元数据时的协议，而下图显示了只记录元数据时的协议。 在每个图中，时间都是向下递增的，图中的每一行都显示了可以发出或可能完成写入的逻辑时间。例如，在数据日志协议（第一张图）中，事务开始块（TxB）的写入和事务内容的写入在逻辑上可以同时发出，因此可以按任意顺序完成；但事务结束块（TxE）的写入必须在前述写入完成后才能发出。同样，在事务结束块提交之前，也不能开始对数据和元数据块进行检查点写入。水平虚线表示必须遵守写入排序要求的位置。 元数据日志协议也有类似的时间轴。请注意，数据写入在逻辑上可以与事务开始和日志内容的写入同时发出，但必须在事务结束发出前发出并完成。 最后要注意的是，时间轴中标记的每次写入的完成时间是任意的。在实际系统中，完成时间由 I/O 子系统决定，它可能会重新安排写入顺序以提高性能。我们对排序的唯一保证是协议正确性所必须执行的（如图中的水平虚线所示）。 ","date":"2024-05-11","objectID":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/:4:8","tags":["OS"],"title":"FSCK和日志","uri":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/"},{"categories":["系统架构"],"content":"5 解决方案#3：其他方法 到目前为止，我们已经描述了保持文件系统元数据一致性的两种方法： 基于 fsck 的惰性方法 日志记录的更主动的方法。 然而，这些并不是唯一的两种方法。 Ganger 和 Patt 提出了一种这样的方法，称为软更新。这种方法仔细地对文件系统的所有写入进行排序，以确保磁盘上的结构永远不会处于不一致的状态。例如，通过在指向它的inode之前将一个指向的数据块写入磁盘，我们可以确保该inode永远不会指向垃圾；对于文件系统的所有结构都可以导出类似的规则。然而，实施软更新可能是一个挑战；虽然上述日志层可以在对确切文件系统结构相对较少的了解的情况下实现，但软更新需要对每个文件系统数据结构的复杂了解，从而给系统增加了相当多的复杂性。 另一种方法称为写时复制（COW），并在许多流行的文件系统中使用，包括 Sun 的 ZFS。此技术永远不会覆盖原位的文件或目录；相反，它将新的更新放置到磁盘上以前未使用的位置。完成多次更新后，COW 文件系统会翻转文件系统的根结构以包含指向新更新的结构的指针。 COW 技术的一个重要优点是它使得保持文件系统的一致性变得更加简单。由于原始数据没有被直接修改，因此不需要复杂的同步或回滚机制来维护一致性，而是通过简单地修改指向新数据的指针来实现。 另一种方法是名为基于反向指针的一致性（backpointer-based consistency, BBC）的技术中，写入之间不强制执行任何顺序。为了实现一致性，系统中的每个块都添加了一个额外的反向指针；例如，每个数据块都有对其所属inode的引用。当访问文件时，文件系统可以通过检查前向指针（例如，inode 或直接块中的地址）是否指向引用它的块来确定文件是否一致。如果是这样，则所有内容都必须已安全到达磁盘，因此文件是一致的；如果不是，则文件不一致，并返回错误。通过向文件系统添加反向指针，可以获得一种新形式的惰性崩溃一致性。 最后，还有一种减少日志协议等待磁盘写入完成的次数的技术。这种新方法被称为乐观崩溃一致性，通过使用事务校验和的通用形式向磁盘发出尽可能多的写入，并包含一些其他技术来检测出现的不一致情况。对于某些工作负载，这些乐观技术可以将性能提高一个数量级。然而，要真正正常运行，需要稍微不同的磁盘接口。 ","date":"2024-05-11","objectID":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/:5:0","tags":["OS"],"title":"FSCK和日志","uri":"/posts/33.fsck%E5%92%8C%E6%97%A5%E5%BF%97/"},{"categories":["系统架构"],"content":"1 旧Unix操作系统的问题 UNIX 操作系统问世之初，UNIX奇才Ken Thompson自己编写了第一个文件系统。我们称之为 “老 UNIX 文件系统”，它非常简单。基本上，它的数据结构在磁盘上看起来是这样的： 超级块 (S) 包含有关整个文件系统的信息：卷有多大、有多少 inode、指向空闲块列表头部的指针等等。磁盘的inode区域包含文件系统的所有inodes。最后，大部分磁盘都被数据块占用了。 旧文件系统的好处是它很简单，并且支持文件系统试图提供的基本抽象：文件和目录层次结构。这个易于使用的系统是从过去笨拙的、基于记录的存储系统向前迈出的真正一步，并且目录层次结构相对于早期系统提供的更简单的单级层次结构来说是真正的进步。 问题是：性能非常糟糕。根据 Kirk McKusick 和他在伯克利的同事的测量，性能从一开始就很糟糕，而且随着时间的推移越来越差，到后来文件系统只能提供整个磁盘带宽的 2%！ 主要问题在于，旧的 UNIX 文件系统把磁盘当作随机存取存储器来处理；数据被分散到各个地方，而不考虑保存数据的介质是磁盘这一事实，因此有实际而昂贵的定位成本。例如，一个文件的数据块往往离其 inode 很远，因此每当先读取 inode，然后再读取文件的数据块时，都会产生昂贵的寻道（这是一个相当常见的操作）。 更糟糕的是，由于没有对空闲空间进行仔细管理，文件系统最终会变得相当碎片化。空闲列表最终会指向散布在磁盘上的大量区块，当文件被分配时，它们只会占用下一个空闲区块。其结果是，逻辑上连续的文件会在磁盘上来回访问，从而大大降低了性能。例如，假设下面的数据块区域包含四个文件（A、B、C 和 D），每个文件的大小为 2 个数据块： 如果删除 B 和 D，则结果布局为： 正如你所看到的，空闲空间被分割成两块，每块两个区块，而不是一块连续的四个区块。假设你现在想分配一个四块大小的文件 E： 你可以看到发生了什么：E 会被分散到整个磁盘，因此在访问 E 时，磁盘的性能不会达到峰值（顺序）。而是先读取 E1 和 E2，然后寻道，再读取 E3 和 E4。这种碎片问题在旧的 UNIX 文件系统中经常出现，而且会影响性能。顺便提一句：磁盘碎片整理工具正是用来解决这个问题的；它们会重组磁盘上的数据，将文件连续放置，并为一个或几个连续区域腾出空间，移动数据，然后重写 inodes 等，以反映变化。 还有一个问题：原始块大小太小（512 字节）。因此，从磁盘传输数据的效率本来就不高。块越小越好，因为可以最大限度地减少内部碎片（块内的浪费），但对传输不利，因为每个块都可能需要定位开销才能到达。这就是问题所在： 如何组织文件系统数据结构以提高性能？在这些数据结构之上，我们需要哪种类型的分配策略？如何让文件系统 “感知磁盘”？ ","date":"2024-05-11","objectID":"/posts/32.%E5%BF%AB%E9%80%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:1:0","tags":["OS"],"title":"快速文件系统","uri":"/posts/32.%E5%BF%AB%E9%80%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"2 FFS：磁盘感知是解决方案 伯克利大学的一个小组决定建立一个更好、更快的文件系统，他们巧妙地将其称为快速文件系统（FFS）。他们的想法是设计 “磁盘感知 “的文件系统结构和分配策略，从而提高性能，他们正是这样做的。因此，FFS 开启了文件系统研究的新纪元；通过保留文件系统的相同接口（相同的 API，包括 open()、read()、write()、close() 和其他文件系统调用），但改变内部实现，作者为新文件系统的构建铺平了道路，这项工作一直持续到今天。几乎所有现代文件系统都遵循现有的接口（从而保持与应用程序的兼容性），同时出于性能、可靠性或其他原因改变其内部结构。 ","date":"2024-05-11","objectID":"/posts/32.%E5%BF%AB%E9%80%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:2:0","tags":["OS"],"title":"快速文件系统","uri":"/posts/32.%E5%BF%AB%E9%80%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3 组织结构：柱面组 第一步是更改磁盘结构。 FFS 将磁盘划分为多个柱面组。单柱面是硬盘驱动器不同表面上距驱动器中心距离相同的一组磁道；它被称为柱面是因为它与所谓的几何形状明显相似。 FFS将N个连续的柱面聚合为一组，因此整个磁盘可以被视为柱面组的集合。这是一个简单的示例，显示了具有六个盘片的驱动器的四个最外层磁道，以及由三个柱面组成的柱面组： 请注意，现代驱动器不会导出足够的信息供文件系统真正理解特定柱面是否正在使用；如前所述，磁盘导出块的逻辑地址空间，并将其几何细节隐藏在客户端之外。因此，现代文件系统（例如Linux ext2、ext3和ext4）将驱动器组织成块组，每个块组只是磁盘地址空间的连续部分。下面的图片说明了一个示例，在该示例中，每8个块被组织到不同的块组中（请注意实际分组将包含更多块）。 无论您将它们称为柱面组还是块组，这些组都是 FFS 用于提高性能的核心机制。至关重要的是，通过将两个文件放在同一组中，FFS 可以确保依次访问不会导致磁盘上的长时间查找。 为了使用这些组来存储文件和目录，FFS 需要能够将文件和目录放入一个组中，并在其中跟踪有关它们的所有必要信息。为此，FFS 包含您可能期望文件系统在每个组中具有的所有结构，例如 inode 空间、数据块以及一些用于跟踪这些结构是否已分配或空闲的结构。以下是 FFS 在单个柱面组中保留的内容的描述： 现在让我们更详细地检查一下这个单个柱面组的组成部分。出于可靠性原因，FFS 会在每个组中保留一份超级块 (S) 副本。挂载文件系统需要超级块；通过保留多个副本，如果其中一个副本损坏，你仍然可以通过工作副本挂载和访问文件系统。 在每个组内，FFS 需要跟踪该组的 inode 和数据块是否已分配。每个组的 inode 位图 (ib) 和数据位图 (db) 对每个组中的 inode 和数据块起作用。位图是管理文件系统中空闲空间的绝佳方法，因为很容易找到一大块空闲空间并将其分配给文件，或许可以避免旧文件系统中空闲列表的一些碎片问题。 最后，inode 和数据块区域与以前的 “非常简单文件系统”（VSFS）一样。像往常一样，每个柱面组的大部分由数据块组成。 FFS 文件创建 作为一个例子，想一想创建文件时必须更新哪些数据结构；在这个例子中，假设用户创建了一个新文件 /foo/bar.txt，文件长度为一个块（4KB）。该文件是新文件，因此需要一个新的 inode；因此，inode 位图和新分配的 inode 都将被写入磁盘。 文件中还有数据，因此也必须分配；数据位图和数据块（最终）将被写入磁盘。因此，对当前分区至少要进行四次写入（请注意，这些写入在进行之前可能会在内存中缓冲一段时间）。但这还不是全部！尤其是，在创建新文件时，还必须将文件放到文件系统的层次结构中，即必须更新目录。具体来说，必须更新父目录 foo，以添加 bar.txt 条目；这一更新可能适合 foo 的现有数据块，也可能需要分配一个新块（以及相关的数据位图）。foo 的 inode 也必须更新，以反映目录的新长度并更新时间字段（如最后修改时间）。 总的来说，创建一个新文件的工作量很大！也许下次再创建新文件时，你应该更加感激，或者至少对创建工作如此顺利感到惊讶。 ","date":"2024-05-11","objectID":"/posts/32.%E5%BF%AB%E9%80%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:0","tags":["OS"],"title":"快速文件系统","uri":"/posts/32.%E5%BF%AB%E9%80%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"4 策略：如何分配文件和目录 有了这个组结构，FFS 现在必须决定如何将文件和目录以及相关元数据放置在磁盘上以提高性能。基本原则很简单：将相关的东西放在一起（其推论就是将不相关的东西分开）。 因此，为了遵守这一原则，FFS 必须决定什么是“相关的”并将其放置在同一个区块组中；相反，不相关的项目应放置在不同的块组中。为了实现这一目标，FFS 使用了一些简单的放置启发式法。 首先是目录的放置。 FFS 采用一种简单的方法：找到分配目录数量较少（以平衡组之间的目录）和空闲 inode 数量较多（以便随后能够分配一堆文件）的柱面组，并将目录数据和inode放在该组中。当然，这里可以使用其他启发式方法（例如，考虑空闲数据块的数量）。 对于文件，FFS 做了两件事。 首先，它确保（在一般情况下）将文件的数据块分配在与其 inode 相同的组中，从而防止 inode 和数据之间的长时间查找（如在旧文件系统中）。 其次，它将同一目录中的所有文件放置在它们所在目录的柱面组中。 因此，如果用户创建四个文件：/a/b、/a/c、/a/d 和 b/ f，FFS 会尝试将前三个放置在彼此附近（同一组），而第四个放置在远处（在其他组中）。 让我们看一个此类分配的示例。在示例中，假设每组只有 10 个 inode 和 10 个数据块（都小得离谱），并且三个目录（根目录 /、/a、/b）和 4 个文件（/a/ c、/a/d、/a/e、/b/f) 根据 FFS 策略放置在其中。假设常规文件的大小各为两个块，并且目录只有一个数据块。对于该图，我们对每个文件或目录使用明显的符号（即 / 表示根目录，a 表示 /a，f 表示 /b/f，等等）。 请注意，FFS 策略做了两个积极的事情：每个文件的数据块都靠近每个文件的 inode，同一目录中的文件彼此靠近（即 /a/c、/a/d 和 /a/e）都在组 1 中，并且目录 /b 及其文件 /b/f 在组 2 中彼此靠近）。 相比之下，现在让我们看一下 inode 分配策略，它只是将 inode 分布在组之间，试图确保没有组的 inode 表很快被填满。最终的分配可能如下所示： 从图中可以看出，虽然此策略确实将文件（和目录）数据保留在其各自的 inode 附近，但目录中的文件在磁盘上任意分布，因此不会保留基于名称的局部性。对文件 /a/c、/a/d 和 /a/e 的访问现在跨越三组，而不是按照 FFS 方法跨越一组。 FFS 策略启发式方法并非基于对文件系统流量或任何特别细微的内容的广泛研究；相反，它们基于良好的老式常识。目录中的文件通常一起访问：想象一下编译一堆文件，然后将它们链接到单个可执行文件中。由于存在这种基于命名空间的局部性，FFS 通常会提高性能，确保相关文件之间的查找良好且简短。 ","date":"2024-05-11","objectID":"/posts/32.%E5%BF%AB%E9%80%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:4:0","tags":["OS"],"title":"快速文件系统","uri":"/posts/32.%E5%BF%AB%E9%80%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"5 文件局部性测量 为了更好地理解这些启发式方法是否有意义，让我们分析一些文件系统访问的痕迹，看看是否确实存在命名空间局部性。由于某种原因，文献中似乎没有对这个主题进行很好的研究。 具体来说，我们将使用 SEER 跟踪并分析目录树中文件访问彼此之间的“距离”有多远。例如，如果文件 f 被打开，然后在跟踪中下一个重新打开（在打开任何其他文件之前），则目录树中这两个打开之间的距离为零（因为它们是同一文件）。如果打开目录 dir中的文件 f（即 dir/f），然后打开同一目录中的文件 g（即 dir/g），则两个文件访问之间的距离为 1，因为它们共享同一目录但不是同一文件。换句话说，我们的距离度量衡量的是您必须在目录树上走多远才能找到两个文件的共同祖先；它们在树中越近，度量越低。 下图显示了在 SEER 集群中所有工作站的 SEER 跟踪中在所有跟踪的整体上观察到的局部性。该图沿 x 轴绘制差异指标，并沿 y 轴显示具有该差异的文件打开的累积百分比。具体来说，对于 SEER 跟踪（图中标记为“Trace”），您可以看到大约 7% 的文件访问是针对先前打开的文件，而近 40% 的文件访问是针对同一文件或到同一目录中的一（即相差零或一）。因此，FFS 局部性假设似乎是有意义的（至少对于这些痕迹而言）。 有趣的是，另外 25% 左右的文件访问是针对距离为 2 的文件的。当用户以多级方式构建一组相关目录并在它们之间持续跳转时，就会发生这种类型的局部性。例如，如果用户有一个 src 目录并将目标文件（.o 文件）构建到 obj 目录中，并且这两个目录都是主目录 proj 的子目录，则常见的访问模式将是 proj/src/foo .c 后跟 proj/obj/foo.o。这两个访问之间的距离是 2，因为 proj 是共同的祖先。 FFS 不会在其策略中捕获这种类型的局部性，因此在此类访问之间会发生更多的查找。 为了进行比较，该图还显示了“随机”轨迹的局部性。随机跟踪是通过以随机顺序从现有 SEER 跟踪中选择文件并计算这些随机排序的访问之间的距离度量来生成的。正如您所看到的，正如预期的那样，随机跟踪中的命名空间局部性较少。然而，因为最终每个文件共享一个共同的祖先（例如根），所以存在一些局部性，因此随机作为比较点是有用的。 ","date":"2024-05-11","objectID":"/posts/32.%E5%BF%AB%E9%80%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:5:0","tags":["OS"],"title":"快速文件系统","uri":"/posts/32.%E5%BF%AB%E9%80%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"6 大文件例外 在 FFS 中，文件放置的一般策略有一个重要的例外，那就是大文件。如果没有不同的规则，一个大文件就会占满它第一次放置的块组（也许还有其他块组）。以这种方式填满一个块组是不可取的，因为这会阻止后续的 “相关 “文件被放置在这个块组中，从而可能会损害文件访问的本地性。 因此，对于大文件，FFS 的做法如下。在第一个块组中分配了一定数量的块之后（例如 12 个块，或一个 inode 中可用的直接指针的数量），FFS 会将文件的下一个 “大 “块（例如第一个间接块指向的那些块）放到另一个块组（可能是为了降低利用率而选择的）中。然后，文件的下一个块被放到另一个不同的块组中，依此类推。 让我们通过一些图表来更好地理解这一策略。如果没有大文件例外情况，单个大文件就会将其所有块放入磁盘的一个部分。我们以一个文件 (/a) 为例进行研究，该文件有 30 个块，FFS 配置为每个组 10 个 inodes 和 40 个数据块。下面是没有大文件例外情况的 FFS 的描述： 如图所示，/a 填满了group 0 中的大部分数据块，而其他组仍然是空的。如果现在在根目录 (/) 中创建了其他文件，那么组中就没有太多空间来存放它们的数据了。 在大文件例外情况下（此处设置为每个块中包含五个块），FFS 会将文件分散到各个组中，因此任何一个组内的利用率都不会太高： 你可能注意到，将文件块分散到磁盘上会降低性能，尤其是在相对常见的顺序文件访问情况下（例如，用户或应用程序按顺序读取 0 到 29 块）。但您可以通过谨慎选择块大小来解决这个问题。 具体来说，如果块的大小足够大，文件系统就会花大部分时间从磁盘传输数据，而只花（相对较少的）时间在块的各块之间查找。这种通过增加每次开销的工作量来减少开销的过程称为摊销，是计算机系统中的一种常用技术。 让我们举个例子：假设磁盘的平均定位时间（即寻道和旋转）为 10 毫秒。再假设磁盘的数据传输速度为 40 MB/s。如果您的目标是将一半时间用于在数据块之间寻道，一半时间用于传输数据（从而达到磁盘峰值性能的 50%），那么每 10 毫秒的定位时间就需要花费 10 毫秒来传输数据。那么问题来了：一个数据块需要多大才能花费 10 毫秒来传输数据？我们来计算一下： $$ \\frac{40\\cancel{MB}}{\\cancel{sec}}\\cdot\\frac{1024KB}{1\\cancel{MB}}\\cdot\\frac{1\\cancel{sec}}{1000\\cancel{ms}}\\cdot10\\cancel{ms}=409.6KB $$ 基本上，这个等式表示的是：如果您以 40 MB/s 的速度传输数据，则每次查找时只需传输 409.6KB，以便将一半的时间用于查找，一半的时间用于传输。同样，您可以计算实现 90% 峰值带宽（结果约为 3.69MB），甚至 99% 峰值带宽（40.6MB！）所需的块大小。正如您所看到的，您越接近峰值，这些块就越大（有关这些值如下图所示）。 不过，FFS 并没有使用这种计算方法，以便将大文件分摊到各个组。相反，它根据 inode 本身的结构采取了一种简单的方法。前 12 个直接块与 inode 放在同一个组中；随后的每个间接块及其指向的所有块则放在不同的组中。对于 4KB 的块大小和 32 位磁盘地址，此策略意味着文件的每 1024 个块 (4MB) 被放置在单独的组中，唯一的例外是直接指针指向的文件的第一个 48KB。 请注意，磁盘驱动器的发展趋势是，传输速率的提高相当快，因为磁盘制造商善于将更多bit压缩到相同的表面，但与寻道有关的驱动器机械方面（磁盘臂速度和旋转速度）的提高却相当缓慢。这意味着，随着时间的推移，机械成本会变得相对更昂贵，因此，为了摊销这些成本，你必须在两次寻道之间传输更多的数据。 ","date":"2024-05-11","objectID":"/posts/32.%E5%BF%AB%E9%80%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:6:0","tags":["OS"],"title":"快速文件系统","uri":"/posts/32.%E5%BF%AB%E9%80%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"7 关于 FFS 的其他一些事情 FFS 还引入了其他一些创新。特别是，设计者们非常担心小文件的容纳问题；事实证明，当时许多文件的大小都在 2KB 左右，使用 4KB 的块虽然有利于传输数据，但空间效率却不高。因此，对于一个典型的文件系统来说，这种内部碎片会导致大约一半的磁盘空间被浪费。 FFS 设计者的解决方案很简单，也很好地解决了这个问题。他们决定引入子块，即文件系统可以分配给文件的 512 字节的小块。这样，如果你创建了一个小文件（比如 1KB 大小），它将占用两个子块，从而不会浪费整个 4KB 的块。随着文件的增大，文件系统将继续为其分配 512 字节的块，直到获得完整的 4KB 数据。这时，FFS 会找到一个 4KB 的块，将子块复制到其中，然后释放子块以备将来使用。 你可能会认为这个过程效率很低，需要文件系统做大量额外的工作（尤其是执行复制时需要大量额外的 I/O）。因此，FFS 通常通过修改 libc 库来避免这种低效行为；该库会对写入内容进行缓冲，然后以 4KB 的分块形式将其发送到文件系统，从而在大多数情况下完全避免了子块特殊化。 FFS 引入的第二项重要功能是优化磁盘布局以提高性能。在那个时代（SCSI 和其他更现代的设备接口出现之前），磁盘的复杂程度要低得多，需要主机 CPU 以更实际的方式控制其运行。当文件被放置在磁盘的连续扇区上时，FFS 就会出现问题，如下图左侧所示。 特别是在顺序读取时出现问题。FFS 会首先发出对 0 号块的读取；当读取完成后，FFS 再发出对 1 号块的读取时，为时已晚：1 号块已经在磁头下方旋转，现在读取 1 号块将会导致完全旋转。 FFS 采用不同的布局解决了这个问题，如上图右侧所示。通过跳过每一个其他块（在示例中），FFS 有足够的时间在下一个块经过磁头之前请求下一个块。事实上，FFS 很聪明，它能计算出特定磁盘在布局时应跳过多少块，以避免额外的旋转；这种技术被称为参数化，因为 FFS 会计算出磁盘的特定性能参数，并利用这些参数来决定准确的交错布局方案。 你可能会想：这个方案毕竟没那么好。事实上，使用这种布局，你只能获得峰值带宽的 50%，因为你必须绕每个磁道两次，才能读取每个区块一次。幸运的是，现代磁盘要聪明得多：它们会在内部读入整个磁道，并将其缓冲到内部磁盘缓存中（因此通常称为磁道缓冲区）。这样，在后续读取磁道时，磁盘就会从缓存中返回所需的数据。因此，文件系统不再需要担心这些令人难以置信的低级细节。如果设计得当，抽象和更高级别的接口可能是件好事。 此外，还增加了其他一些可用性改进。FFS 是最早允许使用长文件名的文件系统之一，从而使文件系统中的文件名更具表现力，而不是传统的固定大小方法（如 8 个字符）。此外，文件系统还引入了一个新概念，即符号链接。硬链接的局限性在于它们不能指向目录（因为担心会在文件系统层次结构中引入循环），而且只能指向同一卷内的文件（即 inode number必须仍然有意义）。符号链接允许用户创建指向系统中任何其他文件或目录的 “别名”，因此更加灵活。FFS 还引入了用于重命名文件的原子 rename() 操作。除基本技术外，易用性方面的改进也为 FFS 赢得了更多用户。 ","date":"2024-05-11","objectID":"/posts/32.%E5%BF%AB%E9%80%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:7:0","tags":["OS"],"title":"快速文件系统","uri":"/posts/32.%E5%BF%AB%E9%80%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"1 思维模型 要考虑文件系统，我们通常建议考虑它们的两个不同方面；如果您了解这两个方面，您可能就会了解文件系统的基本工作原理。 首先是文件系统的数据结构。换句话说，文件系统使用什么类型的磁盘结构来组织其数据和元数据？我们将看到的第一个文件系统（包括下面的 vsfs）采用简单的结构，如块数组或其他对象，而更复杂的文件系统，如 SGI 的 XFS，使用更复杂的基于树的结构。 文件系统的第二个方面是它的访问方法。它如何将进程发出的调用（例如 open()、read()、write() 等）映射到其结构上？在执行特定系统调用期间会读取哪些结构？写了哪些？所有这些步骤的执行效率如何？ 如果您了解文件系统的数据结构和访问方法，您就已经开发了一个关于它如何真正工作的良好思维模型，这是系统思维的关键部分。 文件系统思维模型 思维模型是你在学习系统时真正想要开发的东西。对于文件系统，您的思维模型最终应该包括以下问题的答案： 哪些磁盘结构存储文件系统的数据和元数据？ 当进程打开文件时会发生什么？ 在读取或写入期间访问哪些磁盘结构？ 通过研究和改进您的思维模型，您可以对正在发生的事情形成抽象的理解，而不仅仅是试图理解某些文件系统代码的细节。 ","date":"2024-05-11","objectID":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/:1:0","tags":["OS"],"title":"文件系统实现","uri":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"2 VSFS的整体组织 我们现在开发 vsfs 文件系统数据结构的整体磁盘组织。我们需要做的第一件事是将磁盘分为块；简单的文件系统仅使用一种块大小，这正是我们在这里要做的。我们选择常用的大小 4 KB。 因此，我们对构建文件系统的磁盘分区的看法很简单：一系列块，每个块大小为 4 KB。在大小为 $N$ 个 4 KB 块的分区中，块的寻址范围为 $0$ 到 $N − 1$。假设我们有一个非常小的磁盘，只有 64 个块： 现在让我们考虑一下需要在这些块中存储什么来构建文件系统。当然，首先想到的是用户数据。事实上，任何文件系统中的大部分空间都是（并且应该是）用户数据。我们将用于用户数据的磁盘区域称为数据区域，并且为了简单起见，为这些块保留磁盘的固定部分，例如磁盘上 64 个块中的最后 56 个块： 文件系统必须跟踪每个文件的信息。该信息是元数据的关键部分，跟踪诸如哪些数据块（在数据区域中）组成文件、文件的大小、其所有者和访问权限、访问和修改时间以及其他类似信息等。为了存储这些信息，文件系统通常有一个称为inode的结构。 为了容纳inodes，我们还需要在磁盘上为它们保留一些空间。我们将磁盘的这一部分称为inode表，它仅保存磁盘上inodes的数组。因此，我们的磁盘映像现在看起来像下图，假设我们使用 64 个块中的 5 个作为inodes（在图中用 I 表示）： 这里我们应该注意，inode 通常不会那么大，例如 128 或 256 字节。假设每个 inode 256 字节，一个 4 KB 的块可以容纳 16 个 inodes，而我们上面的文件系统总共包含 80 个 inodes。在我们的简单文件系统中，构建在一个微小的 64 块分区上，这个数字代表我们的文件系统中可以拥有的最大文件数；但是，请注意，构建在更大磁盘上的相同文件系统可以简单地分配更大的inode表，从而容纳更多文件。 到目前为止，我们的文件系统已经有了数据块（D）和 inodes（I），但仍然缺少一些东西。正如您可能已经猜到的，仍然需要的一个主要组件是某种跟踪inodes或数据块是否空闲或已分配的方法。因此，这种分配结构是任何文件系统中必需的元素。 当然，有许多可行的分配跟踪方法。例如，我们可以使用一个指向第一个空闲块的空闲列表，该块再指向下一个空闲块，依此类推。相反，我们选择了一种简单且流行的结构，称为位图，其中包括数据区域（数据位图）和inode表（inode位图）。位图是一个简单的结构：每个位用于指示相应的对象/块是空闲（0）还是正在使用（1）。因此我们新的磁盘布局，带有inode位图 (i) 和数据位图 (d)： 您可能会注意到，为这些位图使用整个 4 KB 块有点过大；这样的位图可以跟踪是否分配了32K个对象，但我们只有80个inode和56个数据块。然而，为了简单起见，我们还是为每个位图使用整个 4 KB 块。 我们非常简单的文件系统的磁盘结构的设计中还剩下一个块。我们将其保留给超级块，在下图中用 S 表示。超级块包含有关此特定文件系统的信息，例如，包括文件系统中有多少个 inodes 和数据块（在本例中分别为 80 和 56）、inode 表开始的位置（块 3）等等。它还可能包含某种幻数来标识文件系统类型（在本例中为 vsfs）。 因此，在挂载文件系统时，操作系统会首先读取超级块，初始化各种参数，然后将卷附加到文件系统树上。这样，当访问卷内文件时，系统就能准确知道在哪里可以找到所需的磁盘结构。 ","date":"2024-05-11","objectID":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/:2:0","tags":["OS"],"title":"文件系统实现","uri":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"3 文件组织：Inode ","date":"2024-05-11","objectID":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/:3:0","tags":["OS"],"title":"文件系统实现","uri":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"3.1 基本介绍 文件系统最重要的磁盘结构之一是 inode；几乎所有文件系统都有与此类似的结构。名称 inode 是index node的缩写，这是 UNIX和可能更早的系统中赋予它的历史名称，使用它是因为这些节点最初排列在数组中，并且在访问特定 inode 时索引到该数组。 数据结构 — INODE inode 是许多文件系统中使用的通用名称，用于描述保存给定文件元数据的结构，例如其长度、权限及其组成块的位置。这个名字至少可以追溯到 UNIX（如果不是更早的系统的话，可能更早可以追溯到 Multics）；它是index node（索引节点）的缩写，因为inode number用于索引磁盘上inodes数组，以便找到该编号的inode。正如我们将看到的，inode的设计是文件系统设计的关键部分之一。大多数现代系统对于它们跟踪的每个文件都有某种类似的结构，但可能将它们称为不同的东西（例如 dnodes、fnodes 等）。 每个inode都隐式地通过一个数字（称为i-number）引用，我们之前称之为文件的底层名称。在vsfs（以及其他简单的文件系统中），给定一个i-number，您应该能够直接计算出对应inode位于磁盘上的位置。例如，以上述的vsfs inode表为例：：大小为20KB（5个4KB块），因此包含80个inodes（假设每个inode为256字节）；进一步假设inode区域从12KB开始（即超级块从0KB开始，inode位图在地址4KB处，数据位图在8KB处，因此inode表紧随其后）。在vsfs中，我们因此有以下布局来表示文件系统分区开头部分的情况（特写视图）: 要读取number为 32 的 inode，文件系统首先要计算 inode 区域的偏移量（$32 \\cdot sizeof (inode)$ 或 $8192$），将其与磁盘上 inode 表的起始地址（inodeStartAddr = 12KB）相加，从而得出所需 inode 块的正确字节地址：20KB。回想一下，磁盘不是字节寻址的，而是由大量可寻址扇区（通常为 512 字节）组成。因此，要获取包含 inode 32 的 inode 块，文件系统将向 $\\frac{20×1024}{512}$ 扇区或 40 扇区发出读取命令，以获取所需的 inode 块。更一般地说，inode 块的扇区地址sector可按如下方式计算： blk = (inumber * sizeof(inode_t)) / blockSize; sector = ((blk * blockSize) + inodeStartAddr) / sectorSize; 每个 inode 内部实际上包含了文件所需的所有信息：文件类型（例如常规文件、目录等）、大小、分配给它的块数、保护信息（例如谁拥有该文件、以及谁可以访问它）、一些时间信息，包括文件创建、修改或上次访问的时间，以及有关其数据块驻留在磁盘上的位置的信息（例如某种指针）。我们将有关文件的所有此类信息称为元数据；事实上，文件系统中除了纯用户数据之外的任何信息通常被称为元数据。 ext2中的一个inode示例如下图所示。 inode 设计中最重要的决策之一是它如何引用数据块的位置。一种简单的方法是在 inode 内有一个或多个直接指针（磁盘地址）；每个指针指向属于该文件的一个磁盘块。这种方法是有限的：例如，如果您想要一个非常大的文件（例如，大于块大小乘以 inode 中的直接指针数量），那么您就不走运了。 ","date":"2024-05-11","objectID":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/:3:1","tags":["OS"],"title":"文件系统实现","uri":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"3.2 多级索引 为了支持更大的文件，文件系统设计者不得不在 inodes 中引入不同的结构。一种常见的想法是使用一种被称为间接指针的特殊指针。它不指向包含用户数据的块，而是指向包含更多指针的块，每个指针都指向用户数据。因此，一个 inode 可能有一定数量的直接指针（如 12 个）和一个间接指针。如果文件长得足够大，就会分配一个间接块（来自磁盘的数据块区域），并将间接指针的 inode 插槽设置为指向它。假设有 4KB 的数据块和 4 字节的磁盘地址，则又增加了 1024 个指针；文件可以增长到 $(12 + 1024) \\cdot 4K$ 或 4144KB。 毫不奇怪，在这种方法中，您可能希望支持更大的文件。要做到这一点，只需向inode添加另一个指针：双间接指针。该指针指向一个包含指向间接块的指针的块，每个间接块都包含对数据块的指针。因此，双间接块增加了通过额外 $1024 × 1024$ 或 100 万个 4KB 块来扩展文件的可能性，换句话说支持超过 4GB 大小的文件。然而您可能需要更多，并且我们打赌您知道这将导致什么：三重间接指针。 总体而言，这种不平衡树被称为多级索引方法来定位文件块。让我们以十二个直接指针为例进行研究，并且还有单间接块和双间接块。假设每个块大小为 4 KB，并且每个指针占用 4 字节，则该结构可以容纳略大于 4 GB 大小的文件（即 $(12 + 1024 + 1024^2) × 4 KB）$。您能计算出通过添加三重间接块可以处理多大尺寸的文件吗？（$1024^3$） 许多文件系统使用多级索引，其中包括常用文件系统如 Linux ext2和ext3、NetApp 的WAFL ，以及原始 UNIX 文件系统等等 。其他一些文件系统如 SGI XFS 和 Linux ext4 使用范围而不是简单指针（它们类似于虚拟内存讨论中段）。 考虑基于范围的方法 另一种方法是使用范围而不是指针。范围只是一个磁盘指针加上一个长度（以块为单位）；因此，不需要为文件的每个块提供一个指针，而只需要一个指针和一个长度来指定文件在磁盘上的位置。只有单个范围是有限的，因为在分配文件时可能很难找到磁盘上连续的可用空间块。因此，基于盘区的文件系统通常允许多个盘区，从而在文件分配期间为文件系统提供了更多的自由度。 比较这两种方法，基于指针的方法最灵活，但每个文件使用大量元数据（特别是对于大文件）。基于范围的方法不太灵活，但更紧凑；特别是，当磁盘上有足够的可用空间并且文件可以连续布置时（这实际上是任何文件分配策略的目标），它们可以很好地工作。 您可能想知道：为什么要使用这样的不平衡树？为什么不采用其他方法呢？事实证明，许多研究人员研究了文件系统及其使用方式，几乎每次他们都会发现几十年来一直存在的某些“真理”。其中一项发现是大多数文件都很小。这种不平衡的设计反映了这样的现实；如果大多数文件确实很小，那么针对这种情况进行优化是有意义的。因此，使用少量的直接指针（典型数字为 12），一个 inode 可以直接指向 48 KB 的数据，而对于较大的文件则需要一个（或多个）间接块。Agrawal等人 最近的一项研究总结了这些结果。 当然，在inode设计的空间中，还存在许多其他的可能性；毕竟，inode 只是一种数据结构，任何存储相关信息并能够有效查询的数据结构就足够了。由于文件系统软件很容易更改，因此如果工作负载或技术发生变化，您应该愿意探索不同的设计。 ","date":"2024-05-11","objectID":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/:3:2","tags":["OS"],"title":"文件系统实现","uri":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"4 目录组织 在 vsfs 中（与许多文件系统一样），目录的组织很简单；目录基本上只包含（条目名称，inode number）对的列表。对于给定目录中的每个文件或目录，目录的数据块中有一个字符串和一个数字。对于每个字符串，也可能有一个长度（假设名称可变）。 例如，假设目录 dir（inode number为 5）中包含三个文件（foo、bar 和 foobar_is_a_pretty_longname ），inode number分别为 12、13 和 24。 dir 的磁盘数据可能如下所示： 在此示例中，每个条目都有一个 inode number、记录长度（名称的总字节数加上任何剩余空间）、字符串长度（名称的实际长度），最后是条目的名称。请注意，每个目录都有两个额外的条目：.点 “和... “点-点”；点目录只是当前目录（本例中为 dir），而点-点是父目录（本例中为根目录）。 删除文件（例如调用 unlink()）可能会在目录中间留下一个空位，因此也应该有某种方法来标记这个空位（例如使用保留的 inode number，如 0）。这种删除是使用记录长度的原因之一：新的条目可能会重复使用旧的、更大的条目，因此会有额外的空间。 基于链接的方法 设计 inode 的另一种更简单的方法是使用链表。因此，在inode内，您不需要多个指针，而只需要一个指针来指向文件的第一个块。要处理更大的文件，请在该数据块的末尾添加另一个指针，依此类推，这样就可以支持大文件。 正如您可能已经猜到的，链接文件分配对于某些工作负载来说表现不佳；例如，考虑读取文件的最后一个块，或者只是进行随机访问。因此，为了使链接分配更好地工作，一些系统将在内存中保留链接信息表，而不是将下一个指针与数据块本身一起存储。该表由数据块D的地址索引；条目的内容只是 D 的下一个指针，即文件中 D 后面的下一个块的地址。空值也可能存在（指示文件结束），或者其他一些标记来指示特定块是空闲的。拥有这样的下一个指针表使得链接分配方案可以有效地进行随机文件访问，只需首先扫描（在内存中）表以找到所需的块，然后直接访问（在磁盘上）它。 这样的表是不是听起来很熟悉？我们所描述的是文件分配表或 FAT 文件系统的基本结构。是的，这个经典的旧 Windows 文件系统（在 NTFS之前）基于简单的基于链接的分配方案。与标准 UNIX 文件系统还存在其他差异；例如，本身没有inodes，而是存储有关文件的元数据并直接引用该文件的第一个块的目录条目，这使得创建硬链接变得不可能。 您可能想知道目录到底存储在哪里。通常，文件系统将目录视为一种特殊类型的文件。因此，目录在 inode 表中的某个位置有一个 inode（inode 的 type 字段标记为“目录”而不是“常规文件”）。该目录具有inode指向的数据块（也许还有间接块）；这些数据块位于我们简单文件系统的数据块区域中。因此，我们的磁盘结构保持不变。 我们还应该再次注意，这个简单的线性目录条目列表并不是存储此类信息的唯一方法。和以前一样，任何数据结构都是可能的。例如，XFS以 B 树形式存储目录，使文件创建操作（必须确保文件名在创建之前未使用过）比具有必须在其目录中完整扫描的简单列表的系统更快。 ","date":"2024-05-11","objectID":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/:4:0","tags":["OS"],"title":"文件系统实现","uri":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"5 空闲空间管理 文件系统必须跟踪哪些 inodes 和数据块是空闲的，哪些不是，以便在分配新文件或目录时能为其找到空间。因此，空闲空间管理对所有文件系统都很重要。在 vsfs 中，我们有两个简单的位图可以完成这项任务。 例如，当我们创建一个文件时，必须为该文件分配一个 inode。因此，文件系统将在位图中搜索空闲的 inode，并将其分配给文件；文件系统必须将 inode 标记为已用（用 1 表示），并最终用正确的信息更新磁盘位图。在分配数据块时，也会进行类似的操作。 在为新文件分配数据块时，还可能需要考虑一些其他因素。例如，一些 Linux 文件系统（如 ext2 和 ext3）在创建新文件并需要数据块时，会寻找一连串空闲的块（如 8 个）；通过找到这样一连串空闲的块，然后将它们分配给新创建的文件，文件系统可以保证文件的一部分在磁盘上是连续的，从而提高性能。因此，这种预分配策略是为数据块分配空间时常用的启发式方法。 管理可用空间的方法有很多种；位图只是一种方式。一些早期的文件系统使用空闲列表，其中超级块中的单个指针被保留指向第一个空闲块；在该块内，保留下一个空闲指针，从而形成系统空闲块的列表。当需要一个块时，使用头块并相应地更新列表。 现代文件系统使用更复杂的数据结构。例如，SGI 的 XFS使用某种形式的 B 树来紧凑地表示磁盘的哪些块是空闲的。与任何数据结构一样，不同的时空权衡都是可能的。 ","date":"2024-05-11","objectID":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/:5:0","tags":["OS"],"title":"文件系统实现","uri":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"6 访问路径：读写 既然我们对文件和目录在磁盘上的存储方式有了一定的了解，我们就应该能够在读取或写入文件的过程中跟踪操作流程。因此，了解访问路径上发生的事情是理解文件系统如何工作的第二个关键；请注意！ 在下面的示例中，我们假设文件系统已经加载，因此超级块已经在内存中。其他一切（即 inodes、目录）仍在磁盘上。 ","date":"2024-05-11","objectID":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/:6:0","tags":["OS"],"title":"文件系统实现","uri":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"6.1 从磁盘读取文件 在这个简单的示例中，我们首先假设您只想简单地打开一个文件（例如 /foo/bar），读取它，然后关闭它。对于这个简单的示例，我们假设文件大小仅为 12KB（即 3 个块）。 当发出 open(\"/foo/bar\", O RDONLY) 调用时，文件系统首先需要找到文件 bar 的 inode，以获取有关文件的一些基本信息（权限信息、文件大小等） 。为此，文件系统必须能够找到inode，但它现在拥有的只是完整路径名。文件系统必须遍历路径名，从而找到所需的inode。 所有遍历都从文件系统的根目录（简称为 /）开始。因此，FS首先从磁盘读取的是根目录的inode。但是这个索引节点在哪里呢？要找到一个 inode，我们必须知道它的 i-number。通常，我们在其父目录中查找文件或目录的 i-number；根没有父父目录（根据定义）。因此，根 inode number必须是“众所周知的”；当文件系统被挂载时，FS必须知道它是什么。在大多数 UNIX 文件系统中，根 inode number为 2。因此，为了开始该过程，FS 读取包含 inode number为2 的块（第一个 inode 块）。 一旦读入 inode，FS 就可以在其中查找指向数据块的指针，其中包含根目录的内容。因此，FS 将使用这些磁盘上的指针来读取目录，在本例中查找 foo 的条目。通过读入一个或多个目录数据块，它将找到 foo 的条目；一旦找到，FS 也将找到接下来需要的 foo 的 inode number（假设是 44）。 下一步是递归遍历路径名，直到找到所需的 inode。在这个例子中，FS读取包含foo的inode的块，然后读取其目录数据，最后找到bar的inode number。 open() 的最后一步是将 bar 的 inode 读入内存；然后，FS 进行最终的权限检查，在每个进程的打开文件表中为此进程分配一个文件描述符，并将其返回给用户。 打开后，程序可以发出 read() 系统调用来读取文件。因此，第一次读取（在偏移量 0 处，除非已调用 lseek()）将读取文件的第一个块，并查询 inode 以查找该块的位置；它还可能用新的上次访问时间更新inode。读取将进一步更新该文件描述符的内存中打开文件表，更新文件偏移量，以便下一次读取将读取第二个文件块等。 在某个时刻，文件将被关闭。这里要做的工作要少得多；显然，文件描述符应该被释放，但现在，这就是 FS 真正需要做的。不发生任何磁盘 I/O。 下图描述了整个过程；时间在图中向下增加。在图中，打开文件会导致发生大量读取，以便最终找到文件的 inode。之后，读取每个块需要文件系统首先查看 inode，然后读取该块，然后通过写入更新 inode 的上次访问时间字段。 另请注意，打开操作生成的 I/O 量与路径名的长度成正比。对于路径中的每个附加目录，我们必须读取其inode及其数据。大型目录的存在会使情况变得更糟；在这里，我们只需要读取一个数据块来获取目录的内容，而对于一个大目录，我们可能需要读取许多数据块才能找到所需的条目。 ","date":"2024-05-11","objectID":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/:6:1","tags":["OS"],"title":"文件系统实现","uri":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"6.2 从磁盘写入文件 写入文件的过程与此类似。首先，必须打开文件（如上所述）。然后，应用程序可以发出 write() 调用，用新内容更新文件。最后，关闭文件。 与读取不同的是，向文件写入也可能分配一个数据块（除非该数据块被覆盖等）。在写入一个新文件时，每次写入不仅要向磁盘写入数据，还要首先决定向文件分配哪个块，并相应地更新磁盘的其他结构（如数据位图和 inode）。因此，对文件的每次写入在逻辑上会产生 5 次 I/O： 一次读取数据位图（然后更新数据位图，将新分配的块标记为已使用）； 一次写入数据位图（将其新状态反映到磁盘上）； 两次读取并写入 inode（根据新块的位置更新 inode）； 最后一次写入实际块本身。 如果考虑到创建文件这种简单而常见的操作，写入流量甚至会更大。要创建一个文件，文件系统不仅要分配一个 inode，还要在包含新文件的目录中分配空间。这样做的 I/O 总流量相当大： 一次读取 inode 位图（查找空闲的 inode）； 一次写入 inode 位图（标记已分配）； 一次写入新 inode 本身（初始化）； 一次写入目录数据（将文件的高级名称与其 inode number联系起来）； 以及一次读取和写入目录 inode 以更新它。 如果目录需要增长以容纳新的条目，还需要额外的 I/O（即数据位图和新目录块）。所有这些都只是为了创建一个文件！ 让我们看一个具体的示例，其中创建了文件 /foo/bar，并向其中写入了三个块。下图显示了 open()（创建文件）期间以及三个 4KB 写入的每一个期间发生的情况。 在图中，对磁盘的读取和写入按照引起它们发生的系统调用进行分组，并且它们可能发生的粗略顺序从图的顶部到底部。您可以看到创建文件的工作量：在本例中需要 10 个 I/O，遍历路径名，然后最终创建文件。您还可以看到，每次分配写入都会花费 5 个 I/O：一对读取和更新 inode，另一对读取和更新数据位图，最后写入数据本身。 文件系统如何以合理的效率完成这些任务？即使是最简单的操作，如打开、读取或写入文件，也会产生大量分散在磁盘上的 I/O 操作。文件系统如何才能降低这么多 I/O 操作带来的高昂成本呢？ ","date":"2024-05-11","objectID":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/:6:2","tags":["OS"],"title":"文件系统实现","uri":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"7 缓存和缓冲 正如上面的例子所示，读写文件的成本很高，需要对（慢速）磁盘进行多次 I/O。大多数文件系统都会积极使用系统内存（DRAM）来缓存重要的数据块，以解决明显存在的巨大性能问题。 想象一下上面的打开示例：如果没有缓存，每次打开文件都需要对目录层次结构中的每一级进行至少两次读取（一次读取相关目录的 inode，至少一次读取其数据）。对于长路径名（例如，/1/2/3/.../100/file.txt），文件系统光是打开文件就需要执行数百次读取！ 因此，早期的文件系统引入了固定大小的缓存来保存常用数据块。就像我们在讨论虚拟内存时一样，LRU 等策略和不同的变体将决定在缓存中保留哪些区块。这种固定大小的缓存通常在启动时分配，大约占总内存的 10%。 然而，这种静态的内存分区可能会造成浪费；如果文件系统在某个时间点不需要 10%的内存怎么办？如果采用上述固定大小的方法，文件缓存中未使用的页面就无法重新用于其他用途，从而造成浪费。 相比之下，现代系统采用的是动态分区方法。具体来说，许多现代操作系统将虚拟内存页和文件系统页整合到统一的页面缓存中。这样，内存就可以更灵活地分配给虚拟内存和文件系统，具体取决于哪个系统在特定时间需要更多内存。 了解静态与静态动态分区 在不同的客户端/用户之间划分资源时，可以使用静态分区或动态分区。静态方法只是将资源一次划分为固定比例；例如，如果有两个可能的内存用户，您可以将一些固定部分的内存分配给一个用户，并将其余部分分配给另一个用户。动态方法更加灵活，随着时间的推移提供不同数量的资源；例如，一个用户可能在一段时间内获得较高百分比的磁盘带宽，但随后，系统可能会切换并决定为不同的用户提供更大比例的可用磁盘带宽。 每种方法都有其优点。静态分区可确保每个用户获得一定的资源份额，通常可以提供更可预测的性能，并且通常更容易实现。动态分区可以实现更好的利用率（通过让资源匮乏的用户消耗原本空闲的资源），但实现起来可能更复杂，并且如果用户的闲置资源被其他用户占用，在需要时需要很长时间才能收回，则会导致性能下降。通常情况下，没有最好的方法；相反，你应该思考手头的问题，然后决定哪种方法最合适。 现在想象一下带缓存的文件打开示例。第一次打开可能会产生大量的 I/O 流量来读取目录 inode 和数据，但同一文件（或同一目录中的文件）的后续文件打开大部分会在缓存中进行，因此不需要 I/O。 我们还要考虑缓存对写入的影响。如果缓存足够大，就可以完全避免读取 I/O，而写入流量必须进入磁盘才能持久化。因此，缓存对写入流量的过滤器与对读取流量的过滤器不同。也就是说，写缓冲确实具有许多性能优势。 首先，通过延迟写入，文件系统可以将一些更新批处理到较小的一组 I/O 中；例如，如果在创建一个文件时更新inode位图，然后在创建另一个文件时更新inode位图，则文件系统会通过在第一次更新后延迟写入来节省 I/O。 其次，通过在内存中缓冲大量写入，系统可以调度后续 I/O，从而提高性能。 最后，有些写入可以通过延迟来完全避免。例如，如果应用程序创建了一个文件然后将其删除，则延迟写入以将文件创建反映到磁盘可以完全避免它们。在这种情况下，懒惰（将块写入磁盘）是一种美德。 基于上述原因，大多数现代文件系统都会在内存中缓冲写入 5 到 30 秒，这也是另一种权衡：如果系统在更新传播到磁盘之前崩溃，更新就会丢失；但是，如果在内存中保留更长时间，就可以通过批处理、调度甚至避免写入来提高性能。 了解持久/性能的权衡 存储系统通常会向用户提供持久/性能的权衡。如果用户希望写入的数据立即持久，系统必须全力将新写入的数据提交到磁盘，因此写入速度很慢（但安全）。但是，如果用户可以容忍少量数据的丢失，系统可以在内存中缓冲写入一段时间，然后将其写入磁盘（在后台）。这样做会使写入看起来很快完成，从而提高感知性能；但是，如果发生崩溃，尚未提交到磁盘的写入将会丢失，因此需要进行权衡。要了解如何正确进行这种权衡，最好了解使用存储系统的应用程序需要什么；例如，虽然丢失网络浏览器下载的最后几张图像可能是可以容忍的，但丢失向您的银行帐户添加资金的数据库事务的一部分可能会更难以容忍。 有些应用程序（如数据库）并不喜欢这种权衡。因此，为了避免因写入缓冲而造成意外数据丢失，它们只需通过调用fsync()、使用绕过缓存的直接 I/O 接口或使用原始磁盘接口来强制写入磁盘，从而完全避开文件系统。虽然大多数应用程序都能接受文件系统的取舍，但如果默认情况不能令人满意，也有足够的控制措施让系统按照你的意愿行事。 ","date":"2024-05-11","objectID":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/:7:0","tags":["OS"],"title":"文件系统实现","uri":"/posts/31.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/"},{"categories":["系统架构"],"content":"1 文件和目录 随着时间的推移，在存储虚拟化过程中形成了两个关键的抽象概念。第一个是文件。文件只是一个由字节组成的线性数组，每个字节都可以读写。每个文件都有某种底层名称，通常是某个数字；通常情况下，用户并不知道这个名称（我们将看到）。由于历史原因，文件的底层名称通常被称为其inode number（索引节点号）。 在大多数系统中，操作系统并不了解文件的结构（例如，它是图片、文本文件还是 C 代码）；相反，文件系统的职责仅仅是将这些数据持久地存储在磁盘上，并确保当你再次请求数据时，你能得到当初放在那里的数据。做到这一点并不像看起来那么简单！ 第二个抽象概念是目录。目录和文件一样，也有一个底层名称（即inode number），但其内容却非常具体：它包含一个（用户可读名称、底层名称）对列表。例如，假设有一个底层名称为 “10 “的文件，用户可读文件名为 “foo”。因此，“foo “所在的目录就会有一个条目（“foo”, “10”），将用户可读名称映射到底层名称。目录中的每个条目都指向文件或其他目录。通过将目录放置在其他目录中，用户可以建立一个任意的目录树（或目录层次结构），所有文件和目录都存储在该目录下。 目录层次结构从根目录开始（在基于 UNIX 的系统中，根目录简称为 /），并使用某种分隔符来命名随后的子目录，直到所需的文件或目录被命名为止。例如，如果用户在根目录/中创建了一个目录 foo，然后在目录 foo 中创建了一个文件 bar.txt，我们可以通过其绝对路径名来引用该文件，在本例中为 /foo/bar.txt 。更复杂的目录树如下图所示。 示例中的有效目录为 /、/foo、/bar、/bar/bar、/bar/foo，有效文件为 /foo/bar.txt 和 /bar/foo/bar.txt。目录和文件可以具有相同的名称，只要它们位于文件系统树中的不同位置即可（例如，图中有两个名为 bar.txt 的文件，/foo/bar.txt 和 /bar/foo/bar.txt）。 您可能还注意到，此示例中的文件名通常由两部分组成：bar 和 txt，以.分隔。第一部分是任意名称（描述文件），而文件名的第二部分通常用于指示文件的类型，例如，它是 C 代码（例如.c）还是图像（例如 .jpg） ，或音乐文件（例如.mp3）。然而，这通常只是一个约定：通常没有强制规定名为 main.c 的文件中包含的数据确实是 C 源代码。 因此，我们可以看到文件系统提供的一件伟大的事情：一种命名我们感兴趣的所有文件的便捷方法。名称在系统中很重要，因为访问任何资源的第一步就是能够命名它。因此，在 UNIX 系统中，文件系统提供了一种统一的方式来访问磁盘、U盘、CD-ROM、许多其他设备以及事实上还有许多其他东西，它们都位于同一个目录树下。 ","date":"2024-05-11","objectID":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/:1:0","tags":["OS"],"title":"文件和目录","uri":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/"},{"categories":["系统架构"],"content":"2 文件系统接口 ","date":"2024-05-11","objectID":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/:2:0","tags":["OS"],"title":"文件和目录","uri":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/"},{"categories":["系统架构"],"content":"2.1 文件操作 2.1.1 创建文件 我们将从最基本的操作开始：创建文件。这可以通过 open 系统调用来实现；调用 open() 并传递 O_CREAT 标志，程序就可以创建一个新文件。下面是一些示例代码，用于在当前工作目录下创建一个名为 “foo “的文件。 int fd = open(\"foo\", O_CREAT|O_WRONLY|O_TRUNC, S_IRUSR|S_IWUSR); 例程open() 使用多个不同的标志。在本例中，如果文件不存在，第二个参数会创建文件（O_CREAT），确保该文件只能被写入（O_WRONLY），并且如果文件已经存在，则将其截断为 0 字节大小，从而删除任何现有内容（O_TRUNC）。第三个参数指定权限，在这种情况下，文件所有者可以读写文件。 open() 的一个重要方面是它的返回值：文件描述符。文件描述符只是一个整数，每个进程都是私有的，在 UNIX 系统中用于访问文件；因此，一旦文件被打开，你就可以使用文件描述符来读取或写入文件，前提是你有这样做的权限。因此，文件描述符是一种能力，即一个不透明的句柄，它赋予你执行某些操作的权力。另一种将文件描述符视为指向文件类型对象的指针的方法是：一旦你有了这样一个对象，你就可以调用其他 “方法 “来访问文件，如read()和 write()。如上所述，文件描述符由操作系统按进程进行管理。这意味着在 UNIX 系统的 proc 结构中保存了某种简单的结构（如数组）。下面是 xv6 内核中的相关内容： struct proc { ... struct file *ofile[NOFILE]; // Open files ... }; 一个简单数组（最多包含 NOFILE 打开的文件）可以跟踪每个进程打开了哪些文件。数组的每个条目实际上只是一个指向struct file的指针，它将用于跟踪正在读取或写入的文件信息。 2.1.2 读写文件 2.1.2.1 顺序读写 有了一些文件后，我们当然会想读取或写入它们，让我们从读取一个现有文件开始。如果我们在命令行中输入，我们可能只使用程序 cat 将文件的内容转储到屏幕上。 \u003e echo 'Hello, World' \u003e foo \u003e cat foo Hello, World 在此代码片段中，我们将程序 echo 的输出重定向到文件 foo，然后该文件中包含内容“Hello, World”。然后我们使用 cat 来查看文件的内容。但是cat程序如何访问文件foo呢？ 为了找到这一点，我们将使用一个非常有用的工具来跟踪程序进行的系统调用。在 Linux 上，该工具称为 strace；其他系统也有类似的工具（请参阅 Mac 上的 dtruss，或某些较旧的 UNIX 变体上的 truss）。 strace 的作用是跟踪程序运行时所做的每个系统调用，并将跟踪转储到屏幕上供您查看。 下面是一个使用 strace 来确定 cat 正在做什么的示例（为了便于阅读，删除了一些调用）： \u003e strace cat foo ... openat(AT_FDCWD, \"foo\", O_RDONLY|O_LARGEFILE) = 3 ... read(3, \"Hello, World\\n\", 131072) = 13 write(1, \"Hello, World\\n\", 13) = 13 Hello, World read(3, \"\", 131072) = 0 close(3) = 0 ... +++ exited with 0 +++ cat 做的第一件事是打开文件进行读取。我们应该注意以下几点： 首先，该文件仅打开用于读取（而不是写入），如 O_RDONLY 标志所示； 其次，使用 64 位偏移量 (O_LARGEFILE)； 第三，对 openat()（和oepn()一样）的调用成功并返回一个文件描述符，其值为 3。 为什么第一次调用 openat() 返回 3，而不是您可能期望的 0 或 1？事实证明，每个正在运行的进程已经打开了三个文件：标准输入（进程可以读取以接收输入）、标准输出（进程可以写入以将信息转储到屏幕）和标准错误（进程可以向其写入错误消息）。它们分别由文件描述符 0、1 和 2 表示。因此，当您第一次打开另一个文件时（如上面的 cat 所做的那样），它几乎肯定是文件描述符 3。 打开成功后，cat 会使用 read() 系统调用从文件中重复读取一些字节。 read() 的第一个参数是文件描述符，它告诉文件系统要读取哪个文件；当然，一个进程可能同时打开多个文件，因此描述符能让操作系统知道某个特定读取指向哪个文件。 第二个参数指向一个缓冲区，read()的结果将放置在这个缓冲区中；在上面的系统调用跟踪中，strace 在这个位置（“Hello, World”）显示了读取的结果。 第三个参数是缓冲区的大小，在本例中为 131072 B。对 read() 的调用也成功返回，这里返回的是读取的字节数（13，其中 12 个字节表示 “Hello, World\"中的字符，1 个字节表示行结束标记）。 此时，你会看到 strace 的另一个有趣结果：对 write() 系统调用的一次调用，调用的是文件描述符 1。如上文所述，这个描述符被称为标准输出，因此它被用来将 “Hello, World\"这个字符串写到屏幕上，就像 cat 程序要做的那样。但它会直接调用 write() 吗？也许会（如果高度优化的话）。但如果没有，cat程序可能会调用库例程 printf()；printf() 会在内部计算出传给它的所有格式细节，并最终写入标准输出，将结果打印到屏幕上。 然后，cat 程序尝试从文件中读取更多信息，但由于文件中已经没有字节了，read() 返回 0，程序知道这意味着它已经读完了整个文件。因此，程序会调用 close() 来表示它已经读完了文件 “foo”，并传入相应的文件描述符。文件就这样关闭了，文件的读取也就完成了。 写文件的步骤与此类似。首先，打开一个文件进行写入，然后调用 write() 系统调用，对于较大的文件，可能会重复调用，最后关闭 write()。使用 strace 来跟踪对文件的写入，或许是跟踪你自己编写的程序，或许是跟踪 dd 工具，例如 dd if=foo of=bar（从文件foo中读取数据，并将其写入到文件bar中）。 2.1.2.2 非顺序读写 到目前为止，我们已经讨论了如何读取和写入文件，但所有访问都是顺序的；也就是说，我们要么从头到尾读取一个文件，要么从头到尾写出一个文件。 然而，有时能够读取或写入文件中的特定偏移量是很有用的。例如，如果您在文本文档上构建索引，并使用它来查找特定单词，您最终可能会从文档中的一些随机偏移量中读取。为此，我们将使用 lseek() 系统调用。这是函数原型： off_t lseek(int fildes, off_t offset, int whence); 第一个参数是filedes的（文件描述符）。 第二个参数是offset，它将文件偏移量定位到文件中的特定位置。 第三个参数由于历史原因被称为 whence，它决定了寻找的具体执行方式。摘自man page: man lseek： 如果whence是SEEK_SET，则偏移量设置为偏移字节。 如果whence是SEEK_CUR，则偏移量设置为其当前位置加上偏移字节。 如果whence是SEEK_END，则偏移量设置为文件的大小加上偏移量字节。 数据结构——打开文件表 每个进程都维护一个文件描述符数组，每个文件描述符都引用系统范围的打开文件表中的一个条目。该表中的每个条目都会跟踪描述符引用的底层文件、当前偏移量以及其他相关详细信息，例如文件是否可读或可写。 从上述描述中可以看出，对于进程打开的每个文件，操作系统都会跟踪一个 “当前 “偏移量，该偏移量决定了下一次读取或写入将从文件的哪个位置开始。因此，打开文件的抽象概念之一就是它有一个当前偏移量，该偏移量通过两种方式之一进行更新。 第一种方式是，当读取或写入 $N$ 个字节时，$N$ 会添加到当前偏移量中；因此每次读取或写入都会隐式更新偏移量。 第二种方式是通过 lseek 来显式更新偏移量，如上文所述。 正如你可能已经猜到的，偏移量保存在我们之前看到的struct file中，由 struct proc 引用。下面是该结构的 xv6（简化）定义： struct file { int ref; char readable; char writable; struct inode *ip; uint off; }; 正如您在该结构中所看到的，操作系统可以使用它来确定打开的文件是否可读或可写（或两者）、它引用的底层文件（由 struct inode 指针 ip 指向）以及当前偏移量（off）。还有一个引用计数（ref），我们将在下面进一步讨论。 这些文件结构代表了系统中当前打开的所有文件；它们有时一起称为打开文件表。 xv6 内核也将它们保留为数组，每个条目有一个锁，如下所示： struct { struct spinlock lock; struct file file[NFILE]; } ftable; 让我们通过几个例子来更清楚地说明这一点。首先，让我们跟踪一个打开文件（大小为 300 字节）并通过重复调用 read() 系统调用来读取该文件的进程，每次读取 100 字节。以下是相关系统调用的跟踪，以及每个系统调用返回的值，以及此文件访问的打开文件表中的当前偏移量的值： 跟踪中有几项值得注意。 ","date":"2024-05-11","objectID":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/:2:1","tags":["OS"],"title":"文件和目录","uri":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/"},{"categories":["系统架构"],"content":"2.2 目录操作 除了文件之外，还可以使用一组与目录相关的系统调用来创建、读取和删除目录。请注意，您永远不能直接写入目录；由于目录的格式被视为文件系统元数据，因此您只能通过在其中创建文件、目录或其他对象类型等方式间接更新目录。通过这种方式，文件系统可以确保目录的内容始终符合预期。 2.2.1 创建目录 要创建目录，可以使用单个系统调用 mkdir()。同名的 mkdir 程序可用于创建这样的目录。让我们看一下当我们运行 mkdir 程序来创建一个名为 foo 的简单目录时会发生什么： \u003e strace mkdir foo ... mkdir(\"foo\", 0777) = 0 ... 当创建这样的目录时，它被视为“empty”，尽管它确实具有最少的内容。具体来说，一个空目录有两个条目：一个条目引用其自身，另一个条目引用其父目录。前者被称为“.” （点）目录，后者为“..”（点-点）。其中根目录是文件系统的顶层目录，因此它没有父目录，在 UNIX 文件系统中，根目录的父目录通常被表示为自身，即指向自己。 您可以通过将标志 (-a) 传递给程序 ls 来查看这些目录： \u003e ls -al foo total 8 drwxrwxr-x 2 zfhe zfhe 4096 Apr 16 19:48 . drwxrwxr-x 3 zfhe zfhe 4096 Apr 16 19:48 .. 2.2.2 读取目录 现在我们已经创建了一个目录，我们可能也希望读取一个目录。事实上，这正是程序 ls 所做的。让我们编写自己的小工具（例如 ls），看看它是如何完成的。 我们不只是像打开文件一样打开目录，而是使用一组新的调用。下面是一个打印目录内容的示例程序。 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cdirent.h\u003e #include \u003cassert.h\u003e int main(int argc, char *argv[]) { DIR *dp = opendir(\".\"); // Open current directory assert(dp != NULL); struct dirent *d; while ((d = readdir(dp)) != NULL) { // Read one directory entry // Print the inode number and name printf(\"%lu %s\\n\", (unsigned long) d-\u003ed_ino, d-\u003ed_name); } closedir(dp); // Close the directory return 0; } 该程序使用了三个调用：opendir()、readdir() 和 closedir() 来完成工作，您可以看到接口是多么简单；我们只是使用一个简单的循环一次读取一个目录条目，并打印出目录中每个文件的名称和inode number。 ❯ make read_dir gcc -c read_dir.c gcc read_dir.o -o read_dir ❯ ./read_dir 26212234 . 22996964 .. 26257183 file.txt 26257285 fork-seek 26256904 Makefile 26261892 fsync.c 26257284 fork-seek.o 26258349 dup 26261922 fsync 26258348 dup.o 26405969 read_dir.o 26212238 README.md 26261927 foo 26405970 read_dir 26405873 read_dir.c 26258222 dup.c 26256864 fork-seek.c 26261921 fsync.o 下面的声明显示了 struct dirent 数据结构中每个目录条目中的可用信息： struct dirent { char d_name[256]; /* filename */ ino_t d_ino; /* inode number */ off_t d_off; /* offset to the next dirent */ unsigned short d_reclen; /* length of this record */ unsigned char d_type; /* type of file */ }; 由于目录中的信息很少（基本上只是将名称映射到 inode number，以及其他一些细节），程序可能希望在每个文件上调用 stat() 来获取每个文件的更多信息，如长度或其他详细信息。事实上，当你给 ls 传递 -l 标志时，它就会这么做。 2.2.3 删除目录 最后，你可以调用 rmdir()（由同名程序 rmdir 使用）删除目录。不过，与删除文件不同，删除目录更加危险，因为一条命令就可能删除大量数据。因此，rmdir() 要求在删除之前目录必须为空（即只有”. “和”.. “条目）。如果试图删除非空目录，rmdir() 函数的调用就会失败。 \u003e echo \"Hello, World\" \u003e foo/foo.txt \u003e rmdir foo rmdir: failed to remove 'foo': Directory not empty \u003e rm foo/foo.txt \u003e rmdir foo ","date":"2024-05-11","objectID":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/:2:2","tags":["OS"],"title":"文件和目录","uri":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/"},{"categories":["系统架构"],"content":"3 链接 ","date":"2024-05-11","objectID":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/:3:0","tags":["OS"],"title":"文件和目录","uri":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/"},{"categories":["系统架构"],"content":"3.1 硬链接 现在，我们通过了解一种在文件系统树中创建条目的新方法，即 link() 系统调用，回到为什么要通过 unlink() 来删除文件的谜题上来。link() 系统调用需要两个参数，一个旧路径名和一个新路径名；当你把一个新文件名 “链接 “到一个旧文件名时，你基本上就创造了另一种方式来引用同一个文件。在本例中，命令行程序 ln 就是用来实现这一功能的： \u003e echo \"Hello, World\" \u003e foo \u003e cat foo Hello, World \u003e ln foo foo2 \u003e cat foo2 Hello, World 这里我们创建了一个包含单词“Hello, World”的文件，并将其命名为foo。然后我们使用 ln 程序创建到该文件的硬链接。之后，我们可以通过打开 foo 或 foo2 来检查该文件。 链接的工作原理是，它只是在创建链接的目录中创建另一个名称，并将其指向与原始文件相同的 inode number（即底层名称）。文件并没有以任何方式复制；相反，你现在只有两个名称（foo和 foo2），它们都指向同一个文件。我们甚至可以在目录本身中看到这一点，打印出每个文件的 inode number： \u003e ls -i foo foo2 1339196 foo 1339196 foo2 通过向 ls 传递 -i 标志，它会打印出每个文件的 inode number（以及文件名）。这样，你就能看到 link 到底做了什么：它只是对相同的 inode number（本例中为 1339196）进行了新的引用。 现在，你可能开始明白为什么 unlink() 要叫 unlink()了。当你创建文件时，实际上是在做两件事。 首先，你正在创建一个结构（inode），它将跟踪文件的几乎所有相关信息，包括文件大小、块在磁盘上的位置等等。 其次，将一个人类可读的名称链接到该文件，并将该链接放到一个目录中。 在文件系统中创建了文件的硬链接后，原始文件名（foo）和新创建的文件名（foo2）就没有什么区别了；事实上，它们都只是指向文件底层元数据的链接，而文件底层元数据就在 inode number1339196中。 因此，要从文件系统中删除文件，我们需要调用 unlink()。在上面的例子中，我们可以删除名为 file 的文件，并且仍然可以顺利访问该文件： \u003e ls foo foo2 \u003e rm foo \u003e cat foo2 Hello, World 这样做的原因是，当文件系统取消链接文件时，它会检查 inode number内的引用计数。该引用计数（有时称为链接计数）允许文件系统跟踪有多少不同的文件名已链接到该特定 inode。当调用 unlink() 时，它会删除文件名（正在删除的文件）与给定 inode number之间的“链接”，并减少引用计数；只有当引用计数为零时，文件系统才会同时释放inode和相关数据块，从而真正“删除”文件。 当然，您可以使用 stat() 查看文件的引用计数。让我们看看当我们创建和删除文件的硬链接时会发生什么。在此示例中，我们将创建指向同一文件的三个链接，然后将其删除。观察链接计数！ \u003e echo \"Hello, World\" \u003e foo \u003e stat foo | grep Inode Device: fc03h/64515d Inode: 1338857 Links: 1 \u003e ln foo foo2 \u003e stat foo | grep Inode Device: fc03h/64515d Inode: 1338857 Links: 2 \u003e ln foo2 foo3 \u003e stat foo | grep Inode Device: fc03h/64515d Inode: 1338857 Links: 3 \u003e rm foo \u003e stat foo2 | grep Inode Device: fc03h/64515d Inode: 1338857 Links: 2 \u003e rm foo2 \u003e stat foo3 | grep Inode Device: fc03h/64515d Inode: 1338857 Links: 1 ","date":"2024-05-11","objectID":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/:3:1","tags":["OS"],"title":"文件和目录","uri":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/"},{"categories":["系统架构"],"content":"3.2 符号链接（软链接） 还有另一种非常有用的链接类型，它称为符号链接，有时也称为软链接。事实证明，硬链接有一定的局限性： 您不能为目录创建硬链接，因为担心会在目录树中创建循环。例如，假设有两个目录A和B，它们都包含一个硬链接到对方的硬链接。这种情况下，无论你从A开始还是从B开始，都会导致无限的循环，因为通过任一路径进入其中一个目录后，你可以通过硬链接返回到另一个目录，反复无穷地进行。 您不能硬链接到其他磁盘分区中的文件（因为 inode number仅在特定文件系统内唯一，而不是跨文件系统）； 因此，创建了一种称为符号链接的新型链接。要创建这样的链接，您可以使用相同的程序 ln，但带有 -s 标志。这是一个例子： \u003e echo \"Hello, World\" \u003e foo \u003e ln -s foo foo2 \u003e cat foo2 Hello, World 正如您所看到的，创建软链接看起来非常相似，现在可以通过文件名 foo 以及符号链接名 foo2 来访问原始文件。 然而，除了表面上的相似性之外，符号链接实际上与硬链接有很大不同。符号链接实际上本身就是一个不同类型的文件。我们已经讨论过常规文件和目录；符号链接是文件系统所知的第三种类型。符号链接上的统计数据揭示了一切： \u003e stat foo | grep regular Size: 13 Blocks: 8 IO Block: 4096 regular file \u003e stat foo2 | grep symbolic Size: 3 Blocks: 0 IO Block: 4096 symbolic link 运行 ls 也揭示了这个事实。如果仔细观察 ls 输出的长格式的第一个字符，您会发现最左侧列中的第一个字符是 - 表示常规文件，d 表示目录，l 表示软链接。您还可以查看符号链接的大小（在本例中为 3 个字节），以及链接指向的内容（名为 foo 的文件）。 \u003e ls -al total 12 drwxrwxr-x 2 zfhe zfhe 4096 Apr 16 21:02 . drwxr-x--- 22 zfhe zfhe 4096 Apr 16 21:03 .. -rw-rw-r-- 1 zfhe zfhe 13 Apr 16 20:56 foo lrwxrwxrwx 1 zfhe zfhe 3 Apr 16 20:56 foo2 -\u003e foo foo2 是 3 个字节的原因是因为符号链接的形成方式是将链接到的文件的路径名作为链接文件的数据。因为我们链接到了一个名为 foo 的文件，所以我们的链接文件 foo2 很小（3 个字节）。如果我们链接到更长的路径名，我们的链接文件会更大： \u003e echo \"Hello, World\" \u003e a_longer_filename \u003e ln -s a_longer_filename file \u003e ls -al a_longer_filename file -rw-rw-r-- 1 zfhe zfhe 13 Apr 16 21:04 a_longer_filename lrwxrwxrwx 1 zfhe zfhe 17 Apr 16 21:05 file -\u003e a_longer_filename 最后，由于符号链接的创建方式，它们留下了所谓的悬空引用的可能性，悬空引用可能会导致程序错误，因为它们试图访问不再有效的内存位置或资源。 \u003e echo \"Hello, World\" \u003e foo \u003e ln -s foo foo2 \u003e cat foo2 Hello, World \u003e rm foo \u003e cat foo2 cat: foo2: No such file or directory 正如您在此示例中所看到的，与硬链接完全不同，删除名为 foo 的原始文件会导致链接指向不再存在的路径名。 ","date":"2024-05-11","objectID":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/:3:2","tags":["OS"],"title":"文件和目录","uri":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/"},{"categories":["系统架构"],"content":"4 权限位和访问控制列表 进程的抽象提供了两个中心虚拟化：CPU和内存。每一种虚拟化都会给进程造成一种错觉，以为它拥有自己的专用 CPU 和专用内存；实际上，操作系统使用了各种技术，以安全可靠的方式在相互竞争的实体之间共享有限的物理资源。 正如本章所述，文件系统也提供了磁盘的虚拟视图，将磁盘从一堆原始块转化为更方便用户使用的文件和目录。然而，文件系统的抽象与 CPU 和内存的抽象明显不同，因为文件通常由不同用户和进程共享，并不总是私有的。因此，文件系统中通常有一套更全面的机制来实现不同程度的共享。 此类机制的第一种形式是经典的 UNIX 权限位。要查看文件 foo.txt 的权限，只需输入： \u003e ls -l foo.txt -rw-rw-r-- 1 zfhe zfhe 0 Apr 16 21:12 foo.txt 我们只关注该输出的第一部分，即 -rw-r--r--。这里的第一个字符仅显示文件的类型： - 表示常规文件（即 foo.txt），d 表示目录，l 表示符号链接，依此类推；这（大部分）与权限无关，所以我们暂时忽略它。 我们感兴趣的是权限位，它们由接下来的九个字符（rw-r--r--）表示。对于每个常规文件、目录和其他实体，这些位确定谁可以访问它以及如何访问它。 权限由三组组成： 文件所有者可以对文件执行哪些操作； 组中的某个人可以对文件执行哪些操作； 最后是任何人（有时称为其他人）都可以执行哪些操作。 所有者、组成员或其他人可以拥有的能力包括读取文件、写入文件或执行文件的能力。在上面的示例中，ls 输出的前三个字符表明该文件可由所有者 (rw-) 读取和写入，并且只能由组zfhe成员以及系统中的其他任何人读取 (r -- 后面跟着 r--)。 文件的所有者可以轻松更改这些权限，例如通过使用 chmod命令（更改文件模式）（还有chown：更改文件或目录的所有者；chgrp：更改文件或目录的所属组）。要删除除所有者之外的任何人访问该文件的能力，您可以输入： \u003e chmod 600 foo.txt \u003e ls -l foo.txt -rw------- 1 zfhe zfhe 0 Apr 16 21:12 foo.txt 这条命令启用了所有者的可读位（4）和可写位（2）（将它们 OR 在一起会产生上面的 6），但将组和其他人的权限位分别设置为 0 和 0，从而将权限设置为 rw-------。 执行位尤其有趣。对于普通文件，它的存在决定了程序是否可以运行。例如，如果我们有一个名为 hello.csh 的简单 shell 脚本，我们可能希望通过输入以下内容来运行它： \u003e ./hello.csh hello, from shell world. 但是，如果我们没有正确设置该文件的执行位，就会发生以下情况： \u003e chmod 600 hello.csh \u003e ./hello.csh zsh: permission denied: ./hello.csh 文件系统的超级用户 允许哪个用户执行特权操作以帮助管理文件系统？例如，如果需要删除一个不活动用户的文件以节省空间，谁有权这样做？ 在本地文件系统中，常见的默认设置是存在某种超级用户（即 root），它可以访问所有文件，而不受权限限制。在分布式文件系统（如 AFS，它有访问控制列表）中，一个名为 system:administrators 的组包含受信任的用户。 在这两种情况下，这些受信任的用户都代表着固有的安全风险；如果攻击者能够以某种方式冒充此类用户，攻击者就可以访问系统中的所有信息，从而违反预期的隐私和保护保证。 对于目录，执行位的行为略有不同。具体来说，它使用户（或组或每个人）能够执行诸如将目录（即 cd）更改为给定目录之类的操作，并结合可写位在其中创建文件。在 UNIX 文件系统中，具体如下： 读权限（r）：允许查看目录中的文件列表（即列出目录中的内容）。 写权限（w）：允许在目录中创建、删除和重命名文件。 执行权限（x）：允许进入目录。要进入目录，用户必须拥有目录的执行权限。 除了权限位之外，一些文件系统，包括称为 AFS 的分布式文件系统，还包括更复杂的控制。例如，AFS 以每个目录的访问控制列表 (ACL) 的形式执行此操作。访问控制列表是一种更通用、更强大的方式来准确表示谁可以访问给定资源。在文件系统中，这使用户能够创建一个非常具体的列表，其中列出谁可以读取一组文件，谁不能读取一组文件，这与上述权限位的所有者/组/所有人模型不同。 例如，以下是一位用户的 AFS 帐户中的私有目录的访问控制，如 fs listacl 命令所示： \u003e fs listacl private Access list for private is Normal rights: system:administrators rlidwka remzi rlidwka 该列表显示系统管理员和用户 remzi 都可以查找、插入、删除和管理此目录中的文件，以及读取、写入和锁定这些文件，具体标识符解释如下。 r: 读取权限 (Read) l: 列出目录权限 (List) i: 插入权限 (Insert) d: 删除权限 (Delete) w: 写入权限 (Write) k: 锁定权限 (Lock) a: 管理权限 (Administer) 要允许某人（在本例中为其他用户）访问此目录，用户 remzi 只需输入以下命令即可。 \u003e fs setacl private/ andrea rl \u003e fs listacl private Access list for private is Normal rights: system:administrators rlidwka remzi rlidwka andrea rl 警惕TOCTTOC TOCTTOU 是 “Time of Check to Time of Use” 的缩写，指的是在检查某个条件和使用该条件之间可能存在的时间间隔。这个术语通常用于描述安全漏洞，特别是在多线程或并发环境中，由于时间间隔导致的条件竞争问题。 1974 年，McPhee注意到计算机系统存在问题。具体来说，McPhee 指出“…如果有效性检查和与该有效性检查相关的操作之间存在时间间隔，并且通过多任务处理，可以在该时间间隔期间故意更改有效性检查变量，导致控制程序执行无效操作。”今天，我们将此称为“Time of Check to Time of Use ”(TOCTTOU) 问题，可惜，这种情况仍然可能发生。 Bishop 和 Dilger描述的一个简单示例展示了用户如何欺骗更值得信赖的服务，从而造成麻烦。例如，想象一下，邮件服务以 root 身份运行（因此有权访问系统上的所有文件）。该服务将传入消息附加到用户的收件箱文件中，如下所示。首先，它调用 lstat() 来获取有关该文件的信息，特别是确保它实际上只是目标用户拥有的常规文件，而不是指向邮件服务器不应更新的另一个文件的链接。然后，检查成功后，服务器用新消息更新文件。 不幸的是，检查和更新之间的差距导致了一个问题：攻击者（在本例中，是接收邮件的用户，因此有权访问收件箱）切换收件箱文件（通过调用 rename()) 指向敏感文件，例如 /etc/passwd（其中保存有关用户及其密码的信息）。如果这种切换发生在正确的时间（在检查和访问之间），服务器将用邮件的内容更新敏感文件。攻击者现在可以通过发送电子邮件写入敏感文件，从而提升权限；通过更新/etc/passwd，攻击者可以添加具有root权限的帐户，从而获得系统的控制权。 TOCTTOU 问题没有任何简单而出色的解决方案。一种方法是减少需要 root 权限才能运行的服务数量，这会有所帮助。 O_NOFOLLOW 标志使得如果目标是符号链接，open() 将失败，从而避免需要所述链接的攻击。更激进的方法，例如使用事务性文件系统，可以解决问题，但广泛部署的事务性文件系统并不多。因此，通常的建议：编写以高权限运行的代码时要小心！ ","date":"2024-05-11","objectID":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/:4:0","tags":["OS"],"title":"文件和目录","uri":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/"},{"categories":["系统架构"],"content":"5 制作和挂载文件系统 我们现在已经了解了访问文件、目录和某些特殊类型链接的基本接口。不过，我们还应该讨论一个话题：如何从许多底层文件系统中生成完整的目录树。要完成这项任务，首先要制作文件系统，然后挂载这些文件系统，以便访问其中的内容。 为了创建文件系统，大多数文件系统都提供了一个工具，通常被称为 mkfs（读作 “make fs”），它可以完成这项任务。其原理如下：输入一个设备（如磁盘分区，如 /dev/sda1）和一个文件系统类型（如 ext3）给该工具，它就会在该磁盘分区中写入一个以根目录为起点的空文件系统。mkfs 说：“那就有一个文件系统吧！” 不过，一旦创建了这样一个文件系统，就需要在统一文件系统树中对其进行访问。这项任务需要通过 mount 程序来完成（它会让底层系统调用 mount() 来完成真正的工作）。mount 程序的作用非常简单，就是将一个现有目录作为目标挂载点，然后在目录树上粘贴一个新的文件系统。 这里的一个例子可能很有用。假设我们有一个未挂载的 ext3 文件系统，存储在设备分区 /dev/sda1，其内容如下：一个根目录，其中包含两个子目录 a 和 b，每个子目录又包含一个名为 foo 的文件。假设我们希望将该文件系统挂载到挂载点 /home/users。我们可以这样输入： \u003e mount -t ext3 /dev/sda1 /home/users 如果挂载成功，这个新文件系统就可用了。不过，请注意现在访问新文件系统的方式。要查看根目录的内容，我们可以这样使用 ls： \u003e ls /home/users/ a b 可以看到，路径名 /home/users/ 现在指的是新挂载目录的根目录。同样，我们可以使用 /home/users/a 和 /home/users/b 这两个路径名访问目录 a 和 b。最后，可以通过 /home/users/a/foo 和 /home/users/b/foo 访问名为 foo 的文件。这就是挂载的魅力所在：挂载将所有文件系统统一为一棵树，使命名统一、方便，而不是拥有多个独立的文件系统。要查看系统上挂载了哪些文件，以及挂载在哪些位置，只需运行mount程序即可。你会看到如下内容： \u003e mount /dev/sda1 on / type ext3 (rw) proc on /proc type proc (rw) sysfs on /sys type sysfs (rw) /dev/sda5 on /tmp type ext3 (rw) /dev/sda7 on /var/vice/cache type ext3 (rw) tmpfs on /dev/shm type tmpfs (rw) AFS on /afs type afs (rw) 这种疯狂的组合表明有大量不同的文件系统，包括 ext3（基于磁盘的标准文件系统）、proc 文件系统（用于访问当前进程信息的文件系统）、tmpfs（仅用于临时文件的文件系统） ）和 AFS（分布式文件系统）都粘合到这台机器的文件系统树上。 ","date":"2024-05-11","objectID":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/:5:0","tags":["OS"],"title":"文件和目录","uri":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/"},{"categories":["系统架构"],"content":"6 总结 文件是可以创建、读取、写入和删除的字节数组。它有一个唯一引用它的底层名称（即number）。此层名称通常称为inode number。 目录是元组的集合，每个元组都包含一个人类可读的名称及其映射到的底层名称。每个条目要么引用另一个目录，要么引用一个文件。每个目录本身也有一个底层名称（inode number）。目录总是有两个特殊条目：.条目（引用自身）和 .. 条目（引用其父条目）。 目录树或目录层次结构将所有文件和目录组织成一棵大树，从根开始。 要访问文件，进程必须使用系统调用（通常为 open()）来请求操作系统的许可。如果授予权限，操作系统会返回一个文件描述符，然后在权限和意图允许的情况下，该文件描述符可用于读或写访问。 每个文件描述符都是一个私有的、每个进程的实体，它引用打开文件表中的一个条目。其中的条目跟踪这次访问引用了哪个文件、文件的当前偏移量（即下一次读取或写入将访问文件的哪一部分）以及其他相关信息。 调用read() 和write() 自然会更新当前偏移量；否则，进程可以使用 lseek() 来更改其值，从而能够随机访问文件的不同部分。 要强制更新持久性存储，进程必须使用fsync() 或相关调用。然而，在保持高性能的同时正确执行此操作具有挑战性，因此在执行此操作时请仔细考虑。 要使文件系统中的多个人类可读名称引用同一基础文件，请使用硬链接或符号链接。每种方法在不同的情况下都有用，因此在使用之前请考虑它们的优点和缺点。请记住，删除文件只是从目录层次结构中执行最后一次unlink() 操作。 大多数文件系统都有启用和禁用共享的机制。此类控制的基本形式是由权限位提供的；更复杂的访问控制列表（ACL）可以更精确地控制谁可以访问和操作信息。 ","date":"2024-05-11","objectID":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/:6:0","tags":["OS"],"title":"文件和目录","uri":"/posts/30.%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/"},{"categories":["系统架构"],"content":"1 引言 当我们使用磁盘时， 有时我们希望它更快； I/O 操作速度很慢，因此可能成为整个系统的瓶颈。 有时我们希望它更大；越来越多的数据被放到网上，因此我们的磁盘变得越来越满。 有时我们希望它更加可靠；当磁盘发生故障时，如果我们的数据没有备份，所有有价值的数据都会消失。 所以关键问题是：我们怎样才能制作大型、快速、可靠的存储系统？有哪些关键技术？不同方法之间的权衡是什么？ 在本章中，我们将介绍廉价磁盘冗余阵列，即 RAIDs，这是一种协同使用多个磁盘来构建更快、更大、更可靠的磁盘系统的技术。该术语是由加州大学伯克利分校的一组研究人员（由 David Patterson 和 Randy Katz 教授以及当时的学生 Garth Gibson 领导）于 20 世纪 80 年代末提出的。大约在这个时候，许多不同的研究人员同时得出了使用多个磁盘来构建更好的存储系统的基本思想。 从外部来看，RAIDs 看起来像一个磁盘：一组可以读取或写入的块。在内部，RAID 是一个复杂的系统，由多个磁盘、内存（易失性和非易失性）以及一个或多个用于管理系统的处理器组成。硬件 RAID 非常类似于计算机系统，专门用于管理一组磁盘的任务。 与单个磁盘相比，RAID 具有如下优点。 性能。并行使用多个磁盘可以大大加快 I/O 时间。 容量。大数据集需要大磁盘。 可靠性；将数据分布在多个磁盘上（没有 RAID 技术）使得数据容易受到单个磁盘丢失的影响；通过某种形式的冗余，RAID 可以容忍磁盘丢失并继续运行，就像没有发生任何问题一样。 提示：透明性有助于部署 在考虑如何为系统添加新功能时，应始终考虑能否以透明的方式添加这些功能，即不要求更改系统的其他部分。要求完全重写现有软件（或彻底改变硬件）会降低想法产生影响的几率。RAID 就是一个很好的例子，当然，它的透明性也是其成功的原因之一；管理员可以安装一个基于 SCSI 的 RAID 存储阵列，而不是 SCSI 磁盘，系统的其他部分（主机、操作系统等）无需做任何改动即可开始使用。通过解决部署问题，RAID 从一开始就取得了巨大成功。 令人惊奇的是，RAID 为使用 RAID 的系统提供了透明的优势，也就是说，对于主机系统而言，RAID 就像一个大磁盘。当然，透明性的好处在于，它使人们能够简单地用 RAID 更换磁盘，而无需更改任何软件；操作系统和客户端应用程序无需修改即可继续运行。通过这种方式，透明性大大提高了 RAID 的可部署性，使用户和管理员在使用 RAID 时不必担心软件兼容性问题。 我们现在讨论 RAID 的一些重要方面。我们首先讨论接口和故障模型，然后讨论如何从容量、可靠性和性能这三个重要方面评估 RAID 设计。然后，我们将讨论对 RAID 设计和实施很重要的其他一些问题。 ","date":"2024-05-11","objectID":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/:1:0","tags":["OS"],"title":"廉价磁盘冗余阵列","uri":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/"},{"categories":["系统架构"],"content":"2 接口和 RAID 内部结构 对于上面的文件系统来说，RAID 看起来就像一个大的、（希望）快速且（希望）可靠的磁盘。就像单个磁盘一样，它表现为块的线性阵列，每个块都可以由文件系统（或其他客户端）读取或写入。 当文件系统向 RAID 发出逻辑 I/O 请求时，RAID 内部必须计算要访问哪个磁盘（或多个磁盘）才能完成请求，然后发出一个或多个物理 I/O 来完成该请求。这些物理 I/O 的确切性质取决于 RAID 级别，我们将在下面详细讨论。然而，作为一个简单的例子，考虑一个 RAID，它保留每个块的两个副本（每个副本位于一个单独的磁盘上）；当写入此类镜像 RAID 系统时，RAID 必须为其发出的每一个逻辑 I/O 执行两次物理 I/O。 RAID 系统通常是一个独立的硬件盒，通过标准连接（如 SCSI 或 SATA）与主机相连。不过，RAID 的内部结构相当复杂，包括一个运行固件的微控制器，用于指导 RAID 的运行；DRAM 等易失性内存，用于在数据块读写时对其进行缓冲；在某些情况下，非易失性内存用于对写入进行安全缓冲；甚至可能还包括用于执行奇偶校验计算的专用逻辑（在某些 RAID 级别中非常有用，下文将详细介绍）。从高层次来看，RAID 在很大程度上是一种专用计算机系统：它有处理器、内存和磁盘；但它运行的不是应用程序，而是专门用于操作 RAID 的软件。 ","date":"2024-05-11","objectID":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/:2:0","tags":["OS"],"title":"廉价磁盘冗余阵列","uri":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/"},{"categories":["系统架构"],"content":"3 故障模型 为了理解 RAID 并比较不同的方法，我们必须有一个故障模型。 RAID 旨在检测某些类型的磁盘故障并从中恢复；因此，准确地了解会出现哪些故障对于实现可行的设计至关重要。 我们假设的第一个故障模型非常简单，被称为故障停止故障模型。在此模型中，磁盘可以恰好处于两种状态之一：工作或故障。使用工作磁盘，所有块都可以读取或写入。相反，当磁盘发生故障时，我们假设它永久丢失。 故障停止模型的一个关键方面是它对故障检测的假设。具体来说，当磁盘出现故障时，我们假设很容易检测到这一点。例如，在 RAID 阵列中，我们假设 RAID 控制器硬件（或软件）可以立即观察到磁盘发生故障。 因此，目前我们不必担心更复杂的“静默”故障，例如磁盘损坏。我们也不必担心单个块在其他工作磁盘上变得无法访问（有时称为潜在扇区错误）。稍后我们将考虑这些更复杂（不幸的是，更现实）的磁盘故障。 ","date":"2024-05-11","objectID":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/:3:0","tags":["OS"],"title":"廉价磁盘冗余阵列","uri":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/"},{"categories":["系统架构"],"content":"4 如何评估 RAID 构建 RAID 有多种不同的方法。这些方法中的每一种都有不同的特征，值得评估，以便了解它们的优点和缺点。 具体来说，我们将依据三个指标评估每个 RAID 设计。 第一个指标是容量；给定一组 N 个磁盘，每个磁盘有 B 个块，RAID 客户端有多少可用容量？如果没有冗余，答案是$N\\cdot B$；相反，如果我们有一个系统保留每个块的两个副本（称为镜像），则我们获得的有用容量为$\\frac{N\\cdot B}{2}$。不同的方案（例如基于奇偶校验的方案）往往介于两者之间。 第二个指标是可靠性。给定的设计可以容忍多少个磁盘故障？根据我们的故障模型，我们假设只有整个磁盘可能发生故障；在之后（即数据完整性），我们将考虑如何处理更复杂的故障模式。 最后一个指标是性能。评估性能有些困难，因为它很大程度上取决于磁盘阵列的工作负载。因此，在评估性能之前，我们将首先介绍一组应该考虑的典型工作负载。 我们现在考虑三种重要的 RAID 设计：RAID Level 0（条带化）、RAID Level 1（镜像）和 RAID Levels 4/5（基于奇偶校验的冗余）。将这些设计中的每一个命名为“level”源于atterson，Gibson和Katz在伯克利的开创性工作。 在分析 RAID 性能时，可以考虑两种不同的性能指标。首先是单请求延迟。了解 RAID 的单个 I/O 请求的延迟非常有用，因为它揭示了单个逻辑 I/O 操作期间可以存在多少并行性。第二个是 RAID 的稳态吞吐量，即许多并发请求的总带宽。由于 RAID 通常用于高性能环境，因此稳态带宽至关重要，因此将成为我们分析的主要焦点。 为了更详细地了解吞吐量，我们需要提出一些感兴趣的工作负载。在本次讨论中，我们假设有两种类型的工作负载：顺序工作负载和随机工作负载。对于顺序工作负载，我们假设对数组的请求来自大的连续块；例如，访问 1 MB 数据的请求（或一系列请求），从块 $x$ 开始到块 ($x+1$ MB) 结束，将被视为连续的。顺序工作负载在许多环境中都很常见（想象一下在大文件中搜索关键字），因此被认为很重要。 对于随机工作负载，我们假设每个请求都相当小，并且每个请求都发送到磁盘上不同的随机位置。例如，随机请求流可能首先访问逻辑地址 10 处的 4KB，然后访问逻辑地址 550,000，然后访问 20,100，等等。一些重要的工作负载，例如数据库管理系统 (DBMS) 上的事务工作负载，表现出这种类型的访问模式，因此它被认为是重要的工作负载。 当然，真正的工作负载并不那么简单，并且通常混合了顺序和看似随机的组件以及两者之间的行为。为了简单起见，我们只考虑这两种可能性。 正如您所知，顺序和随机工作负载将导致磁盘的性能特征存在很大差异。通过顺序访问，磁盘以其最有效的模式运行，花费很少的时间寻道和等待旋转，而大部分时间用于传输数据。对于随机访问，情况恰恰相反：大部分时间都花在寻道和等待旋转上，而花在传输数据上的时间相对较少。为了在我们的分析中捕捉到这种差异，我们假设磁盘在顺序工作负载下可以以 $S\\text{ MB/s}$ 的速度传输数据，在随机工作负载下可以以$R\\text{ MB/s}$的速度传输数据。一般来说，S 远大于 R（即 S ≫ R）。 为了确保我们理解这种差异，让我们做一个简单的练习。具体来说，我们根据以下磁盘特性来计算 S 和 R。假设顺序传输平均大小为 10 MB，随机传输平均大小为 10 KB。 另外，假设以下磁盘特性： 平均寻道时间 7 ms 平均旋转延迟 3 ms 磁盘传输速率 50 MB/s 为了计算 S，我们需要首先计算出典型的 10 MB 传输所花费的时间。首先，我们花费 7 毫秒进行寻道，然后花费 3 毫秒进行旋转。最后，传输开始；$\\frac{10\\text{ MB}}{50\\text{ MB/s}}$ 导致传输时间为 $\\frac{1}{5}s$，即 200 毫秒。因此，对于每个 10 MB 请求，我们花费 210 毫秒完成请求。要计算 S，我们只需： $$ S=\\frac{\\text{Amount of Data}}{\\text{Time to access}}=\\frac{10\\text{ MB}}{210ms}=47.62\\text{ MB/s} $$ 正如我们所看到的，由于传输数据花费大量时间，S 非常接近磁盘的峰值带宽（寻道和旋转成本已摊销）。我们可以类似地计算 R。寻道和旋转是一样的；然后我们计算传输所花费的时间，即$\\frac{10\\text{ KB}}{50\\text{ MB/s}}$ ，即 0.195 毫秒。 $$ R=\\frac{\\text{Amount of Data}}{\\text{Time to access}}=\\frac{10\\text{ KB}}{10ms+0.195ms}=0.981\\text{ MB/s} $$ 我们可以看到，R 小于 1 MB/s，S/R 接近 50 MB/s ","date":"2024-05-11","objectID":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/:4:0","tags":["OS"],"title":"廉价磁盘冗余阵列","uri":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/"},{"categories":["系统架构"],"content":"5 RAID Level 0：条带化 ","date":"2024-05-11","objectID":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/:5:0","tags":["OS"],"title":"廉价磁盘冗余阵列","uri":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/"},{"categories":["系统架构"],"content":"5.1 基本介绍 第一个 RAID Level实际上根本不是 RAID Level，因为没有冗余。不过，RAID Level（或称条带化）是性能和容量的绝佳上限，因此值得了解。 最简单的条带化形式是在系统磁盘上对数据块进行条带化，如下所示（这里假设有 4 个磁盘阵列）： 从上表中，你可以了解到基本概念：将磁盘阵列的数据块以循环方式分布在磁盘上。这种方法的设计目的是在请求连续的磁盘阵列块时，从磁盘阵列中提取最大的并行性（例如，在大的顺序读取中）。我们将同一行中的块称为一个条带；因此，块 0、1、2 和 3 位于上述同一条带中。 在示例中，我们做了一个简化假设，即在移动下一个磁盘之前，每个磁盘上只放置一个块（每个块的大小为 4KB）。然而，这种安排并不一定是必须的。例如，我们可以将块跨越多个磁盘进行排列，如下表所示： 在本例中，我们在每个磁盘上放置两个 4KB 的数据块，然后再移动到下一个磁盘。因此，该 RAID 阵列的数据块大小为 8KB，一个磁条由 4 个数据块或 32KB 的数据组成。 RAID 映射问题 在研究 RAID 的容量、可靠性和性能特征之前，我们首先介绍一下所谓的映射问题。所有RAID阵列都会出现这个问题；简而言之，给定一个要读取或写入的逻辑块，RAID 如何准确地知道要访问哪个物理磁盘和偏移量？ 对于这些简单的 RAID levels，我们不需要太复杂就能将逻辑块正确映射到其物理位置。以上面的第一个条带化示例为例（块大小=1，数据块 = 4KB）。在这种情况下，给定逻辑块地址 A，RAID 可以使用两个简单的方程轻松计算所需的磁盘和偏移量： Disk = A % number_of_disks Offset = A / number_of_disks 请注意，这些都是整数运算（例如，4 / 3 = 1 而不是 1.33333…）。让我们通过一个简单的例子来看看这些方程是如何工作的。想象一下，在上面的第一个 RAID 中，块 14 的请求到达。假设有 4 个磁盘，这意味着我们感兴趣的磁盘是 (14 % 4 = 2)：磁盘 2。确切的块计算公式为： （14 / 4 = 3)：块3。因此，块14应该在第三个磁盘（磁盘2，从0开始）的第四个块（块3，从0开始）上找到，这正是它所在的位置。 ","date":"2024-05-11","objectID":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/:5:1","tags":["OS"],"title":"廉价磁盘冗余阵列","uri":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/"},{"categories":["系统架构"],"content":"5.2 块大小 块大小主要影响阵列的性能。例如，较小的块大小意味着许多文件将在许多磁盘上进行条带化，从而提高单个文件读写的并行性；然而，跨多个磁盘访问块的定位时间会增加，因为整个请求的定位时间由跨所有驱动器的请求定位时间的最大值决定。 另一方面，大的块大小会降低这种文件内并行性，从而依赖多个并发请求来实现高吞吐量。然而，大的块大小会减少定位时间；例如，如果单个文件适合一个块并因此被放置在单个磁盘上，则访问它时产生的定位时间将只是单个磁盘的定位时间。 因此，确定“最佳”块大小很难，因为它需要大量有关磁盘系统的工作负载的知识。对于本次讨论的其余部分，我们将假设数组使用单个块 (4KB) 的块大小。大多数数组使用较大的块大小（例如 64 KB），但对于我们下面讨论的问题，确切的块大小并不重要；因此，为了简单起见，我们使用单个块。 ","date":"2024-05-11","objectID":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/:5:2","tags":["OS"],"title":"廉价磁盘冗余阵列","uri":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/"},{"categories":["系统架构"],"content":"5.3 评估 条带化 现在让我们来评估条带化的容量、可靠性和性能。从容量的角度来看，条带化是完美的：给定 N 块磁盘，每块磁盘的大小为 B 块，条带化就能提供$N\\cdot B$ 个有用容量容量块。从可靠性的角度来看，条带化也是完美的，但也是糟糕的：任何磁盘故障都会导致数据丢失。 最后，性能也非常出色：所有磁盘都能利用，而且往往是并行利用，为用户的 I/O 请求提供服务。例如，从延迟的角度来看，单块请求的延迟应与单个磁盘的延迟基本相同；毕竟 RAID-0 只需将该请求重定向到其中一个磁盘即可。从稳态吞吐量的角度来看，我们希望获得系统的全部带宽。因此，吞吐量等于 N（磁盘数量）乘以 S（单个磁盘的连续带宽）。对于大量随机 I/O，我们可以再次使用所有磁盘，从而获得 $N\\cdot R$MB/s。我们将在下文中看到，这些值既是最简单的计算值，也是与其他 RAID levels相比的上限。 ","date":"2024-05-11","objectID":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/:5:3","tags":["OS"],"title":"廉价磁盘冗余阵列","uri":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/"},{"categories":["系统架构"],"content":"6 RAID Level 1：镜像 ","date":"2024-05-11","objectID":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/:6:0","tags":["OS"],"title":"廉价磁盘冗余阵列","uri":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/"},{"categories":["系统架构"],"content":"6.1 基本介绍 除条带化之外，我们的第一个 RAID Level称为 RAID Level 1，或镜像。在镜像系统中，我们只需为系统中的每个数据块制作一个以上的副本；当然，每个副本都应放置在单独的磁盘上。通过这种方法，我们可以容忍磁盘故障。 在典型的镜像系统中，我们假设 RAID 会为每个逻辑块保留两个物理副本。下面是一个例子： 在示例中，磁盘 0 和磁盘 1 的内容完全相同，磁盘 2 和磁盘 3 的内容也完全相同；数据在这些镜像对中进行条带化处理。事实上，你可能已经注意到，在磁盘上放置块拷贝有多种不同的方法。上面的排列方式很常见，有时也被称为 RAID-10 或（RAID 1+0），因为它使用镜像对（RAID-1），然后在其上使用条带（RAID-0）；另一种常见的排列方式是 RAID-01（或 RAID 0+1），它包含两个大型条带（RAID-0）阵列，然后在其上使用镜像（RAID-1）。现在，我们只讨论假设上述布局的镜像。 从镜像阵列读取数据块时，RAID 有一个选择：可以读取任一副本。例如，如果向 RAID 发出读取逻辑块 5 的命令，RAID 可以自由选择从磁盘 2 或磁盘 3 读取。但在写入逻辑块时，就没有这样的选择了：RAID 必须更新数据的两个副本，以保持可靠性。但请注意，这些写入可以并行进行；例如，对逻辑块 5 的写入可以同时写入磁盘 2 和磁盘 3。 ","date":"2024-05-11","objectID":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/:6:1","tags":["OS"],"title":"廉价磁盘冗余阵列","uri":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/"},{"categories":["系统架构"],"content":"6.2 RAID-1分析 让我们评估一下 RAID-1。 从容量的角度来看，RAID-1 是昂贵的；镜像级别 = 2 时，我们只能获得峰值有用容量的一半。在 N 块磁盘上有 B 个数据块时，RAID-1 的有用容量为 $\\frac{N\\cdot B}{2}$。 从可靠性的角度来看，RAID-1 表现出色。它可以承受任何一块磁盘的故障。如果运气好的话，RAID-1 还能做得更好。想象一下，在上图中，磁盘 0 和磁盘 2 同时发生故障。在这种情况下，数据不会丢失！一般来说，镜像系统（镜像级别为 2）可以承受 1 个磁盘的故障，最多可以承受 $\\frac{N}{2}$ 个磁盘的故障，具体取决于哪些磁盘发生故障。在实践中，我们通常不喜欢听天由命，因此大多数人认为镜像可以很好地处理单个故障。 最后，我们分析一下性能。从单个读取请求的延迟角度来看，我们可以看到它与单个磁盘的延迟相同；RAID-1 所做的只是将读取指向其中一个副本。写入则略有不同：它需要两次物理写入才能完成。这两次写入是并行进行的，因此时间与单个写入的时间大致相同；但是，由于逻辑写入必须等待两次物理写入完成，因此会受到两个请求中最坏情况下的寻道和旋转延迟，因此（平均而言）会略高于写入单个磁盘的时间。 RAID 一致性更新问题 在分析 RAID-1 之前，让我们首先讨论任何多磁盘 RAID 系统中都会出现的一个问题，即一致性更新问题 。写入任何必须在单个逻辑操作期间更新多个磁盘的 RAID 时都会出现此问题。在这种情况下，假设我们正在考虑镜像磁盘阵列。 想象一下，向 RAID 发出写操作，然后 RAID 决定必须将其写入两个磁盘，即磁盘 0 和磁盘 1。然后，RAID 向磁盘 0 发出写操作，但就在 RAID 可以向磁盘发出请求之前1、发生断电（或系统崩溃）。在这种不幸的情况下，让我们假设对磁盘 0 的请求已完成（但显然对磁盘 1 的请求没有完成，因为它从未发出）。 这种过早断电的结果是该块的两个副本现在不一致；磁盘 0 上的副本是新版本，磁盘 1 上的副本是旧版本。我们希望发生的是两个磁盘的状态都以原子方式改变，即，要么两个磁盘最终都成为新版本，要么都不成为新版本。 解决这个问题的一般方法是在执行之前使用某种预写日志首先记录 RAID 将要执行的操作（即用某条数据更新两个磁盘）。通过采用这种方法，我们可以确保在发生崩溃时，会发生正确的事情；通过运行将所有待处理事务重播到 RAID 的恢复过程，我们可以确保没有两个镜像副本（在 RAID-1 情况下）不同步。 最后一点：由于每次写入时记录到磁盘的成本非常昂贵，因此大多数 RAID 硬件都包含少量非易失性 RAM（例如，电池供电的 RAM），用于执行此类记录。因此，无需花费高昂的日志记录到磁盘的成本即可提供一致的更新。 为了分析稳态吞吐量，我们从顺序工作负载开始。当顺序写入磁盘时，每次逻辑写入必须导致两次物理写入；例如，当我们写入逻辑块0（上图）时，RAID内部会将其同时写入磁盘0和磁盘1。因此，我们可以得出镜像阵列顺序写入时获得的最大带宽为（$\\frac{N}{2}\\cdot S$)，或峰值带宽的一半。 不幸的是，我们在顺序读取期间获得了完全相同的性能。人们可能认为顺序读取可以做得更好，因为它只需要读取数据的一份副本，而不是两者都读取。然而，让我们用一个例子来说明为什么这没有多大帮助。假设我们需要读取块 0、1、2、3、4、5、6 和 7。假设我们将 0 的读取发送到磁盘 0，将 1 的读取发送到磁盘 2，将 2 的读取发送到磁盘 1 ，以及将 3 读取到磁盘 3。我们继续分别向磁盘 0、2、1 和 3 发出对 4、5、6 和 7 的读取。人们可能天真地认为，由于我们利用了所有磁盘，因此我们实现了阵列的全部带宽。 然而，要知道情况并非（必然）如此，请考虑单个磁盘（例如磁盘 0）收到的请求。首先，它收到对块0的请求；然后，它收到对块 4 的请求（跳过块 2）。事实上，每个磁盘都会收到对每个其他块的请求。当它在跳过的块上旋转时，它不会向客户端提供有用的带宽。因此，每个磁盘只能提供其峰值带宽的一半。因此，顺序读取只能获得($\\frac{N}{2}\\cdot S$)MB/s的带宽。 随机读取是镜像 RAID 的最佳情况。在这种情况下，我们可以将读取分布在所有磁盘上，从而获得全部可能的带宽。因此，对于随机读取，RAID-1 提供 $N\\cdot R$ MB/s。 最后，随机写入的性能如您所料：$\\frac{N}{2}\\cdot R$ MB/s。每个逻辑写入必须转化为两个物理写入，因此当所有磁盘都在使用时，客户端只会将其视为可用带宽的一半。尽管对逻辑块 $x$ 的写入变成了对两个不同物理磁盘的两次并行写入，但许多小请求的带宽仅达到我们在条带化中看到的一半。正如我们很快就会看到的，获得一半的可用带宽实际上非常好！ ","date":"2024-05-11","objectID":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/:6:2","tags":["OS"],"title":"廉价磁盘冗余阵列","uri":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/"},{"categories":["系统架构"],"content":"7 RAID Level 4：使用奇偶校验节省空间 ","date":"2024-05-11","objectID":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/:7:0","tags":["OS"],"title":"廉价磁盘冗余阵列","uri":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/"},{"categories":["系统架构"],"content":"7.1 基本介绍 我们现在介绍一种不同的向磁盘阵列添加冗余的方法，称为奇偶校验。基于奇偶校验的方法试图使用更少的容量，从而克服镜像系统所付出的巨大空间代价。然而，这种方法以性能为代价。 下面是一个五磁盘 RAID-4 系统示例。 我们为每个数据条带添加了一个奇偶校验块，用于存储该数据块条带的冗余信息。例如，奇偶校验块 P1 具有从块 4、5、6 和 7 计算出的冗余信息。 要计算奇偶校验，我们需要使用一个数学函数，使我们能够承受条带中任何一个块的丢失。事实证明，简单的函数 XOR 就能很好地做到这一点。对于一组给定的bit，如果bit中 1 的个数为偶数，则所有这些bit的 XOR 返回 0；如果 1 的个数为奇数，则返回 1。例如： 在第一行（0,0,1,1）中，有两个 1（C2、C3），因此所有这些值的 XOR 将是 0 (P)；同样，在第二行中只有一个 1（C1），因此 XOR 必须是 1 (P)。您可以用一种简单的方法记住这一点：任何一行中 1 的个数必须是偶数（而不是奇数）；这就是 RAID 必须保持的不变性，这样奇偶校验才会正确。 从上面的例子中，您或许还能猜到如何使用奇偶校验信息来从故障中恢复。假设标有 C2 的列丢失了。要想知道该列中应该有哪些值，我们只需读入该行中的所有其他值（包括 XOR 的奇偶校验位），然后重建正确的答案。具体来说，假设第一行 C2 列的值丢失了（它是一个 1）；通过读取该行中的其他值（C0 中的 0、C1 中的 0、C3 中的 1 和奇偶校验列 P 中的 0），我们得到了 0、0、1 和 0。因为我们知道 XOR 在每一行中保持偶数个 1，所以我们知道丢失的数据一定是：一个 。请注意我们是如何计算重构值的：我们只需将数据位和奇偶校验位一起 XOR 即可，与最初计算奇偶校验的方法相同。 现在你可能想知道：我们说的是将所有这些bit进行 XOR，但从上面我们知道 RAID 在每个磁盘上放置了 4KB （或更大）的数据块；我们如何对一堆数据块应用 XOR 来计算奇偶校验呢？事实证明这也很简单。只需对数据块的每个位执行逐位 XOR 即可；将每个逐位 XOR 的结果放入奇偶校验块的相应位槽中即可。例如，如果我们有大小为 4 位的数据块，它们可能看起来像这样： 从表中可以看出，每个数据块的每个bit都要计算奇偶校验，并将计算结果放入奇偶校验数据块中。 ","date":"2024-05-11","objectID":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/:7:1","tags":["OS"],"title":"廉价磁盘冗余阵列","uri":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/"},{"categories":["系统架构"],"content":"7.2 RAID-4 分析 现在让我们分析一下RAID-4。从容量的角度来看，RAID-4 使用 1 个磁盘来为其保护的每组磁盘提供奇偶校验信息。因此，RAID 组的有用容量为 $(N − 1) · B$。 可靠性也很容易理解：RAID-4 只能容忍 1 个磁盘故障，不能再出现更多故障。如果多个磁盘丢失，则根本无法重建丢失的数据。 最后，还有性能。这次，让我们从分析稳态吞吐量开始。顺序读取性能可以利用除奇偶校验磁盘之外的所有磁盘，从而提供 $(N − 1) · S\\text{ MB/s}$ 的峰值有效带宽（一个简单的情况）。 要了解顺序写入的性能，我们必须首先了解它们是如何完成的。将大块数据写入磁盘时，RAID-4 可以执行称为全条带写入的简单优化。例如，想象一下块 0、1、2 和 3 已作为写入请求的一部分发送到 RAID 的情况（如下表所示）。 在这种情况下，RAID可以简单地计算P0的新值（通过对块0、1、2和3执行异或），然后将所有块（包括奇偶校验块）并行写入上面的五个磁盘中（表中以灰色突出显示）。因此，全条带写入是 RAID-4 写入磁盘的最有效方式。 一旦我们了解了全条带写入，计算 RAID-4 上顺序写入的性能就很容易了；有效带宽也是$(N − 1) · S\\text{ MB/s}$。即使在操作过程中不断使用奇偶校验磁盘，客户端也无法从中获得性能优势。 现在我们来分析一下随机读取的性能。从上表中还可以看到，一组 1-block 随机读取将分布在系统的数据磁盘上，但不会分布在奇偶校验磁盘上。因此，有效性能为：$(N − 1) · R\\text{ MB/s}$。 我们最后保存的随机写入呈现了 RAID-4 最有趣的情况。假设我们希望覆盖上面示例中的块 1。我们可以直接覆盖它，但这会给我们带来一个问题：奇偶校验块 P0 将不再准确地反映条带的正确奇偶校验值；在此示例中，P0 也必须更新。如何才能既正确又高效地更新呢？ 事实证明有两种方法。第一个称为加法奇偶校验，要求我们执行以下操作。要计算新奇偶校验块的值，请并行读入条带中的所有其他数据块（在示例中为块 0、2 和 3），并将这些数据块与新块 (1) 进行异或。结果就是新的奇偶校验块。为了完成写入，您可以将新数据和新奇偶校验写入各自的磁盘，同样是并行的。 该技术的问题在于它会随着磁盘数量的增加而扩展，因此在较大的 RAID 中需要大量读取来计算奇偶校验。因此，采用减法奇偶校验法。 例如，想象一下这一串位（4 个数据位，一个奇偶校验）： 假设我们希望用一个新值覆盖位 C2，我们将其称为$C2_{new}$ 。减法分三个步骤进行。 首先，我们读入C2处的旧数据（$C2_{old}=1$）和旧奇偶校验（$P_{old}=0$）。 然后，我们比较旧数据和新数据； 如果它们相同（例如，$C2_{new}=C2_{old}$），那么我们知道奇偶校验位也将保持相同（即，$P_{new}=P_{old}$）。 然而，如果它们不同，那么我们必须将旧奇偶校验位翻转到其当前状态的相反状态，即，如果($P_{old}==1$)，$P_{new}$将被设置为0；如果 ($P_{old}==0$)，$P_{new}$将被设置为 1。我们可以用 XOR 巧妙地表达整个过程（其中 $\\oplus$ 是 XOR 运算符）： $$ P_{new}=(C_{old}\\oplus C_{new})\\oplus P_{old} $$ 由于我们处理的是数据块而不是bit，因此我们对数据块中的所有bit进行计算（例如，每个数据块中的 4096 个字节乘以每个字节的 8 个bit）。因此，在大多数情况下，新的数据块会与旧的数据块不同，因此新的奇偶校验数据块也会不同。现在，你应该能算出何时使用加法奇偶校验计算，何时使用减法奇偶校验计算。想一想，系统中需要有多少磁盘才能使加法计算法的 I/O 次数少于减法计算法；交叉点是多少？ 在进行性能分析时，我们假设使用的是减法。因此，每写一次，RAID 必须执行 4 次物理 I/O（两次读和两次写）。现在假设有大量的写操作提交给 RAID，那么 RAID-4 可以并行执行多少次写操作呢？要理解这一点，让我们再看看 RAID-4 布局，如下表所示。 现在假设大约在同一时间有 2 个小写入提交到 RAID-4，即块 4 和 13（表中用 * 标记）。这些磁盘的数据位于磁盘 0 和 1 上，因此数据的读取和写入可以并行发生，这很好。出现的问题是奇偶校验磁盘；两个请求都必须读取 4 和 13 的相关奇偶校验块、奇偶校验块 P1 和 P3（用 + 标记）。希望问题现在已经清楚了：奇偶校验磁盘是此类工作负载下的瓶颈；因此，我们有时将其称为基于奇偶校验的 RAID 的小写入问题。因此，即使数据磁盘可以并行访问，奇偶校验磁盘也会阻止任何并行性的实现；由于奇偶校验磁盘的存在，对系统的所有写入都将被序列化。由于奇偶校验磁盘每个逻辑 I/O 必须执行两次 I/O（一次读，一次写），因此我们可以通过计算奇偶校验磁盘在这两个 I/O 上的性能来计算 RAID-4 中小型随机写入的性能，因此我们达到了 $\\frac{R}{2}$ MB/s。随机小写入下的 RAID-4 吞吐量很糟糕；当您向系统添加磁盘时，它不会得到改善。 最后，我们将分析 RAID-4 中的 I/O 延迟。大家现在都知道，单次读取（假设没有故障）只是映射到单个磁盘，因此其延迟相当于单个磁盘请求的延迟。单次写入的延迟需要两次读取，然后两次写入；读取和写入可以并行进行，因此总延迟大约是单个磁盘的两倍（存在一些差异，因为我们必须等待两次读取完成，从而获得最坏情况下的定位时间，但更新不会产生寻道成本，因此可能是比平均定位成本更好的定位时间）。 ","date":"2024-05-11","objectID":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/:7:2","tags":["OS"],"title":"廉价磁盘冗余阵列","uri":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/"},{"categories":["系统架构"],"content":"8 RAID Level 5：旋转奇偶校验 ","date":"2024-05-11","objectID":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/:8:0","tags":["OS"],"title":"廉价磁盘冗余阵列","uri":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/"},{"categories":["系统架构"],"content":"8.1 基本介绍 为了解决（至少部分地）小写入问题，Patterson、Gibson 和 Katz 引入了 RAID-5。 RAID-5 的工作方式几乎与 RAID-4 相同，只是它在驱动器之间旋转奇偶校验块，如下表所示。 正如您所看到的，每个条带的奇偶校验块现在在磁盘上旋转，以消除 RAID-4 的奇偶校验磁盘瓶颈。 ","date":"2024-05-11","objectID":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/:8:1","tags":["OS"],"title":"廉价磁盘冗余阵列","uri":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/"},{"categories":["系统架构"],"content":"8.2 RAID 5 分析 RAID-5 的大部分分析与 RAID-4 相同。例如，两个级别的有效容量和容错能力是相同的。顺序读写性能也是如此。单个请求（无论是读还是写）的延迟也与 RAID-4 相同。 随机读取性能好一点，因为我们现在可以利用所有磁盘。最后，随机写入性能比 RAID-4 显着提高，因为它允许跨请求并行。想象一下对块 1 的写入和对块 10 的写入；这将变成对磁盘 1 和磁盘 4 的请求（针对块 1 及其奇偶校验P0）以及对磁盘 0 和磁盘 2 的请求（针对块 10 及其奇偶校验P2）。因此，它们可以并行进行。事实上，我们通常可以假设，给定大量随机请求，我们将能够保持所有磁盘均匀忙碌。如果是这样的话，那么我们小写的总带宽将是 $\\frac{N}{4}\\cdot R$ MB/s。 4 个丢失的因素是由于每次 RAID-5 写入仍然生成 4 次总 I/O 操作，这只是使用基于奇偶校验的 RAID 的成本。 因为 RAID-5 基本上与 RAID-4 相同，除了在少数情况下更好之外，在市场上几乎完全取代了 RAID-4。唯一没有被取代的地方是那些知道自己永远不会执行大写操作的系统，从而完全避免小写问题；在这些情况下，有时会使用 RAID-4，因为它构建起来稍微简单一些。 ","date":"2024-05-11","objectID":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/:8:2","tags":["OS"],"title":"廉价磁盘冗余阵列","uri":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/"},{"categories":["系统架构"],"content":"9 RAID 比较 现在，如下表所示，我们总结了 RAID Levels的简化比较。 请注意，我们省略了许多细节以简化我们的分析。例如，在镜像系统中写入时，平均寻道时间比仅写入单个磁盘时稍长，因为寻道时间是两次寻道（每个磁盘上一次）的最大值。因此，两个磁盘的随机写入性能通常会略低于单个磁盘的随机写入性能。此外，在更新 RAID-4/5 中的奇偶校验磁盘时，第一次读取旧奇偶校验可能会导致完全寻道和旋转，但第二次写入奇偶校验只会导致旋转。 然而，表中的比较确实捕捉到了本质差异，并且对于理解跨 RAID Levels的权衡很有用。对于延迟分析，我们简单地使用 T 来表示对单个磁盘的请求所花费的时间。 总而言之： 如果您严格要求性能而不关心可靠性，那么条带化显然是最好的。 然而，如果您想要随机 I/O 性能和可靠性，镜像是最好的；您所付出的成本是损失容量。 如果容量和可靠性是您的主要目标，那么 RAID-5 就是首选；您付出的代价是小写性能。最后，如果您始终执行顺序 I/O 并希望最大化容量，那么 RAID-5 也是最有意义的。 ","date":"2024-05-11","objectID":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/:9:0","tags":["OS"],"title":"廉价磁盘冗余阵列","uri":"/posts/29.%E5%BB%89%E4%BB%B7%E7%A3%81%E7%9B%98%E5%86%97%E4%BD%99%E9%98%B5%E5%88%97/"},{"categories":["系统架构"],"content":"几十年来，硬盘驱动器一直是计算机系统中持久数据存储的主要形式，文件系统技术的大部分发展都是基于它们的行为。因此，在构建管理磁盘的文件系统软件之前，有必要了解磁盘操作的细节。 关键问题 现代硬盘驱动器如何存储数据？接口是什么？数据实际上是如何布局和访问的？磁盘调度如何提高性能？ ","date":"2024-05-11","objectID":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/:0:0","tags":["OS"],"title":"硬盘驱动器","uri":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/"},{"categories":["系统架构"],"content":"1 接口 让我们先来了解一下现代磁盘驱动器的接口。所有现代硬盘的基本接口都很简单。硬盘由大量扇区（512 字节块）组成，每个扇区都可读写。在有 n 个扇区的磁盘上，扇区的编号从 0 到 n - 1。因此，我们可以将磁盘视为一个扇区数组；0 至 n - 1 就是硬盘的地址空间。 多扇区操作是可能的；事实上，许多文件系统一次可以读写 4KB （或更多）。不过，在更新磁盘时，硬盘制造商唯一能保证的是单次 512 字节的写入是原子性的（即要么全部完成，要么根本不完成）；因此，如果发生意外断电，可能只会完成较大写入的一部分（有时称为撕裂写入）。 大多数磁盘驱动器客户端都会做出一些假设，但这些假设并没有在接口中直接指定；Schlosser 和 Ganger 将此称为磁盘驱动器的 “不成文契约”。具体来说，我们通常可以假定，访问硬盘地址空间内相邻的两个区块会比访问相距较远的两个区块更快。我们通常还可以假设，以连续块（即顺序读取或写入）方式访问块是最快的访问模式，通常比任何随机访问模式都要快得多。 ","date":"2024-05-11","objectID":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/:1:0","tags":["OS"],"title":"硬盘驱动器","uri":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/"},{"categories":["系统架构"],"content":"2 基本几何 让我们开始了解现代磁盘的一些组成部分。我们先从盘片开始，盘片是一个圆形硬表面，通过磁性变化将数据持久地存储在上面。磁盘可能有一个或多个盘片；每个盘片有两个面，每个面称为一个表面。这些盘片通常由某种硬质材料（如铝）制成，然后涂上一层薄薄的磁层，使硬盘即使在关机时也能持久存储比特数据。 盘片都围绕主轴结合在一起，主轴与电机相连，电机以恒定（固定）的速度带动盘片旋转（当硬盘接通电源时）。转速通常以每分钟转数（RPM）为单位，现代的典型值在 7,200 RPM 到 15,000 RPM 之间。请注意，我们通常会对单次旋转的时间感兴趣，例如，转速为 10,000 RPM 的硬盘意味着单次旋转大约需要 6 毫秒（6 毫秒）。 数据以同心圆扇形编码在每个表面上；我们称这样的同心圆为一个磁道。单个表面包含成千上万条轨道，它们紧密地排列在一起，数百条轨道的宽度仅相当于人的头发丝。 要从磁盘表面读写，我们需要一种机制，让我们能够感知（即读取）磁盘上的磁性图案，或引起磁性图案的变化（即写入）。读写过程由磁头完成；驱动器的每个表面都有一个磁头。磁头连接在单个磁盘臂上，磁盘臂在磁盘表面移动，将磁头定位在所需磁道上。 ","date":"2024-05-11","objectID":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/:2:0","tags":["OS"],"title":"硬盘驱动器","uri":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/"},{"categories":["系统架构"],"content":"3 简单的磁盘驱动器 ","date":"2024-05-11","objectID":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/:3:0","tags":["OS"],"title":"硬盘驱动器","uri":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/"},{"categories":["系统架构"],"content":"3.1 工作原理 磁盘结构如下： 让我们通过一次一个磁道构建模型来了解磁盘的工作原理。假设我们有一个单磁道的简单磁盘，如下图所示。 该磁道只有 12 个扇区，每个扇区大小为 512 字节（我们典型的扇区大小），因此通过数字 0 到 11 进行寻址。我们这里的单盘片围绕主轴旋转，电机连接到主轴上。当然磁道本身并不重要；我们希望能够读取或写入这些扇区，因此我们需要一个磁头，连接到磁盘臂上，就像下图所示。在图中，连接到臂末端的磁盘头位于扇区 6 上方，并且表面逆时针旋转。 ","date":"2024-05-11","objectID":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/:3:1","tags":["OS"],"title":"硬盘驱动器","uri":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/"},{"categories":["系统架构"],"content":"3.2 单磁道延迟：旋转延迟 为了了解简单的单磁道磁盘如何处理请求，设想我们现在收到一个读取 0 号数据块的请求。磁盘应如何处理该请求？ 在我们的简单磁盘中，磁盘无需做太多工作。特别是，它必须等待所需的扇区在磁头下旋转。这种等待在现代硬盘中经常发生，是 I/O 服务时间的重要组成部分，因此有一个专门的名称：旋转延迟。在示例中，如果全部旋转延迟为$R$，那么磁盘在等待 0 进入读/写磁头（如果我们从 6 开始）时，需要大约 $\\frac{R}{2}$ 的旋转延迟。在此单磁道上，最坏的情况是向扇区 5 提出请求，为了满足这样的请求，磁盘几乎要产生一个完整的旋转延迟。 ","date":"2024-05-11","objectID":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/:3:2","tags":["OS"],"title":"硬盘驱动器","uri":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/"},{"categories":["系统架构"],"content":"3.3 多磁道：寻道时间 到目前为止，我们的磁盘只有一条磁道，这不太现实；现代磁盘当然有数百万条磁道。因此，让我们来看看更加逼真的磁盘表面，这个磁盘有三个磁道如下图所示。 在图中，磁头当前位于最内侧的磁道上（包含 24 到 35 个扇区）；下一个磁道包含下一组扇区（12 到 23），最外侧的磁道包含第一个扇区（0 到 11）。 为了了解驱动器如何访问给定扇区，我们现在跟踪对远程扇区的请求会发生什么，例如，对扇区 11 的读取。为了服务此读取，驱动器必须首先将磁盘臂移动到正确的磁道（在本例中为最外层），这一过程称为寻道。查找和旋转是成本最高的磁盘操作之一。 应该注意的是，寻道有多个阶段：首先是磁盘臂移动的加速阶段；然后当磁盘臂全速移动时滑行，然后当磁盘臂减慢时减速；当磁头小心地定位在正确的磁道上时，最终稳定下来。稳定时间通常非常重要，例如 0.5 到 2 毫秒，因为驱动器必须确保找到正确的磁道。 寻道后，磁盘臂将磁头定位在正确的磁道上。下图描述了寻道。 正如我们所看到的，在寻道过程中，磁盘臂已移动到所需的磁道，并且盘片当然也旋转了，在本例中大约旋转了 3 个扇区。这样，扇区9即将从磁头下方经过，我们只需忍受短暂的旋转延迟即可完成传输。 当扇区 11 经过磁盘头下方时，将发生 I/O 的最后阶段，称为传输，其中数据从表面读取或写入表面。这样，我们就有了 I/O 时间的完整情况：首先是寻道，然后等待旋转延迟，最后是传输。 ","date":"2024-05-11","objectID":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/:3:3","tags":["OS"],"title":"硬盘驱动器","uri":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/"},{"categories":["系统架构"],"content":"3.4 其他一些细节 关于硬盘驱动器的运行方式还有一些其他有趣的细节。许多驱动器采用某种磁道倾斜来确保即使在跨越磁道边界时也可以正确服务顺序读取。在我们的简单示例磁盘中，这可能如下图所示。 扇区通常会出现这样的倾斜，因为从一个磁道切换到另一个磁道时，磁盘需要时间来重新定位磁头（甚至是相邻的磁道）。如果没有这种偏斜，磁头会移动到下一个磁道，但所需的下一个区块已经在磁头下方旋转，因此硬盘需要等待几乎整个旋转延迟才能访问下一个区块。 另一个实际情况是，外磁道往往比内磁道有更多的扇区，这是几何学的结果；因为外磁道有更多的空间。这些磁道通常被称为多分区磁盘驱动器，即磁盘被组织成多个区，一个区是表面上连续的一组磁道。每个区的每个磁道都有相同数量的扇区，外区的扇区数量多于内区。 最后，现代磁盘驱动器的一个重要组成部分是缓存，由于历史原因，有时也称为磁道缓冲区。这种缓存只是一小部分内存（通常约为 8 或 16 MB），磁盘驱动器可以用它来保存从磁盘读取或写入磁盘的数据。例如，从磁盘读取扇区时，磁盘驱动器可能会决定读入该磁道上的所有扇区，并将其缓存在内存中；这样做可让磁盘驱动器快速响应对同一磁道的任何后续请求。 在写入时，磁盘驱动器可以选择：是在将数据存入内存时确认写入已完成，还是在数据实际写入磁盘后确认？前者称为回写缓存（有时也称为即时报告），后者称为直写缓存。回写缓存有时会让磁盘驱动器看起来 “更快”，但也可能是危险的；如果文件系统或应用程序要求按一定顺序将数据写入磁盘以保证正确性，回写缓存可能会导致问题。 ","date":"2024-05-11","objectID":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/:3:4","tags":["OS"],"title":"硬盘驱动器","uri":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/"},{"categories":["系统架构"],"content":"4 I/O时间 现在我们有了磁盘的抽象模型，可以通过一些分析来更好地了解磁盘性能。特别是，我们现在可以将 I/O 时间表示为三个主要部分的总和： $$ T_{I/O}=T_{seek}+T_{rotation}+T_{transfer} $$ 请注意，I/O 速率 ($R_{I/O}$) 通常更容易用于驱动器之间的比较（如下所示），可以轻松地根据时间计算出来。只需将传输大小除以所花费的时间即可： $$ R_{I/O}=\\frac{Size_{Transfer}}{T_{I/O}} $$ 为了更好地了解 I/O 时间，让我们执行以下计算。假设有两个我们感兴趣的工作负载。第一个称为随机工作负载，向磁盘上的随机位置发出小（例如 4KB）读取。随机工作负载在许多重要应用程序中很常见，包括数据库管理系统。第二种称为顺序工作负载\u003c/，它只是从磁盘连续读取大量扇区，而不会跳转。顺序访问模式非常常见，因此也很重要。 为了了解随机工作负载和顺序工作负载之间的性能差异，我们需要首先对磁盘驱动器做出一些假设。让我们看一下Seagate的几款现代磁盘。第一个称为 Cheetah 15K.5，是一款高性能 SCSI 驱动器。第二个是 Barracuda，是一款专为容量而设计的硬盘。两者的详细信息如下图所示。 正如您所看到的，这些驱动器具有截然不同的特征，并且在许多方面很好地概括了磁盘驱动器市场的两个重要组成部分。第一个是**“高性能”驱动器市场，该市场的驱动器设计为尽可能快地旋转、提供较短的寻道时间并快速传输数据。第二个是“容量”**市场，其中每字节成本是最重要的方面；因此，驱动器速度较慢，但可以将尽可能多的位装入可用空间。 根据这些数字，我们可以开始计算驱动器在上述两种工作负载下的表现如何。让我们首先看看随机工作负载。假设每次 4 KB 读取发生在磁盘上的随机位置，我们可以计算每次此类读取需要多长时间。关于Cheetah： $$ T_{seek}=4ms,T_{rotation}=2ms,T_{transfer}=30\\mu s $$ 平均寻道时间（4 毫秒）是根据制造商报告的平均时间得出的；请注意，完全寻道（从表面的一端到另一端）可能需要三倍的时间。 所有寻道距离的平均值（对于具有N个磁道的磁盘），在两个磁道x和y之间。 $\\frac{1}{N^2}\\sum\\limits_{x=0}^N\\sum\\limits_{y=0}^N|x-y|\\approx \\frac{1}{N^2}\\int_{x=0}^N\\int_{y=0}^N|x-y|dxdy=\\frac{1}{N^2}(\\frac{1}{3}x^3-\\frac{N}{2}x^2+\\frac{N^2}{2}x)|_0^N=\\frac{N}{3}$ 平均旋转延迟是直接根据转速计算出来的。15000 RPM 等于 250 RPS（每秒旋转次数）；因此，每次旋转需要 4 毫秒。磁盘平均旋转半圈，因此平均时间为 2 毫秒。最后，传输时间只是峰值传输速率的传输大小；在这里，它非常小，只需30 微秒。 因此，根据上述公式，Cheetah的 $T_{I/O}$大概等于 6 毫秒。要计算 I/O 速率，我们只需用传输大小除以平均时间，即可得出 Cheetah 在随机工作负载下的 RI/O 速率约为 0.66 MB/s。对 Barracuda 进行同样的计算后，$T_{I/O}$ 约为 13.2 毫秒，速度慢了一倍多，因此传输速率约为 0.31 MB/s。 现在我们来看看顺序工作负载。在这里，我们可以假设在进行一次很长的传输之前，有一次寻道和旋转。为简单起见，假设传输大小为 100 MB。因此，Cheetah 和 Barracuda 的 $T_{I/O}$分别约为 800 毫秒和 950 毫秒。因此，I/O 速率非常接近 125 MB/s 和 105 MB/s 的峰值传输速率。下图总结了这些计算。 该图向我们展示了一些重要信息。首先，也是最重要的一点，随机和顺序工作负载之间的硬盘性能差距很大，Cheetah 几乎相差 200 倍左右，而 Barracuda 则相差 300 倍以上。这就是计算史上最明显的设计提示。 第二点更为微妙：高端 “性能 “硬盘与低端 “容量 “硬盘之间的性能差异很大。出于这个原因（还有其他原因），人们往往愿意花高价购买前者，而尽可能便宜地购买后者。 ","date":"2024-05-11","objectID":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/:4:0","tags":["OS"],"title":"硬盘驱动器","uri":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/"},{"categories":["系统架构"],"content":"5 磁盘调度 由于 I/O 的成本很高，操作系统在决定向磁盘发出 I/O 的顺序方面一直扮演着重要角色。更具体地说，给定一组 I/O 请求后，磁盘调度程序会检查这些请求，并决定下一步调度哪个请求。在作业调度中，每个作业的长度通常是未知的，而磁盘调度则不同，我们可以很好地猜测一个 “作业”（即磁盘请求）需要多长时间。通过估算请求的寻道时间和可能的旋转延迟，磁盘调度程序可以知道每个请求需要多长时间，从而（贪婪地）挑选出服务时间最短的请求。因此，磁盘调度程序在运行时会尽量遵循 SJF（最短作业优先）原则。 ","date":"2024-05-11","objectID":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/:5:0","tags":["OS"],"title":"硬盘驱动器","uri":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/"},{"categories":["系统架构"],"content":"5.1 SSTF：最短寻道时间优先 一种早期的磁盘调度方法称为最短寻道时间优先 (SSTF)（也称为最短寻道优先或 SSF）。 SSTF 按磁道对 I/O 请求队列进行排序，选择最近磁道上的请求首先完成。例如，假设磁头当前位置在内磁道上方，并且我们有对扇区21（中磁道）和2（外磁道）的请求，那么我们首先向21发出请求，等待其完成，然后向 2 发出请求，如下图所示。 SSTF 在此示例中效果很好，首先搜索中磁道，然后搜索外磁道。然而，SSTF 并不是万能的，原因如下。首先，驱动器几何结构对于主机操作系统不可用；相反，它看到的是一个块数组。幸运的是，这个问题很容易解决。操作系统可以简单地实现最近块优先（NBF），而不是 SSTF，它接下来使用最近的块地址来调度请求。 第二个问题更为根本：饥饿。想象一下，在上面的示例中，如果磁头当前所在的内部轨道有稳定的请求流。然后，纯 SSTF 方法将完全忽略对任何其他轨道的请求。因此问题的关键是：如何处理磁盘饥饿？我们如何实现类似 SSTF 的调度但避免饥饿？ ","date":"2024-05-11","objectID":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/:5:1","tags":["OS"],"title":"硬盘驱动器","uri":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/"},{"categories":["系统架构"],"content":"5.2 电梯调度（又称 SCAN 或 C-SCAN） 这个问题的答案早在几年前就已提出，而且相对简单明了。该算法最初被称为 SCAN，它只是在磁盘上来回移动，按顺序在磁道上处理请求。我们把在磁盘上的单次移动（从外磁道到内磁道，或从内磁道到外磁道）称为一次扫描。因此，如果磁道上的某个块的请求已经在这次磁盘扫描中得到过处理，那么该请求不会立即得到处理，而是会排队等待下一次扫描（另一个方向）。 SCAN 有许多变体，其作用都差不多。例如，Coffman 等人提出了 F-SCAN，在进行扫描时冻结待处理队列；这一操作将扫描过程中收到的请求放入队列，稍后再处理。这样做可以通过延迟服务晚到（但距离较近）的请求来避免远端请求的饥饿。 C-SCAN 是另一种常见的变体，是 Circular SCAN 的缩写。该算法不是双向扫描磁盘，而是只从外向内扫描，然后在外层磁道重置，重新开始。这样做对内磁道和外磁道都比较公平，因为纯粹的来回 SCAN 会偏向于中间磁道，也就是说，在扫描完外磁道后，SCAN 会经过中间磁道两次，然后再回到外磁道。 现在应该很清楚SCAN 算法（及其同类算法）有时被称为电梯算法的原因，因为它的行为就像一部电梯，要么上行，要么下行，而不仅仅是根据哪个楼层更近来处理对哪个楼层的请求。试想一下，如果你从 10 楼下到 1 楼，有人在 3 楼上了电梯并按了 4 楼，而电梯却因为 4 楼比 1 楼 “近 “而上了 4 楼，那该有多烦人！正如你所看到的，电梯算法在现实生活中的使用，可以防止在电梯上发生打斗。在磁盘中，它只是防止饥饿。 遗憾的是，SCAN 及其类似技术并不代表最好的调度技术。特别是，SCAN（甚至是 SSTF）实际上并没有尽可能地遵循 SJF 原则。尤其是，它们忽略了旋转。因此，这也是另一个关键症结所在：我们如何实现一个算法，更加接近SJF，并考虑寻道和旋转？ ","date":"2024-05-11","objectID":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/:5:2","tags":["OS"],"title":"硬盘驱动器","uri":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/"},{"categories":["系统架构"],"content":"5.3 SPTF： 最短定位时间优先 在讨论最短定位时间优先或 SPTF 调度（有时也称为最短访问时间优先或 SATF）（这是我们问题的解决方案）之前，让我们确保更详细地理解这个问题。下图展示了一个例子。 在该示例中，磁头当前位于内轨道的第 30 个扇区上方。因此，调度程序必须决定：下一个请求应该调度 16 号扇区（位于中间磁道）还是 8 号扇区（位于外磁道）。那么，下一次应该为哪个扇区提供服务呢？ 答案当然是 “视情况而定”。这里所说的取决于寻道时间与旋转时间的相对比。在我们的例子中，如果寻道时间远高于旋转延迟，那么 SSTF（及其变体）就没有问题。但是，设想一下： 如果寻道时间比旋转时间快很多。那么，在我们的示例中，在外磁道上进一步寻道以服务请求 8 将比在中间磁道上执行较短的寻道以服务请求 16 更有意义，因为请求 16 在经过磁盘头之前必须旋转一圈。 如果旋转时间比寻道时间快很多。那么，服务请求16则比服务请求8更好。 如上所述，在现代硬盘上，寻道和旋转大致相同（当然，这取决于具体的请求），因此 SPTF 非常有用并能提高性能。然而，在操作系统中实现 SPTF 就更加困难了，因为操作系统通常并不清楚磁道边界的位置或磁头当前的位置（旋转意义上）。因此，SPTF 通常在硬盘内部执行。 ","date":"2024-05-11","objectID":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/:5:3","tags":["OS"],"title":"硬盘驱动器","uri":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/"},{"categories":["系统架构"],"content":"5.4 其他调度问题 在简要介绍基本磁盘操作、调度和相关主题时，我们还没有讨论其他许多问题。其中一个问题是：在现代系统中，磁盘调度是在哪里执行的？在旧系统中，所有的调度工作都是由操作系统完成的；在查看了一系列待处理请求后，操作系统会挑选出最佳请求并将其发送给磁盘。该请求完成后，再选择下一个请求，以此类推。那时的磁盘比较简单。 在现代系统中，磁盘可以容纳多个未处理请求，而且本身就有复杂的内部调度器（可以准确执行 SPTF；在磁盘控制器内部，所有相关细节都是可用的，包括磁头的准确位置）。因此，操作系统调度程序通常会选择它认为最好的几个请求（比如 16 个），并将它们全部发送给磁盘；然后，磁盘会利用其内部的磁头位置知识和详细的磁道布局信息，以最佳的（SPTF）顺序为上述请求提供服务。 磁盘调度程序执行的另一项重要相关任务是 I/O 合并。例如，假设有一系列读取区块 33、8、34 的请求，如上图所示。在这种情况下，调度程序应将对第 33 和第 34 块的请求合并为一个单一的双块请求；调度程序所做的任何重新排序都是根据合并后的请求执行的。合并在操作系统层面尤为重要，因为它可以减少发送到磁盘的请求数量，从而降低开销。 现代调度程序要解决的最后一个问题是：在向磁盘发出 I/O 之前，系统应该等待多长时间？人们可能会天真地认为，磁盘一旦有了哪怕一个 I/O，就应该立即向驱动器发出请求；这种方法被称为工作保护，因为如果有请求需要服务，磁盘就永远不会闲置。然而，对预期磁盘调度的研究表明，有时等待一下会更好，这就是所谓的非工作保护方法。通过等待，新的、“更好的 “请求可能会到达磁盘，从而提高整体效率。当然，决定何时等待、等待多长时间可能很棘手。 ","date":"2024-05-11","objectID":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/:5:4","tags":["OS"],"title":"硬盘驱动器","uri":"/posts/28.%E7%A1%AC%E7%9B%98%E9%A9%B1%E5%8A%A8%E5%99%A8/"},{"categories":["系统架构"],"content":"1 系统架构 为了开始我们的讨论，让我们看一下典型系统的“经典”图。 该图显示了通过某种内存总线或互连连接到系统主内存的单个 CPU。一些设备通过通用 I/O 总线连接到系统，在许多现代系统中，该总线是 PCI（或其众多衍生产品之一）；显卡和其他一些更高性能的 I/O 设备可能会在这里找到。最后，更底层的是我们所说的一种或多种外围总线，例如 SCSI、SATA 或 USB。它们将慢速设备连接到系统，包括磁盘、鼠标和键盘。 您可能会问的一个问题是：为什么我们需要这样的层次结构？简而言之：物理和成本。公共汽车速度越快，其长度就必须越短；因此，高性能内存总线没有太多空间来插入设备等。此外，设计高性能总线的成本相当高。因此，系统设计人员采用了这种分层方法，其中需要高性能的组件（例如显卡）靠近 CPU。性能较低的组件距离较远。将磁盘和其他慢速设备放置在外围总线上的好处是多方面的。特别是，您可以在其上放置大量设备。 当然，现代系统越来越多地使用专用芯片组和更快的点对点互连来提高性能。下图为Intel Z270 芯片组的示意图。 在顶部，CPU 与内存系统的连接最紧密，但也与显卡（以及显示器）有高性能连接，以支持游戏和其他图形密集型应用程序。 CPU 通过英特尔专有的 DMI（Direct Media Interface, 直接媒体接口）连接到 I/O 芯片，其余设备通过许多不同的互连连接到该芯片。右侧，一个或多个硬盘通过eSATA接口连接到系统； ATA（AT 附件，指提供与 IBM PC AT 的连接）、SATA（串行 ATA）和现在的 eSATA（外部 SATA）代表了过去几十年来存储接口的演变，每向前一步都在增加性能与现代存储设备保持同步。 I/O 芯片下方是许多 USB（Universal Serial Bus, 通用串行总线）连接，在此描述中，这些连接使键盘和鼠标能够连接到计算机。在许多现代系统中，USB 用于此类低性能设备。 最后，在左侧，其他更高性能的设备可以通过 PCIe（Peripheral Component Interconnect Express，外围组件互连扩展）连接到系统。在此图中，网络接口连接到系统；更高性能的存储设备（例如NVMe持久存储设备）通常连接在这里。 下图是一个真实的配备 Xeon E5-2600 v4 的双插槽服务器，展示了两个CPU（中央处理器）及其相关组件的连接方式。每个CPU都具有多达22个核心，这两个CPU通过QPI链接连接，然后通过内存控制器与DRAM连接（DDR4（Double Data Rate 4）是一种内存标准，它提供了更高的数据传输速率和更低的功耗，是当前常见的内存类型）。此外，它们还与PCIe总线相连，并分别有40条PCIe线路到CPU1和CPU2。 CPU与众多外设的连接通常是通过主板上的I/O芯片组实现的，这个芯片组包括北桥（PCH，Platform Controller Hub）和南桥（ICH，I/O Controller Hub）。在较新的系统中，这些功能可能被集成到一个单一的PCH芯片中。DMI（Direct Media Interface）是CPU与PCH之间的一种高速连接接口，它允许CPU通过PCH与各种外设进行通信。 下图显示了一个计算机系统的PCIe连接布局。从CPU Package开始，它通过Host Bridge与Root Complex(RC)相连。在RC中，有多个Core与Memory Controller相连。PCIe Switch位于RC和外设之间，管理着数据传输。此外，还有多个PCIe Bus、PCIe Bridge和PCIe Endpoint。每个部分都有其对应的bus、dev、fun、pri、sec和sub的标识。 ","date":"2024-05-11","objectID":"/posts/27.io%E8%AE%BE%E5%A4%87/:1:0","tags":["OS"],"title":"IO设备","uri":"/posts/27.io%E8%AE%BE%E5%A4%87/"},{"categories":["系统架构"],"content":"2 规范设备 现在让我们看一个规范设备（不是真实的设备），并使用该设备来加深我们对提高设备交互效率所需的一些机制的理解。如下图所示，我们可以看到设备有两个重要的组件。第一个是它向系统其余部分提供的硬件接口。就像软件一样，硬件也必须提供某种接口，允许系统软件控制其操作。因此，所有设备都有一些特定的接口和协议用于典型的交互。 任何设备的第二部分是其内部结构。设备的这一部分是特定于实现的，负责实现设备向系统呈现的抽象。非常简单的设备将有一个或几个硬件芯片来实现其功能；更复杂的设备将包括一个简单的 CPU、一些通用内存和其他特定于设备的芯片来完成其工作。例如，现代 RAID 控制器可能包含数十万行固件（即硬件设备内的软件）来实现其功能。 ","date":"2024-05-11","objectID":"/posts/27.io%E8%AE%BE%E5%A4%87/:2:0","tags":["OS"],"title":"IO设备","uri":"/posts/27.io%E8%AE%BE%E5%A4%87/"},{"categories":["系统架构"],"content":"3 规范协议 在上图中，（简化的）设备接口由三个寄存器组成： 状态寄存器，可通过读取状态寄存器来查看设备的当前状态； 命令寄存器，用于通知设备执行某项任务； 数据寄存器，用于向设备传递数据或从设备获取数据。 通过读写这些寄存器，操作系统可以控制设备的行为。现在，让我们来描述一下操作系统与设备之间可能进行的典型交互，以便让设备代表自己做一些事情。协议如下： While (STATUS == BUSY) ; // wait until device is not busy Write data to DATA register Write command to COMMAND register (Doing so starts the device and executes the command) While (STATUS == BUSY) ; // wait until device is done with your request 该协议有四个步骤。 首先，操作系统通过重复读取状态寄存器来等待设备准备好接收命令；我们称之为轮询设备（基本上，只是询问发生了什么）。 其次，操作系统将一些数据发送到数据寄存器；例如，可以想象，如果这是一个磁盘，则需要进行多次写入才能将磁盘块（例如 4KB）传输到设备。当主 CPU 参与数据移动时（如本示例协议所示），我们将其称为编程 I/O (PIO)。 然后，操作系统向命令寄存器写入命令；这样做会隐式地让设备知道数据存在并且它应该开始处理命令。 最后，操作系统通过再次循环轮询设备来等待设备完成，等待查看它是否完成（然后可能会收到一个错误代码来指示成功或失败）。 这个基本协议的优点是简单且有效。然而，这也存在一些低效率和不便之处。您可能在协议中注意到的第一个问题是轮询似乎效率低下；具体来说，它浪费了大量的 CPU 时间来等待（可能很慢的）设备完成其活动，而不是切换到另一个就绪进程，从而更好地利用 CPU。 所以问题关键是操作系统如何在不频繁轮询的情况下检查设备状态，从而降低管理设备所需的 CPU 开销？ ","date":"2024-05-11","objectID":"/posts/27.io%E8%AE%BE%E5%A4%87/:3:0","tags":["OS"],"title":"IO设备","uri":"/posts/27.io%E8%AE%BE%E5%A4%87/"},{"categories":["系统架构"],"content":"4 通过中断降低 CPU 开销 多年前，许多工程师为了改善这种交互方式，发明了我们已经见过的：中断。操作系统可以发出一个请求，让调用进程进入休眠状态，然后切换到另一个任务，而不是反复轮询设备。当设备最终完成操作时，它会引发硬件中断，导致 CPU 在预定的中断服务例程（ISR）或更简单的中断处理程序处跳转到操作系统。处理程序只是一段操作系统代码，它将完成请求（例如，从设备读取数据和错误代码），并唤醒等待 I/O 的进程，然后该进程可按需要继续运行。 因此，中断允许计算和 I/O 重叠，这是提高利用率的关键。这条时间线显示了问题所在： 在图中，进程 1 在 CPU 上运行一段时间（由 CPU 线上重复的 1 表示），然后向磁盘发出 I/O 请求以读取一些数据。在没有中断的情况下，系统只是简单地自旋，重复轮询设备的状态，直到 I/O 完成（由 p 表示）。磁盘服务该请求，最后进程 1 可以再次运行。 相反，如果我们利用中断并允许重叠，操作系统可以在等待磁盘时执行其他操作： 在此示例中，操作系统在 CPU 上运行进程 2，同时磁盘服务进程 1 的请求。当磁盘请求完成时，会发生中断，操作系统唤醒进程1并再次运行它。这样，CPU和磁盘在中间的一段时间内都得到了适当的利用。 请注意，使用中断并不总是最好的解决方案。例如，假设一个设备执行任务的速度非常快：第一次轮询通常会发现该设备已完成任务。在这种情况下使用中断实际上会减慢系统速度：切换到另一个进程、处理中断以及切换回发出进程的成本很高。因此，如果设备速度很快，最好进行轮询；如果速度很慢，那么允许重叠的中断是最好的。如果设备的速度未知，或者有时快有时慢，最好使用混合轮询一段时间，然后如果设备尚未完成，则使用中断。这种分两阶段的方法可能会达到两全其美的效果。 不使用中断的另一个原因出现在网络中。当大量传入数据包均产生中断时，操作系统可能会发生活锁，即发现自己只处理中断，而不允许用户级进程运行并实际服务请求。例如，假设一个 Web 服务器由于成为黑客新闻上排名最高的条目而经历了负载爆发。在这种情况下，最好偶尔使用轮询来更好地控制系统中发生的情况，并允许 Web 服务器在返回设备检查更多数据包到达之前为某些请求提供服务。 另一种基于中断的优化是合并。在这样的设置中，需要引发中断的设备首先等待一段时间，然后再将中断传递给 CPU。在等待期间，其他请求可能很快完成，因此可以将多个中断合并为单个中断传递，从而降低中断处理的开销。当然，等待太久会增加请求的延迟，这是系统中常见的权衡。 ","date":"2024-05-11","objectID":"/posts/27.io%E8%AE%BE%E5%A4%87/:4:0","tags":["OS"],"title":"IO设备","uri":"/posts/27.io%E8%AE%BE%E5%A4%87/"},{"categories":["系统架构"],"content":"5 通过 DMA 实现更高效的数据移动 不幸的是，我们的规范协议还有另一个方面需要我们注意。特别是，当使用编程 I/O (PIO) 将大量数据传输到设备时，CPU 再次因一项相当琐碎的任务而负担过重，从而浪费了大量的时间和精力，而这些时间和精力本来可以更好地花在运行上其他流程。这个时间线说明了这个问题： 在时间线中，进程 1 正在运行，然后希望将一些数据写入磁盘。然后它启动 I/O，该 I/O 必须将数据从内存显式复制到设备，一次一个字（图中标记为 c）。复制完成后，I/O 开始在磁盘上进行，CPU 最终可以用于其他用途。 关键：如何降低 PIO 开销 使用 PIO，CPU 会花费太多时间手动将数据移入和移出设备。我们如何才能卸载这项工作，从而更有效地利用 CPU？ 解决这一问题的方法就是我们所说的直接内存访问（DMA）。DMA 引擎本质上是系统中一个非常特殊的设备，它可以在设备和主内存之间协调传输，而无需 CPU 的过多干预。DMA 的工作原理如下。以向设备传输数据为例，操作系统将对 DMA 引擎进行编程，告诉它数据在内存中的位置、需要复制多少数据以及发送到哪个设备。 void setup_dma_transfer(void *source_address, void *destination_address, size_t data_size); 此时，操作系统就完成了传输，可以继续其他工作。当 DMA 完成时，DMA 控制器会发出中断，操作系统因此知道传输已经完成。修改后的时间线如下： 从时间轴上可以看到，复制数据的工作现在由 DMA 控制器负责。因为在这段时间内 CPU 是空闲的，操作系统可以做其他事情，这里选择运行进程 2。这样，在进程 1 再次运行之前，进程 2 可以使用更多的 CPU。 ","date":"2024-05-11","objectID":"/posts/27.io%E8%AE%BE%E5%A4%87/:5:0","tags":["OS"],"title":"IO设备","uri":"/posts/27.io%E8%AE%BE%E5%A4%87/"},{"categories":["系统架构"],"content":"6 设备交互 现在我们对执行 I/O 所涉及的效率问题有了一定的了解，为了将设备合并到现代系统中，我们还需要处理一些其他问题。到目前为止，您可能已经注意到一个问题：我们还没有真正谈论操作系统如何与设备实际通信！因此，关键问题是： 硬件应该如何与设备通信？是否应该有明确的指示？或者还有其他方法可以做到吗？ 随着时间的推移，已经开发出两种主要的设备通信方法。第一种也是最古老的方法（IBM 大型机使用了很多年）是使用显式 I/O 指令。这些指令指定操作系统将数据发送到特定设备寄存器的方式，从而允许构建上述协议。 例如，在 x86 系统中，in 和 out 指令可用于与设备通信。例如，要向设备发送数据，调用者需要指定一个包含数据的寄存器和一个命名设备的特定端口。执行该指令后，就会产生所需的行为。 此类指令通常具有特权。操作系统控制着设备，因此操作系统是唯一允许与设备直接通信的实体。试想一下，如果任何程序都能读写磁盘，那么整个系统都会陷入混乱（一如既往），因为任何用户程序都可以利用这个漏洞完全控制机器。 与设备交互的第二种方法称为内存映射 I/O。采用这种方法时，硬件会将设备寄存器当作内存位置来使用。要访问特定寄存器，操作系统会发出加载（读取）或存储（写入）地址；然后硬件会将加载/存储路由到设备，而不是主内存。 这两种方法并没有很大的优势。内存映射方法的优点是不需要新指令来支持，但这两种方法目前仍在使用。 ","date":"2024-05-11","objectID":"/posts/27.io%E8%AE%BE%E5%A4%87/:6:0","tags":["OS"],"title":"IO设备","uri":"/posts/27.io%E8%AE%BE%E5%A4%87/"},{"categories":["系统架构"],"content":"7 适配操作系统：设备驱动程序 我们要讨论的最后一个问题是：我们将讨论的最后一个问题是：如何将具有非常特定接口的设备整合到操作系统中，而且我们希望保持尽可能通用。例如，考虑一个文件系统。我们希望构建一个可以在SCSI磁盘、IDE磁盘、USB闪存驱动器等设备上运行的文件系统，我们希望文件系统能相对忽略如何向这些不同类型的驱动器发出读取或写入请求的所有细节。 因此，我们面临的关键问题是：如何让操作系统的大部分功能保持设备中立，从而将设备交互的细节从主要的操作系统子系统中隐藏起来？ 这个问题可以通过古老的抽象技术来解决。在最底层，操作系统中的一个软件必须详细了解设备是如何工作的。我们称这一软件为设备驱动程序，设备交互的任何细节都封装在其中。 让我们通过研究 Linux 文件系统软件栈，看看这种抽象如何帮助操作系统的设计和实现。下图粗略描绘了 Linux 软件的组织结构。 从图中可以看出，文件系统（当然也包括上面的应用程序）完全不关心它所使用的磁盘类的具体情况；它只需向通用块层发出块读写请求，通用块层会将这些请求路由到相应的设备驱动程序，设备驱动程序会处理发出具体请求的细节。虽然经过简化，但该图显示了这些细节是如何从操作系统的大部分功能中隐藏起来的。 该图还显示了设备的原始接口，它使特殊应用程序（例如文件系统检查器或磁盘碎片整理工具）能够直接读取和写入块，而不使用文件抽象。大多数系统提供这种类型的接口来支持这些低级存储管理应用程序。 请注意，上面看到的封装也有其缺点。例如，如果有一个设备具有许多特殊功能，但必须向内核的其余部分提供通用接口，那么这些特殊功能将不会被使用。例如，在具有 SCSI 设备的 Linux 中就会出现这种情况，这些设备具有非常丰富的错误报告；因为其他块设备（例如 ATA/IDE）的错误处理要简单得多，所以更高级别的软件收到的只是通用 EIO（通用 IO 错误）错误代码；因此，SCSI 可能提供的任何额外细节都会在文件系统中丢失。 有趣的是，由于您可能插入系统的任何设备都需要设备驱动程序，因此随着时间的推移，它们已经占据了内核代码的很大一部分。对 Linux 内核的研究表明，超过 70% 的操作系统代码都存在于设备驱动程序中 ；对于基于 Windows 的系统，该值可能也相当高。因此，当人们告诉您操作系统有数百万行代码时，他们真正说的是操作系统有数百万行设备驱动程序代码。当然，对于任何给定的安装，大部分代码可能并不活跃（即，一次只有少数设备连接到系统）。也许更令人沮丧的是，由于驱动程序通常是由“业余爱好者”（而不是全职内核开发人员）编写的，因此它们往往会存在更多错误，因此是导致内核崩溃的主要因素。 ","date":"2024-05-11","objectID":"/posts/27.io%E8%AE%BE%E5%A4%87/:7:0","tags":["OS"],"title":"IO设备","uri":"/posts/27.io%E8%AE%BE%E5%A4%87/"},{"categories":["系统架构"],"content":"8 案例研究：简单的 IDE 磁盘驱动程序（xv6 使用 QEMU IDE） 为了更深入地研究，让我们快速看一下实际的设备：IDE 磁盘驱动器。我们将查看 xv6 源代码，以获取工作 IDE 驱动程序的简单示例。 IDE 磁盘为系统提供了一个简单的接口，由四种类型的寄存器组成： 控制寄存器 Address 0x3F6 = 0x80 (0000 1RE0): R=reset, E=0 means “enable interrupt” 命令块寄存器 Address 0x1F0 = Data Port Address 0x1F1 = Error Address 0x1F2 = Sector Count Address 0x1F3 = LBA low byte (Logical Block Address) Address 0x1F4 = LBA mid byte Address 0x1F5 = LBA hi byte Address 0x1F6 = 1B1D TOP4LBA: B=LBA, D=drive Address 0x1F7 = Command/status 状态寄存器 Address 0x1F7 7 6 5 4 3 2 1 0 USY | EADY | AULT | EEK | RQ | ORR | DX/EX | RROR | 错误寄存器 Address 0x1F1 7 6 5 4 3 2 1 0 BK | NC | C | DNF | CR | BRT | 0NF | MNF | BBK: Bad Block UNC: Uncorrectable data error MC: Media Changed IDNF: ID mark Not Found MCR: Media Change Requested ABRT: Command aborted T0NF: Track 0 Not Found AMNF: Address Mark Not Found 控制、命令块、状态和错误。通过使用（在 x86 上）in和out I/O 指令读取或写入特定的“I/O 地址”（例如下面的 0x3F6），可以使用这些寄存器。 与设备交互的基本协议如下，假设设备已经初始化。 **等待驱动器准备就绪。**读取状态寄存器 (0x1F7)，直到驱动器就绪且不繁忙。 **将参数写入命令寄存器。**将扇区计数、要访问的扇区的逻辑块地址 (LBA) 和驱动器编号（主驱动器 = 0x00 或从驱动器 = 0x10，因为 IDE 只允许两个驱动器）写入命令寄存器 (0x1F2-0x1F6)。 **启动I/O。**通过向命令寄存器发出读/写命令。将 READ—WRITE 命令写入命令寄存器 (0x1F7)。 数据传输（用于写入）：等待驱动器状态为READY 和DRQ（驱动器数据请求）；将数据写入数据端口。 **处理中断。**在最简单的情况下，为每个传输的扇区处理一个中断；更复杂的方法允许批处理，从而在整个传输完成时进行最后一次中断。 **错误处理。**每次操作后，读取状态寄存器。如果 ERROR 位打开，读取错误寄存器以了解详细信息。 该协议的大部分内容可以在 xv6 IDE 驱动程序中找到，如下面这段代码所示： struct buf { //chunk of 512B to read/write int flags; uint dev; uint sector; struct buf *prev; // LRU cache list struct buf *next; struct buf *qnext; // disk queue uchar data[512]; }; #define B_BUSY 0x1 // buffer is locked by some process #define B_VALID 0x2 // buffer has been read from disk #define B_DIRTY 0x4 // buffer needs to be written to disk static int ide_wait_ready() { while (((int r = inb(0x1f7)) \u0026 IDE_BSY) || !(r \u0026 IDE_DRDY)) ; // loop until drive isn’t busy } static void ide_start_request(struct buf *b) { ide_wait_ready(); outb(0x3f6, 0); // generate interrupt outb(0x1f2, 1); // how many sectors? one // write LBA to command register outb(0x1f3, b-\u003esector \u0026 0xff); // LBA goes here ... LBA 0-7 outb(0x1f4, (b-\u003esector \u003e\u003e 8) \u0026 0xff); // ... and here LBA 8-15 outb(0x1f5, (b-\u003esector \u003e\u003e 16) \u0026 0xff); // ... and here! LBA 16-23 // 0x30 set LBA mode, ((b-\u003edev\u00261)\u003c\u003c4) 根据设备号（b-\u003edev）来设置主/从设备位。设备号为 0 或 1，左移 4 位后会设置到控制寄存器中相应的位置。((b-\u003esector\u003e\u003e24)\u00260x0f) 用于提取 LBA 的第24到第27位，这些位表示扇区地址的高四位，然后通过与 0x0f 位掩码进行按位与运算来获取这些位。 outb(0x1f6, 0xe0 | ((b-\u003edev\u00261)\u003c\u003c4) | ((b-\u003esector\u003e\u003e24)\u00260x0f)); // B_DIRTY：缓冲区数据被修改过；B_VALID：缓冲区数据有效 if(b-\u003eflags \u0026 B_DIRTY){ outb(0x1f7, IDE_CMD_WRITE); // this is a WRITE，告诉磁盘控制器执行写入操作 outsl(0x1f0, b-\u003edata, 512/4); // transfer data too!写入数据寄存器，outsl函数以32位（4字节）为单位传输数据。 } else { outb(0x1f7, IDE_CMD_READ); // this is a READ (no data) 告诉磁盘控制器执行读取操作。 } } void ide_rw(struct buf *b) { acquire(\u0026ide_lock); // 获取锁，确保对队列的访问是安全的 for (struct buf **pp = \u0026ide_queue; *pp; pp=\u0026(*pp)-\u003eqnext) ; // 遍历磁盘I/O 请求队列，移动到队尾 *pp = b; // add request to end if (ide_queue == b) // if q is empty，则立即发送请求 ide_start_request(b); // send req to disk while ((b-\u003eflags \u0026 (B_VALID|B_DIRTY)) != B_VALID) // 直到请求的数据状态变为有效为止 sleep(b, \u0026ide_lock); // wait for completion release(\u0026ide_lock); } void ide_intr() { struct buf *b; acquire(\u0026ide_lock); // 检查当前请求是否是读取操作并且磁盘处于就绪状态 if (!(b-\u003eflags \u0026 B_DIRTY) \u0026\u0026 ide_wait_ready() \u003e= 0) insl(0x1f0, b-\u003edata, 512/4); // if READ: get data b-\u003eflags |= B_VALID; // set flag to VALID，表示数据已经被读取或写入 b-\u003eflags \u0026= ~B_DIRTY; // 清除DIRTY flag wakeup(b); // wake waiting process if ((ide_queue = b-\u003eqnext) != 0) // start next request ide_start_request(ide_queue); // (if one exists) release(\u0026ide_lock); } 该驱动程序（初始化后）通过四个主要函数工作。 第一个是 ide_rw()，它将请求排队（如果还有其他待处理的请求），或者直接将其发送到磁盘（通过 ide_start_request()）；无论哪种情况，例程都会等待请求完成并将调用进程置于睡眠状态。 第二个是 ide_start_request()，用于向磁盘发送请求（在写入的情况下可能还有数据）； in 和 out x86 指令分别被调用来读取和写入设备寄存器。 启动请求例程使用第三个函数 ide_wait_read()，以确保驱动器在向其发出请求之前已准备就绪。 最后，当发生中断时，会调用 ide_intr()；它从设备读取数据（如果请求是读，而不是写），唤醒等待 I/O 完成的进程，并且（如果 I/O 队列中有更多请求），通过 ide_start_request()启动下一个 I/O。 ","date":"2024-05-11","objectID":"/posts/27.io%E8%AE%BE%E5%A4%87/:8:0","tags":["OS"],"title":"IO设备","uri":"/posts/27.io%E8%AE%BE%E5%A4%87/"},{"categories":["系统架构"],"content":"到目前为止，我们在写并发性的时候，好像构建并发应用程序的唯一方法就是使用线程。就像生活中的许多事情一样，这并不完全正确。具体来说，基于图形用户界面的应用程序和某些类型的互联网服务器经常使用不同风格的并发编程。这种风格被称为基于事件的并发，已在一些现代系统中流行起来，包括 node.js 等服务器端框架，但其根源在于 C/UNIX 系统，我们将在下文讨论。 基于事件的并发解决了两个方面的问题。首先，在多线程应用程序中正确管理并发性是一项挑战；正如我们所讨论的，可能会出现锁丢失、死锁和其他令人讨厌的问题。其次，在多线程应用程序中，开发人员几乎无法控制特定时刻的调度；相反，程序员只需创建线程，然后寄希望于底层操作系统以合理的方式在可用 CPU 上调度这些线程。由于很难构建一个通用的调度程序，在所有情况下都能很好地处理所有工作负载，操作系统有时会以非最佳的方式调度工作。因此，我们的关键是： 我们如何在不使用线程的情况下构建并发服务器，从而保留对并发的控制并避免一些似乎困扰多线程应用程序的问题？ ","date":"2024-05-11","objectID":"/posts/26.%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91/:0:0","tags":["OS"],"title":"基于事件的并发","uri":"/posts/26.%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91/"},{"categories":["系统架构"],"content":"1 基本思想：事件循环 如上所述，我们将使用的基本方法称为基于事件的并发。这种方法非常简单：只需等待某件事情（即 “事件”）发生；当事件发生时，检查事件的类型，并完成所需的少量工作（可能包括发出 I/O 请求，或安排其他事件的未来处理等）。就是这样！ 在了解细节之前，我们先来看看典型的基于事件的服务器是什么样的。此类应用程序基于一个简单的结构，即事件循环。事件循环的伪代码是这样的： while (1) { events = getEvents(); for (e in events) processEvent(e); } 其实就是这么简单。主循环只需等待事件发生（在上面的代码中调用 getEvents()），然后对返回的每个事件逐个进行处理；处理每个事件的代码称为事件处理程序。重要的是，当处理程序处理事件时，它是系统中发生的唯一活动；因此，决定下一步处理哪个事件就相当于调度。这种对调度的显式控制是基于事件的方法的基本优势之一。 但是，上述讨论给我们留下了一个更大的问题：基于事件的服务器究竟如何确定哪些事件正在发生，尤其是在网络和磁盘 I/O 方面？具体来说，事件服务器如何判断信息是否已经到达？ ","date":"2024-05-11","objectID":"/posts/26.%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91/:1:0","tags":["OS"],"title":"基于事件的并发","uri":"/posts/26.%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91/"},{"categories":["系统架构"],"content":"2 一个重要的API：select()（或者poll()） 考虑到这个基本事件循环，接下来我们必须解决如何接收事件的问题。在大多数系统中，可以通过 select() 或 poll() 系统调用使用一个基本 API。 这些接口使程序能够简单地检查是否有任何需要处理的传入 I/O。例如，想象一下一个网络应用（比如一个 Web 服务器）希望检查是否有任何网络数据包已经到达以便对其进行服务。这些系统调用让你正好做到了这一点。以 select() 为例。手册页（在 Mac 上）描述了该 API 的方式： int select(int nfds, fd_set *restrict readfds, fd_set *restrict writefds, fd_set *restrict errorfds, struct timeval *restrict timeout); 手册页中的实际描述： select() 检查其地址在 readfds、writefds 和 errorfds中传递的 I/O 描述符集，以查看其中的某些描述符是否已准备好读取、准备好写入或有异常条件待定。检查每个集合中的第一个 nfds 描述符，即检查描述符集合中从 0 到 nfds-1 的描述符。返回时，select() 将给定的描述符集替换为由已准备好执行请求的操作的描述符组成的子集。 select() 返回所有集合中就绪描述符的总数。 关于 select() 的几点。首先，请注意，它可以让您检查描述符是否可以读取和写入；前者让服务器确定新数据包已到达并需要处理，而后者让服务知道何时可以回复（即出站队列未满）。 其次，注意超时参数。这里的一种常见用法是将超时设置为 NULL，这会导致 select() 无限期地阻塞，直到某个描述符准备就绪。然而，更强大的服务器通常会指定某种超时；一种常见的技术是将超时设置为零，从而使用对 select() 的调用来立即返回。 poll() 系统调用非常相似。有关详细信息，请参阅其手册页。不管怎样，这些基本原语为我们提供了一种构建非阻塞事件循环的方法，它只需检查传入的数据包，从套接字中读取消息，并根据需要进行回复。 ","date":"2024-05-11","objectID":"/posts/26.%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91/:2:0","tags":["OS"],"title":"基于事件的并发","uri":"/posts/26.%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91/"},{"categories":["系统架构"],"content":"3 使用select() 为了更具体地说明这一点，我们来看看如何使用 select() 查看哪些网络描述符上有传入的报文。下面这段代码显示了一个简单的示例。 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003csys/time.h\u003e #include \u003csys/types.h\u003e #include \u003cunistd.h\u003e int main(void) { // open and set up a bunch of sockets (not shown) // main loop while (1) { // initialize the fd_set to all zero fd_set readFDs; FD_ZERO(\u0026readFDs); // now set the bits for the descriptors // this server is interested in // (for simplicity, all of them from min to max) int fd; for (fd = minFD; fd \u003c maxFD; fd++) FD_SET(fd, \u0026readFDs); // do the select int rc = select(maxFD+1, \u0026readFDs, NULL, NULL, NULL); // check which actually have data using FD_ISSET() for (fd = minFD; fd \u003c maxFD; fd++) if (FD_ISSET(fd, \u0026readFDs)) processFD(fd); } } 这段代码其实相当简单易懂。在初始化之后，服务器进入一个无限循环。在循环内部，它首先使用 FD_ZERO() 宏清除文件描述符集，然后使用 FD_SET() 将 minFD 到 maxFD 的所有文件描述符都包含在文件描述符集中。例如，这组描述符可能代表服务器正在关注的所有网络套接字。最后，服务器调用 select() 查看哪些连接上有可用数据。然后，在一个循环中使用 FD_ISSET()，事件服务器就能看到哪些描述符已准备好数据，并处理传入的数据。 当然，真正的服务器要比这复杂得多，需要在发送消息、发出磁盘 I/O 和许多其他细节时使用逻辑。 ","date":"2024-05-11","objectID":"/posts/26.%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91/:3:0","tags":["OS"],"title":"基于事件的并发","uri":"/posts/26.%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91/"},{"categories":["系统架构"],"content":"4 为什么更简单？不需要锁 有了单 CPU 和基于事件的应用程序，并发程序中的问题就不复存在了。具体来说，由于一次只处理一个事件，因此无需获取或释放锁；基于事件的服务器不会被其他线程中断，因为它是绝对的单线程。因此，线程程序中常见的并发问题在基于事件的基本方法中并不存在。 TIP：不要阻塞基于事件的服务器 基于事件的服务器可以对任务调度进行细粒度的控制。然而，为了维持这种控制，不能进行任何阻止调用者执行的调用；不遵守此设计技巧将导致基于事件的服务器被阻塞，会发生一系列的严重问题。 ","date":"2024-05-11","objectID":"/posts/26.%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91/:4:0","tags":["OS"],"title":"基于事件的并发","uri":"/posts/26.%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91/"},{"categories":["系统架构"],"content":"5 问题：阻塞系统调用 到目前为止，基于事件的编程听起来不错，对吗？你只需编写一个简单的循环，然后在事件发生时进行处理。你甚至不需要考虑锁定问题！但是有一个问题：如果一个事件要求你发出一个可能会阻塞的系统调用怎么办？ 例如，假设客户端向服务器发出请求，要求从磁盘读取文件，并将文件内容返回给请求客户端（就像简单的 HTTP 请求一样）。要处理这样的请求，某个事件处理程序最终必须发出 open() 系统调用来打开文件，然后再发出一系列 read() 调用来读取文件。当文件被读入内存后，服务器可能会开始向客户端发送结果。 open() 和 read() 调用都可能向存储系统发出 I/O 请求（当所需的元数据或数据不在内存中时），因此可能需要很长时间才能提供服务。对于基于线程的服务器来说，这不是问题：当发出 I/O 请求的线程暂停（等待 I/O 完成）时，其他线程可以运行，从而使服务器取得进展。事实上，I/O 和其他计算的这种自然重叠正是基于线程的编程非常自然和简单的原因。 然而，在基于事件的方法中，没有其他线程可以运行：只有主事件循环。这就意味着，如果事件处理程序发出的调用阻塞，整个服务器就会这样做：阻塞，直到调用完成。当事件循环阻塞时，系统就会处于闲置状态，从而造成巨大的潜在资源浪费。因此，在基于事件的系统中，我们有一条必须遵守的规则：不允许阻塞调用。 ","date":"2024-05-11","objectID":"/posts/26.%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91/:5:0","tags":["OS"],"title":"基于事件的并发","uri":"/posts/26.%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91/"},{"categories":["系统架构"],"content":"6 解决方案：异步 I/O 为了克服这一限制，许多现代操作系统引入了向磁盘系统发出 I/O 请求的新方法，一般称为异步 I/O。这些接口使应用程序能够发出 I/O 请求，并在 I/O 完成之前立即将控制权返回给调用者；其他接口使应用程序能够确定各种 I/O 是否已完成。 例如，让我们看看 Mac 提供的接口（其他系统也有类似的 API）。应用程序接口围绕着一个基本结构，即struct aiocb 或 AIO 控制块（常用术语）。该结构的简化版本如下（更多信息请参阅手册）： struct aiocb { int aio_fildes; /* File descriptor */ off_t aio_offset; /* File offset */ volatile void *aio_buf; /* Location of buffer */ size_t aio_nbytes; /* Length of transfer */ }; 要对文件进行异步读取，应用程序应首先在此结构中填入相关信息：要读取文件的文件描述符（aio_fildes）、文件中的偏移量（aio_offset）以及请求的长度（aio_nbytes），最后是读取结果应复制到的目标内存位置（aio_buf）。 填入此结构后，应用程序必须发出异步调用来读取文件；在 Mac 上，此 API 只是异步读取 API： int aio_read(struct aiocb *aiocbp); 该调用会尝试发出 I/O；如果成功，它就会立即返回，应用程序（即基于事件的服务器）可以继续工作。 不过，我们还必须解决最后一个难题。我们如何判断 I/O 是否已完成，从而确定缓冲区（aio_buf 指向的缓冲区）中已包含所请求的数据？这就需要最后一个 API。在 Mac 上，它被称为 aio_error()。该 API 如下所示： int aio_error(const struct aiocb *aiocbp); 该系统调用检查 aiocbp 引用的请求是否已完成。如果是，则例程返回成功（用零表示）；如果不是，则返回 EINPROGRESS。因此，对于每个未完成的异步 I/O，应用程序可以通过调用 aio_error() 定期轮询系统，以确定所述 I/O 是否尚未完成。 您可能已经注意到的一件事是检查 I/O 是否已完成是一件很痛苦的事情；如果一个程序在给定时间点发出了数十或数百个 I/O，它是否应该简单地重复检查每个 I/O，或者先等待一会儿，或者……？ 为了解决这个问题，一些系统提供了一种基于中断的方法。此方法使用 UNIX 信号来通知应用程序异步 I/O 何时完成，从而无需重复询问系统。 在没有异步 I/O 的系统中，纯粹基于事件的方法无法实现。不过，聪明的研究人员已经推导出了能很好代替它们的方法。例如，Pai 等人 描述了一种混合方法，其中事件用于处理网络数据包，线程池用于管理未完成的 I/O。详情请阅读他们的论文。 UNIX 信号 在所有现代 UNIX 变体中，都有一个被称为信号的庞大而迷人的基础架构。最简单来说，信号提供了一种与进程通信的方式。具体来说，信号可以传递给应用程序；传递信号时，应用程序会停止正在进行的任何操作，以运行信号处理程序（即应用程序中处理该信号的代码）。处理完成后，进程将恢复之前的行为。 每个信号都有一个名称，如 HUP（挂起）、INT（中断）、SEGV（分段违规）等；详情请查看手册页面：man signal。有趣的是，有时内核本身也会发出信号。例如，当你的程序遇到分段违规时，操作系统会向其发送 SIGSEGV（在信号名称前加上 SIG 是很常见的）；如果你的程序被配置为捕获该信号，你实际上可以运行一些代码来响应这种错误的程序行为（这对调试很有用）。当一个信号被发送到一个未配置为处理该信号的进程时，一些默认行为将被执行；对于 SEGV，该进程将被杀死。 下面是一个进入无限循环的简单程序，但它首先设置了一个信号处理程序来捕获 SIGHUP： #include \u003cstdio.h\u003e #include \u003csignal.h\u003e void handle(int arg) { printf(\"stop wakin’ me up...\\n\"); } int main(int argc, char *argv[]) { signal(SIGHUP, handle); while (1) ; // doin’ nothin’ except catchin’ some sigs return 0; } 你可以使用 kill 命令行工具向它发送信号。这样做会中断程序中的主 while 循环，并运行处理程序代码 handle()： ❯ ./loop_signal\u0026 [1] 66420 ❯ kill -HUP 66420 stop wakin’ me up... ","date":"2024-05-11","objectID":"/posts/26.%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91/:6:0","tags":["OS"],"title":"基于事件的并发","uri":"/posts/26.%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91/"},{"categories":["系统架构"],"content":"7 另一个问题：状态管理 基于事件的方法的另一个问题是，这类代码的编写通常比传统的基于线程的代码复杂。原因如下：当一个事件处理程序发出异步 I/O 时，它必须打包一些程序状态，供下一个事件处理程序在 I/O 最终完成时使用；而在基于线程的程序中不需要这项额外工作，因为程序所需的状态在线程的栈中。Adya 等人将这项工作称为人工栈管理，它是基于事件的编程的基础。 为了更具体地说明这一点，让我们来看一个简单的例子：基于线程的服务器需要从文件描述符（fd）中读取数据，并在完成后将从文件中读取的数据写入网络套接字描述符（sd）。代码（忽略错误检查）如下： int rc = read(fd, buffer, size); rc = write(sd, buffer, size); 正如你所看到的，在多线程程序中，做这样的工作是轻而易举的；当 read() 最终返回时，代码会立即知道要写入哪个套接字，因为该信息就在线程的堆栈中（在变量 sd 中）。 而在基于事件的系统中，情况就没那么简单了。要执行同样的任务，我们首先要使用上述 AIO 调用异步发出读取指令。假设我们使用 aio_error() 调用定期检查读取是否完成；当该调用通知我们读取完成时，基于事件的服务器如何知道该做什么？ 正如 Adya 等人所描述的那样，解决办法是使用一种古老的编程语言结构，即 continuation。虽然听起来很复杂，但其实想法很简单：基本上，在某个数据结构中记录完成处理该事件所需的信息；当事件发生时（即磁盘 I/O 完成时），查找所需的信息并处理该事件。 在这种特殊情况下，解决方案是在某种数据结构（如哈希表）中记录套接字描述符 (sd)，并以文件描述符 (fd) 为索引。磁盘 I/O 完成后，事件处理程序将使用文件描述符查找continuation，并将套接字描述符的值返回给调用者。此时（最后），服务器就可以进行最后的工作，将数据写入套接字。 ","date":"2024-05-11","objectID":"/posts/26.%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91/:7:0","tags":["OS"],"title":"基于事件的并发","uri":"/posts/26.%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91/"},{"categories":["系统架构"],"content":"8 事件仍有哪些困难？ 基于事件的方法还有一些其他困难需要提及。例如，当系统从单核 CPU 转向多核 CPU 时，基于事件的方法的一些简便性就消失了。具体来说，为了利用一个以上的 CPU，事件服务器必须并行运行多个事件处理程序；这样做时，通常的同步问题（如临界区）就会出现，必须采用通常的解决方案（如锁）。因此，在现代多核系统上，不加锁的简单事件处理已不再可能。 基于事件的方法的另一个问题是，它不能很好地与分页等某些类型的系统活动集成。例如，如果事件处理程序发生页面故障，它就会阻塞，因此服务器在页面故障完成之前不会取得进展。尽管服务器在结构上已经避免了显式阻塞，但页面故障导致的这种隐式阻塞是难以避免的，因此在普遍存在时会导致严重的性能问题。 第三个问题是，随着时间的推移，基于事件的代码可能难以管理，因为各种例程的确切语义会发生变化。例如，如果一个例程从非阻塞变为阻塞，那么调用该例程的事件处理程序也必须随之改变，以适应其新的性质，即把自己撕成两半。由于阻塞对于基于事件的服务器来说是灾难性的，因此程序员必须时刻注意每个事件所使用的应用程序接口在语义上的变化。 最后，虽然异步磁盘 I/O 现在已经可以在大多数平台上实现，但它需要很长的时间才能实现，而且它与异步网络 I/O 的集成方式也不像你想象的那么简单和统一。例如，虽然我们希望使用 select() 接口来管理所有未完成的 I/O，但通常需要将用于网络的 select() 和用于磁盘 I/O 的 AIO 调用结合起来使用。 ","date":"2024-05-11","objectID":"/posts/26.%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91/:8:0","tags":["OS"],"title":"基于事件的并发","uri":"/posts/26.%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%B9%B6%E5%8F%91/"},{"categories":["系统架构"],"content":"1 存在哪些类型的并发bug？ 第一个也是最明显的问题是：复杂的并发程序中会出现哪些类型的并发bug？这个问题一般来说很难回答，但幸运的是，其他一些人已经为我们完成了这项工作。具体来说，我们依赖于 Lu 等人的一项研究。它详细分析了许多流行的并发应用程序，以了解实践中出现的bug类型。 该研究重点关注四个主要且重要的开源应用程序：MySQL（流行的数据库管理系统）、Apache（著名的 Web 服务器）、Mozilla（著名的 Web 浏览器）和 OpenOffice（MS Office 套件的免费版本，有些人实际使用）。在这项研究中，作者研究了在每个代码库中发现并修复的并发性bug，将开发人员的工作转化为定量bug分析；了解这些结果可以帮助您了解成熟代码库中实际发生的问题类型。 下图显示了 Lu 及其同事研究的bug汇总。从图中可以看出，总共有 105 个bug，其中大部分不是死锁（74 个）；其余 31 个是死锁bug。此外，您还可以看到每个应用程序的bug数量；OpenOffice 的并发bug总数只有 8 个，而 Mozilla 则有近 60 个。 我们现在对这些不同类别的bug（非死锁、死锁）进行更深入的研究。对于第一类非死锁bug，我们将使用研究中的示例进行讨论。对于第二类死锁bug，我们将讨论在预防、避免或处理死锁方面所做的大量工作。 ","date":"2024-05-11","objectID":"/posts/25.%E5%B9%B6%E5%8F%91bug/:1:0","tags":["OS"],"title":"并发bug","uri":"/posts/25.%E5%B9%B6%E5%8F%91bug/"},{"categories":["系统架构"],"content":"2 非死锁bug 根据 Lu 的研究，非死锁bug占并发bug的大多数。但这些bug属于哪种类型？它们是如何产生的？我们该如何修复它们？我们现在讨论 Lu 等人发现的两大类非死锁bug：原子性违规bug和顺序违规bug。 ","date":"2024-05-11","objectID":"/posts/25.%E5%B9%B6%E5%8F%91bug/:2:0","tags":["OS"],"title":"并发bug","uri":"/posts/25.%E5%B9%B6%E5%8F%91bug/"},{"categories":["系统架构"],"content":"2.1 原子性违规bug 遇到的第一类问题被称为原子性违规。下面是一个在 MySQL 中发现的简单示例。 Thread 1:: if (thd-\u003eproc_info) { ... fputs(thd-\u003eproc_info, ...); ... } Thread 2:: thd-\u003eproc_info = NULL; 在示例中，两个不同的线程访问了结构体 thd 中的字段 proc_info。第一个线程检查值是否为非空值，然后打印其值；第二个线程将其设置为空值。显然，如果第一个线程执行了检查，但在调用 fputs 之前被中断，那么第二个线程可能会在中间运行，从而将指针设置为 NULL；当第一个线程恢复运行时，它将崩溃，因为 NULL 指针将被 fputs 解除引用。 根据 Lu 等人的说法，原子性违规的更正式定义是：“违反了多个内存访问之间所需的可串行性（即代码区域应该是原子性的，但在执行过程中并未强制执行原子性）。”在上面的示例中，代码对 proc_info 的非 NULL 检查以及 fputs() 调用中 proc_info 的使用有一个原子性假设（用 Lu 的话说）；当假设不正确时，代码将无法按预期工作。 找到此类问题的解决方案通常（但并非总是）很简单。在此解决方案中，我们只需在共享变量引用周围添加锁，确保当任一线程访问 proc_info 字段时，它都持有锁（proc_info_lock）。当然，访问该结构的任何其他代码也应该在执行此操作之前获取此锁。 pthread_mutex_t proc_info_lock = PTHREAD_MUTEX_INITIALIZER; Thread 1:: pthread_mutex_lock(\u0026proc_info_lock); if (thd-\u003eproc_info) { ... fputs(thd-\u003eproc_info, ...); ... } pthread_mutex_unlock(\u0026proc_info_lock); Thread 2:: pthread_mutex_lock(\u0026proc_info_lock); thd-\u003eproc_info = NULL; pthread_mutex_unlock(\u0026proc_info_lock); ","date":"2024-05-11","objectID":"/posts/25.%E5%B9%B6%E5%8F%91bug/:2:1","tags":["OS"],"title":"并发bug","uri":"/posts/25.%E5%B9%B6%E5%8F%91bug/"},{"categories":["系统架构"],"content":"2.2 顺序违规bug Lu 等人发现的另一种常见的非死锁bug被称为 “顺序违规”。下面是另一个简单的例子。 Thread 1:: void init() { ... mThread = PR_CreateThread(mMain, ...); ... } Thread 2:: void mMain(...) { ... mState = mThread-\u003eState; ... } 线程 2 中的代码似乎假定变量 mThread 已被初始化（并且不是 NULL）；但是，如果线程 2 创建后立即运行，那么在线程 2 的 mMain() 中访问 mThread 时，它的值将不会被设置，并且很可能会因解引用 NULL 指针而崩溃。请注意，我们假设 mThread 的值最初为 NULL；如果不是，那么在线程 2 中通过解引用访问任意内存位置时，可能会发生更奇怪的事情。 违反顺序的更正式定义是这样的：“两个（组）内存访问之间的理想顺序被颠倒（即 A 应总是在 B 之前执行，但在执行过程中顺序并没有被强制执行）\"。 解决这类bug的方法一般是强制执行排序。正如我们之前详细讨论过的，使用条件变量是将这种同步方式添加到现代代码库中的一种简单而稳健的方法。在上面的例子中，我们可以将代码重写如下： pthread_mutex_t mtLock = PTHREAD_MUTEX_INITIALIZER; pthread_cond_t mtCond = PTHREAD_COND_INITIALIZER; int mtInit = 0; Thread 1:: void init() { ... mThread = PR_CreateThread(mMain, ...); // signal that the thread has been created... pthread_mutex_lock(\u0026mtLock); mtInit = 1; pthread_cond_signal(\u0026mtCond); pthread_mutex_unlock(\u0026mtLock); ... } Thread 2:: void mMain(...) { ... // wait for the thread to be initialized... pthread_mutex_lock(\u0026mtLock); while (mtInit == 0) pthread_cond_wait(\u0026mtCond, \u0026mtLock); pthread_mutex_unlock(\u0026mtLock); mState = mThread-\u003eState; ... } 在这个固定的代码序列中，我们添加了一个锁（mtLock）和相应的条件变量（mtCond），以及一个状态变量（mtInit）。初始化代码运行时，它会将 mtInit 的状态设置为 1，并发出信号表示已完成设置。如果线程 2 在这之前运行，它将等待这个信号和相应的状态变化；如果线程 2 在之后运行，它将检查状态，发现初始化已经发生（即 mtInit 被设置为 1），从而继续正常运行。需要注意的是，我们可以使用 mThread 作为状态变量本身，但为了简单起见，这里不这样做。当线程之间需要排序时，条件变量（或 信号量）就能派上用场。 ","date":"2024-05-11","objectID":"/posts/25.%E5%B9%B6%E5%8F%91bug/:2:2","tags":["OS"],"title":"并发bug","uri":"/posts/25.%E5%B9%B6%E5%8F%91bug/"},{"categories":["系统架构"],"content":"3 死锁bug ","date":"2024-05-11","objectID":"/posts/25.%E5%B9%B6%E5%8F%91bug/:3:0","tags":["OS"],"title":"并发bug","uri":"/posts/25.%E5%B9%B6%E5%8F%91bug/"},{"categories":["系统架构"],"content":"3.1 基本介绍 除了上面提到的并发bug，在许多具有复杂锁定协议的并发系统中还会出现一个典型的问题，即死锁。例如，当一个线程（例如线程 1）持有一个锁（L1）并等待另一个锁（L2）时，就会出现死锁；不幸的是，持有锁 L2 的线程（线程 2）正在等待 L1 被释放。下面的代码片段演示了这种潜在的死锁： Thread 1: Thread 2: pthread_mutex_lock(L1); pthread_mutex_lock(L2); pthread_mutex_lock(L2); pthread_mutex_lock(L1); 注意，如果这段代码运行，并不一定会发生死锁；相反，如果线程 1 获取锁 L1，然后线程 2 发生上下文切换，则可能会发生这种情况。此时，线程 2 获取 L2，并尝试获取 L1。因此，我们遇到了死锁，因为每个线程都在等待另一个线程，而两个线程都无法运行。 如下图所示，图中出现循环就表明出现了死锁。这张图应该能说明问题。程序员应该如何编写代码以便以某种方式处理死锁？我们问题的关键是我们应该如何构建系统来预防、避免或至少检测死锁并从中恢复？这是当今系统中真正的问题吗？ ","date":"2024-05-11","objectID":"/posts/25.%E5%B9%B6%E5%8F%91bug/:3:1","tags":["OS"],"title":"并发bug","uri":"/posts/25.%E5%B9%B6%E5%8F%91bug/"},{"categories":["系统架构"],"content":"3.2 为什么会出现死锁 你可能会想，像上面这样的简单死锁似乎很容易避免。例如，如果线程 1 和线程 2 都确保以相同的顺序抓取锁，死锁就永远不会出现。那么，为什么会出现死锁呢？ 其中一个原因是，在大型代码库中，组件之间会产生复杂的依赖关系。以操作系统为例。虚拟内存系统可能需要访问文件系统，以便从磁盘分页读入一个数据块；文件系统随后可能需要一个内存页来读入该数据块，从而与虚拟内存系统发生关联。因此，在大型系统中设计锁定策略时必须小心谨慎，以避免代码中可能自然出现的循环依赖关系造成死锁。 另一个原因是封装的本质。作为软件开发人员，我们被教导要隐藏实现的细节，从而使软件更容易以模块化的方式构建。遗憾的是，这种模块化与锁定并不匹配。正如 Jula 等人所指出的，一些看似无害的接口几乎会让你陷入死锁。例如，以 Java 向量类和 AddAll() 方法为例。这个例程的调用过程如下 Vector v1, v2; v1.AddAll(v2); 在内部，由于该方法需要是多线程安全的，因此需要获取添加到 (v1) 的向量和参数 (v2) 的锁。该例程以某种任意顺序获取所述锁（先是 v1，然后是 v2），以便将 v2 的内容添加到 v1。如果其他线程几乎同时调用 v2.AddAll(v1)，则可能会出现死锁，而所有这些都对调用应用程序来说是隐藏的。 ","date":"2024-05-11","objectID":"/posts/25.%E5%B9%B6%E5%8F%91bug/:3:2","tags":["OS"],"title":"并发bug","uri":"/posts/25.%E5%B9%B6%E5%8F%91bug/"},{"categories":["系统架构"],"content":"3.3 死锁原因 发生死锁需要满足四个条件： 互斥：线程声明对其所需资源的独占控制（例如，线程获取锁）。 持有并等待：线程持有分配给它们的资源（例如，它们已经获取的锁），同时等待其他资源（例如，它们希望获取的锁）。 不可抢占：无法从持有资源的线程中强制删除资源（例如锁）。 循环等待：存在循环线程链，使得每个线程持有链中下一个线程正在请求的一个或多个资源（例如，锁）。 如果这四个条件中任何一个不满足，就不会发生死锁。因此，我们首先探索防止死锁的技术；这些策略中的每一个都旨在防止出现上述情况之一，因此是处理死锁问题的一种方法。 ","date":"2024-05-11","objectID":"/posts/25.%E5%B9%B6%E5%8F%91bug/:3:3","tags":["OS"],"title":"并发bug","uri":"/posts/25.%E5%B9%B6%E5%8F%91bug/"},{"categories":["系统架构"],"content":"3.4 预防死锁 3.4.1 循环等待 最实用的预防方法（当然也是经常使用的方法）可能是编写锁定代码，使其永远不会引起循环等待条件。要做到这一点，最直接的方法就是为锁的获取提供一个总排序。例如，如果系统中只有两个锁（L1 和L2），则可以通过始终在 L2 之前获取 L1 来防止死锁。这种严格的排序可以确保不会出现循环等待，从而避免死锁。 当然，在更复杂的系统中，会存在两个以上的锁，因此很难实现完全的锁排序（也许根本没有必要）。因此，部分排序可以有效地构建锁获取结构，从而避免死锁。Linux 中的内存映射代码就是一个很好的部分锁排序的真实例子；源代码顶部的注释揭示了十组不同的锁获取顺序，包括简单的如 “i_mutex before i_mmap_mutex “和更复杂的如 “i_mmap_mutex before private_lock before swap_lock before mapping-\u003etree_lock\"。 可以想象，无论是全部排序还是部分排序，都需要精心设计锁定策略，而且必须非常谨慎。此外，排序只是一种惯例，马虎的程序员很容易忽略锁定协议，并可能导致死锁。最后，锁排序要求对代码库以及各种例程的调用方式有深入的了解；只要有一个bug，就可能导致死锁。 TIP：通过锁地址强制执行锁排序 在某些情况下，一个函数必须获取两个（或更多）锁；因此，我们知道我们必须小心，否则可能会出现死锁。想象一个按如下方式调用的函数：do_something(mutex_t *m1, mutex_t *m2)。如果代码总是在 m2 之前获取 m1（或者总是在 m1 之前获取 m2），则可能会死锁，因为一个线程可以调用 do_something(L1, L2)，而另一个线程可以调用 do_something(L2, L1)。 为了避免这个特殊问题，聪明的程序员可以使用每个锁的地址作为获取锁的顺序。通过以从高到低或从低到高的地址顺序获取锁，do_something() 可以保证它始终以相同的顺序获取锁，无论它们传入的顺序如何。代码看起来像这样这： if (m1 \u003e m2) { // grab locks in high-to-low address order pthread_mutex_lock(m1); pthread_mutex_lock(m2); } else { pthread_mutex_lock(m2); pthread_mutex_lock(m1); } // Code assumes that m1 != m2 (it is not the same lock) 通过使用这种简单的技术，程序员可以确保简单高效地实现无死锁的多锁获取。 3.4.2 持有并等待 通过原子方式一次性获取所有锁，可以避免死锁的保持和等待要求。在实际操作中，可以通过以下方式实现： pthread_mutex_lock(prevention); // begin lock acquisition pthread_mutex_lock(L1); pthread_mutex_lock(L2); ... pthread_mutex_unlock(prevention); // end 通过首先获取锁prevention，此代码确保在获取锁时不会发生任何不及时的线程切换，从而再次避免死锁。当然，这要求任何时候任何线程抓取一个锁时，它首先获取全局预防锁。例如，如果另一个线程尝试以不同顺序抓取锁L1和L2，则是可以的，因为在这样做时它将持有prevention锁。 请注意，由于多种原因，该解决方案存在问题。和以前一样，封装对我们不利：当调用例程时，这种方法要求我们准确地知道必须持有哪些锁并提前获取它们。这种技术还可能会降低并发性，因为所有锁都必须尽早（立即）获取，而不是在真正需要时获取。 3.4.3 不可抢占 因为我们通常将锁视为一直保持到调用解锁为止，所以多次获取锁常常会给我们带来麻烦，因为在等待一个锁时，我们正在持有另一个锁。许多线程库提供了一组更灵活的接口来帮助避免这种情况。具体来说，例程 pthread_mutex_trylock() 要么获取锁（如果可用）并返回成功，要么返回指示锁已被持有的bug代码；在后一种情况下，如果您想抓住该锁，可以稍后重试。 这样的接口可以按如下方式使用来构建无死锁、有序鲁棒的锁获取协议： top: pthread_mutex_lock(L1); if (pthread_mutex_trylock(L2) != 0) { pthread_mutex_unlock(L1); goto top; } 需要注意的是，另一个线程可以遵循相同的协议，但以另一种顺序（先 L2 后 L1）获取锁，这样程序仍然不会出现死锁。然而，一个新的问题出现了：活锁。两个线程有可能（虽然可能性不大）都在重复尝试这种顺序，但多次都无法获得两个锁。在这种情况下，两个系统都在重复运行这个代码序列（因此不是死锁），但却没有取得进展，因此被称为活锁。活锁问题也有解决方法：例如，可以在循环之前添加一个随机延迟，然后重新尝试整个过程，从而降低竞争线程之间重复干扰的几率。 关于这个解决方案的一点是：它绕过了使用 trylock 方法的难点。第一个可能再次出现的问题是封装：如果这些锁中的一个被埋在某个被调用的例程中，那么跳回起点的实现就会变得更加复杂。例如，如果在获取 L1 后，代码分配了一些内存，那么在获取 L2 失败后，就必须释放这些内存，然后再跳回到顶层，重新尝试整个序列。不过，在有限的情况下（例如前面提到的 Java 向量方法），这种方法可能会很有效。 你可能还会注意到，这种方法并没有真正加入抢占（从拥有锁的线程中强行夺走锁的操作），而是使用 trylock 方法允许开发者以一种优雅的方式退出锁的所有权（即抢占自己的所有权）。不过，这是一种实用的方法，因此尽管在这方面并不完美，我们还是将其包含在这里。 3.4.4 互斥 最后一种防范技术是完全避免互斥。一般来说，我们知道这很困难，因为我们希望运行的代码确实存在临界区。那么我们能做些什么呢？ Herlihy 提出了一个想法：我们可以设计各种完全不需要锁的数据结构。这些无锁（以及相关的无等待）方法背后的理念很简单：利用强大的硬件指令，可以以不需要显式锁定的方式构建数据结构。 举个简单的例子，假设我们有一条比较和交换指令，你可能还记得这是一条由硬件提供的原子指令，它的作用如下： int CompareAndSwap(int *address, int expected, int new) { if (*address == expected) { *address = new; return 1; // success } return 0; // failure } 想象一下，我们现在想以原子方式将一个值递增一定量。我们可以这样做： void AtomicIncrement(int *value, int amount) { do { int old = *value; } while (CompareAndSwap(value, old, old + amount) == 0); } 我们没有获取锁，进行更新，然后释放它，而是构建了一种方法，反复尝试将值更新为心智并使用CompareAndSwap来执行此操作。通过这种方式，不会获取锁，并且不会出现死锁（尽管活锁仍然是可能的）。 让我们考虑一个稍微复杂的例子：列表插入。以下是在列表头部插入的代码： void insert(int value) { node_t *n = malloc(sizeof(node_t)); assert(n != NULL); n-\u003evalue = value; n-\u003enext = head; head = n; } 这段代码执行简单的插入操作，但如果多个线程 “同时 “调用，就会出现竞争条件。当然，我们可以用获取和释放锁来解决这个问题： void insert(int value) { node_t *n = malloc(sizeof(node_t)); assert(n != NULL); n-\u003evalue = value; pthread_mutex_lock(listlock); // begin critical section n-\u003enext = head; head = n; pthread_mutex_unlock(listlock); // end critical section } 在这个解决方案中，我们使用了传统的锁。相反，我们可以尝试使用CompareAndSwap指令，以无锁定方式执行插入操作。下面是一种可行的方法： void insert(int value) { node_t *n = malloc(sizeof(node_t)); assert(n != NULL); n-\u003evalue = value; do { n-\u003enext = head; } while (CompareAndSwap(\u0026head, n-\u003enext, n) == 0); } 这里的代码会更新下一个指针，使其指向当前头部，然后尝试将新创建的节点交换到列表的新头部。但是，如果其他线程在此期间成功地交换了一个新的头，那么这个操作就会失败，从而导致这个线程用新的头再次重试。 当然，建立一个有用的列表需要的不仅仅是列表插入，毫不奇怪，建立一个能以无锁方式插入、删除和执行查找的列表并非易事。 ","date":"2024-05-11","objectID":"/posts/25.%E5%B9%B6%E5%8F%91bug/:3:4","tags":["OS"],"title":"并发bug","uri":"/posts/25.%E5%B9%B6%E5%8F%91bug/"},{"categories":["系统架构"],"content":"3.5 通过调度避免死锁 在某些情况下，避免死锁比预防死锁更可取。避免死锁需要一些全局知识，了解各个线程在执行期间可能会获取哪些锁，并随后以保证不会发生死锁的方式调度所述线程。 例如，假设我们有两个处理器和四个线程，必须在它们上进行调度。进一步假设我们知道线程 1 (T1) 获取锁 L1 和 L2（以某种顺序，在执行期间的某个时刻），T2 也获取 L1 和 L2，T3 仅获取 L2，而 T4 根本不获取锁。我们可以以表格形式展示线程的这些锁获取需求： T1 T2 T3 T4 L1 yes yes no no L2 yes yes yes no 因此，智能调度程序可以计算出，只要 T1 和 T2 不同时运行，就不会出现死锁。下面就是这样一个调度程序： 请注意，（T3 和 T1）或（T3 和 T2）是可以重叠的。即使 T3 抓住了锁 L2，它也不会因为与其他线程同时运行而导致死锁，因为它只抓住了一个锁。让我们再看一个例子。在这个例子中，对相同资源（同样是锁 L1 和 L2）的争用更多，如下面的争用表所示： T1 T2 T3 T4 L1 yes yes Yes no L2 yes yes yes no 其中，线程 T1、T2 和 T3 都需要在执行过程中的某个时刻同时抓住锁 L1 和 L2。下面是一个可以保证不发生死锁的调度表： 正如你所看到的，静态调度导致了一种保守的方法，即 T1、T2 和 T3 都在同一个处理器上运行，因此完成作业的总时间大大延长。虽然这些任务有可能同时运行，但由于担心死锁，我们无法这样做，而代价就是性能。 Dijkstra 的银行家算法就是这种方法的一个著名例子。遗憾的是，这些方法只在非常有限的环境中有用，例如，在嵌入式系统中，人们完全了解必须运行的全部任务集及其所需的锁。此外，这种方法还会限制并发性，正如我们在上文第二个例子中看到的那样。因此，通过调度避免死锁并不是一种广泛使用的通用解决方案。 ","date":"2024-05-11","objectID":"/posts/25.%E5%B9%B6%E5%8F%91bug/:3:5","tags":["OS"],"title":"并发bug","uri":"/posts/25.%E5%B9%B6%E5%8F%91bug/"},{"categories":["系统架构"],"content":"3.6 检测和恢复 最后一个通用策略是允许死锁偶尔发生，然后在检测到死锁后采取一些措施。例如，如果操作系统每年都会出现一次死锁，那么你只需重启操作系统，然后继续愉快地（或暴躁地）工作。如果死锁很少发生，那么这种不解决问题的方法确实非常实用。 许多数据库系统都采用了死锁检测和恢复技术。死锁检测器定期运行，构建资源图并检查其是否存在循环。一旦出现循环（死锁），系统就需要重新启动。如果首先需要对数据结构进行更复杂的修复，则可能需要人工参与，以简化修复过程。 ","date":"2024-05-11","objectID":"/posts/25.%E5%B9%B6%E5%8F%91bug/:3:6","tags":["OS"],"title":"并发bug","uri":"/posts/25.%E5%B9%B6%E5%8F%91bug/"},{"categories":["系统架构"],"content":"1 信号量：定义 信号量是一个具有整数值的对象，我们可以使用两个例程对其进行操作；在 POSIX 标准中，这些例程是 sem_wait() 和 sem_post()。因为信号量的初始值决定了它的行为，所以在调用任何其他例程与信号量交互之前，我们必须首先将其初始化为某个值，代码所下示。 #include \u003csemaphore.h\u003e sem_t s; sem_init(\u0026s, 0, 1); 在代码，我们声明了一个信号量 s 并通过将 1 作为第三个参数传递来将其初始化值为 1。在我们将看到的所有示例中，sem_init() 的第二个参数都将设置为 0；**这表明信号量在同一进程中的线程之间共享。**有关信号量其他用法的详细信息（即如何使用它们来同步不同进程之间的访问），请参阅手册页：man sem_init，这需要第二个参数的不同值。 信号量初始化后，我们可以调用两个函数之一与之交互：sem_wait() 或 sem_post()。这两个函数的行为如下所示。 int sem_wait(sem_t *s) { // Decrement the value of semaphore s by one // If the value becomes negative, the calling thread will block until it becomes positive // Once the value becomes positive, the thread will continue } int sem_post(sem_t *s) { // Increment the value of semaphore s by one // If there are one or more threads waiting (i.e., the semaphore was previously negative), // wake one of the waiting threads } 目前，我们不关心这些例程的实施，这显然需要一些小心；当多个线程调用 sem_wait() 和 sem_post() 时，显然需要管理这些临界区。我们现在将重点讨论如何使用这些原语；稍后我们可能会讨论它们是如何构建的。 我们应该在这里讨论接口的几个重要方面。 首先，我们可以看到 sem_wait() 要么立即返回（因为当我们调用 sem_wait() 时信号量的值为 1 或更高），要么导致调用者暂停执行以等待后续的操作。当然，多个调用线程可能会调用 sem_wait()，因此所有线程都会排队等待被唤醒。 其次，我们可以看到 sem_post() 不会像 sem_wait() 那样等待某些特定条件成立。相反，它只是增加信号量的值，然后，如果有一个线程等待被唤醒，则唤醒其中一个线程。 第三，信号量的值，当为负时，等于等待线程的数量。虽然信号量的用户一般看不到这个值，但这个不变量还是值得了解的，也许它能帮助你记住信号量的功能。 （暂时）不用担心信号量内可能出现的竞争条件；假设它们所做的操作是原子执行的。我们很快就会使用锁和条件变量来做到这一点。 ","date":"2024-05-11","objectID":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/:1:0","tags":["OS"],"title":"信号量","uri":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/"},{"categories":["系统架构"],"content":"2 二进制信号量（锁） 我们现在准备使用信号量。我们的第一个用途将是我们已经熟悉的：使用信号量作为锁。代码片段如下；其中，您会看到我们只是用 sem_wait()/sem post() 包围感兴趣的临界区。然而，使这项工作成功的关键是信号量 m 的初始值（代码中初始化为 X）。 X 应该是什么？ sem_t m; sem_init(\u0026m, 0, X); // Initialize semaphore to X; what should X be? sem_wait(\u0026m); // Critical section here sem_post(\u0026m); 回顾上面 sem_wait() 和 sem_post() 例程的定义，我们可以看到初始值应该是 1。 为了清楚起见，让我们想象有两个线程的场景。第一个线程（线程0）调用sem_wait()；它首先会递减信号量的值，将其更改为 0。然后，仅当该值不大于或等于 0 时才会等待。因为该值为 0，所以 sem_wait() 将简单地返回，并且调用线程将继续，线程 0 现在可以自由进入临界区。如果当线程 0 在临界区内时没有其他线程尝试获取锁，则当它调用 sem_post() 时，它只会将信号量的值恢复为 1（并且不会唤醒正在等待的线程，因为没有） 。下图显示了该场景的踪迹。 当线程 0 “持有锁”（即，它已调用 sem_wait() 但尚未调用 sem_post()），并且另一个线程（线程 1）尝试通过调用 sem_wait 进入临界区时，会出现更有趣的情况。在这种情况下，线程 1 会将信号量的值递减至 $-1$，从而等待（使其自身进入睡眠状态并放弃处理器）。当线程 0 再次运行时，它最终会调用 sem_post()，将信号量的值递增回零，然后唤醒等待线程（线程 1），线程 1 就能够为自己获取锁。当线程 1 完成时，它将再次增加信号量的值，再次将其恢复为 1。 下图显示了此示例的踪迹。除了线程操作外，图中还显示了每个线程的调度器状态：运行、就绪（即可运行但未运行）和休眠。请特别注意，线程 1 在试图获取已持有的锁时进入了睡眠状态；只有当线程 0 再次运行时，线程 1 才能被唤醒并再次运行。 如果你想通过自己的示例来解决这个问题，可以尝试多个线程排队等待锁的场景。在这种跟踪过程中，semaphore 的值会是多少？ 因此，我们可以将 semaphores 用作锁。由于锁只有两种状态（持有和未持有），因此我们有时将用作锁的信号量称为二进制信号量。需要注意的是，如果你只是以这种二进制方式使用一个信号量，那么它的实现方式可能比我们在这里介绍的通用信号量更简单。 ","date":"2024-05-11","objectID":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/:2:0","tags":["OS"],"title":"信号量","uri":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/"},{"categories":["系统架构"],"content":"3 用于排序的信号量 信号量对于对并发程序中的事件进行排序也很有用。例如，线程可能希望等待列表变为非空，以便可以从中删除元素。在这种使用模式中，我们经常发现一个线程等待某件事发生，而另一个线程使某件事发生，然后发出信号表明它已经发生，从而唤醒等待的线程。因此，我们使用信号量作为排序原语（类似于我们之前使用条件变量）。 下面是一个简单的例子。设想一个线程创建了另一个线程，然后想等待它完成执行。 sem_t s; void *child(void *arg) { printf(\"child\\n\"); sem_post(\u0026s); // Signal here: child is done return NULL; } int main(int argc, char *argv[]) { sem_init(\u0026s, 0, X); // What should X be? printf(\"parent: begin\\n\"); pthread_t c; Pthread_create(\u0026c, NULL, child, NULL); sem_wait(\u0026s); // Wait here for child printf(\"parent: end\\n\"); return 0; } 当这个程序运行时，我们希望看到以下内容： parent: begin child parent: end 那么问题来了，如何使用信号量来达到这样的效果？事实证明，答案相对容易理解。正如您在代码中看到的，父线程只需调用 sem_wait() ，则子线程 调用sem_post() ，等待子线程完成执行的条件变为 true。然而，这就提出了一个问题：这个信号量的初始值应该是多少？ 答案当然是信号量的值应该设置为0。有两种情况需要考虑。首先，我们假设父线程创建了子线程，但子线程尚未运行（即，它位于就绪队列中但未运行）。在这种情况下，如下图所示，父线程将子线程调用 sem_post() 之前调用 sem_wait()；我们希望父线程等待子线程运行起来。 发生这种情况的唯一方法是信号量的值不大于 0；因此，0 是初始值。父进程运行，将信号量递减（至 -1），然后等待（睡眠）。当子进程最终运行时，它将调用 sem_post()，将信号量的值增加到 0，并唤醒父进程，然后父进程将从 sem_wait() 返回并完成程序。 第二种情况发生在子线程在父线程有机会调用sem_wait() 之前运行完成时，运行跟踪如下图所示。在这种情况下，子线程将首先调用 sem_post()，从而将信号量的值从 0 增加到 1。当父线程有机会运行时，它将调用 sem_wait() 并发现信号量的值为 1；因此，父线程将递减该值（到 0）并从 sem_wait() 返回，无需等待，也达到了预期的效果。 ","date":"2024-05-11","objectID":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/:3:0","tags":["OS"],"title":"信号量","uri":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/"},{"categories":["系统架构"],"content":"4 生产者/消费者（有界缓冲区）问题 ","date":"2024-05-11","objectID":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/:4:0","tags":["OS"],"title":"信号量","uri":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/"},{"categories":["系统架构"],"content":"4.1 首次尝试 我们解决这个问题的首次尝试引入了两个信号量：empty 和 full，线程将分别使用它们来指示缓冲区条目何时被清空或填满。下面是解决生产者和消费者问题的首次尝试代码。 int buffer[MAX]; int fill = 0; int use = 0; void put(int value) { buffer[fill] = value; // Line F1: Place value in the buffer at the current fill index fill = (fill + 1) % MAX; // Line F2: Move the fill index to the next position in a circular buffer } int get() { int tmp = buffer[use]; // Line G1: Retrieve the value from the buffer at the current use index use = (use + 1) % MAX; // Line G2: Move the use index to the next position in a circular buffer return tmp; // Return the retrieved value } sem_t empty; sem_t full; void *producer(void *arg) { int i; for (i = 0; i \u003c loops; i++) { sem_wait(\u0026empty); // Line P1: Wait for at least one empty buffer slot put(i); // Line P2: Produce an item and place it in the buffer sem_post(\u0026full); // Line P3: Signal that a buffer slot has been filled } } void *consumer(void *arg) { int i, tmp = 0; while (tmp != -1) { sem_wait(\u0026full); // Line C1: Wait for at least one filled buffer slot tmp = get(); // Line C2: Consume an item from the buffer sem_post(\u0026empty); // Line C3: Signal that a buffer slot has been emptied printf(\"%d\\n\", tmp); } } int main(int argc, char *argv[]) { // ... sem_init(\u0026empty, 0, MAX); // MAX buffers are empty to begin with... sem_init(\u0026full, 0, 0); // ... and 0 are full // ... } 在这个示例中，生产者首先等待缓冲区变空，然后将数据放入缓冲区，而消费者同样等待缓冲区被填满，然后才使用缓冲区。让我们先假设 MAX=1（数组中只有一个缓冲区），看看这样是否可行。 再假设有两个线程，一个生产者，一个消费者。让我们看看在单 CPU 上的具体情况。假设消费者先运行。因此，消费者将运行代码中的 C1 行，调用 sem_wait(\u0026full)。由于 full 的初始化值为 0，因此调用将递减 full（至 -1），阻塞消费者，并等待另一个线程按预期在 full 上调用 sem_post()。 假设生产者随后运行。它将运行到 P1 行，从而调用 sem_wait(\u0026empty) 例程。与消费者不同，生产者将继续运行这一行，因为 empty 已被初始化为 MAX 值（在本例中为 1）。因此，empty 将被递减为 0，生产者将把一个数据值放入缓冲区的第一个入口（P2 行）。然后，生产者将继续运行到 P3 行，并调用 sem_post(\u0026full)，将 full 信号量的值从 -1 改为 0，并唤醒消费者（例如，将其从阻塞状态转为就绪状态）。 在这种情况下，可能会发生两种情况。如果生产者继续运行，它将循环并再次运行 P1 行。如果生产者被中断，消费者开始运行，它将调用 sem_wait(\u0026full)（C1 行），发现缓冲区确实已满，从而消耗掉缓冲区。无论哪种情况，我们都实现了所需的行为。 你可以用更多线程（例如多个生产者和多个消费者）来尝试这个例子。它应该仍然有效。 现在让我们假设 MAX 大于 1（比如 MAX = 10）。在这个例子中，我们假设有多个生产者和多个消费者。现在我们遇到了一个问题：竞争条件。仔细看看 put() 和get() 代码。想象一下，两个生产者（$P_a$ 和 $P_b$）同时调用 put()。假设生产者 $P_a$ 首先运行，并开始填充第一个缓冲区条目（F1 行的 fill = 0）。$P_a$ 还没来得及将fill计数器递增到 1，就被中断了。生产者 $P_b$ 开始运行，并在第 F1 行将其数据放入缓冲区的第 0 个元素，这意味着那里的旧数据被覆盖！这是不允许的；我们不希望生产者的任何数据丢失。 ","date":"2024-05-11","objectID":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/:4:1","tags":["OS"],"title":"信号量","uri":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/"},{"categories":["系统架构"],"content":"4.2 一个解决方案：添加互斥 正如你所看到的，我们在这里忘记了互斥。缓冲区的填充和缓冲区索引的递增是一个临界区，因此必须小心保护。因此，让我们使用我们的二进制信号量并添加一些锁，代码如下。 sem_t empty; sem_t full; sem_t mutex; void *producer(void *arg) { int i; for (i = 0; i \u003c loops; i++) { sem_wait(\u0026mutex); // Line P0 (NEW LINE) sem_wait(\u0026empty); // Line P1 put(i); // Line P2 sem_post(\u0026full); // Line P3 sem_post(\u0026mutex); // Line P4 (NEW LINE) } } void *consumer(void *arg) { int i; for (i = 0; i \u003c loops; i++) { sem_wait(\u0026mutex); // Line C0 (NEW LINE) sem_wait(\u0026full); // Line C1 int tmp = get(); // Line C2 sem_post(\u0026empty); // Line C3 sem_post(\u0026mutex); // Line C4 (NEW LINE) printf(\"%d\\n\", tmp); } } int main(int argc, char *argv[]) { // ... sem_init(\u0026empty, 0, MAX); // MAX buffers are empty to begin with... sem_init(\u0026full, 0, 0); // ... and 0 are full sem_init(\u0026mutex, 0, 1); // mutex=1 because it is a lock (NEW LINE) // ... } ","date":"2024-05-11","objectID":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/:4:2","tags":["OS"],"title":"信号量","uri":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/"},{"categories":["系统架构"],"content":"4.3 避免死锁 现在，我们在代码的整个 put()/get() 部分添加了一些锁，如 NEW LINE 注释所示。这似乎是个正确的想法，但却行不通。为什么？死锁。为什么会出现死锁？想象一下两个线程，一个生产者，一个消费者。消费者先运行。它获取了mutex（C0 行），然后在full信号量上调用 sem_wait()（C1 行）；由于还没有数据，这个调用会导致消费者阻塞，从而占用 CPU；但重要的是，消费者仍然持有锁。 然后生产者运行。如果它能运行，就能唤醒消费者线程，一切都会好起来。不幸的是，它做的第一件事就是调用二进制 mutex信号量（P0 行）上的 sem_wait()。该锁已被锁定。因此，生产者现在也只能等待。 这里有一个简单的循环。消费者持有mutex，正在等待某人发出full的信号。生产者可以发出full的信号，但也在等待mutex。因此，生产者和消费者都在互相等待：这就是典型的死锁。 ","date":"2024-05-11","objectID":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/:4:3","tags":["OS"],"title":"信号量","uri":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/"},{"categories":["系统架构"],"content":"4.4 可行的解决方案 要解决这个问题，我们只需缩小锁的范围。下面代码显示了正确的解决方案。 sem_t empty; sem_t full; sem_t mutex; void *producer(void *arg) { int i; for (i = 0; i \u003c loops; i++) { sem_wait(\u0026empty); // Line P1 sem_wait(\u0026mutex); // Line P1.5 (MOVED MUTEX HERE...) put(i); // Line P2 sem_post(\u0026mutex); // Line P2.5 (... AND HERE) sem_post(\u0026full); // Line P3 } } void *consumer(void *arg) { int i; for (i = 0; i \u003c loops; i++) { sem_wait(\u0026full); // Line C1 sem_wait(\u0026mutex); // Line C1.5 (MOVED MUTEX HERE...) int tmp = get(); // Line C2 sem_post(\u0026mutex); // Line C2.5 (... AND HERE) sem_post(\u0026empty); // Line C3 printf(\"%d\\n\", tmp); } } int main(int argc, char *argv[]) { // ... sem_init(\u0026empty, 0, MAX); // MAX buffers are empty to begin with... sem_init(\u0026full, 0, 0); // ... and 0 are full sem_init(\u0026mutex, 0, 1); // mutex=1 because it is a lock // ... } 正如你所看到的，我们只需将mutex获取和释放移到临界区附近；而full等待empty空等待以及信号代码则留在外部。这就是一个简单而有效的有界缓冲区，是多线程程序中常用的模式。 ","date":"2024-05-11","objectID":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/:4:4","tags":["OS"],"title":"信号量","uri":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/"},{"categories":["系统架构"],"content":"5 读者—写者锁 另一个经典问题源于人们对更灵活的锁定原语的渴望，即不同的数据结构访问可能需要不同类型的锁定。举例来说，假设有许多并发的列表操作，包括插入和简单的查找。插入操作会改变 list 的状态（因此传统的临界区是合理的），而查找操作只是读取数据结构；只要我们能保证没有插入操作正在进行，我们就能允许许多查找操作并发进行。我们现在要开发的支持这种操作的特殊类型锁被称为读写锁。这种锁的代码如下所示： typedef struct _rwlock_t { sem_t lock; // binary semaphore (basic lock) sem_t writelock; // used to allow ONE writer or MANY readers int readers; // count of readers reading in critical section } rwlock_t; void rwlock_init(rwlock_t *rw) { rw-\u003ereaders = 0; sem_init(\u0026rw-\u003elock, 0, 1); // Initialize lock semaphore with value 1 sem_init(\u0026rw-\u003ewritelock, 0, 1); // Initialize writelock semaphore with value 1 } void rwlock_acquire_readlock(rwlock_t *rw) { sem_wait(\u0026rw-\u003elock); // Lock the critical section rw-\u003ereaders++; // Increment the number of readers if (rw-\u003ereaders == 1) sem_wait(\u0026rw-\u003ewritelock); // First reader acquires writelock, preventing writers sem_post(\u0026rw-\u003elock); // Unlock the critical section } void rwlock_release_readlock(rwlock_t *rw) { sem_wait(\u0026rw-\u003elock); // Lock the critical section rw-\u003ereaders--; // Decrement the number of readers if (rw-\u003ereaders == 0) sem_post(\u0026rw-\u003ewritelock); // Last reader releases writelock, allowing writers sem_post(\u0026rw-\u003elock); // Unlock the critical section } void rwlock_acquire_writelock(rwlock_t *rw) { sem_wait(\u0026rw-\u003ewritelock); // Acquire writelock, preventing other readers and writers } void rwlock_release_writelock(rwlock_t *rw) { sem_post(\u0026rw-\u003ewritelock); // Release writelock, allowing other readers and writers } 代码非常简单。如果某个线程想要更新相关数据结构，它应该调用一对新的同步操作：rwlock_acquire_writelock()（获取写锁）和 rwlock_release_ writelock()（释放写锁）。在内部，这些操作只是使用writelock信号量来确保只有单个写者可以获取锁，从而进入临界区更新相关数据结构。 更有趣的是一对获取和释放读锁的例程。在获取读取锁时，读者首先获取锁，然后递增 readers 变量，以跟踪当前数据结构中有多少个读者。当第一个读者获得锁时，rwlock_acquire_readlock() 中的重要步骤就开始了；在这种情况下，读者也会通过调用writelock信号量上的 sem_wait() 来获得写锁，然后通过调用 sem_post() 来释放锁。 因此，一旦一个读者获得了读锁，就会允许更多读者也获得读锁；但是，任何希望获得写锁的线程都必须等到所有读者都读完；最后一个退出临界区的线程会调用 writelock 信号量上的sem_post()，从而让等待的写者获得写锁。 这种方法有效（如预期），但也有一些负面影响，特别是在公平性方面。特别是，读者饿死写者是相对容易的。对于这个问题存在更复杂的解决方案；也许你能想到更好的实现？提示：考虑一下一旦写者正在等待，您需要做什么来防止更多的读取者进入锁。 读者饿死写者的问题可以通过修改读者和写者的优先级策略来解决。具体思路如下： 增加写者优先策略：让写者优先于读者获取锁，这样当有写者等待时，新到来的读者需要等待写者完成后才能进入临界区。 写者优先锁设计：引入一个额外的变量或信号量来表示写者是否在等待，如果有写者等待，读者需要等待写者完成后才能获取锁。 最后，应该注意的是，应该谨慎使用读写锁。它们通常会增加更多的开销（特别是对于更复杂的实现），因此与仅使用简单且快速的锁定原语相比，最终不会提高性能。不管怎样，它们再次展示了我们如何以有趣且有用的方式使用信号量。 TIP：简单而愚蠢的方法可能更好（希尔定律） 你永远不应该低估这样一种观念：简单而愚蠢的方法可能是最好的方法。对于锁定，有时简单的自旋锁效果最好，因为它易于实现且速度快。虽然读/写锁之类的东西听起来很酷，但它们很复杂，而复杂可能意味着缓慢。因此，总是先尝试简单而愚蠢的方法。这种追求简单的想法在很多地方都可以找到。早期的一个来源是 Mark Hill 的论文，该论文研究了如何为 CPU 设计缓存。 Hill 发现简单的直接映射缓存比花哨的集合关联设计效果更好（原因之一是在缓存中，更简单的设计可以实现更快的查找）。正如希尔简洁地总结他的工作：“大而笨更好。”因此，我们将类似的建议称为希尔定律。 ","date":"2024-05-11","objectID":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/:5:0","tags":["OS"],"title":"信号量","uri":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/"},{"categories":["系统架构"],"content":"6 哲学家就餐问题 ","date":"2024-05-11","objectID":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/:6:0","tags":["OS"],"title":"信号量","uri":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/"},{"categories":["系统架构"],"content":"6.1 基本介绍 Dijkstra 提出并解决的一个最著名的并发问题被称为 “哲学家就餐问题”。这个问题之所以有名，是因为它很有趣，在智力上也有点意思；然而，它的实际效用却很低。 问题的基本设置是这样的，如下图所示：假设有五位 “哲学家 “围坐在一张桌子旁。每对 “哲学家 “之间有一把叉子（因此一共有五把叉子）。哲学家们有思考的时候，不需要叉子，也有吃饭的时候。为了吃饭，哲学家需要两把叉子，左边的和右边的。对这些叉子的争夺以及随之而来的同步问题，正是我们在并发编程中要研究的问题。 这是每个哲学家的基本循环： while (1) { think(); getforks(); eat(); putforks(); } 那么，关键的挑战是编写例程 getforks() 和 putforks()，这样就不会出现死锁，不会有哲学家挨饿而永远吃不到东西，并且并发性很高（即，许多哲学家可以同时吃饭）尽可能）。 我们将使用一些辅助函数来找到解决方案，如下： int left(int p) { return p; } int right(int p) { return (p + 1) % 5; } 当哲学家 $p$ 希望引用他们左边的叉子时，他们只需调用 left(p)。类似地，通过调用 right(p) 来引用哲学家 $p$ 右边的叉子；其中的模运算符处理最后一个哲学家 ($p=4$) 试图抓住他们右边的叉子（叉子 0）的情况。 我们还需要一些信号量来解决这个问题。假设我们有五个，每个叉子一个：sem_t forks[5]。 ","date":"2024-05-11","objectID":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/:6:1","tags":["OS"],"title":"信号量","uri":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/"},{"categories":["系统架构"],"content":"6.2 残缺的解决方案 我们尝试第一个解决方案。假设我们将每个信号量（在 forks 数组中）初始化为值 1。还假设每个哲学家都知道自己的数字 (p)。因此，我们可以编写 getforks() 和 putforks() 例程，代码如下所示。 void getforks() { sem_wait(forks[left(p)]); sem_wait(forks[right(p)]); } void putforks() { sem_post(forks[left(p)]); sem_post(forks[right(p)]); } 这个（残缺的）解决方案背后的直觉如下。为了获得叉子，我们只需抓住每个叉子上的“锁”：首先是左边的，然后是右边的。当我们吃完后，我们就释放它们。很简单，不是吗？不幸的是，在这种情况下，简单就意味着破碎。 如果每个哲学家碰巧在任何哲学家抓住右边的叉子之前抓住了他们左边的叉子，那么每个哲学家都会永远拿着一把叉子并等待另一把叉子。具体来说，哲学家0抓叉子0，哲学家1抓叉子1，哲学家2抓叉子2，哲学家3抓叉子3，哲学家4抓叉子4；所有的叉子都已获得，所有的哲学家都在等待另一位哲学家拥有的叉子。我们很快就会更详细地研究死锁；目前，可以肯定地说这不是一个有效的解决方案。 ","date":"2024-05-11","objectID":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/:6:2","tags":["OS"],"title":"信号量","uri":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/"},{"categories":["系统架构"],"content":"6.3 解决方案：打破依赖 要解决这个问题，最简单的方法就是改变至少一位哲学家获取分叉的方式；事实上，Dijkstra 本人就是这样解决这个问题的。具体来说，假设哲学家 4（编号最高者）以不同的顺序获取分叉。代码如下： void getforks() { if (p == 4) { sem_wait(forks[right(p)]); sem_wait(forks[left(p)]); } else { sem_wait(forks[left(p)]); sem_wait(forks[right(p)]); } } 由于最后一位哲学家会先抓右边，然后再抓左边，因此不会出现每位哲学家都抓到一个叉子，却只能等待另一个叉子的情况；等待的循环被打破了。 像这样的 “著名 “问题还有很多，比如抽烟者问题或睡觉的理发师问题。它们中的大多数只是思考并发问题的借口；其中有些问题的名字很吸引人。如果你有兴趣了解更多，或者只是想多练习并发思维，可以去查查这些问题。 ","date":"2024-05-11","objectID":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/:6:3","tags":["OS"],"title":"信号量","uri":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/"},{"categories":["系统架构"],"content":"7 如何实现信号量 最后，让我们使用低级同步原语、锁和条件变量来构建我们自己的信号量版本，称为Zemaphores。这个任务相当简单，代码如下所示。 typedef struct __Zem_t { int value; // Value of the semaphore pthread_cond_t cond; // Condition variable for signaling pthread_mutex_t lock; // Mutex for protecting shared data } Zem_t; // Initializes the semaphore with the specified initial value void Zem_init(Zem_t *s, int value) { s-\u003evalue = value; // Set initial value Cond_init(\u0026s-\u003econd); // Initialize condition variable Mutex_init(\u0026s-\u003elock); // Initialize mutex } // Decrements the value of the semaphore (waits if the value is zero) void Zem_wait(Zem_t *s) { Mutex_lock(\u0026s-\u003elock); // Lock the mutex while (s-\u003evalue \u003c= 0) { // Wait while value is less than or equal to 0 Cond_wait(\u0026s-\u003econd, \u0026s-\u003elock); // Wait on the condition variable } s-\u003evalue--; // Decrement the value Mutex_unlock(\u0026s-\u003elock); // Unlock the mutex } // Increments the value of the semaphore and signals waiting threads void Zem_post(Zem_t *s) { Mutex_lock(\u0026s-\u003elock); // Lock the mutex s-\u003evalue++; // Increment the value Cond_signal(\u0026s-\u003econd); // Signal waiting threads Mutex_unlock(\u0026s-\u003elock); // Unlock the mutex } 从代码中可以看出，我们只使用了一把锁和一个条件变量，再加上一个状态变量来跟踪信号量的值。 Zem_t结构体定义了一个信号量，其中包含了一个整数值 value 用于表示信号量的状态，一个条件变量 cond 用于线程间的同步通信，以及一个互斥锁 lock 用于保护共享数据。 Zem_init 函数用于初始化信号量，将初始值赋给 value，并分别初始化条件变量和互斥锁。 Zem_wait 函数用于等待信号量，首先获取互斥锁，然后在一个循环中检查 value 是否小于等于 0，如果是则等待条件变量，直到被唤醒后再次检查。一旦 value 大于 0，就将其减一并释放互斥锁。 Zem_post 函数用于释放信号量，首先获取互斥锁，然后将 value 加一，以及唤醒等待在条件变量上的线程，最后释放互斥锁。 我们的 Zemaphore 和 Dijkstra 定义的纯信号量之间的一个细微差别是，我们不保持信号量的值（当为负时）反映等待线程的数量这一不变式；事实上，该值永远不会低于零。此行为更容易实现并且与当前的 Linux 实现相匹配。 TIP：小心泛化 因此，泛化的抽象技术在系统设计中非常有用，其中一个好的想法可以变得稍微更广泛，从而解决更大类别的问题。然而，泛化时要小心；正如Lampson警告我们的那样，“不要泛化；泛化通常是错误的”。 人们可以将信号量视为锁和条件变量的泛化；然而，是否需要这样的泛化？而且，考虑到在信号量之上实现条件变量的困难，也许这种泛化并不像您想象的那么普遍。 ","date":"2024-05-11","objectID":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/:7:0","tags":["OS"],"title":"信号量","uri":"/posts/24.%E4%BF%A1%E5%8F%B7%E9%87%8F/"},{"categories":["系统架构"],"content":"到目前为止，我们已经开发了锁的概念，并了解了如何通过正确的硬件和操作系统支持组合来正确构建锁。不幸的是，锁并不是构建并发程序所需的唯一原语。 特别是，在很多情况下，线程希望在继续执行之前检查条件是否为真。例如，父线程可能希望在继续之前检查子线程是否已完成（这通常称为 join()）；这样的等待应该如何实现呢？我们来看下面这段代码。 #include \u003cstdio.h\u003e #include \"common_threads.h\" void *child(void *arg) { printf(\"child\\n\"); // XXX how to indicate we are done? return NULL; } int main(int argc, char *argv[]) { printf(\"parent: begin\\n\"); pthread_t c; Pthread_create(\u0026c, NULL, child, NULL); // create child // XXX how to wait for child? printf(\"parent: end\\n\"); return 0; } 我们希望在这里看到以下输出： parent: begin child parent: end 我们可以尝试使用共享变量，如下面这段代码所示。此解决方案通常可以工作，但效率非常低，因为父进程会自旋并浪费 CPU 时间。我们在这里想要的是某种方法让父进程进入睡眠状态，直到我们等待的条件（例如，子进程完成执行）实现为止。 #include \u003cstdio.h\u003e #include \"common_threads.h\" volatile int done = 0; void *child(void *arg) { printf(\"child\\n\"); done = 1; return NULL; } int main(int argc, char *argv[]) { printf(\"parent: begin\\n\"); pthread_t c; Pthread_create(\u0026c, NULL, child, NULL); // create child while (done == 0) // spin ; printf(\"parent: end\\n\"); return 0; } 关键：如何等待条件？ 在多线程程序中，线程在继续操作之前等待某些条件变为真通常很有用。这种简单的方法，即只是自旋直到条件成立，效率非常低并且浪费 CPU 周期，并且在某些情况下可能是不正确的。那么，线程应该如何等待条件呢？ ","date":"2024-05-11","objectID":"/posts/23.%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/:0:0","tags":["OS"],"title":"条件变量","uri":"/posts/23.%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"1 定义和例程 为了等待条件成真，线程可以使用所谓的条件变量。条件变量是一个显式队列，当某些执行状态（即某些条件）不符合预期时（通过等待条件），线程可以将自己置于该队列中；当其他线程改变上述状态时，可以唤醒一个（或多个）等待的线程，从而允许它们继续执行（通过向条件发出信号）。这个想法可以追溯到 Dijkstra 使用的 “私有信号”；后来，Hoare 在他关于监控器的工作中将类似的想法命名为 “条件变量”。 要声明这样一个条件变量，只需这样写：pthread_cond_t c;，将 c 声明为条件变量（注意：还需要适当的初始化）。条件变量有两个相关操作：wait() 和 signal()。wait()调用在线程希望进入休眠状态时执行；signal()调用在线程改变了程序中的某些内容，从而希望唤醒在此条件下等待的休眠线程时执行。具体来说，POSIX 调用是这样的： pthread_cond_wait(pthread_cond_t *c, pthread_mutex_t *m); pthread_cond_signal(pthread_cond_t *c); 为简单起见，我们通常将其称为 wait() 和 signal()。关于 wait()调用，有一点你可能会注意到，它也将一个mutex作为参数；它假定在调用 wait() 时这个mutex已被锁定。wait()的职责是释放锁并让调用线程休眠（原子式）；当线程醒来时（在其他线程发出信号后），它必须在返回调用者之前重新获取锁。之所以如此复杂，是因为我们希望在线程试图让自己进入休眠状态时，防止出现某些竞争条件。 让我们来看看join问题的解决方案，以便更好地理解这一点，代码如下所示。 #include \u003cstdio.h\u003e #include \u003cpthread.h\u003e #include \"common_threads.h\" int done = 0; pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER; pthread_cond_t c = PTHREAD_COND_INITIALIZER; void thr_exit() { Pthread_mutex_lock(\u0026m); done = 1; Pthread_cond_signal(\u0026c); // wake up waiting thread Pthread_mutex_unlock(\u0026m); } void *child(void *arg) { printf(\"child\\n\"); thr_exit(); return NULL; } void thr_join() { Pthread_mutex_lock(\u0026m); while (done == 0) Pthread_cond_wait(\u0026c, \u0026m); // unlock m and wait for signal Pthread_mutex_unlock(\u0026m); } int main(int argc, char *argv[]) { printf(\"parent: begin\\n\"); pthread_t p; Pthread_create(\u0026p, NULL, child, NULL); thr_join(); printf(\"parent: end\\n\"); return 0; } 有两种情况需要考虑。第一种情况是父线程创建了子线程，但自己继续运行（假设我们只有一个处理器），因此立即调用 thr_join() 等待子线程完成。在这种情况下，父线程会获取锁，检查子线程是否完成（未完成），然后调用 wait() 使自己进入休眠状态（从而释放锁）。子线程最终将运行，打印信息 “child”，并调用 thr_exit() 来唤醒父线程；该代码只是获取锁、设置状态变量 done，并向父线程发出信号，从而唤醒父线程。最后，父线程将运行（从 wait()返回时锁已被锁定）、解锁并打印最终信息 “parent:end：结束”。 在第二种情况下，子进程在创建后立即运行，将 done 设为 1，调用信号唤醒睡眠线程（但没有，所以直接返回），然后完成。然后父线程运行，调用 thr_join()，发现 done 为 1，于是不再等待，直接返回。 最后一点：你可能会发现父进程在决定是否等待条件时使用了 while 循环而不是 if 语句。虽然从程序逻辑上看，这并非绝对必要，但这始终是个好主意，我们将在下文中看到。 为了确保你理解 thr_exit() 和 thr_join() 代码中每一段代码的重要性，让我们尝试几种不同的实现方法。首先，你可能想知道我们是否需要完成状态变量。如果代码看起来像下面的示例呢？这样行得通吗？ void thr_exit() { Pthread_mutex_lock(\u0026m); Pthread_cond_signal(\u0026c); Pthread_mutex_unlock(\u0026m); } void thr_join() { Pthread_mutex_lock(\u0026m); Pthread_cond_wait(\u0026c, \u0026m); Pthread_mutex_unlock(\u0026m); } 不幸的是，这种方法是有问题的。想象一下，如果子进程立即运行并立即调用thr_exit()；在这种情况下，子进程会发出信号，但条件上没有任何线程处于休眠状态。当父进程运行时，它将简单地调用wait并被卡住；没有任何线程会唤醒它。从这个例子中，你应该意识到状态变量done的重要性；它记录了线程感兴趣的值。睡眠、唤醒和锁定都围绕着它构建。 以下是另一个糟糕的实现方式。在这个例子中，我们假设不需要持有锁来发出信号和等待。可能会出现什么问题？思考一下！ void thr_exit() { done = 1; Pthread_cond_signal(\u0026c); } void thr_join() { if (done == 0) { Pthread_cond_wait(\u0026c); } } 这里的问题是一个微妙的竞争条件。具体来说，如果父线程调用thr_join()，然后检查done的值，它会发现它是0，从而尝试进入睡眠状态。但就在它调用 wait 进入睡眠状态之前，父线程被中断，子线程开始运行。子线程将状态变量 done 更改为 1 并发出信号，但没有线程在等待，因此没有线程被唤醒。当父线程再次运行时，它就永远沉睡了，这是可悲的。 TIP：在发出信号时始终保持锁定 虽然并非在所有情况下都严格要求保持锁定，但在使用条件变量时，在发出信号时保持锁定可能是最简单且最好的方法。上面的示例显示了必须持有锁才能正确的情况；然而，在其他一些情况下，不这样做也可以，但可能是您应该避免的事情。因此，为了简单起见，在调用信号时保持锁定。 本技巧的反面，即在调用 wait 时保持锁定，不仅仅是一个技巧，而是 wait 语义所强制的，因为 wait 总是 假设在调用它时锁定已被持有， 释放当让调用者进入睡眠状态时所说的锁 在返回之前重新获取锁。 因此，这个技巧的概括是正确的：在调用 signal 或 wait 时保持锁定，你将永远处于良好状态。 ","date":"2024-05-11","objectID":"/posts/23.%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/:1:0","tags":["OS"],"title":"条件变量","uri":"/posts/23.%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"2 生产者—消费者（有界缓冲区）问题 ","date":"2024-05-11","objectID":"/posts/23.%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/:2:0","tags":["OS"],"title":"条件变量","uri":"/posts/23.%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"2.1 基本概念 在本章中，我们将面对的下一个同步问题被称为生产者/消费者问题，有时也被称为有界缓冲区问题，它是由 Dijkstra 首次提出的。事实上，正是这个生产者/消费者问题促使 Dijkstra 和他的同事们发明了广义的 semaphore（可用作锁或条件变量）。 设想一个或多个生产者线程和一个或多个消费者线程。生产者生成数据项并将其放入缓冲区；消费者从缓冲区中抓取上述数据项，并以某种方式消费它们。 这种安排在许多实际系统中都会出现。例如，在多线程网络服务器中，生产者将 HTTP 请求放入工作队列（即有界缓冲区）；消费者线程从队列中取出请求并进行处理。 有界缓冲区也用于将一个程序的输出导入另一个程序，例如，grep foo file.txt | wc -l。此示例同时运行两个进程：grep 将 file.txt 中含有 foo 字符串的行写入它认为的标准输出；UNIX shell 将输出重定向到所谓的 UNIX 管道（通过pipe系统调用创建）。管道的另一端连接到 wc 进程的标准输入，该进程只需计算输入流的行数并打印出结果。因此，grep 进程是生产者，wc 进程是消费者，它们之间是一个内核有界缓冲区。 由于有界缓冲区是共享资源，我们当然必须要求同步访问它，以免出现竞争条件。为了更好地理解这个问题，让我们来看看一些实际的代码。我们首先需要一个共享缓冲区，生产者将数据放入缓冲区，消费者从缓冲区中取出数据。为了简单起见，我们只使用一个整数（当然，你也可以想象把一个数据结构的指针放到这个槽中），以及两个内部例程，分别用于向共享缓冲区中放入一个值，以及从缓冲区中取出一个值。代码如下所示： int buffer; int count = 0; // initially, empty void put(int value) { assert(count == 0); count = 1; buffer = value; } int get() { assert(count == 1); count = 0; return buffer; } put() 例程假定缓冲区为空（并通过assert进行检查），然后简单地将一个值放入共享缓冲区，并通过将counter设为 1 来标记缓冲区已满。不用担心这个共享缓冲区只有一个入口；稍后，我们将把它推广到可以容纳多个入口的队列，这将比听起来更有趣。 现在我们需要编写一些例程来知道何时可以访问缓冲区以将数据放入其中或从其中取出数据。其条件应该是显而易见的：仅当 count 为零时（即缓冲区为空时）才将数据放入缓冲区，并且仅当 count 为 1 时（即缓冲区已满时）从缓冲区中获取数据。如果我们编写同步代码，使得生产者将数据放入已满的缓冲区中，或者消费者从空缓冲区中获取数据，那么我们就做错了（在这段代码中，将触发assert）。 这项工作将由两种类型的线程完成，其中一组我们称为生产者线程，另一组我们称为消费者线程。如下所示， 显示了生产者将整数放入共享缓冲区循环次数的代码，以及消费者从共享缓冲区中获取数据（永远）的代码，每次打印从共享缓冲区中拉出的数据项。 void *producer(void *arg) { int i; int loops = (int)arg; for (i = 0; i \u003c loops; i++) { put(i); } } void *consumer(void *arg) { int i; while (1) { int tmp = get(); printf(\"%d\\n\", tmp); } } ","date":"2024-05-11","objectID":"/posts/23.%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/:2:1","tags":["OS"],"title":"条件变量","uri":"/posts/23.%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"2.2 一个残缺的解决方案 现在想象一下，我们只有一个生产者和一个消费者。显然，put() 和 get() 例程都有临界区，因为 put() 会更新缓冲区，而 get() 会从缓冲区读取数据。然而，在代码周围加锁是行不通的；我们需要更多的东西。毫不奇怪，我们需要的是一些条件变量。如下代码所示：在这个（残缺的）首次尝试中，我们只有一个条件变量 cond 和相关的锁mutex。 int loops; // must initialize somewhere... cond_t cond; mutex_t mutex; void *producer(void *arg) { int i; for (i = 0; i \u003c loops; i++) { Pthread_mutex_lock(\u0026mutex); // p1 if (count == 1) // p2 Pthread_cond_wait(\u0026cond, \u0026mutex); // p3 put(i); // p4 Pthread_cond_signal(\u0026cond); // p5 Pthread_mutex_unlock(\u0026mutex); // p6 } } void *consumer(void *arg) { int i; for (i = 0; i \u003c loops; i++) { Pthread_mutex_lock(\u0026mutex); // c1 if (count == 0) // c2 Pthread_cond_wait(\u0026cond, \u0026mutex); // c3 int tmp = get(); // c4 Pthread_cond_signal(\u0026cond); // c5 Pthread_mutex_unlock(\u0026mutex); // c6 printf(\"%d\\n\", tmp); } } 让我们来看看生产者和消费者之间的信号逻辑。当生产者想要填满缓冲区时，它会等待缓冲区为空（p1-p3）。消费者的逻辑完全相同，但等待的条件不同：缓冲区满（c1-c3）。如果只有一个生产者和一个消费者，上面代码就能正常工作。但是，如果我们有多个线程（例如两个消费者），解决方案就会出现两个关键问题。它们是什么？ 让我们来了解第一个问题，它与等待之前的 if 语句有关。假设有两个消费者（$T_{c_1}$ 和 $T_{c_2}$）和一个生产者（$T_p$）。首先，运行消费者 ($T_{c_1}$)；它获取锁 (c1)，检查是否有缓冲区可供使用 (c2)，如果没有，则等待 (c3)（释放锁）。 然后运行生产者 ($T_p$)。它获取锁 (p1)，检查所有缓冲区是否已满 (p2)，如果没有，则继续填充缓冲区 (p4)。然后，生产者发出缓冲区已填满的信号（p5）。重要的是，这将第一个消费者（$T_{c_1}$ ）从条件变量的休眠状态移到就绪队列；$T_{c_1}$ 现在可以运行（但尚未运行）。然后，生产者继续运行，直到发现缓冲区已满，这时它才进入休眠状态（p6, p1-p3）。 问题就出现在这里：另一个消费者（$T_{c_2}$ ）悄悄进入并消耗了缓冲区中的一个现有值（c1、c2、c4、c5、c6，由于缓冲区已满，跳过了 c3 处的wait）。现在假设 $T_{c_1}$运行，在从等待返回之前，它会重新获取锁，然后返回。然后它调用 get() (c4)，但没有缓冲区要使用！断言触发了，代码没有按预期运行。显然，我们应该以某种方式阻止 $T_{c_1}$ 尝试消耗，因为$T_{c_2}$ 偷偷地进入并消耗了缓冲区中产生的一个值。下图显示了每个线程执行的操作及其随时间变化的调度器状态（就绪、运行或休眠）。 出现问题的原因很简单：在生产者唤醒 $T_{c_1}$ 之后，但在 $T_{c_1}$ 运行之前，有界缓冲区的状态发生了变化（这要归功于 $T_{c_2}$）。向线程发出信号只能唤醒它们，因此它只是提示世界的状态已经发生了变化（在本例中，缓冲区中已经放入了一个值），但并不能保证当被唤醒的线程运行时，状态仍然如愿以偿。对信号含义的这种解释通常被称为 Mesa 语义，这是以首次以这种方式构建条件变量的研究命名的；与之相对的是 Hoare 语义，它更难构建，但能更有力地保证被唤醒的线程在被唤醒后立即运行。几乎所有已构建的系统都采用了 Mesa 语义。 ","date":"2024-05-11","objectID":"/posts/23.%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/:2:2","tags":["OS"],"title":"条件变量","uri":"/posts/23.%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"2.3 更好，但仍然残缺：while，而不是if 幸运的是，解决方法很简单：将 if 改为 while。代码如下所示： int loops; cond_t cond; mutex_t mutex; void *producer(void *arg) { int i; for (i = 0; i \u003c loops; i++) { Pthread_mutex_lock(\u0026mutex); // p1 while (count == 1) // p2 Pthread_cond_wait(\u0026cond, \u0026mutex); // p3 put(i); // p4 Pthread_cond_signal(\u0026cond); // p5 Pthread_mutex_unlock(\u0026mutex); // p6 } } void *consumer(void *arg) { int i; for (i = 0; i \u003c loops; i++) { Pthread_mutex_lock(\u0026mutex); // c1 while (count == 0) // c2 Pthread_cond_wait(\u0026cond, \u0026mutex); // c3 int tmp = get(); // c4 Pthread_cond_signal(\u0026cond); // c5 Pthread_mutex_unlock(\u0026mutex); // c6 printf(\"%d\\n\", tmp); } } 想一想为什么会这样：现在消费者 $T_{c_1}$ 会醒来，并（在锁定的情况下）立即重新检查共享变量 (c2) 的状态。如果此时缓冲区是空的，消费者就会继续休眠 (c3)。在生产者中，if 的推论也被改为 while (p2)。 得益于 Mesa 语义，使用条件变量时要记住一条简单的规则，那就是始终使用 while 循环。有时不必重新检查条件，但这样做总是安全的。 然而，这段代码仍然有一个错误，也就是上面提到的两个问题中的第二个。你能发现吗？它与只有一个条件变量有关。 当两个消费者首先运行（$T_{c_1}$ 和 $T_{c_2}$ ）并都进入睡眠状态（c3）时，问题就出现了。然后，生产者运行，将一个值放入缓冲区，并唤醒其中一个消费者（例如 $T_{c_1}$ ）。然后，生产者返回循环（沿途释放并重新获取锁），并尝试将更多数据放入缓冲区；由于缓冲区已满，生产者转而等待条件（因此进入睡眠）。现在，一个消费者已准备好运行（$T_{c_1}$ ），两个线程正在等待一个条件（$T_{c_2}$ 和 $T_{p}$ ）。 关键问题来了。然后，消费者 $T_{c_1}$ 从 wait() 返回 (c3) 唤醒，重新检查条件 (c2)，发现缓冲区已满，于是消耗值 (c4)。重要的是，这个消费者会根据条件（c5）发出信号，只唤醒一个处于睡眠状态的线程。然而，它应该唤醒哪个线程呢？ 因为消费者清空了缓冲区，显然应该唤醒生产者。但是，如果唤醒消费者 $T_{c_2}$（这是绝对可能的，取决于等待队列的管理方式），我们就会遇到问题。具体来说，消费者 $T_{c_2}$ 会在醒来时发现缓冲区是空的（c2），然后继续休眠（c3）。生产者$T_{p}$ 有一个值要放入缓冲区，但却处于休眠状态。另一个消费者线程 $T_{c_1}$ 也继续休眠。所有三个线程都处于休眠状态，这是一个明显的bug；如下图所示，显示了有关这一可怕灾难的残酷步骤。 信号显然是需要的，但必须更有针对性。消费者不应唤醒其他消费者，只能唤醒生产者，反之亦然。 ","date":"2024-05-11","objectID":"/posts/23.%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/:2:3","tags":["OS"],"title":"条件变量","uri":"/posts/23.%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"2.4 单一缓冲区生产者/消费者解决方案 这里的解决方案又是一个小解决方案：使用两个条件变量而不是一个，以便在系统状态发生变化时正确地发出应该唤醒哪种类型的线程的信号。改进的代码如下所示。 cond_t empty, fill; mutex_t mutex; void *producer(void *arg) { int i; for (i = 0; i \u003c loops; i++) { Pthread_mutex_lock(\u0026mutex); while (count == 1) Pthread_cond_wait(\u0026empty, \u0026mutex); put(i); Pthread_cond_signal(\u0026fill); Pthread_mutex_unlock(\u0026mutex); } } void *consumer(void *arg) { int i; for (i = 0; i \u003c loops; i++) { Pthread_mutex_lock(\u0026mutex); while (count == 0) Pthread_cond_wait(\u0026fill, \u0026mutex); int tmp = get(); Pthread_cond_signal(\u0026empty); Pthread_mutex_unlock(\u0026mutex); printf(\"%d\\n\", tmp); } } 在上面的代码中，生产者线程等待条件为empty，并发出fill信号。相反，消费者线程等待fill并发出empty信号。通过这样做，上面的第二个问题在设计上就得到了避免：消费者永远不会意外唤醒消费者，生产者也永远不会意外唤醒生产者。 ","date":"2024-05-11","objectID":"/posts/23.%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/:2:4","tags":["OS"],"title":"条件变量","uri":"/posts/23.%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"2.5 最终的生产者/消费者解决方案 我们现在有了一个有效的生产者/消费者解决方案，尽管不是一个完全通用的解决方案。我们所做的最后一个改变是实现更高的并发性和效率；具体来说，我们添加更多的缓冲区槽，以便在睡眠前可以生成多个值，同样可以在睡眠前消耗多个值。由于只有一个生产者和消费者，这种方法更加高效，因为它减少了上下文切换；对于多个生产者或消费者（或两者），它甚至允许并发生产或消费，从而增加并发性。幸运的是，这与我们当前的解决方案相比只是一个小小的改变。 要实现这一正确的解决方案，首先要改变的是缓冲区结构本身以及相应的 put() 和 get()，代码如下所示。 #define MAX 10 int buffer[MAX]; int fill_ptr = 0; int use_ptr = 0; int count = 0; mutex_t mutex; cond_t empty, fill; void put(int value) { Pthread_mutex_lock(\u0026mutex); while (count == MAX) Pthread_cond_wait(\u0026empty, \u0026mutex); buffer[fill_ptr] = value; fill_ptr = (fill_ptr + 1) % MAX; count++; Pthread_cond_signal(\u0026fill); Pthread_mutex_unlock(\u0026mutex); } int get() { int tmp; Pthread_mutex_lock(\u0026mutex); while (count == 0) Pthread_cond_wait(\u0026fill, \u0026mutex); tmp = buffer[use_ptr]; use_ptr = (use_ptr + 1) % MAX; count--; Pthread_cond_signal(\u0026empty); Pthread_mutex_unlock(\u0026mutex); return tmp; } 我们还稍微修改了生产者和消费者为确定是否休眠而检查的条件。下面代码显示了正确的等待和信号逻辑。 cond_t empty, fill; mutex_t mutex; void *producer(void *arg) { int i; for (i = 0; i \u003c loops; i++) { Pthread_mutex_lock(\u0026mutex); // p1 while (count == MAX) // p2 Pthread_cond_wait(\u0026empty, \u0026mutex); // p3 put(i); // p4 Pthread_cond_signal(\u0026fill); // p5 Pthread_mutex_unlock(\u0026mutex); // p6 } } void *consumer(void *arg) { int i; for (i = 0; i \u003c loops; i++) { Pthread_mutex_lock(\u0026mutex); // c1 while (count == 0) // c2 Pthread_cond_wait(\u0026fill, \u0026mutex); // c3 int tmp = get(); // c4 Pthread_cond_signal(\u0026empty); // c5 Pthread_mutex_unlock(\u0026mutex); // c6 printf(\"%d\\n\", tmp); } } 生产者只有在所有缓冲区都被填满的情况下才会休眠（p2）；同样，消费者只有在所有缓冲区都被清空的情况下才会休眠（c2）。这样，我们就解决了生产者/消费者的问题。 TIP：对条件使用 WHILE（而非 IF） 在多线程程序中检查条件时，使用 while 循环始终是正确的；而仅使用 if 语句可能是错误的，这取决于信号的语义。因此，始终使用 while 语句，你的代码就会按照预期运行。 在条件检查周围使用 while 循环还能处理发生虚假唤醒的情况。在某些线程包中，由于实现的细节问题，可能会出现两个线程被唤醒的情况，尽管只发生了一个信号。虚假唤醒是重新检查线程正在等待的条件的进一步理由。 ","date":"2024-05-11","objectID":"/posts/23.%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/:2:5","tags":["OS"],"title":"条件变量","uri":"/posts/23.%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"3 覆盖条件 现在我们再来看一个如何使用条件变量的例子。本代码研究摘自 Lampson 和 Redell 关于 Pilot 的论文 ，正是他们首次实现了上文所述的 Mesa 语义（他们使用的语言是 Mesa，因此得名）。 他们遇到的问题最好通过简单的示例来说明，这里的示例是一个简单的多线程内存分配库，代码如下所示。 // how many bytes of the heap are free? int bytesLeft = MAX_HEAP_SIZE; // need lock and condition too cond_t c; mutex_t m; void * allocate(int size) { Pthread_mutex_lock(\u0026m); while (bytesLeft \u003c size) Pthread_cond_wait(\u0026c, \u0026m); void *ptr = ...; // get mem from heap bytesLeft -= size; Pthread_mutex_unlock(\u0026m); return ptr; } void free(void *ptr, int size) { Pthread_mutex_lock(\u0026m); bytesLeft += size; Pthread_cond_signal(\u0026c); // Signal waiting threads Pthread_mutex_unlock(\u0026m); } 正如你在代码中看到的，当线程调用内存分配代码时，可能需要等待更多内存被释放。反之，当线程释放内存时，就会发出更多内存可用的信号。然而，我们上面的代码有一个问题：哪个等待的线程（可能不止一个）应该被唤醒？ 请考虑以下情况。假设空闲字节数为零；线程 $T_a$ 调用 allocate(100)，紧随其后的线程 $T_b$ 调用 allocate(10)，要求获得更少的内存。因此， $T_a$和 $T_b$ 都等待条件并进入休眠；没有足够的空闲字节来满足这两个请求。 这时，假设第三个线程 $T_c$调用 free(50)。不幸的是，当它调用 signal 来唤醒一个等待线程时，可能没有唤醒正确的等待线程 $T_b$，因为 $T_b$ 只等待释放 10 个字节；$T_a$ 应该继续等待，因为还没有足够的空闲内存。因此，上面的代码不起作用，因为唤醒其他线程的线程不知道该唤醒哪个（或哪些）线程。 Lampson 和 Redell 提出的解决方案非常简单：用调用 pthread_cond_broadcast() 代替上面代码中的 pthread_cond_signal()，唤醒所有等待的线程。这样，我们就能保证所有应该被唤醒的线程都被唤醒了。当然，这样做的缺点是可能会对性能产生负面影响，因为我们可能会不必要地唤醒许多其他不应该（尚未）被唤醒的等待线程。这些线程会简单地唤醒，重新检查条件，然后立即回到睡眠状态。 Lampson 和 Redell 将这种条件称为覆盖条件，因为它涵盖了（保守地）需要唤醒线程的所有情况；正如我们已经讨论过的，代价是可能会唤醒过多的线程。精明的读者可能也注意到了，我们本可以在更早的时候使用这种方法（参见只有一个条件变量的生产者/消费者问题）。不过，在这种情况下，我们有一个更好的解决方案，因此我们使用了它。一般来说，如果你发现只有当你将信号改为广播时，你的程序才能运行（但你认为它不需要这样），那么你可能遇到了一个错误；请修复它！但在类似上述内存分配器的情况下，广播可能是最直接的解决方案。 ","date":"2024-05-11","objectID":"/posts/23.%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/:3:0","tags":["OS"],"title":"条件变量","uri":"/posts/23.%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"在讨论锁之前，我们首先描述如何在一些常见的数据结构中使用锁。向数据结构添加锁以使其可由线程使用，从而使该结构成为线程安全的。如何加锁决定了数据结构的正确性和性能。因此，我们面临着关键挑战：当给定一个特定的数据结构时，我们应该如何向它添加锁，以使其正常工作？此外，我们如何添加锁以使数据结构产生高性能，使许多线程能够同时（即并发）访问该结构？ ","date":"2024-05-11","objectID":"/posts/22.%E9%94%81%E5%AE%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:0:0","tags":["OS"],"title":"锁定数据结构","uri":"/posts/22.%E9%94%81%E5%AE%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":["系统架构"],"content":"1 并发计数器 计数器是最简单的数据结构之一。它是一种常用的结构，具有简单的接口。下面代码中中定义了一个简单的非并发计数器。 typedef struct __counter_t { int value; } counter_t; void init(counter_t *c) { c-\u003evalue = 0; } void increment(counter_t *c) { c-\u003evalue++; } void decrement(counter_t *c) { c-\u003evalue--; } int get(counter_t *c) { return c-\u003evalue; } ","date":"2024-05-11","objectID":"/posts/22.%E9%94%81%E5%AE%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:1:0","tags":["OS"],"title":"锁定数据结构","uri":"/posts/22.%E9%94%81%E5%AE%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":["系统架构"],"content":"1.1 简单但不可扩展 正如您所看到的，非并发计数器是一个简单的数据结构，需要少量的代码来实现。现在我们面临下一个挑战：如何使这段代码线程安全？下面这段代码显示了我们如何做到这一点。 typedef struct __counter_t { int value; pthread_mutex_t lock; } counter_t; void init(counter_t *c) { c-\u003evalue = 0; pthread_mutex_init(\u0026c-\u003elock, NULL); } void increment(counter_t *c) { pthread_mutex_lock(\u0026c-\u003elock); c-\u003evalue++; pthread_mutex_unlock(\u0026c-\u003elock); } void decrement(counter_t *c) { pthread_mutex_lock(\u0026c-\u003elock); c-\u003evalue--; pthread_mutex_unlock(\u0026c-\u003elock); } int get(counter_t *c) { pthread_mutex_lock(\u0026c-\u003elock); int rc = c-\u003evalue; pthread_mutex_unlock(\u0026c-\u003elock); return rc; } 这个并发计数器很简单并且工作正常。事实上，它遵循最简单和最基本的并发数据结构常见的设计模式：它只是添加一个锁，该锁在调用操作数据结构的例程时获取，并在从调用返回时释放。通过这种方式，它类似于使用监视器构建的数据结构，当您调用对象方法并从对象方法返回时，会自动获取和释放锁。 至此，你已经有了一个可以运行的并发数据结构。你可能会遇到的问题是性能。如果你的数据结构速度太慢，你需要做的就不仅仅是添加一个锁了；因此，如果需要进行此类优化，这将是本章其余部分的主题。需要注意的是，如果数据结构的运行速度不是太慢，那么你就大功告成了！如果简单的数据结构也能正常工作，那么就没必要做什么花哨的事情了。 为了了解简单方法的性能代价，我们运行了一个基准，其中每个线程更新单个共享计数器的次数是固定的；然后我们改变线程的数量。如下图所示，显示了在一到四个线程活动的情况下所花费的总时间；每个线程更新计数器 100 万次。本实验在配备四颗英特尔 2.7 GHz i5 CPU 的 iMac 上运行；如果激活的 CPU 越多，我们希望单位时间内完成的总工作量就越大。 从图中最上面一行（标注为 “Precise”）可以看出，并发计数器的性能扩展性很差。单个线程可以在极短的时间内（大约 0.03 秒）完成百万次计数器更新，而让两个线程同时更新计数器 100 万次则会导致速度大幅下降（超过 5 秒！）。线程越多，情况越糟糕。 理想情况下，线程在多处理器上完成的速度要和单线程在单处理器上完成的速度一样快。实现这一目标被称为完美扩展；即使要完成更多工作，也是并行完成的，因此完成任务所需的时间不会增加。 ","date":"2024-05-11","objectID":"/posts/22.%E9%94%81%E5%AE%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:1:1","tags":["OS"],"title":"锁定数据结构","uri":"/posts/22.%E9%94%81%E5%AE%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":["系统架构"],"content":"1.2 可扩展计数器 令人惊讶的是，研究人员多年来一直在研究如何构建更具可扩展性的计数器。更令人惊叹的是，可扩展计数器的重要性，正如最近在操作系统性能分析方面的工作所显示的那样；如果没有可扩展计数，在 Linux 上运行的一些工作负载在多核机器上就会出现严重的可扩展性问题。 为了解决这个问题，人们开发了许多技术。我们将介绍一种称为近似计数器的方法 [C06]。 近似计数器的工作原理是通过众多本地物理计数器（每个 CPU 内核一个）和一个全局计数器来表示一个逻辑计数器。具体来说，在一台有四个 CPU 的机器上，有四个本地计数器和一个全局计数器。除了这些计数器外，还有锁：每个本地计数器和全局计数器各有一个锁。 近似计数器的基本思想如下。当运行在给定内核上的线程希望递增计数器时，它会递增其本地计数器；通过相应的本地锁同步访问该本地计数器。由于每个 CPU 都有自己的本地计数器，因此跨 CPU 的线程可以无竞争地更新本地计数器，因此计数器的更新是可扩展的。 不过，为了保持全局计数器的最新状态（以防线程希望读取其值），本地计数器的值会定期转移到全局计数器上，方法是获取全局锁，并根据本地计数器的值递增；然后将本地计数器重置为零。 这种从本地到全局的转移发生频率由阈值 S 确定。S 越小，计数器的行为就越像上述不可扩展的计数器；S 越大，计数器的可扩展性就越强，但全局值可能会偏离实际计数。我们可以简单地获取所有本地锁和全局锁（按指定顺序，以避免死锁）来获得精确值，但这是不可扩展的。 为了说明这一点，我们来看一个例子，如下图所示。 在这个例子中，阈值 S 设置为 5，四个 CPU 上都有线程在更新本地计数器 L1 … L4。全局计数器值 (G) 也显示在跟踪中，随着时间的推移不断向下增加。在每个时间步长，本地计数器都可能递增；如果本地值达到阈值 S，本地值就会转移到全局计数器，然后本地计数器被重置。 在上图中（标注为 “Approximate”）的下线显示了阈值 S 为 1024 的近似计数器的性能。该计数器的性能非常出色；在四个处理器上更新计数器 400 万次所需的时间几乎不超过在一个处理器上更新计数器 100 万次所需的时间。 下图显示了阈值 S 的重要性，四个线程在四个 CPU 上各递增计数器 100 万次。如果 S 值较低，则性能较差（但全局计数总是相当准确）；如果 S 值较高，则性能出色，但全局计数滞后（最多滞后 CPU 数量乘以 S）。近似计数器正是通过这种精度/性能权衡实现的。 近似计数器的粗略版本如下面这段代码所示。 typedef struct __counter_t { int global; // global count pthread_mutex_t glock; // global lock int local[NUMCPUS]; // local count (per cpu) pthread_mutex_t llock[NUMCPUS]; // ... and locks int threshold; // update frequency } counter_t; // init: record threshold, init locks, init values // of all local counts and global count void init(counter_t *c, int threshold) { c-\u003ethreshold = threshold; c-\u003eglobal = 0; pthread_mutex_init(\u0026c-\u003eglock, NULL); int i; for (i = 0; i \u003c NUMCPUS; i++) { c-\u003elocal[i] = 0; pthread_mutex_init(\u0026c-\u003ellock[i], NULL); } } // update: usually, just grab local lock and update local amount // once local count has risen by ’threshold’, grab global // lock and transfer local values to it void update(counter_t *c, int threadID, int amt) { int cpu = threadID % NUMCPUS; pthread_mutex_lock(\u0026c-\u003ellock[cpu]); c-\u003elocal[cpu] += amt; // assumes amt \u003e 0 if (c-\u003elocal[cpu] \u003e= c-\u003ethreshold) { // transfer to global pthread_mutex_lock(\u0026c-\u003eglock); c-\u003eglobal += c-\u003elocal[cpu]; pthread_mutex_unlock(\u0026c-\u003eglock); c-\u003elocal[cpu] = 0; } pthread_mutex_unlock(\u0026c-\u003ellock[cpu]); } // get: just return global amount (which may not be perfect) int get(counter_t *c) { pthread_mutex_lock(\u0026c-\u003eglock); int val = c-\u003eglobal; pthread_mutex_unlock(\u0026c-\u003eglock); return val; // only approximate! } ","date":"2024-05-11","objectID":"/posts/22.%E9%94%81%E5%AE%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:1:2","tags":["OS"],"title":"锁定数据结构","uri":"/posts/22.%E9%94%81%E5%AE%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":["系统架构"],"content":"2 并发链表 ","date":"2024-05-11","objectID":"/posts/22.%E9%94%81%E5%AE%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:2:0","tags":["OS"],"title":"锁定数据结构","uri":"/posts/22.%E9%94%81%E5%AE%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":["系统架构"],"content":"2.1 基本实现 接下来，我们要研究一种更复杂的结构—链表。让我们再次从基本方法开始。为了简单起见，我们将省略这种列表中的一些显而易见的例程，而只关注并发插入；至于查找、删除等，我们将留给读者自己去思考或者可以在仓库中找到更详细的版本。下面显示了这种初级数据结构的代码。 // basic node structure typedef struct __node_t { int key; struct __node_t *next; } node_t; // basic list structure (one used per list) typedef struct __list_t { node_t *head; pthread_mutex_t lock; } list_t; void List_Init(list_t *L) { L-\u003ehead = NULL; pthread_mutex_init(\u0026L-\u003elock, NULL); } int List_Insert(list_t *L, int key, int thread_id) { pthread_mutex_lock(\u0026L-\u003elock); printf(\"Thread %d: Inserting %d\\n\", thread_id, key); node_t *new = malloc(sizeof(node_t)); if (new == NULL) { perror(\"malloc\"); pthread_mutex_unlock(\u0026L-\u003elock); return -1; // fail } new-\u003ekey = key; new-\u003enext = L-\u003ehead; L-\u003ehead = new; pthread_mutex_unlock(\u0026L-\u003elock); return 0; // success } 从代码中可以看出，代码只是在进入插入例程时获取一个锁，并在退出时释放它。如果 malloc() 恰好失败（这种情况很少见），就会出现一个棘手的小问题；在这种情况下，代码还必须在插入失败前释放锁。 事实证明，这种特殊的控制流非常容易出错；最近对 Linux 内核补丁的一项研究发现，很大一部分错误（近 40%）都是在这种很少使用的代码路径上发现的。因此，我们面临着一个挑战：我们能否重写插入和查找例程，使其在并发插入时保持正确，但避免失败路径也需要我们添加unlock调用的情况？ 在这种情况下，答案是肯定的。具体来说，我们可以重构一下List_Insert代码，使锁定和释放只围绕插入代码中的实际临界区，并在删除代码中使用共同的退出路径。前者之所以有效，是因为部分查找代码实际上无需锁定；假设 malloc() 和printf本身是线程安全的，那么每个线程都可以调用它，而不必担心出现竞争条件或其他并发错误。只有在更新共享列表时才需要加锁。有关这些修改的详细信息，请见下面这段代码。 // basic node structure typedef struct __node_t { int key; struct __node_t *next; } node_t; // basic list structure (one used per list) typedef struct __list_t { node_t *head; pthread_mutex_t lock; } list_t; void List_Init(list_t *L) { L-\u003ehead = NULL; pthread_mutex_init(\u0026L-\u003elock, NULL); } int List_Insert(list_t *L, int key, int thread_id) { printf(\"Thread %d: Inserting %d\\n\", thread_id, key); node_t *new = malloc(sizeof(node_t)); if (new == NULL) { perror(\"malloc\"); pthread_mutex_unlock(\u0026L-\u003elock); return -1; // fail } new-\u003ekey = key; pthread_mutex_lock(\u0026L-\u003elock); new-\u003enext = L-\u003ehead; L-\u003ehead = new; pthread_mutex_unlock(\u0026L-\u003elock); return 0; // success } ","date":"2024-05-11","objectID":"/posts/22.%E9%94%81%E5%AE%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:2:1","tags":["OS"],"title":"锁定数据结构","uri":"/posts/22.%E9%94%81%E5%AE%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":["系统架构"],"content":"2.2 扩展链表 虽然我们又有了一个基本的并发链表，但我们又一次遇到了它不能很好扩展的情况。为了在链表中实现更多并发性，研究人员探索了一种技术，即所谓的 “手拉手锁定”（又称 “锁耦合”）。 这个想法非常简单。你可以为链表的每个节点添加一个锁，而不是为整个链表添加一个锁。当遍历列表时，代码会先抓取下一个节点的锁，然后释放当前节点的锁（这就是 hand-over-hand 名称的由来）。 从概念上讲，“交手 “链表是有一定道理的；它可以实现高度并发的操作。然而，在实践中，这种结构很难比简单的单锁方法更快，因为为遍历链表的每个节点获取和释放锁的开销太大。即使是非常大的链表和大量的线程，允许多个正在进行的遍历所带来的并发性也不可能比简单地获取单锁、执行操作和释放锁更快。也许某种混合方式（每隔几个节点就抓取一个新锁）值得研究。 TIP：并发越多不一定越快 如果您设计的方案增加了很多开销（例如，频繁获取和释放锁，而不是一次性），那么它更具并发性可能就不重要了。简单的方案往往效果良好，特别是如果它们很少使用昂贵的例程。增加更多锁和复杂性可能会导致失败。尽管如此，有一种真正需要了解的方法：构建两种替代方案（简单但并发性较低、复杂但并发性较高）并测量它们的表现。最终，您无法在性能上作弊；您的想法要么更快，要么不是。 警惕锁和控制流 一个通用的设计提示，在并发代码以及其他地方都很有用，就是要警惕导致函数返回、退出或其他类似错误条件从而停止函数执行的控制流变化。因为许多函数会首先获取锁、分配一些内存或进行其他类似的有状态操作，当出现错误时，代码必须在返回之前撤销所有状态，这样容易出错。因此，最好结构化代码以最小化这种模式。 ","date":"2024-05-11","objectID":"/posts/22.%E9%94%81%E5%AE%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:2:2","tags":["OS"],"title":"锁定数据结构","uri":"/posts/22.%E9%94%81%E5%AE%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":["系统架构"],"content":"3 并发队列 正如您现在所知，制作并发数据结构总是有一个标准方法：添加一个大锁。对于队列，我们将跳过该方法，假设您可以弄清楚。 相反，我们将看一下由 Michael 和 Scott 设计的并发程度稍高的队列。代码如下所示。 typedef struct __node_t { int value; struct __node_t *next; } node_t; typedef struct __queue_t { node_t *head; node_t *tail; pthread_mutex_t headLock; // Mutex for head pointer pthread_mutex_t tailLock; // Mutex for tail pointer } queue_t; // Initialize the queue void Queue_Init(queue_t *q) { // Allocate memory for a dummy node to represent the head of the queue node_t *tmp = malloc(sizeof(node_t)); tmp-\u003enext = NULL; // Initialize the head and tail pointers to the dummy node q-\u003ehead = q-\u003etail = tmp; // Initialize mutexes for head and tail pointers pthread_mutex_init(\u0026q-\u003eheadLock, NULL); pthread_mutex_init(\u0026q-\u003etailLock, NULL); } // Enqueue an element into the queue void Queue_Enqueue(queue_t *q, int value) { // Allocate memory for the new node node_t *tmp = malloc(sizeof(node_t)); assert(tmp != NULL); tmp-\u003evalue = value; tmp-\u003enext = NULL; // Acquire the tailLock mutex pthread_mutex_lock(\u0026q-\u003etailLock); // Insert the new node after the current tail node q-\u003etail-\u003enext = tmp; // Update the tail pointer to point to the new node q-\u003etail = tmp; // Release the tailLock mutex pthread_mutex_unlock(\u0026q-\u003etailLock); } // Dequeue an element from the queue int Queue_Dequeue(queue_t *q, int *value) { // Acquire the headLock mutex pthread_mutex_lock(\u0026q-\u003eheadLock); // Get the current head node node_t *tmp = q-\u003ehead; // Get the next node after the head node_t *newHead = tmp-\u003enext; // If the queue is empty (newHead is NULL), release the headLock mutex and return -1 if (newHead == NULL) { pthread_mutex_unlock(\u0026q-\u003eheadLock); return -1; // queue was empty } // Extract the value from the node to be dequeued *value = newHead-\u003evalue; // Update the head pointer to point to the next node q-\u003ehead = newHead; // Release the headLock mutex pthread_mutex_unlock(\u0026q-\u003eheadLock); // Free the memory of the dequeued node free(tmp); // Return 0 indicating successful dequeue operation return 0; } 如果你仔细研究这段代码，你会发现有两个锁，一个用于队列的头部，一个用于队列的尾部。这两个锁的目标是实现入队和出队操作的并发。在常见情况下，入队例程将仅访问尾部锁，而出队只会访问头部锁。 Michael 和 Scott 使用的一个技巧是添加一个虚拟节点（在队列初始化代码中分配）；这个虚拟节点可以实现头尾操作的分离。 队列通常用在多线程应用程序中。然而，这里使用的队列类型（仅带有锁）通常不能完全满足此类程序的需求。一个更充分开发的有界队列，使线程能够在队列为空或过满时等待，这是条件变量可以做到的事情。 ","date":"2024-05-11","objectID":"/posts/22.%E9%94%81%E5%AE%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:3:0","tags":["OS"],"title":"锁定数据结构","uri":"/posts/22.%E9%94%81%E5%AE%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":["系统架构"],"content":"4 并发哈希表 最后，我们将讨论一种简单而又广泛适用的并发数据结构—哈希表。我们将重点讨论一个不调整大小的简单哈希表，代码如下所示；处理调整大小需要做更多的工作，我们将其作为一个练习留给读者（抱歉！）。 #define BUCKETS (101) typedef struct __hash_t { list_t lists[BUCKETS]; } hash_t; void Hash_Init(hash_t *H) { int i; for (i = 0; i \u003c BUCKETS; i++) { List_Init(\u0026H-\u003elists[i]); } } int Hash_Insert(hash_t *H, int key, int thread_id) { int bucket = key % BUCKETS; return List_Insert(\u0026H-\u003elists[bucket], key, thread_id); } int Hash_Remove(hash_t *H, int key, int thread_id) { int bucket = key % BUCKETS; return List_Remove(\u0026H-\u003elists[bucket], key, thread_id); } 这个并发哈希表非常简单，使用我们之前开发的并发链表构建，而且运行得非常好。它之所以性能出色，是因为它没有为整个结构设置一个锁，而是为每个哈希桶（每个哈希桶由一个链表表示）设置了一个锁。这样就可以进行许多并发操作。 下图 显示了哈希表在并发更新下的性能（在同一台配备四个 CPU 的 iMac 电脑上，四个线程的并发更新次数从 10,000 次到 50,000 次不等）。为便于比较，图中还显示了链表的性能（使用单锁）。从图中可以看出，这个简单的并发哈希表的扩展能力很强，而链表则不然。 避免过早优化（KNUTH定律） 在构建并发数据结构时，应从最基本的方法开始，即添加一个大锁以提供同步访问。这样做，你就有可能构建一个正确的锁；如果你发现它存在性能问题，你可以对它进行改进，从而在必要时使它变得更快。正如 Knuth 的名言：“过早优化是万恶之源”。 在向多处理器过渡之初，许多操作系统都使用单锁，包括 Sun OS 和 Linux。在后者中，这种锁甚至有一个名字，即大内核锁（BKL）。多年来，这种简单的方法一直很好，但当多 CPU 系统成为常态时，内核中每次只允许一个活动线程就成了性能瓶颈。因此，终于到了为这些系统添加改进并发性优化的时候了。在 Linux 系统中，采用了更直接的方法：用多个锁代替一个锁。而在 Sun 内部，则做出了一个更激进的决定：建立一个全新的操作系统，即 Solaris，从一开始就从根本上融入并发性。 ","date":"2024-05-11","objectID":"/posts/22.%E9%94%81%E5%AE%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:4:0","tags":["OS"],"title":"锁定数据结构","uri":"/posts/22.%E9%94%81%E5%AE%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":["系统架构"],"content":"1 锁：基本思想 举个例子，假设我们的临界区如下所示，共享变量的规范更新： balance = balance + 1; 当然，其他临界区也是可能的，例如向链表添加元素或对共享结构进行其他更复杂的更新，但我们现在只保留这个简单的示例。要使用锁，我们在临界区周围添加一些代码，如下所示： lock_t mutex; // some globally-allocated lock ’mutex’ ... lock(\u0026mutex); balance = balance + 1; unlock(\u0026mutex); 锁只是一个变量，因此要使用它，您必须声明某种类型的锁变量（例如上面的mutex）。该锁变量（或简称“锁”）保存任意时刻锁的状态。它要么可用（或未锁定或空闲），因此没有线程持有该锁，要么已获取（或锁定或持有），因此恰好有一个线程持有该锁，并且可能位于临界区中。我们还可以在数据类型中存储其他信息，例如哪个线程持有锁，或者用于获取锁的顺序队列，但此类信息对锁的用户是隐藏的。 lock() 和unlock() 例程的语义很简单。调用例程 lock() 尝试获取锁；如果没有其他线程持有该锁（即它是空闲的），则该线程将获取该锁并进入临界区；该线程有时被称为锁的所有者。如果另一个线程随后对同一个锁变量（本例中为mutex）调用 lock()，则当锁被另一个线程持有时，它不会返回；这样，当第一个持有锁的线程位于临界区时，其他线程就无法进入临界区。 一旦锁的所有者调用unlock()，锁就再次可用（空闲）。如果没有其他线程正在等待锁（即没有其他线程调用lock() 并被卡在其中），则锁的状态将简单地更改为空闲。如果有等待线程（卡在 lock() 中），其中一个线程将（最终）注意到（或被告知）锁状态的这一变化，获取锁，并进入临界区。 锁为程序员提供了对调度的最小程度的控制。一般来说，我们将线程视为由程序员创建但由操作系统以操作系统选择的任何方式调度的实体。锁将部分控制权交还给程序员；通过在一段代码周围放置一个锁，程序员可以保证该代码中最多只有一个线程处于活动状态。因此，锁有助于将传统操作系统调度的混乱转变为更受控制的活动。 ","date":"2024-05-11","objectID":"/posts/21.%E9%94%81/:1:0","tags":["OS"],"title":"锁","uri":"/posts/21.%E9%94%81/"},{"categories":["系统架构"],"content":"2 Pthread 锁 POSIX 库为锁使用的名称是 mutex，因为它用于提供线程之间的互斥，也就是说，如果一个线程处于临界区，它将禁止其他线程进入，直到它完成该临界区。因此，当你看到下面的 POSIX 线程代码时，你应该明白它在做与上面相同的事情（我们再次使用我们的封装器，在锁定和解锁时检查错误）： pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; Pthread_mutex_lock(\u0026lock); // wrapper; exits on failure balance = balance + 1; Pthread_mutex_unlock(\u0026lock); 你可能还会注意到，POSIX 版本会通过传递一个变量来加锁和解锁，因为我们可能会使用不同的锁来保护不同的变量。这样做可以提高并发性：我们通常会使用不同的锁来保护不同的数据和数据结构，而不是在访问任何临界区时使用一个大锁（粗粒度锁定策略），从而允许更多线程同时进入锁定代码（更细粒度的方法）。 ","date":"2024-05-11","objectID":"/posts/21.%E9%94%81/:2:0","tags":["OS"],"title":"锁","uri":"/posts/21.%E9%94%81/"},{"categories":["系统架构"],"content":"3 评估锁—基本标准 在构建任何锁之前，我们首先应该了解我们的目标是什么，因此我们会问如何评估特定锁实现的有效性。要评估一个锁是否有效（而且效果很好），我们首先应该建立一些如下的基本标准。 首先是锁是否完成了它的基本任务，即提供互斥。基本上，锁是否能阻止多个线程进入临界区？ 其次是公平性。一旦锁被释放，每个争夺锁的线程是否都能公平地获得锁？另一种方法是考察更极端的情况：是否有任何线程在争夺锁的过程中陷入饥饿，从而永远无法获得锁？ 最后一个标准是性能，特别是使用锁所增加的时间开销。这里有几种不同的情况值得考虑。 一种是无竞争的情况；当单线程运行并抓取和释放锁时，这样做的开销是多少？ 另一种情况是多个线程在单个 CPU 上争夺锁；在这种情况下，是否存在性能问题？ 最后，当涉及多个 CPU 且每个 CPU 上的线程都在争夺锁时，锁的性能如何？ 通过比较这些不同的情况，我们可以更好地了解使用各种锁技术对性能的影响。 ","date":"2024-05-11","objectID":"/posts/21.%E9%94%81/:3:0","tags":["OS"],"title":"锁","uri":"/posts/21.%E9%94%81/"},{"categories":["系统架构"],"content":"4 控制中断 最早用于提供互斥的解决方案之一是禁用临界区的中断；这种解决方案是为单处理器系统发明的。代码如下 void lock() { DisableInterrupts(); } void unlock() { EnableInterrupts(); } 假设我们正在这样的单处理器系统上运行。通过在进入临界区之前关闭中断（使用某种特殊的硬件指令），我们可以确保临界区内的代码不会被中断，从而像原子一样执行。当我们完成后，我们重新启用中断（再次通过硬件指令），因此程序照常进行。 这种方法的主要优点是它的简单性。当然，您不必绞尽脑汁就能弄清楚为什么会这样。在没有中断的情况下，线程可以确保它执行的代码将会执行，并且没有其他线程会干扰它。 不幸的是，负面因素有很多。首先，这种方法要求我们允许任何调用线程执行特权操作（打开和关闭中断），因此相信该设施不会被滥用。正如您所知，每当我们需要信任任意程序时，我们都可能遇到麻烦。在这里，问题以多种方式表现出来：贪婪的程序可以在执行开始时调用lock()，从而独占处理器；更糟糕的是，错误或恶意程序可能调用 lock() 并进入无限循环。在后一种情况下，操作系统永远不会重新获得对系统的控制，只有一个办法：重新启动系统。使用中断禁用作为通用同步解决方案需要对应用程序过多的信任。 其次，该方法不适用于多处理器。如果多个线程运行在不同的CPU上，并且每个线程都尝试进入同一个临界区，那么是否禁用中断并不重要；线程将能够在其他处理器上运行，因此可以进入临界区。由于多处理器现在很常见，我们的通用解决方案必须比这做得更好。 第三，长时间关闭中断可能会导致中断丢失，从而导致严重的系统问题。例如，想象一下，如果 CPU 错过了磁盘设备已完成读取请求的事实。操作系统如何知道唤醒等待所述读取的进程？ 最后，也许也是最不重要的一点是，这种方法可能效率低下。与正常指令执行相比，现代 CPU 执行屏蔽或取消屏蔽中断的代码往往执行速度较慢。 由于这些原因，关闭中断仅在有限的上下文中用作互斥原语。例如，在某些情况下，操作系统本身将使用中断屏蔽来保证访问其自己的数据结构时的原子性，或者至少防止出现某些混乱的中断处理情况。这种用法是有道理的，因为信任问题在操作系统内部消失了，操作系统始终相信自己能够执行特权操作。 ","date":"2024-05-11","objectID":"/posts/21.%E9%94%81/:4:0","tags":["OS"],"title":"锁","uri":"/posts/21.%E9%94%81/"},{"categories":["系统架构"],"content":"5 失败的尝试：仅使用加载/存储 要想超越基于中断的技术，我们就必须依靠 CPU 硬件及其提供的指令来构建适当的锁。让我们首先尝试使用一个标志变量来构建一个简单的锁。在这次失败的尝试中，我们将看到构建锁所需的一些基本思想，并明白为什么仅仅使用单个变量并通过正常的加载和存储来访问它是不够的。 第一次尝试的代码如下： typedef struct __lock_t { int flag; } lock_t; void init(lock_t *mutex) { // 0 -\u003e lock is available, 1 -\u003e held mutex-\u003eflag = 0; } void lock(lock_t *mutex) { while (mutex-\u003eflag == 1) // TEST the flag ; // spin-wait (do nothing) mutex-\u003eflag = 1; // now SET it! } void unlock(lock_t *mutex) { mutex-\u003eflag = 0; } 在第一次尝试中，我们的想法非常简单：使用一个简单的变量（flag）来指示某个线程是否拥有锁。进入临界区的第一个线程将调用 lock()，它将测试flag是否等于 1（在本例中不等于 1），然后将flag设置为 1，表示该线程现在持有锁。完成临界区后，线程会调用 unlock() 并清除flag，从而表明不再持有锁。 如果另一个线程在第一个线程处于临界区时调用了 lock()，那么它只需在 while 循环中自旋等待该线程调用 unlock()并清除flag。一旦第一个线程这样做了，等待的线程就会退出 while 循环，将自己的flag设置为 1，然后进入临界区。 不幸的是，该代码有两个问题：一个是正确性，另一个是性能。一旦您习惯于思考并发编程，正确性问题就很容易看出。想象一下下面的的代码交错；假设 flag=0 开始。 正如您从这种交错中看到的，通过及时（不及时？）中断，我们可以很容易地产生这样一种情况：两个线程都将flag设置为 1，因此两个线程都能进入临界区。我们显然没有满足最基本的要求**：提供互斥**。 我们稍后将详细讨论的性能问题是线程等待获取已持有的锁的方式：它无休止地检查flag的值，这是一种称为自旋等待的技术。自旋等待会浪费时间等待另一个线程释放锁。在单处理器上浪费非常高，其中等待者正在等待的线程甚至无法运行（至少在发生上下文切换之前）！ ","date":"2024-05-11","objectID":"/posts/21.%E9%94%81/:5:0","tags":["OS"],"title":"锁","uri":"/posts/21.%E9%94%81/"},{"categories":["系统架构"],"content":"6 用Test-And-Set构建工作自旋锁 由于禁用中断在多处理器上不起作用，而且使用加载和存储（如上所示）的简单方法也不起作用，系统设计人员开始发明硬件支持锁定。最早的多处理器系统，如 20 世纪 60 年代初的 Burroughs B5000，就提供了这种支持；如今，所有系统都提供了这种支持，即使是单 CPU 系统也不例外。 最简单易懂的硬件支持被称为test-and-set（或原子交换）指令。我们通过下面的 C 代码片段来定义 test-and-set 指令的作用： int TestAndSet(int *old_ptr, int new) { int old = *old_ptr; // fetch old value at old_ptr *old_ptr = new; // store ’new’ into old_ptr return old; // return the old value } test-and-set指令的作用如下。它返回 ptr 指向的old，同时将所述值更新为new。当然，关键在于这一系列操作都是以原子方式执行的。之所以称为 “test-and-set”，是因为它可以 “test “旧值（即返回值），同时将内存位置 “设置 “为新值；事实证明，这条功能稍强的指令足以构建一个简单的自旋锁，如下面这段代码所示。 typedef struct __lock_t { int flag; } lock_t; void init(lock_t *lock) { // 0: lock is available, 1: lock is held lock-\u003eflag = 0; } void lock(lock_t *lock) { while (TestAndSet(\u0026lock-\u003eflag, 1) == 1) ; // spin-wait (do nothing) } void unlock(lock_t *lock) { lock-\u003eflag = 0; } 让我们先了解一下这种锁的工作原理。首先设想这样一种情况：线程调用 lock() 而当前没有其他线程持有锁；因此，flag 应为 0。当线程调用 TestAndSet(flag, 1) 时，例程将返回 flag 的旧值，即 0；因此，正在测试 flag 值的调用线程不会陷入 while 循环的自旋，并将获得锁。线程也会原子地将该值设置为 1，从而表明锁已被锁定。当线程完成其临界区后，会调用 unlock() 将flag置回 0。 我们可以想象的第二种情况是，一个线程已经持有锁（即flag为 1）。在这种情况下，该线程将调用 lock() 并调用 TestAndSet(flag,1)。这一次，TestAndSet() 将返回 flag 的旧值，即 1（因为锁已被持有），同时再次将其设置为 1。只要锁被另一个线程持有，TestAndSet() 就会反复返回 1，因此这个线程会自旋，直到锁最终被释放。当flag最终被其他线程设置为 0 时，该线程将再次调用 TestAndSet()，此时它将返回 0，同时原子地将该值设置为 1，从而获得锁并进入临界区。 通过将test（旧锁值）和 set（新锁值）作为单个原子操作，我们可以确保只有一个线程获得锁。这就是构建互斥原语的方法！ 现在你可能也明白为什么这种锁通常被称为自旋锁了。它是最简单的一种锁，只需使用 CPU 周期旋 转，直到锁可用为止。要在单处理器上正常工作，它需要一个抢占式调度程序（即通过定时器中断线程，以便不时运行不同的线程）。如果没有抢占式调度，自旋锁在单 CPU 上的意义就不大，因为在 CPU 上旋转的线程永远不会放弃自旋锁。 ","date":"2024-05-11","objectID":"/posts/21.%E9%94%81/:6:0","tags":["OS"],"title":"锁","uri":"/posts/21.%E9%94%81/"},{"categories":["系统架构"],"content":"7 评估自旋锁 有了基本的自旋锁，我们现在就可以根据之前描述的标准来评估它的有效性。锁最重要的方面是正确性：它能提供互斥吗？答案是肯定的：自旋锁每次只允许一个线程进入临界区。因此，我们拥有一个正确的锁。 下一个标准是公平性。自旋锁对等待线程的公平性如何？你能保证等待线程永远不会进入临界区吗？不幸的是，自旋锁不提供任何公平性保证。事实上，一个正在自旋的线程可能会在竞争中永远自旋下去。简单的自旋锁（如前面所讨论的）是不公平的，可能会导致饥饿。 最后一个标准是性能。使用自旋锁的代价是什么？为了更仔细地分析这个问题，我们建议考虑几种不同的情况。 第一种情况是线程在单个处理器上竞争锁； 对于自旋锁，在单 CPU 的情况下，性能开销可能会相当大；想象一下持有锁的线程在临界区被抢占的情况。然后，调度程序可能会运行每个其他线程（假设有 N - 1 个其他线程），每个线程都试图获取锁。在这种情况下，每个线程在放弃 CPU 之前都会持续运行一个时间片，浪费了 CPU 周期。 第二种情况是线程分布在多个 CPU 上。 然而，在多个 CPU 上，自旋锁工作得相当好（如果线程数大致等于 CPU 数）。思路如下：想象 CPU 1 上的线程 A 和 CPU 2 上的线程 B，两者都竞争锁。如果线程 A (CPU 1) 获取锁，然后线程 B 尝试获取锁，则 B 将自旋（在 CPU 2 上）。然而，大概临界区很短，因此锁很快就变得可用，并被线程 B 获取。在这种情况下，自旋等待另一个处理器上持有的锁不会浪费很多周期，因此可能是有效的。 ","date":"2024-05-11","objectID":"/posts/21.%E9%94%81/:7:0","tags":["OS"],"title":"锁","uri":"/posts/21.%E9%94%81/"},{"categories":["系统架构"],"content":"8 Compare-And-Swap 某些系统提供的另一种硬件原语被称为 **“compare-and-swap “**指令（例如 SPARC 上的名称）或 **“compare-and-exchange “**指令（x86 上的名称）。下面是这条指令的 C 语言伪代码。 int CompareAndSwap(int *ptr, int expected, int new) { int actual = *ptr; if (actual == expected) *ptr = new; return actual; } 其基本思想是，compare-and-swap指令测试 ptr 指定地址上的值是否等于预期值；如果是，则用新值更新 ptr 指向的内存位置。如果不相等，则什么也不做。无论哪种情况，都会返回该内存位置的实际值，从而让调用compare-and-swap指令的代码知道它是否成功。 有了compare-and-swap指令，我们就可以用与test-and-set指令类似的方式建立锁。例如，我们可以将上面的 lock() 例程替换为下面的例程： void lock(lock_t *lock) { while (CompareAndSwap(\u0026lock-\u003eflag, 0, 1) == 1) ; // spin } 代码的其余部分与上面的test-and-set示例相同。这段代码的工作原理非常相似；它只需检查flag是否为 0，如果为 0，则原子交换 1，从而获取锁。如果线程试图在锁被锁定时获取锁，就会被卡住，直到锁最终被释放。 下面是实际 C 代码（调用汇编）x86版本中显示的compare-and-swap的简单示例。 #include \u003cstdio.h\u003e int global = 0; // Function to perform a compare and swap operation // Parameters: // ptr: pointer to the memory location where the operation will be performed // old: expected value to compare against // new: new value to store if the comparison succeeds // Returns: // 1 if the comparison succeeded and the value was updated, 0 otherwise char compare_and_swap(int *ptr, int old, int new) { unsigned char ret; // Assembly code to perform the compare and swap operation // Note: sete sets a byte not the word __asm__ __volatile__ ( \" lock\\n\" \" cmpxchgl %2,%1\\n\" \" sete %0\\n\" : \"=q\" (ret), \"=m\" (*ptr) : \"r\" (new), \"m\" (*ptr), \"a\" (old) : \"memory\"); return ret; } int main(int argc, char *argv[]) { // Before successful compare and swap printf(\"before successful cas: %d\\n\", global); // Perform successful compare and swap operation int success = compare_and_swap(\u0026global, 0, 100); // Print result after successful compare and swap printf(\"after successful cas: %d (success: %d)\\n\", global, success); // Before failing compare and swap printf(\"before failing cas: %d\\n\", global); // Perform failing compare and swap operation success = compare_and_swap(\u0026global, 0, 200); // Print result after failing compare and swap printf(\"after failing cas: %d (old: %d)\\n\", global, success); return 0; } 最后，正如你可能已经感觉到的，compare-and-swap是一条比test-and-set功能更强大的指令。今后，当我们深入探讨无锁同步等主题时，我们将利用这一功能。不过，如果我们只是用它构建一个简单的自旋锁，其行为与我们上面分析的自旋锁完全相同。 ","date":"2024-05-11","objectID":"/posts/21.%E9%94%81/:8:0","tags":["OS"],"title":"锁","uri":"/posts/21.%E9%94%81/"},{"categories":["系统架构"],"content":"9 Load-Linked and Store-Conditional 一些平台提供了一对协同工作的指令来帮助构建临界区。例如，在 MIPS 架构上，加载链接指令和存储条件指令可以串联使用来构建锁和其他并发结构。这些指令的 C 伪代码如下所示。 Alpha、PowerPC 和 ARM 提供类似的指令。 int LoadLinked(int *ptr) { return *ptr; } int StoreConditional(int *ptr, int value) { if (no update to *ptr since LoadLinked to this address) { *ptr = value; return 1; // success! } else { return 0; // failed to update } } 加载链接的操作与典型的加载指令非常相似，只是从内存中获取一个值并将其放入寄存器中。关键的区别在于条件存储，只有在没有对地址进行干预存储的情况下，条件存储才会成功（并更新存储在刚刚加载链接的地址处的值）。如果成功，store-conditional 返回 1 并将 ptr 处的值更新为 value；如果失败，则 ptr 处的值不会更新并返回 0。 下面这段代码展示了如何使用加载链接和存储条件来构建自旋锁。 void lock(lock_t *lock) { while (1) { while (LoadLinked(\u0026lock-\u003eflag) == 1) ; // spin until it’s zero if (StoreConditional(\u0026lock-\u003eflag, 1) == 1) return; // if set-it-to-1 was a success: all done // otherwise: try it all over again } } void unlock(lock_t *lock) { lock-\u003eflag = 0; } lock() 代码是唯一有趣的部分。首先，线程自旋，等待flag设置为 0（从而指示未持有锁）。一旦这样，线程尝试通过store-conditional获取锁；如果成功，线程会自动将flag的值更改为 1，从而可以进入临界区。 注意存储条件失败可能出现的情况。一个线程调用lock()并执行load-linked，返回0表示锁未被持有。在它尝试store-conditional之前，它被中断，另一个线程进入锁代码，同样执行load-linked指令，并得到0继续执行。此时，两个线程各自执行了load-linked，并且即将尝试store-conditional。这些指令的关键特点是这两个线程中只有一个会成功地将flag更新为1从而获取锁；第二个尝试store-conditional的线程会失败（因为另一个线程在其load-linked和store-conditional之间更新了flag值），因此必须再次尝试获取锁。 一种更简洁的lock()写法如下： void lock(lock_t *lock) { while (1) { while (LoadLinked(\u0026lock-\u003eflag) == 1 || !StoreConditional(\u0026lock-\u003eflag, 1)) ; // spin until the condition does not hold } } ","date":"2024-05-11","objectID":"/posts/21.%E9%94%81/:9:0","tags":["OS"],"title":"锁","uri":"/posts/21.%E9%94%81/"},{"categories":["系统架构"],"content":"10 Fetch-And-Add 最后一个硬件原语是fetch-and-add指令，它以原子方式递增一个值，同时返回特定地址上的旧值。fetch-and-add指令的 C 语言伪代码如下： int FetchAndAdd(int *ptr) { int old = *ptr; *ptr = old + 1; return old; } lock和unlock代码如下所示。在这个例子中，我们将使用fetch-and-add来构建一个更有趣的票据锁，由Mellor-Crummey和Scott引入。 typedef struct __lock_t { int ticket; int turn; } lock_t; void lock_init(lock_t *lock) { lock-\u003eticket = 0; lock-\u003eturn = 0; } void lock(lock_t *lock) { int myturn = FetchAndAdd(\u0026lock-\u003eticket); while (lock-\u003eturn != myturn) ; // spin } void unlock(lock_t *lock) { lock-\u003eturn = lock-\u003eturn + 1; } 这个解决方案不是使用单一值，而是结合使用ticket和turn变量来构建一个自旋锁。 基本操作非常简单：当线程希望获取锁时，首先对ticket进行原子fetch-and-add操作；该值现在被视为此线程的“轮次”（myturn）。 然后全局共享的lock-\u003eturn用于确定哪个线程的轮次；当给定线程的(myturn == turn)时，就是该线程进入临界区的机会。 unlock只需通过增加turn即可完成，以便下一个等待的线程（如果有）现在可以进入临界区。 请注意这种解决方案与我们之前尝试过的方法之间存在一个重要差异：它确保所有线程都能取得进展。 一旦分配了某个线程自己的ticket，它将在未来某个时间点被调度执行（一旦排队等候其前面已经通过临界区并释放了锁）。 在我们之前尝试过的情况下，并不存在这样保证；例如，在test-and-set上自旋着等待，即使其他线程获取并释放了锁也可能永远自旋下去。 ","date":"2024-05-11","objectID":"/posts/21.%E9%94%81/:10:0","tags":["OS"],"title":"锁","uri":"/posts/21.%E9%94%81/"},{"categories":["系统架构"],"content":"11 太多自旋：现在怎么办？ 我们基于硬件的简单锁非常简单（只有几行代码），而且能正常工作，这是任何系统或代码的两个优秀特性。然而，在某些情况下，这些解决方案的效率可能很低。想象一下，你在单个处理器上运行两个线程。现在假设一个线程（线程 0）正处于临界区，因此被锁定，并不幸被中断。第二个线程（线程 1）现在试图获取锁，但发现锁已被锁定。于是，它开始不停地自旋。然后又自旋了几圈。最后，定时器中断，线程 0 再次运行，释放了锁，最后（比如说下次运行时），线程 1 就不用自旋那么多圈了，就能获得锁。因此，在这种情况下，线程一旦陷入自旋，就会浪费一整个时间片，而只是检查一个不会改变的值外，什么也不做！如果有 N 个线程在争夺一个锁，问题就更严重了；N - 1 个时间片可能会以类似的方式被浪费掉，仅仅是在自旋并等待一个线程释放锁。这就是我们的下一个问题：如何避免自旋？我们怎样才能开发出一种不会无谓地浪费时间在 CPU 上自旋的锁？仅靠硬件支持无法解决问题。我们还需要操作系统的支持！现在就让我们来看看如何实现这一点。 ","date":"2024-05-11","objectID":"/posts/21.%E9%94%81/:11:0","tags":["OS"],"title":"锁","uri":"/posts/21.%E9%94%81/"},{"categories":["系统架构"],"content":"12 一个简单的方法：只需yield 硬件支持让我们取得了相当大的进展：工作锁，甚至（如票据锁）锁获取的公平性。然而，我们仍然面临一个问题：当上下文切换发生在临界区时，线程开始无休止地自旋，等待被中断的（持有锁的）线程再次运行，这时该怎么办？ 我们首先尝试的是一种简单而友好的方法：当你要自旋时，把 CPU 让给另一个线程。或者，就像Al Davis说的那样，“让一让，宝贝！\"。下面这段代码展示了这种方法。 void init() { flag = 0; } void lock() { while (TestAndSet(\u0026flag, 1) == 1) yield(); // 放弃 CPU 控制权 } void unlock() { flag = 0; } 在这种方法中，我们假定一个线程在想要放弃 CPU 并让另一个线程运行时，可以调用操作系统原语 yield()。一个线程可以处于三种状态（运行、就绪或阻塞）之一；yield 只是一个系统调用，它将调用者从运行状态移到就绪状态，从而将另一个线程提升到运行状态。因此，yield过程本质上是自我取消调度的。 回想一下一个 CPU 上有两个线程的例子，在这种情况下，我们基于 yield 的方法就能很好地发挥作用。如果一个线程碰巧调用了 lock() 并发现锁被锁定，它就会简单地让出 CPU，这样另一个线程就会运行并完成其临界区。在这种简单的情况下，yield方法运行良好。 现在让我们考虑一下有多个线程（比如 100 个）重复争夺一个锁的情况。在这种情况下，如果一个线程获得了锁，并在释放锁之前被抢占，那么其他 99 个线程将分别调用 lock()，发现锁被持有，并让出 CPU。假设有某种循环调度程序，那么 99 个线程中的每一个都会在持有锁的线程再次运行之前执行这种run-and-yield模式。虽然这种方法比我们的 “自旋\"方法要好（“自旋 “会浪费 99 个时间片），但上下文切换的成本可能很高，因此会造成大量浪费。 更糟糕的是，我们根本没有解决饥饿问题。当其他线程反复进入和退出临界区时，一个线程可能会陷入无休止的yield循环。显然，我们需要一种能直接解决这一问题的方法。 ","date":"2024-05-11","objectID":"/posts/21.%E9%94%81/:12:0","tags":["OS"],"title":"锁","uri":"/posts/21.%E9%94%81/"},{"categories":["系统架构"],"content":"13 使用队列：睡眠而不是自旋 我们之前的方法的真正问题在于，它们留下了太多的偶然性。调度器决定下一个运行的线程；如果调度器做出了错误的选择，运行的线程要么必须自旋等待锁（我们的第一种方法），要么立即让出 CPU（我们的第二种方法）。无论哪种方法，都有可能造成浪费，而且无法避免饥饿。 因此，我们必须明确控制在当前持有者释放锁后，下一个获得锁的线程。为此，我们需要更多的操作系统支持，以及一个队列来跟踪哪些线程正在等待获取锁。 为简单起见，我们将使用 Solaris 提供的支持，即两个调用：park() 用于使调用线程休眠，unpark(threadID) 用于唤醒threadID 指定的特定线程。这两个例程可以配合使用，构建一个锁，当调用者试图获取一个被锁定的锁时，该锁会使调用者休眠，而当锁被释放时，调用者会被唤醒。 下面这段代码实现了简单的锁。 typedef struct __lock_t { int flag; int guard; queue_t *q; } lock_t; void lock_init(lock_t *m) { m-\u003eflag = 0; m-\u003eguard = 0; queue_init(m-\u003eq); } void lock(lock_t *m) { while (TestAndSet(\u0026m-\u003eguard, 1) == 1) ; // 通过自旋获取 guard 锁 if (m-\u003eflag == 0) { m-\u003eflag = 1; // 获取锁 m-\u003eguard = 0; } else { queue_add(m-\u003eq, gettid()); m-\u003eguard = 0; park(); } } void unlock(lock_t *m) { while (TestAndSet(\u0026m-\u003eguard, 1) == 1) ; // 通过自旋获取 guard 锁 if (queue_empty(m-\u003eq)) m-\u003eflag = 0; // 释放锁；没有线程要获取它 else unpark(queue_remove(m-\u003eq)); // 保持锁（给下一个线程！） m-\u003eguard = 0; } 在这个例子中，我们做了几件有趣的事情。首先，我们将老式的test-and-set思想与显式的锁等待者队列相结合，以实现更高效的锁。其次，我们使用队列来帮助控制下一个获得锁的人，从而避免饥饿。 你可能会注意到 guard 是如何使用的，它基本上是围绕锁使用的标志和队列操作的自旋锁。因此，这种方法并不能完全避免自旋等待；线程在获取或释放锁时可能会被中断，从而导致其他线程自旋等待该线程再次运行。不过，自旋所花费的时间非常有限（只是lock()和unlock()代码中的几条指令，而不是用户定义的临界区），因此这种方法可能是合理的。 其次，你可能会注意到，在 lock() 中，当一个线程无法获取锁（它已被持有）时，我们会小心地将该线程加入一个队列（通过调用 gettid() 函数获取当前线程的threadID），将 guard 设为 0，并让出 CPU。但如果在 park() 之后而不是之前释放guard锁，会发生什么情况？这会导致其他线程暂时无法再获得 guard 锁，因为该锁仍然由先前的线程持有。如果其他线程试图获取锁，则会一直自旋等待 guard 锁被释放。而由于无法获取guard锁，其他线程无法执行 unlock() 函数，所以即使某个线程被唤醒，也无法继续执行unlock操作。这就导致了死锁状态，所有线程都被阻塞，无法正常运行。 你可能还会注意到一个有趣的事实，那就是当另一个线程被唤醒时，flag不会被设置回 0。这是为什么呢？这并不是一个错误，而是一种必然！当一个线程被唤醒时，它就像从 park() 返回一样；然而，它在代码中的这一点上并不持有guard，因此甚至无法尝试将flag设置为 1。因此，我们只是将锁从释放锁的线程直接传递给下一个获取锁的线程；在这中间，flag不会被设置为 0。 最后，你可能会注意到在解决方案中，就在调用 park() 之前出现了竞争条件。例如线程B在调用park()之前线程A释放了锁，那么线程B可能会永远休眠，因为在调用 park() 之前它已经错过了唤醒的时机。这个问题有时被称为唤醒/等待竞争。 Solaris 通过添加第三个系统调用 setpark() 来解决这个问题。通过调用该例程，线程可以表明它即将park。如果线程在调用 park() 之前被中断（例如收到了一个信号），而另一个线程在这个时候调用了 unpark() 来唤醒当前线程，则当前线程下一次调用 park() 不会真正进入休眠状态，而是立即返回，继续执行后续的代码。lock()内部的代码修改很小： queue_add(m-\u003eq, gettid()); setpark(); // new code , (before open guard) m-\u003eguard = 0; 另一种不同的解决方案是将guard传递给内核。在这种情况下，内核可以采取预防措施，以原子方式释放锁，并将运行中的线程出列。 ","date":"2024-05-11","objectID":"/posts/21.%E9%94%81/:13:0","tags":["OS"],"title":"锁","uri":"/posts/21.%E9%94%81/"},{"categories":["系统架构"],"content":"14 不同的操作系统，不同的支持 到目前为止，我们已经看到了操作系统为在线程库中建立更高效的锁而提供的一种支持。其他操作系统也提供类似的支持，但细节各有不同。 例如，Linux 提供的 futex 与 Solaris 接口类似，但提供了更多内核功能。具体来说，每个 futex 都关联了一个特定的物理内存位置，以及每个 futex 的内核队列。调用者可以根据需要使用 futex 调用来休眠和唤醒。具体来说， 有两种调用方式可用。调用 futex_wait(address,expected)后，调用线程将进入休眠状态，前提是地址中的值等于预期值。如果不相等，调用将立即返回。调用例程 futex_wake(address) 会唤醒一个正在队列中等待的线程。这些调用在 Linux mutex中的用法如下所示。 void mutex_lock(int *mutex) { int v; /* Bit 31 was clear, we got the mutex (the fastpath) */ if (atomic_bit_test_set(mutex, 31) == 0) return; // Atomic operations increase the number of waiters on the lock atomic_increment(mutex); while (1) { // Spin waits for other threads to release the lock if (atomic_bit_test_set(mutex, 31) == 0) { // The current thread holds the lock and the number of waiters is reduced by 1 atomic_decrement(mutex); return; } /* We have to wait. First make sure the futex value we are monitoring is truly negative (locked). */ v = *mutex; if (v \u003e= 0) continue; futex_wait(mutex, v); } } void mutex_unlock(int *mutex) { /* Adding 0x80000000 to counter results in 0 if and only if there are not other interested threads */ if (atomic_add_zero(mutex, 0x80000000)) return; /* There are other threads waiting for this mutex, wake one of them up. */ futex_wake(mutex); } nptl 库（gnu libc 库的一部分） 中 lowlevellock.h的这段 代码片段之所以有趣，有几个原因。首先，它使用一个整数来跟踪锁是否被持有（整数的高位）以及锁上等待者的数量（所有其他位）。因此，如果锁是负数，它就是被持有的（因为高位被设置，而该位决定了整数的符号）。 其次，代码片段展示了如何针对常见情况进行优化，特别是在没有锁竞争的情况下；只有一个线程获取和释放锁，只需完成很少的工作（原子位test-and-set锁定以及原子位添加释放锁）。 ","date":"2024-05-11","objectID":"/posts/21.%E9%94%81/:14:0","tags":["OS"],"title":"锁","uri":"/posts/21.%E9%94%81/"},{"categories":["系统架构"],"content":"15 两阶段锁 最后一点：Linux 方法有一种旧方法的味道，这种方法已经断断续续地使用了很多年，至少可以追溯到 1960 年代初的 Dahm Locks ，现在被称为两阶段锁。两阶段锁意识到自旋可能很有用，特别是在锁即将被释放的情况下。所以在第一阶段，锁会自旋一段时间，希望能够获取到锁。 但是，如果在第一个自旋阶段没有获取锁，则会进入第二个阶段，调用者将进入睡眠状态，只有在锁稍后释放时才会被唤醒。上面的 Linux 锁就是这种锁的一种形式，但它只自旋一次；对此的概括可以是在使用 futex 支持进入睡眠之前循环自旋固定的时间。两阶段锁是混合方法的另一个实例，其中结合两个好的想法确实可能会产生更好的想法。当然，它是否确实在很大程度上取决于很多因素，包括硬件环境、线程数量和其他工作负载细节。与往常一样，制作一个适合所有可能用例的通用锁是一个相当大的挑战。 ","date":"2024-05-11","objectID":"/posts/21.%E9%94%81/:15:0","tags":["OS"],"title":"锁","uri":"/posts/21.%E9%94%81/"},{"categories":["系统架构"],"content":"16 Dekker算法和Peterson算法 20 世纪 60 年代，Dijkstra 向他的朋友们提出了并发问题，其中一位名叫 Theodorus Jozef Dekker 的数学家提出了解决方案。与我们在此讨论的使用特殊硬件指令甚至操作系统支持的解决方案不同，Dekker 的算法仅使用加载和存储（假定它们之间是原子关系，这在早期的硬件上是正确的）。下面是Dekker算法的代码： int flag[2]; int turn; void init() { flag[0] = flag[1] = 0; turn = 0; } void lock() { flag[self] = 1; while (flag[1 - self] == 1) { if (turn != self) { flag[self] = 0; while (turn != self) ; flag[self] = 1; } } } void unlock() { flag[self] = 0; turn = 1 - self; } Dekker的方法后来被Peterson改进。同样，该算法只使用加载和存储，其目的是确保两个线程不会同时进入临界区。下面是 Peterson 的算法（两个线程）： int flag[2]; int turn; void init() { // indicate you intend to hold the lock w/ ’flag’ flag[0] = flag[1] = 0; // whose turn is it? (thread 0 or 1) turn = 0; } void lock() { // ’self’ is the thread ID of caller flag[self] = 1; // make it other thread’s turn turn = 1 - self; while ((flag[1 - self] == 1) \u0026\u0026 (turn == 1 - self)) ; // spin-wait while it’s not your turn } void unlock() { // simply undo your intent flag[self] = 0; } 出于某种原因，开发无需特殊硬件支持就能工作的锁曾风靡一时，给理论家们带来了许多难题。当然，当人们意识到假定有一点硬件支持会容易得多时，这一行就变得毫无用处了（事实上，这种支持在多进程的早期就已经存在了）。此外，类似上述的算法在现代硬件上也行不通（因为内存一致性模型被放宽了），因此它们的用处比以前更小了。然而，更多的研究已被历史尘封…… ","date":"2024-05-11","objectID":"/posts/21.%E9%94%81/:16:0","tags":["OS"],"title":"锁","uri":"/posts/21.%E9%94%81/"},{"categories":["系统架构"],"content":"1 线程创建 编写多线程程序的第一件事就是创建新线程，因此必须有某种线程创建接口。在 POSIX 中，这很容易： #include \u003cpthread.h\u003e int pthread_create( pthread_t* thread, const pthread_attr_t* attr, void* (*start_routine)(void*), void* arg); 这个函数声明有四个参数：thread、attr、start_routine 和 arg。第一个参数 thread 是指向 pthread_t 类型结构的指针；我们将使用该结构与线程交互，因此需要将其传递给 pthread_create() 以对其进行初始化。 第二个参数 attr 用于指定该线程可能具有的任何属性。例如包括设置栈大小或可能有关线程的调度优先级的信息。通过单独调用 pthread_attr_init() 来初始化属性；有关详细信息，请参阅手册页：man pthread_create。然而，在大多数情况下，默认值就可以了，在这种情况下，我们将简单地传递 NULL 值。 第三个参数是最复杂的，但实际上只是询问：这个线程应该开始在哪个函数中运行？在 C 中，我们将其称为函数指针，这告诉我们预期的内容：函数名称（start_routine），它传递一个类型为 void * 的单个参数（如start_routine后面的括号中所示），以及它返回一个 void * 类型的值（即，一个 void 指针）。如果此例程需要整数参数而不是 void 指针，则声明将如下所示： int pthread_create(..., // first two args are the same void * (*start_routine)(int), int arg); 如果例程的参数是一个 void 指针，但返回值是一个整数，那么就会是这样： int pthread_create(..., // first two args are the same int (*start_routine)(void *), void * arg); 最后，第四个参数 arg 正是要传递给线程开始执行的函数的参数。你可能会问：为什么我们需要这些 void 指针？答案其实很简单：将 void 指针作为函数start_routine的参数，可以让我们传递任何类型的参数；将它作为返回值，可以让线程返回任何类型的结果。 还有函数的返回值，如果运行正常，则返回 0（否则为错误代码：EAGAIN、EINVAL、EPERM）。 让我们看看下面这段代码。 #include \u003cassert.h\u003e #include \u003cstdio.h\u003e #include \"common.h\" #include \"common_threads.h\" typedef struct { int a; int b; } myarg_t; void *mythread(void *arg) { myarg_t *args = (myarg_t *) arg; printf(\"%d %d\\n\", args-\u003ea, args-\u003eb); return NULL; } int main(int argc, char *argv[]) { pthread_t p; myarg_t args = { 10, 20 }; int rc = pthread_create(\u0026p, NULL, mythread, \u0026args); assert(rc == 0); (void) pthread_join(p, NULL); printf(\"done\\n\"); return 0; } 在这里，我们只是创建了一个线程，它传递了两个参数，并打包成我们自己定义的单一类型（myarg t）。线程创建后，可以简单地将其参数转换为它所期望的类型，从而根据需要解包参数。就是这样！一旦创建了线程，你就真正拥有了另一个活生生的执行实体，它拥有自己的调用栈，与程序中当前存在的所有线程运行在同一地址空间。程序的运行结果如下： ❯ make thread_create gcc -o thread_create thread_create.c -Wall -Werror -I../include -pthread ❯ ./thread_create 10 20 done ","date":"2024-05-11","objectID":"/posts/20.%E7%BA%BF%E7%A8%8Bapi/:1:0","tags":["OS"],"title":"线程API","uri":"/posts/20.%E7%BA%BF%E7%A8%8Bapi/"},{"categories":["系统架构"],"content":"2 等待线程完成 上面的例子展示了如何创建一个线程。但是，如果您想等待线程完成，会发生什么情况？你需要做一些特别的事情才能等待完成；特别是，您必须调用例程 pthread_join()。 int pthread_join(pthread_t thread, void **value_ptr); 此例程需要两个参数。第一个参数的类型是 pthread_t，用于指定等待哪个线程。该变量由线程创建例程初始化（将指针作为参数传递给 pthread create()）；如果保留该变量，就可以用它来等待该线程终止。 第二个参数是指向你期望返回值的指针。由于该例程可以返回任何值，因此它被定义为返回 void 的指针；由于 pthread_join() 例程会改变传入参数的值，因此你需要传入指向该值的指针，而不仅仅是该值本身。 让我们看下面这段代码，在代码中，再次创建了一个单线程，并通过 myarg_t 结构传递了几个参数。返回值使用 myret_t 类型。一旦线程运行完毕，一直在 pthread_join() 例程 中等待的主线程就会返回，我们就可以访问从线程返回的值，即 myret_t 中的值。 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \"common.h\" #include \"common_threads.h\" typedef struct { int a; int b; } myarg_t; typedef struct { int x; int y; } myret_t; void *mythread(void *arg) { myarg_t *args = (myarg_t *) arg; printf(\"args %d %d\\n\", args-\u003ea, args-\u003eb); myret_t *rvals = malloc(sizeof(myret_t)); assert(rvals != NULL); rvals-\u003ex = 1; rvals-\u003ey = 2; return (void *) rvals; } int main(int argc, char *argv[]) { pthread_t p; myret_t *rvals; myarg_t args = { 10, 20 }; Pthread_create(\u0026p, NULL, mythread, \u0026args); Pthread_join(p, (void **) \u0026rvals); printf(\"returned %d %d\\n\", rvals-\u003ex, rvals-\u003ey); free(rvals); return 0; } 关于这个例子，有几点需要注意。首先，很多时候我们不必对参数进行这些痛苦的打包和拆包。例如，如果我们只是创建一个不带参数的线程，我们可以在创建线程时将 NULL 作为参数传递进去。同样，如果我们不关心返回值，也可以将 NULL 传递给 pthread_join()。 其次，如果我们只传递一个值（如 int），就不必将其打包为参数。 如下面这段代码所示，在这种情况下，我们不必将参数和返回值打包到结构内部。 #include \u003cstdio.h\u003e #include \"common.h\" #include \"common_threads.h\" void *mythread(void *arg) { long long int value = (long long int) arg; printf(\"%lld\\n\", value); return (void *) (value + 1); } int main(int argc, char *argv[]) { pthread_t p; long long int rvalue; Pthread_create(\u0026p, NULL, mythread, (void *) 100); Pthread_join(p, (void **) \u0026rvalue); printf(\"returned %lld\\n\", rvalue); return 0; } 第三，我们应该注意，从线程返回值的方式必须非常谨慎。尤其是，千万不要返回指向线程调用栈中分配的指针。如果这样做，你觉得会发生什么？(想想吧！）下面是一段危险代码的示例，它是根据上面的示例修改的。 void *mythread(void *arg) { myarg_t *m = (myarg_t *)arg; printf(\"%d %d\\n\", m-\u003ea, m-\u003eb); myret_t r; // ALLOCATED ON STACK: BAD! r.x = 1; r.y = 2; return (void *)\u0026r; } 在这种情况下，变量 r 被分配到 mythread 的栈中。然而，当它返回时，该值会被自动解除分配（毕竟这就是栈如此易于使用的原因！），因此，将指向已解除分配的变量的指针传回会导致各种糟糕的结果。 最后，你可能会注意到，使用 pthread_create() 创建线程，然后立即调用 pthread_join() 是一种非常奇怪的创建线程的方法。事实上，有一种更简单的方法可以完成这一任务，那就是过程调用。显然，我们通常要创建不止一个线程并等待它完成，否则使用线程就没有什么意义了。 我们应该注意，并非所有多线程代码都使用join例程。例如，多线程网络服务器可能会创建许多工作线程，然后使用主线程接受请求并将请求无限期地传递给工作线程。因此，这种长寿命程序可能不需要join。然而，创建线程执行特定任务（并行）的并行程序可能会使用 join 来确保在退出或进入下一阶段计算之前，所有这些工作都已完成。 ","date":"2024-05-11","objectID":"/posts/20.%E7%BA%BF%E7%A8%8Bapi/:2:0","tags":["OS"],"title":"线程API","uri":"/posts/20.%E7%BA%BF%E7%A8%8Bapi/"},{"categories":["系统架构"],"content":"3 锁 除了线程创建和等待线程完成之外，POSIX 线程库提供的下一组最有用的函数可能就是那些通过锁为临界区提供互斥的函数了。为此目的使用的最基本的一对例程如下： int pthread_mutex_lock(pthread_mutex_t *mutex); int pthread_mutex_unlock(pthread_mutex_t *mutex); 例程应该易于理解和使用。当您的代码区域是临界区，因此需要受到保护以确保正确操作时，锁非常有用。你大概可以想象代码的样子： pthread_mutex_t lock; pthread_mutex_lock(\u0026lock); x = x + 1; // 或者不管你的临界区是什么 pthread_mutex_unlock(\u0026lock); 代码的意图如下：如果调用 pthread_mutex_lock() 时没有其他线程持有锁，则该线程将获取锁并进入临界区。如果另一个线程确实持有锁，则尝试获取锁的线程将不会从调用中返回，直到它获得锁（这意味着持有锁的线程已通过unlock调用释放了锁）。当然，在给定时间，许多线程可能会卡在锁获取函数内等待；然而，只有获得锁的线程才应该调用unlock。 不幸的是，这段代码在两个重要方面被破坏了。第一个问题是缺乏正确的初始化。所有锁都必须正确初始化，以保证它们具有正确的值，从而在调用lock和unlock时按需要工作。 对于 POSIX 线程，有两种初始化锁的方法。一种方法是使用 PTHREAD_MUTEX_INITIALIZER，如下所示： pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; 这样做会将锁设置为默认值，从而使锁可用。动态方法（即在运行时）是调用 pthread_mutex_init()，如下所示： int rc = pthread_mutex_init(\u0026lock, NULL); assert(rc == 0 \u0026\u0026 “Error in mutex init”); 该例程的第一个参数是锁本身的地址，第二个参数是一组可选属性。传递 NULL 即只需使用默认值即可。两种方法都可以，但我们通常使用动态（后一种）方法。需要注意的是，在使用完锁后，还需要调用 pthread_mutex_destroy()。 上述代码的第二个问题是，它在调用lock和unlock时没有检查错误代码。就像你在 UNIX 系统中调用的几乎所有库例程一样，这些例程也可能失败！如果你的代码没有正确检查错误代码，失败就会无声无息地发生，在这种情况下，可能会允许多个线程进入临界区段。在最低限度上，应使用包装器来断言例程成功（如下面这段代码所示）；更复杂的（非玩具）程序在出错时不能简单地退出，而应检查失败，并在lock或unlock不成功时采取适当的措施。 // Use this to keep your code clean but check for failures // Only use if exiting program is OK upon failure void Pthread_mutex_lock(pthread_mutex_t *mutex) { int rc = pthread_mutex_lock(mutex); assert(rc == 0 \u0026\u0026 “Error in acquire”); } lock和unlock例程并不是 pthreads 库中与锁交互的唯一例程。这里还有两个例程可能值得关注： int pthread_mutex_trylock(pthread_mutex_t *mutex); int pthread_mutex_timedlock(pthread_mutex_t *mutex, struct timespec *abs_timeout); 这两个调用用于获取锁。如果锁已被持有，trylock 版本会返回失败；获取锁的 timedlock 版本会在超时或获取锁后返回，以先发生者为准。因此，超时后的 timedlock 会退化为 trylock。一般来说，这两种情况都应该避免；不过，在某些情况下，避免卡在（也许是无限期地）锁获取例程中是有用的。 ","date":"2024-05-11","objectID":"/posts/20.%E7%BA%BF%E7%A8%8Bapi/:3:0","tags":["OS"],"title":"线程API","uri":"/posts/20.%E7%BA%BF%E7%A8%8Bapi/"},{"categories":["系统架构"],"content":"4 条件变量 任何线程库的另一个主要组成部分，当然也包括 POSIX 线程，就是条件变量的存在。当线程之间必须进行某种信号传递时，如果一个线程正在等待另一个线程做某事，然后才能继续，那么条件变量就非常有用。希望以这种方式进行交互的程序主要使用两个例程： int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex); int pthread_cond_signal(pthread_cond_t *cond); 要使用条件变量，还必须拥有与该条件关联的锁。当调用上述任一例程时，应保持此锁。 第一个例程 pthread_cond_wait() 使调用线程进入睡眠状态，从而等待其他线程向其发出信号，通常是在程序中的某些内容发生更改而现在正在睡眠的线程可能关心的情况下。典型的用法如下： pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; pthread_cond_t cond = PTHREAD_COND_INITIALIZER; Pthread_mutex_lock(\u0026lock); while (ready == 0) Pthread_cond_wait(\u0026cond, \u0026lock); Pthread_mutex_unlock(\u0026lock); 在此代码中，在初始化相关锁和条件之后，线程检查变量ready是否已设置为非零的值。如果没有，该线程只需调用等待例程即可休眠，直到其他线程将其唤醒。唤醒一个线程的代码如下所示，该代码将在其他线程中运行： Pthread_mutex_lock(\u0026lock); ready = 1; Pthread_cond_signal(\u0026cond); Pthread_mutex_unlock(\u0026lock); 关于这个代码序列，有几点需要注意。首先，在发送信号时（以及修改全局变量 ready 时），我们始终要确保lock。这样可以确保我们的代码不会意外引入竞争条件。 其次，你可能会注意到，wait 调用的第二个参数是锁，而 signal 调用只需要一个条件。造成这种差异的原因是，wait 调用除了让调用线程休眠外，还会在让调用者休眠时释放锁。试想一下，如果不这样做，其他线程怎么可能获得锁并发出信号唤醒它呢？不过，在被唤醒后返回之前，pthread_cond_wait() 会重新获取锁，从而确保在等待序列开始时获取锁和结束时释放锁之间的任何时间，等待线程都持有锁。 最后一个奇怪的现象：等待线程在 while 循环中重新检查条件，而不是简单的 if 语句。因为使用 while 循环是简单安全的做法。虽然它会重新检查条件（可能会增加一点开销），但有些 pthread 实现可能会错误地唤醒等待线程；在这种情况下，如果不重新检查，等待线程就会继续认为条件改变，即使它并没有改变。例如，如果有多个线程在等待，而只有一个线程应该抓取数据（生产者-消费者）。因此，更安全的做法是将唤醒视为可能已发生变化的提示，而不是绝对的事实。 需要注意的是，有时在两个线程之间使用一个简单的标志来发出信号，而不是使用条件变量和相关的锁，这很有诱惑力。例如，我们可以重写上面的等待代码，在等待代码中看起来更像这样： while (ready == 0) ; // spin 相关的信号代码如下： ready = 1; 永远不要这样做，原因如下。首先，它在很多情况下表现不佳（长时间自旋，即持续检查某个条件是否满足，这只会浪费 CPU 周期）。其次，容易出错。使用标志（如上所述）在线程之间进行同步时非常容易出错。 ","date":"2024-05-11","objectID":"/posts/20.%E7%BA%BF%E7%A8%8Bapi/:4:0","tags":["OS"],"title":"线程API","uri":"/posts/20.%E7%BA%BF%E7%A8%8Bapi/"},{"categories":["系统架构"],"content":"5 线程API指南 当你使用POSIX线程库（或者实际上，任何线程库）构建一个多线程程序时，有一些小但重要的事情需要记住。它们包括： **保持简单。**最重要的是，任何涉及线程之间的锁定或信号的代码都应尽可能简单。复杂的线程交互会导致错误。 **最小化线程交互。**尽量减少线程之间交互的方式。每个交互都应该经过深思熟虑，并用经过验证的方法构建。 **初始化锁和条件变量。**未初始化将导致代码有时能够正常工作，有时会以非常奇怪的方式失败。 **检查返回码。**当然，在你所做的任何C和UNIX编程中，你都应该检查每一个返回码，这在这里也是正确的。不这样做将导致奇怪且难以理解的行为。 **在传递参数给线程和从线程返回值时要小心。**特别是，任何时候你传递指向栈上分配的变量的引用时，你可能在做一些错误的事情。 **每个线程都有自己的栈。**与上面的观点相关，请记住每个线程都有自己的栈。因此，如果你在某个线程执行的函数中有一个在本地分配的变量，它基本上是私有的，其他线程无法（轻易）访问它。要在线程之间共享数据，这些值必须在堆上或者以其他全局可访问的位置。 **总是使用条件变量来在线程之间进行信号传递。**虽然使用简单的标志往往很诱人，但不要这样做。 **使用手册页面。**特别是在Linux上，pthread手册页面非常有信息量。 ","date":"2024-05-11","objectID":"/posts/20.%E7%BA%BF%E7%A8%8Bapi/:5:0","tags":["OS"],"title":"线程API","uri":"/posts/20.%E7%BA%BF%E7%A8%8Bapi/"},{"categories":["系统架构"],"content":"到目前为止，我们已经看到了操作系统执行的基本抽象的发展。我们已经了解了如何将单个物理 CPU 转变为多个虚拟 CPU，从而实现多个程序同时运行的错觉。我们还了解了如何为每个进程创建一个大的、私有的虚拟内存；当操作系统确实在物理内存（有时是磁盘）上秘密复用地址空间时，地址空间的这种抽象使每个程序的行为就好像它拥有自己的内存一样。 在本文中，我们为单个正在运行的进程引入了一种新的抽象：线程。我们通常认为程序中只有一个执行点（即从一台 PC 获取指令并执行），而多线程程序则有多个执行点（即多台 PC，每台 PC 获取指令并执行）。也许我们可以换个角度来理解，每个线程都很像一个独立的进程，但有一点不同：它们共享相同的地址空间，因此可以访问相同的数据。 因此，单个线程的状态与进程的状态非常相似。它有一个程序计数器 (PC)，用于跟踪程序从何处获取指令。每个线程都有自己的一组用于计算的私有寄存器；因此，如果有两个线程在单个处理器上运行，则当从运行一个线程 (T1) 切换到运行另一个线程 (T2) 时，必须进行上下文切换。线程之间的上下文切换与进程之间的上下文切换非常相似，因为在运行T2之前必须保存T1的寄存器状态并恢复T2的寄存器状态。对于进程，我们将状态保存到进程控制块（PCB）；现在，我们需要一个或多个线程控制块（TCB）来存储进程的每个线程的状态。不过，与进程相比，我们在线程之间执行的上下文切换有一个主要区别：地址空间保持不变（即无需切换我们正在使用的页表）。 线程与进程的另一个主要区别与栈有关。在我们对传统进程（我们现在可以称之为单线程进程）地址空间的简单模型中，只有一个栈，通常位于地址空间的底部，如下图所示（左）。 但是，在多线程进程中，每个线程都是独立运行的，当然也会调用各种例程来完成自己的工作。地址空间中的堆栈不是单一的，而是每个线程都有一个。假设我们有一个多线程进程，其中有两个线程，那么产生的地址空间看起来就不一样了（上图右）。 从图中可以看到，在整个进程的地址空间中分布着两个栈。因此，任何栈分配的变量、参数、返回值以及其他我们放在栈上的东西都将被放在有时被称为线程本地存储的地方，即相关线程的栈中。 你可能还会注意到，这破坏了我们美丽的地址空间布局。以前，栈和堆可以独立增长，只有当地址空间空间不足时才会出现问题。在这里，我们不再有这样好的情况了。幸运的是，这通常没有问题，因为栈一般不需要很大（大量使用递归的程序除外）。 ","date":"2024-05-11","objectID":"/posts/19.%E5%B9%B6%E5%8F%91%E5%92%8C%E7%BA%BF%E7%A8%8B/:0:0","tags":["OS"],"title":"并发和线程","uri":"/posts/19.%E5%B9%B6%E5%8F%91%E5%92%8C%E7%BA%BF%E7%A8%8B/"},{"categories":["系统架构"],"content":"1 为什么要使用线程 在了解线程的细节和编写多线程程序时可能遇到的一些问题之前，让我们先回答一个更简单的问题。为什么要使用线程？ 事实证明，使用线程至少有两个主要原因。第一个原因很简单：并行性。想象一下，你正在编写一个对大型数组执行操作的程序，例如，将两个大型数组相加，或将数组中每个元素的值递增一定量。如果只在单个处理器上运行，任务就很简单：只需执行每个操作即可完成。但是，如果在多处理器系统上执行程序，则可以通过使用处理器分别执行部分操作来大大加快这一过程。将标准的单线程程序转换为能在多个 CPU 上完成此类工作的程序的任务称为并行化，而在每个 CPU 上使用一个线程来完成这项工作是使程序在现代硬件上运行得更快的一种自然而典型的方法。 第二个原因比较微妙：避免因 I/O 速度慢而导致程序进程受阻。想象一下，你正在编写一个执行不同类型 I/O 的程序：等待发送或接收消息，等待显式磁盘 I/O 完成，甚至（隐式）等待页面故障完成。与其等待，你的程序可能希望做其他事情，包括利用 CPU 进行计算，甚至发出更多 I/O 请求。使用线程是避免卡死的一种自然方法；当程序中的一个线程在等待（即等待 I/O 时被阻塞）时，CPU 调度器可以切换到其他线程，这些线程已经准备好运行并做一些有用的事情。线程可以使 I/O 与单个程序中的其他活动重叠，就像跨程序进程的多编程一样；因此，许多基于服务器的现代应用程序（网络服务器、数据库管理系统等）在其实现中都使用了线程。 当然，在上述任何一种情况下，你都可以使用多进程来代替线程。不过，线程共享地址空间，因此很容易共享数据，因此是构建这类程序时的自然选择。而对于逻辑上独立的任务，几乎不需要共享内存中的数据结构，进程则是更合理的选择。 ","date":"2024-05-11","objectID":"/posts/19.%E5%B9%B6%E5%8F%91%E5%92%8C%E7%BA%BF%E7%A8%8B/:1:0","tags":["OS"],"title":"并发和线程","uri":"/posts/19.%E5%B9%B6%E5%8F%91%E5%92%8C%E7%BA%BF%E7%A8%8B/"},{"categories":["系统架构"],"content":"2 示例：线程创建 让我们来了解一些细节。假设我们想运行一个程序，创建两个线程，每个线程都做一些独立的工作，在本例中就是打印 “A “或 “B”，代码如下。 #include \u003cstdio.h\u003e #include \u003cassert.h\u003e #include \u003cpthread.h\u003e #include \"common.h\" #include \"common_threads.h\" void *mythread(void *arg) { printf(\"%s\\n\", (char *) arg); return NULL; } int main(int argc, char *argv[]) { pthread_t p1, p2; printf(\"main: begin\\n\"); Pthread_create(\u0026p1, NULL, mythread, \"A\"); Pthread_create(\u0026p2, NULL, mythread, \"B\"); Pthread_join(p1, NULL); Pthread_join(p2, NULL); printf(\"main: end\\n\"); return 0; } 主程序创建了两个线程，每个线程都将运行函数 mythread()，但使用不同的参数（字符串 A 或 B）。线程创建后，可能会立即开始运行（取决于调度程序的奇思妙想）；也可能处于 “就绪 “状态，但不是 “运行 “状态，因此尚未运行。当然，在多处理器上，线程甚至可以同时运行，但我们先不要担心这种可能性。 创建两个线程（我们暂且称其为 T1 和 T2）后，主线程调用 pthread_join()，等待特定线程完成。它会这样做两次，从而确保 T1 和 T2 运行并完成，最后才允许主线程再次运行；当主线程运行时，它会打印 \"main: end\"并退出。总的来说，这次运行共使用了三个线程：主线程、T1 和 T2。 让我们来看看这个小程序可能的执行顺序。 在执行图中，时间向下递增，每一列表示不同线程（主线程、线程 1 或线程 2）运行的时间。 正如你所看到的，一种理解线程创建的方法是，它有点像函数调用；不过，系统并不是首先执行函数，然后返回给调用者，而是为被调用的例程创建一个新的执行线程，它独立于调用者运行，可能在从创建返回之前运行，但也可能更晚。下一步运行什么由操作系统调度程序决定，虽然调度程序很可能实现了某种合理的算法，但很难知道在任何给定时间内会运行什么。 ","date":"2024-05-11","objectID":"/posts/19.%E5%B9%B6%E5%8F%91%E5%92%8C%E7%BA%BF%E7%A8%8B/:2:0","tags":["OS"],"title":"并发和线程","uri":"/posts/19.%E5%B9%B6%E5%8F%91%E5%92%8C%E7%BA%BF%E7%A8%8B/"},{"categories":["系统架构"],"content":"3 为什么情况会变得更糟：共享数据 我们上面展示的简单线程示例很有用，它展示了线程是如何创建的，以及它们是如何根据调度程序的决定以不同顺序运行的。但它没有向你展示线程在访问共享数据时是如何交互的。 让我们想象一个简单的例子：两个线程希望更新一个全局共享变量，代码如下。 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cpthread.h\u003e #include \"common.h\" #include \"common_threads.h\" int max; volatile int counter = 0; // shared global variable void *mythread(void *arg) { char *letter = arg; int i; // stack (private per thread) printf(\"%s: begin [addr of i: %p]\\n\", letter, \u0026i); for (i = 0; i \u003c max; i++) { counter = counter + 1; // shared: only one } printf(\"%s: done\\n\", letter); return NULL; } int main(int argc, char *argv[]) { if (argc != 2) { fprintf(stderr, \"usage: main-first \u003cloopcount\u003e\\n\"); exit(1); } max = atoi(argv[1]); pthread_t p1, p2; printf(\"main: begin [counter = %d] [%x]\\n\", counter, (unsigned int) \u0026counter); Pthread_create(\u0026p1, NULL, mythread, \"A\"); Pthread_create(\u0026p2, NULL, mythread, \"B\"); // join waits for the threads to finish Pthread_join(p1, NULL); Pthread_join(p2, NULL); printf(\"main: done\\n [counter: %d]\\n [should: %d]\\n\", counter, max*2); return 0; } 首先，Pthread create() 只需调用 pthread create()，并确保返回代码为 0；如果不是，Pthread create() 只需打印一条信息并退出。其次，我们不再为工作线程使用两个独立的函数体，而是只使用一段代码，并向线程传递一个参数（在本例中是一个字符串），这样我们就可以让每个线程在其消息前打印不同的字母。 最后，也是最重要的一点，我们现在可以看看每个工作线程要做什么：在共享变量计数器中添加一个数字，并在一个循环中执行 1000 万次（1e7）。因此，我们想要的最终结果是：20,000,000。 现在我们编译并运行程序，看看它的运行情况。不幸的是，当我们运行这段代码时，即使在单个处理器上，我们也不一定能得到期望的结果。 ❯ make shared_data gcc -o shared_data shared_data.c -Wall ❯ ./shared_data 10000000 main: begin [counter = 0] [2b2c000] A: begin [addr of i: 0x16d362fac] B: begin [addr of i: 0x16d3eefac] A: done B: done main: done [counter: 10306439] [should: 20000000] 我们可以多运行几次，可以发现不仅每次运行都是错误的，而且得出的结果也不一样！还有一个大问题：为什么会出现这种情况？ ","date":"2024-05-11","objectID":"/posts/19.%E5%B9%B6%E5%8F%91%E5%92%8C%E7%BA%BF%E7%A8%8B/:3:0","tags":["OS"],"title":"并发和线程","uri":"/posts/19.%E5%B9%B6%E5%8F%91%E5%92%8C%E7%BA%BF%E7%A8%8B/"},{"categories":["系统架构"],"content":"4 问题的核心：不受控制的调度 要理解为什么会出现这种情况，我们必须了解编译器为更新counter而生成的代码序列。在本例中，我们希望简单地向counter添加一个数字 (1)。因此，这样做的代码序列可能是这样的（在 x86 中）； mov 0x8049a1c, %eax add $0x1, %eax mov %eax, 0x8049a1c 本例假设变量计数器位于地址 0x8049a1c。在这个三条指令序列中，首先使用 x86 mov 指令获取地址处的内存值，并将其放入寄存器 eax。然后执行 add 指令，将 eax 寄存器的内容加上 1 (0x1)，最后将 eax 的内容存储回相同地址的内存中。 假设两个线程中的一个（线程 1）进入了代码的这一区域，并准备将counter递增 1。它将counter的值（假设一开始是 50）加载到寄存器 eax 中。因此，线程 1 的寄存器 eax=50。然后在寄存器中加一，因此 eax=51 。 现在，不幸的事情发生了：定时器中断触发，操作系统将当前运行线程的状态（PC、包括 eax 在内的寄存器等）保存到线程的 TCB 中。现在更糟的事情发生了：线程 2 被选中运行，它也进入了这段代码。它也执行了第一条指令，获取了counter的值并将其放入 eax（记住：每个线程在运行时都有自己的专用寄存器；寄存器由上下文切换代码虚拟化，用于保存和恢复寄存器）。此时计数器的值仍然是 50，因此线程 2 的 eax=50。假设线程 2 执行了接下来的两条指令，将 eax 递增 1（因此 eax=51），然后将 eax 的内容保存到counter（地址 0x8049a1c）中。这样，全局变量计数器现在的值是 51。 最后，进行另一次上下文切换，线程 1 恢复运行。回想一下，线程 1 刚刚执行了 mov 和 add 指令，现在即将执行最后一条 mov 指令。还记得 eax=51。因此，执行了最后一条 mov 指令，并将值保存到内存中；计数器再次被设置为 51。 简单地说，发生的情况是这样的：counter递增的代码运行了两次，但counter从 50 开始，现在只等于 51。这个程序的 “正确 “版本应该是变量counter等于 52。 让我们看一下详细的执行跟踪，以便更好地理解这个问题。在这个示例中，假设上述代码加载到内存地址 100，就像下面的序列一样（注意：x86 有可变长度指令；mov 指令占用 5 字节内存，而 add 指令只占用 3 字节内存）： 100 mov 0x8049a1c, %eax 105 add $0x1, %eax 108 mov %eax, 0x8049a1c 如下图所示，假设计数器的起始值为 50，并跟踪此示例以确保了解发生了什么。 我们在这里演示的称为竞争条件（或更具体地说，数据竞争）：结果取决于代码的执行时机。如果运气不好（即上下文切换发生在执行过程中的不适时点），我们就会得到错误的结果。事实上，我们每次都可能得到不同的结果；因此，我们将这种结果称为不确定结果，而不是我们习惯于计算机中的良好确定性计算，即不知道输出是什么，并且在不同的运行中它确实可能会有所不同。 由于执行此代码的多个线程可能会导致竞争条件，因此我们将此代码称为临界区。临界区是访问共享变量（或更一般地说，共享资源）的一段代码，并且不能由多个线程同时执行。 对于这段代码，我们真正想要的是我们所说的互斥。这一属性保证如果一个线程在临界区内执行，其他线程将被阻止这样做。 ","date":"2024-05-11","objectID":"/posts/19.%E5%B9%B6%E5%8F%91%E5%92%8C%E7%BA%BF%E7%A8%8B/:4:0","tags":["OS"],"title":"并发和线程","uri":"/posts/19.%E5%B9%B6%E5%8F%91%E5%92%8C%E7%BA%BF%E7%A8%8B/"},{"categories":["系统架构"],"content":"5 对原子性的渴望 解决这个问题的一种方法是使用功能更强大的指令，只需一步就能完成我们需要完成的任何工作，从而消除不适时中断的可能性。例如，如果我们有这样一条超级指令： memory-add 0x8049a1c, $0x1 假设该指令向内存位置添加一个值，并且硬件保证它以原子方式执行；当指令执行时，它将根据需要执行更新。它不能在指令中间被中断，因为这正是我们从硬件得到的保证：当中断发生时，要么指令根本没有运行，要么已经运行完成；没有中间状态。 在这种情况下，“原子”意味着“作为一个单元”，有时我们将其视为“全部或无”。我们想要的是原子地执行三个指令序列： mov 0x8049a1c, %eax add $0x1, %eax mov %eax, 0x8049a1c 正如我们所说，如果我们有一条指令来执行此操作，我们只需发出该指令即可完成。但一般情况下，我们不会有这样的指令。想象一下我们正在构建一个并发 B 树，并希望更新它；我们真的希望硬件支持“B 树原子更新”指令吗？可能不是，至少在健全的指令集中是这样。 因此，我们要做的是向硬件请求一些有用的指令，根据这些指令我们可以构建一组我们称之为同步原语的通用指令。通过使用这种硬件支持，并结合操作系统的一些帮助，我们将能够构建以同步和受控方式访问临界区的多线程代码，从而可靠地产生正确的结果，尽管并发执行具有挑战性。 ","date":"2024-05-11","objectID":"/posts/19.%E5%B9%B6%E5%8F%91%E5%92%8C%E7%BA%BF%E7%A8%8B/:5:0","tags":["OS"],"title":"并发和线程","uri":"/posts/19.%E5%B9%B6%E5%8F%91%E5%92%8C%E7%BA%BF%E7%A8%8B/"},{"categories":["系统架构"],"content":"6 另一个问题：等待另一个线程 本章在讨论并发问题时，将线程间的交互设定为只有一种类型，即访问共享变量和需要支持临界区的原子性。事实证明，还有另一种常见的交互，即一个线程必须等待另一个线程完成某些操作后才能继续。例如，当一个线程执行磁盘 I/O 并进入休眠状态时，就会出现这种交互；当 I/O 完成后，该线程需要从沉睡中被唤醒，以便继续运行。有时，多个线程的操作应该是同步的。许多线程在数值问题中并行执行迭代， 所有线程应立即开始下一次迭代（屏障） ，此睡眠/唤醒周期将由条件变量控制。 关键并发术语：临界区、竞争条件、不确定性、互斥 这四个术语对于并发代码非常重要 临界区是访问共享资源（通常是变量或数据结构）的一段代码。 如果多个执行线程大致同时进入临界区，则会出现竞争条件（或数据竞争）。两者都尝试更新共享数据结构，导致不符合期望的结果。 不确定程序由一个或多个竞争条件组成；程序的输出每次运行都会有所不同，具体取决于运行的线程。因此，结果是不确定性的，这与我们通常从计算机系统中期望的情况不同。 为了避免这些问题，线程应该使用某种互斥原语；这样做可以保证只有一个线程进入临界区，从而避免竞争，并产生确定性的程序输出。 ","date":"2024-05-11","objectID":"/posts/19.%E5%B9%B6%E5%8F%91%E5%92%8C%E7%BA%BF%E7%A8%8B/:6:0","tags":["OS"],"title":"并发和线程","uri":"/posts/19.%E5%B9%B6%E5%8F%91%E5%92%8C%E7%BA%BF%E7%A8%8B/"},{"categories":["系统架构"],"content":"在结束对虚拟内存的研究之前，让我们仔细看看整个虚拟内存系统是如何组合起来的。我们已经看到了此类系统的关键要素，包括大量页表设计、与 TLB 的交互（有时甚至由操作系统本身处理），以及决定将哪些页保留在内存中、将哪些页踢出内存的策略。然而，还有许多其他特性构成了一个完整的虚拟内存系统，其中包括许多性能、功能和安全特性。这就是我们的关键所在：如何构建完整的虚拟内存系统？实现完整的虚拟内存系统需要哪些功能？它们如何提高性能、增强安全性或改进系统？ 为此，我们将介绍两个系统。第一个系统是 “现代 “虚拟内存管理器的最早范例之一，即 20 世纪 70 年代和 80 年代初开发的 VAX/VMS 操作系统 。有些想法，即使是 50 年前的想法，仍然值得了解，这种想法对于大多数其他领域（如物理学）的人来说是众所周知的，但在技术驱动型学科（如计算机科学）中却不得不说。 其次是 Linux，原因显而易见。Linux 是一种广泛使用的系统，可以在小到功率不足的手机系统，大到现代数据中心中最具扩展性的多核系统上有效运行。因此，其虚拟机系统必须足够灵活，以便在所有这些场景中成功运行。我们将对每个系统进行讨论，以说明如何将前面章节中提出的概念整合到一个完整的内存管理器中。 ","date":"2024-04-25","objectID":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/:0:0","tags":["OS"],"title":"完整VM系统","uri":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"1 VAX/VMS 虚拟内存 VAX-11 微型计算机体系结构由Digital Equipment Corporation (DEC) 于 20 世纪 70 年代末推出。在微型计算机时代，DEC 是计算机行业的巨头；不幸的是，一系列错误的决策和 PC 的出现慢慢地（但肯定地）导致了它们的消亡，。该架构有多种实现形式，包括 VAX-11/780 和功能较弱的 VAX-11/750。 该系统的操作系统被称为 VAX/VMS（或简称 VMS），其主要设计者之一是 Dave Cutler，他后来领导开发了微软的 Windows NT [C93]。VMS 存在一个普遍的问题，即它可以在各种机器上运行，包括非常便宜的 VAXen（是的，这是正确的复数）到同一架构系列中的极其高端和强大的机器。因此，操作系统必须拥有能够在如此广泛的系统中发挥作用（并且运作良好）的机制和策略。 另外一个问题是，VMS 是利用软件创新来掩盖体系结构固有缺陷的一个极好例子。尽管操作系统经常依赖硬件来构建有效的抽象和幻象，但有时硬件设计者并不能完全做到万无一失；在 VAX 硬件中，我们将看到一些这样的例子，以及 VMS 操作系统是如何克服这些硬件缺陷来构建一个有效的、可运行的系统的。 ","date":"2024-04-25","objectID":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/:1:0","tags":["OS"],"title":"完整VM系统","uri":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"1.1 内存管理硬件 VAX-11 为每个进程提供 32 位虚拟地址空间，分为 512 字节页。因此，虚拟地址由 23 位 VPN 和 9 位偏移量组成。此外，VPN 的上两位用于区分页面所在的分段；因此，如前所述，该系统是分页和分段的混合体。 地址空间的下半部分被称为 “进程空间”，每个进程都是唯一的。在进程空间的前半部分（称为 P0），可以找到用户程序以及向下增长的堆。在进程空间的后半部（P1），我们可以找到向上生长的栈。地址空间的上半部分称为系统空间（S），但只有一半被使用。受保护的操作系统代码和数据存放在这里，操作系统以这种方式在各进程间共享。 VMS 设计人员的一个主要顾虑是，VAX 硬件中的页面大小（512 字节）小得令人难以置信。由于历史原因而选择的这种大小存在一个基本问题，即简单的线性页表过于庞大。因此，VMS 设计人员的首要目标之一就是确保 VMS 不会因为页表而使内存不堪重负。系统通过两种方式减轻了页表对内存的压力。首先，VAX-11 将用户地址空间划分为两个区域，VAX-11为每个进程的每个区域（P0 和 P1）提供一个页表；因此，栈和堆之间未使用的地址空间部分不需要页表空间。基址寄存器和边界寄存器的使用正如你所期望的那样；基址寄存器保存该段的页表地址，边界寄存器保存其大小（即页表条目数）。 其次，操作系统将用户页表（P0 和 P1，每个进程两个）置于内核虚拟内存中，从而进一步降低了内存压力。因此，在分配或增长页表时，内核会从自己的虚拟内存 S 段中分配空间。如果内存压力过大，内核可以将这些页表的页交换到磁盘，从而将物理内存用于其他用途。 将页表放在内核虚拟内存中意味着地址转换变得更加复杂。例如，要转换 P0 或 P1 中的虚拟地址，硬件必须首先尝试在其页表（该进程的 P0 或 P1 页表）中查找该页的页表条目；但在此过程中，硬件可能必须首先查阅系统页表（位于物理内存中）；完成转换后，硬件才能了解页表中的页面地址，然后最终了解所需内存访问的地址。幸运的是，VAX 硬件管理的 TLB 使所有这一切都变得更快，通常（希望）可以避免这种费力的查找。 ","date":"2024-04-25","objectID":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/:1:1","tags":["OS"],"title":"完整VM系统","uri":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"2 真实的地址空间 研究 VMS 的一个好处是，我们可以看到真实地址空间是如何构建的，如下图所示。 到目前为止，我们假设的地址空间很简单，只有用户代码、用户数据和用户堆，但正如上文所述，真实的地址空间要复杂得多。例如，代码段永远不会从第 0 页开始，而是标记为不可访问，以便为检测空指针访问提供一些支持。因此，在设计地址空间时，需要考虑的一个问题就是对调试的支持，而不可访问的 0 页在某种程度上提供了这种支持。 为什么空指针访问会导致 SEG 错误？ 你现在应该对解引用空指针时发生的情况有了很好的了解。一个进程生成了一个虚拟地址 0，具体方法如下： int *p = NULL; // set p = 0 *p = 10; // try to store 10 to virtual addr 0 硬件尝试在 TLB 中查找 VPN（此处也是 0），结果导致 TLB 未命中。查阅页表后发现，VPN 0 的条目被标记为无效。这样，我们就有了一个无效访问，它将控制权转移到操作系统，而操作系统可能会终止进程（在 UNIX 系统中，进程会收到一个信号，允许它们对此类故障做出反应；但如果未被捕获，进程就会被杀死）。 也许更重要的是，内核虚拟地址空间（即其数据结构和代码）是每个用户地址空间的一部分。在上下文切换时，操作系统会更改 P0 和 P1 寄存器，使其指向即将运行的进程的相应页表；但不会更改 S 基寄存器和边界寄存器，因此 “相同的 “内核结构会映射到每个用户地址空间。 内核被映射到每个地址空间的原因有很多。举例来说，当操作系统从用户程序（例如在 write() 系统调用中）得到一个指针时，很容易将指针中的数据复制到自己的结构中。操作系统是自然编写和编译的，无需担心访问的数据来自何处。相反，如果内核完全位于物理内存中，就很难做到将页表中的页面交换到磁盘这样的事情；如果内核有自己的地址空间，在用户应用程序和内核之间移动数据又会变得复杂而痛苦。有了这种结构（现在被广泛使用），内核几乎就成了应用程序的一个库，尽管是受保护的库。 关于这个地址空间的最后一点与保护有关。显然，操作系统不希望用户应用程序读写操作系统的数据或代码。因此，硬件必须为页面提供不同的保护级别。VAX 就是这样做的，它在页表的保护位中规定了 CPU 访问特定页面必须达到的权限级别。因此，系统数据和代码的保护级别要高于用户数据和代码；如果试图从用户代码访问此类信息，就会向操作系统发出中断，违规进程很可能会被终止。 ","date":"2024-04-25","objectID":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/:2:0","tags":["OS"],"title":"完整VM系统","uri":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"2.1 页面替换 VAX 中的页表项 (PTE) 包含以下位：一个有效位、一个保护字段（4 位）、一个修改（或脏）位、一个保留给操作系统使用的字段（5 位），最后是一个物理页号（PFN），用于存储页在物理内存中的位置。精明的读者可能会注意到：没有引用位！因此，VMS 替换算法必须在没有硬件支持的情况下确定哪些页面处于活动状态。 模拟参考位 事实证明，你并不需要硬件引用位来获得系统中正在使用的页面的概念。事实上，早在 20 世纪 80 年代初，Babaoglu 和 Joy 就证明 VAX 的保护位可以用来模拟参考位。基本原理：如果想了解系统中哪些页面正在被活跃使用，可将页表中的所有页面标记为不可访问（但保留进程真正可访问的页面信息，可能在页表条目的 “保留操作系统字段 “部分）。当进程访问页面时，它将向操作系统发出一个中断；然后操作系统将检查该页面是否真的应该被访问，如果是，则将该页面恢复到正常的保护状态（如只读或读写）。在替换时，操作系统可以检查哪些页面仍然标记为不可访问，从而了解哪些页面最近没有被使用过。这种引用位 “仿真 “的关键在于减少开销，同时还能很好地了解页面的使用情况。操作系统在标记页面不可访问时不能过于激进，否则开销会过高。操作系统在标记页面时也不能太被动，否则所有页面最终都会被引用；操作系统也无法很好地知道应该驱逐哪个页面。 开发人员还担心内存占用者，即占用大量内存并导致其他程序难以运行的程序。迄今为止，我们已经研究过的大多数策略都很容易出现这种占用内存的情况；例如，LRU 是一种全局策略，不能在进程之间公平地共享内存。 为了解决这两个问题，开发人员提出了分段 FIFO 替换策略。这种策略的思路很简单：每个进程在内存中可保留的最大页数，即常驻集大小（RSS）。每个页面都保存在一个先进先出列表中；当一个进程超过其 RSS 时，“先进 “的页面就会被驱逐。FIFO 显然不需要任何硬件支持，因此很容易实现。 当然，正如我们前面所看到的，纯粹的 FIFO 性能并不是特别好。为了提高 FIFO 的性能，VMS 引入了两个二次机会列表，即全局的干净页面列表和 脏页面 列表，用于放置从内存中驱逐前的页面。当进程 P 超过其 RSS 时，会从其每个进程的 FIFO 中移除一个页面；如果是干净页面（未修改），则将其放在干净页面列表的末尾；如果是脏页面（已修改），则将其放在脏页面列表的末尾。 如果另一个进程 Q 需要一个空闲页面，它会从全局干净页面列表中获取第一个空闲页面。但是，如果原进程 P 在该页被回收前发生错误，P 会从空闲（或脏页）列表中回收该页，从而避免了代价高昂的磁盘访问。这些全局二次机会列表越大，分段 FIFO 算法的性能就越接近 LRU。 VMS 中使用的另一种优化方法也有助于克服 VMS 中的小页面问题。具体来说，由于页面太小，磁盘在交换过程中的 I/O 效率会非常低，因为磁盘在进行大容量传输时效率更高。为了提高交换 I/O 的效率，VMS 增加了许多优化功能，其中最重要的是集群功能。通过集群，VMS 将全局脏页面列表中的大批量页面集中在一起，然后一次性将它们写入磁盘（从而使它们变得干净）。集群技术在大多数现代系统中都得到了应用，因为可以自由地将页面放置在交换空间的任何位置，这使得操作系统可以对页面进行分组，执行更少、更大的写入操作，从而提高性能。 ","date":"2024-04-25","objectID":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/:2:1","tags":["OS"],"title":"完整VM系统","uri":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"2.2 其他妙招 VMS 还有两个现在已成为标准的技巧：需求清零和写时复制。现在我们就来介绍一下这些懒惰优化。VMS（以及大多数现代系统）中的一种懒惰形式是页面的需求清零。为了更好地理解这一点，让我们以在地址空间（比如在堆中）中添加一个页面为例。在最简单的实现中，操作系统会在物理内存中找到一个页面，将其清零（这是为了安全起见，否则你就能看到其他进程使用该页面时页面上的内容了！），然后将其映射到地址空间（即设置页表，以便根据需要引用该物理页面），以此来响应向堆中添加页面的请求。但这种天真的实现方式代价高昂，尤其是当该页面未被进程使用时。 通过需求清零，当页面被添加到地址空间时，操作系统只需做很少的工作；它会在页表中添加一个条目，标记该页面不可访问。如果进程读取或写入该页面，操作系统就会收到一个中断。在处理中断时，操作系统会注意到（通常是通过在页表项的 “为操作系统保留 “部分标记的某些位）这实际上是一个需要清零的页面；此时，操作系统会进行必要的工作，找到一个物理页，将其清零，并映射到进程的地址空间中。如果进程从不访问该页，所有这些工作都可以避免，这就是需求清零的优点。 VMS 中另一个很酷的优化（同样，几乎所有现代操作系统中都有这种优化）是写时复制（简称 COW）。这个概念至少可以追溯到 TENEX 操作系统，它的原理很简单：当操作系统需要将一个页面从一个地址空间复制到另一个地址空间时，它可以不复制该页面，而是将其映射到目标地址空间，并在两个地址空间中都标记为只读。如果两个地址空间都只读取该页面，则不会采取进一步的操作，这样操作系统就实现了快速复制，而实际上没有移动任何数据。 但是，如果其中一个地址空间确实尝试向该页面写入数据，则会向操作系统发出中断。操作系统会注意到该页是 COW 页，从而（懒散地）分配一个新页，将数据填入其中，并将这个新页映射到故障进程的地址空间。然后该进程继续运行，现在它拥有自己的页面私有副本。 由于多种原因，COW 非常有用。当然，任何类型的共享库都可以通过写时复制映射到许多进程的地址空间，从而节省宝贵的内存空间。在 UNIX 系统中，由于 fork() 和 exec() 的语义，COW 甚至更为重要。你可能还记得，fork() 会创建一个调用者地址空间的精确副本；如果地址空间很大，创建这样的副本既慢又耗费数据。更糟糕的是，大部分地址空间会立即被后续的 exec() 调用所覆盖，这将使调用进程的地址空间与即将执行的程序的地址空间重叠。通过执行写入时复制 fork()，操作系统避免了大部分不必要的复制，从而在提高性能的同时保留了正确的语义。 ","date":"2024-04-25","objectID":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/:2:2","tags":["OS"],"title":"完整VM系统","uri":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3 Lnux 虚拟内存系统 现在我们将讨论 Linux VM 系统的一些更有趣的方面。 Linux 的发展是由真正的工程师解决生产中遇到的实际问题推动的，因此大量的功能已经慢慢地融入到现在功能齐全、功能齐全的虚拟内存系统中。 虽然我们无法讨论 Linux VM 的各个方面，但我们将讨论最重要的方面，特别是它超出了 VAX/VMS 等经典 VM 系统中的范围。我们还将尝试强调 Linux 和旧系统之间的共性。 在本次讨论中，我们将重点关注适用于 Intel x86 的 Linux。虽然 Linux 可以而且确实在许多不同的处理器架构上运行，但 x86 上的 Linux 是其最主要和最重要的部署，因此也是我们关注的焦点。 ","date":"2024-04-25","objectID":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/:3:0","tags":["OS"],"title":"完整VM系统","uri":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3.1 Linux 地址空间 与其他现代操作系统和 VAX/VMS 一样，Linux 虚拟地址空间由用户部分（用户程序代码、栈、堆和其他部分所在）和内核部分（内核代码、栈、堆和其他部分所在）组成。与其他系统一样，在上下文切换时，当前运行的地址空间的用户部分会发生变化；而内核部分则在不同进程中保持不变。与其他系统一样，在用户模式下运行的程序也无法访问内核虚拟页；只有进入内核并转换到特权模式，才能访问这些内存。 在经典的 32 位 Linux（即具有 32 位虚拟地址空间的 Linux）中，用户和内核地址空间的分割发生在地址 0xC0000000，即地址空间的四分之三处。因此，虚拟地址 0 到 0xBFFFFFFF 是用户虚拟地址；其余的虚拟地址（0xC0000000 到 0xFFFFFFFF）属于内核虚拟地址空间。64 位 Linux 也有类似的分割，但分割点略有不同。 下图 显示了典型（简化）地址空间的描述。 Linux 的一个有趣之处在于它包含两种内核虚拟地址。第一种称为内核逻辑地址 。内核代码只需调用 kmalloc 即可获得更多此类内存。大多数内核数据结构都在这里，如页表、每个进程的内核栈等。与系统中的大多数其他内存不同，内核逻辑内存不能交换到磁盘。 内核逻辑地址最有趣的地方在于它们与物理内存的联系。具体来说，内核逻辑地址与物理内存的第一部分之间存在直接映射关系。因此，内核逻辑地址 0xC0000000 相当于物理地址 0x00000000，0xC0000FFF 相当于 0x00000FFF，以此类推。这种直接映射有两个意义。首先，在内核逻辑地址和物理地址之间来回转换非常简单；因此，这些地址通常被当作物理地址来处理。其次，如果一块内存在内核逻辑地址空间中是连续的，那么它在物理内存中也是连续的。这使得在内核地址空间的这一部分分配的内存适用于需要连续物理内存才能正常工作的操作，例如通过目录内存访问 (DMA) 进行设备间的 I/O 传输。 另一种内核地址是内核虚拟地址。要获取这种类型的内存，内核代码会调用不同的分配器 vmalloc，该分配器会返回一个指向所需大小的虚拟连续区域的指针。与内核逻辑内存不同，内核虚拟内存通常不是连续的；每个内核虚拟页都可能映射到非连续的物理页（因此不适合 DMA）。不过，这样的内存更容易分配，因此可用于大型缓冲区，而要在这些缓冲区中找到连续的大块物理内存则非常困难。 在 32 位 Linux 中，内核虚拟地址存在的另一个原因是，它们能让内核寻址超过（大约）1 GB 的内存。多年前，机器的内存比现在少得多，因此访问超过 1 GB 的内存不是问题。然而，随着技术的进步，很快就需要让内核使用更大的内存。内核虚拟地址和它们与物理内存一对一的严格映射关系使这成为可能。不过，随着向 64 位 Linux 迁移，这种需求就不那么迫切了，因为内核不再局限于最后 1 GB 的虚拟地址空间。 ","date":"2024-04-25","objectID":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/:3:1","tags":["OS"],"title":"完整VM系统","uri":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3.2 页表结构 由于我们关注的是 x86 的 Linux，因此我们的讨论将围绕 x86 提供的页表结构类型展开，因为它决定了 Linux 能做什么、不能做什么。如上所述，x86 提供了一种硬件管理的多级页表结构，每个进程有一个页表；操作系统只需在内存中设置映射，将特权寄存器指向页目录的起始位置，剩下的就交给硬件处理了。操作系统会在进程创建、删除和上下文切换时参与其中，确保硬件 MMU 在每种情况下都使用正确的页表进行转换。 近年来最大的变化可能就是从 32 位 x86 迁移到 64 位 x86（如上文所述）。正如在 VAX/VMS 系统中看到的那样，32 位地址空间已经存在了很长时间，随着技术的变化，它们终于开始成为程序的真正限制。虚拟内存使系统编程变得容易，但由于现代系统包含许多 GB 内存，32 位已不足以引用每个内存。因此，下一次飞跃成为必要。 迁移到 64 位地址会以预期的方式影响 x86 中的页表结构。因为 x86 使用的是多级页表，而当前的 64 位系统使用的是四级页表。不过，虚拟地址空间的全部 64 位尚未使用，而仅使用了最下面的 48 位。因此，虚拟地址可以这样理解： 如图所示，虚拟地址的前 16 位未使用（因此在转换中不起作用），后 12 位（由于 4 KB 页面大小）用作偏移量（因此直接使用，没有转换），留下虚拟地址的中间36位参与转换。地址的 P1 部分用于索引最顶层的页目录，并且从那里开始进行转换，一次一层，直到页表的实际页被 P4 索引，产生所需的页表条目。 随着系统内存变得更大，这个庞大的地址空间的更多部分将被启用，从而导致五级和最终六级页表树结构。想象一下：一个简单的页表查找需要六级转换，只是为了找出某个数据在内存中的位置。 ","date":"2024-04-25","objectID":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/:3:2","tags":["OS"],"title":"完整VM系统","uri":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3.3 大页面支持 Intel x86 允许使用多种页面大小，而不仅仅是标准的 4 KB 页面。具体来说，最近的设计在硬件中支持 2 MB 甚至 1 GB 页面。因此，随着时间的推移，Linux 已经发展到允许应用程序利用这些大页面。正如前面所暗示的，使用大页面会带来很多好处。正如 VAX/VMS 中所见，这样做可以减少页表中所需的映射数量；页面越大，映射越少。然而，较少的页表条目并不是大页面背后的驱动力；相反，它是更好的 TLB 行为和相关的性能提升。 当进程主动使用大量内存时，它会很快用转换填满 TLB。如果这些转换针对 4 KB 页面，则只能访问少量的总内存，而不会导致 TLB 未命中。其结果是，对于在具有许多GB内存的机器上运行的现代“大内存”工作负载来说，会带来显著的性能成本；最近的研究表明，一些应用程序将其周期的10%用于服务TLB未命中。 大页面允许进程通过使用 TLB 中较少的槽来访问大片内存而不会发生 TLB 未命中，因此这是主要优点。然而，大页面还有其他好处：TLB 未命中路径较短，这意味着当发生 TLB 未命中时，可以更快地对其进行处理。此外，分配可以非常快（在某些情况下），这是一个很小但有时很重要的好处。 Linux 对大页面的支持的一个有趣的方面是它是如何逐步实现的。起初，Linux 开发人员知道这种支持仅对少数应用程序很重要，例如具有严格性能要求的大型数据库。因此，决定允许应用程序显式请求大页面内存分配（通过 mmap() 或 shmget() 调用）。这样，大多数应用程序将不受影响（并且继续仅使用 4 KB 页面；一些要求较高的应用程序将不得不更改为使用这些接口，但对它们来说这是值得的。 最近，由于许多应用程序对更好的 TLB 行为的需求更加普遍，Linux 开发人员添加了透明大页面支持。启用此功能后，操作系统会自动寻找机会分配大页面（通常为 2 MB，但在某些系统上为 1 GB），而无需修改应用程序。 大页面并非没有代价。最大的潜在成本是内部碎片，即页面很大但很少使用。这种形式的浪费可能会用大量但很少使用的页面填充内存。交换（如果启用）也不能很好地处理大页面，有时会大大增加系统的 I/O 量。分配的开销也可能很糟糕（在某些其他情况下）。总的来说，有一件事是明确的：多年来为系统提供良好服务的 4 KB 页面大小不再像以前那样是通用解决方案；不断增长的内存大小要求我们将大页面和其他解决方案视为虚拟内存系统必要发展的一部分。 Linux 对这种基于硬件的技术的缓慢采用证明了即将发生的变化。 ","date":"2024-04-25","objectID":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/:3:3","tags":["OS"],"title":"完整VM系统","uri":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3.4 页面缓存 为了降低访问持久存储的成本，大多数系统使用积极的缓存子系统将常用的数据项保留在内存中。在这方面，Linux 与传统操作系统没有什么不同。 Linux 页面缓存是统一的，将来自三个主要来源的页面保留在内存中：内存映射文件、来自设备的文件数据和元数据（通常通过直接对文件系统进行 read() 和 write() 调用来访问）以及堆和栈组成每个进程的页面（有时称为匿名内存，因为它下面没有命名文件，而是交换空间）。这些实体保存在页面缓存哈希表中，以便在需要所述数据时可以快速查找。 内存映射的普遍性 内存映射早于 Linux 出现了好几年，并在 Linux 和其他现代系统中的许多地方使用。这个想法很简单：通过在已经打开的文件描述符上调用 mmap()，进程将返回一个指向文件内容似乎所在的虚拟内存区域开头的指针。然后，通过使用该指针，进程可以通过简单的指针解引用来访问文件的任何部分。 对内存映射文件中尚未进入内存的部分的访问会触发页面错误，此时操作系统将分页相关数据，并通过相应地更新进程的页表来使其可访问（即，请求分页） ）。 每个常规 Linux 进程都使用内存映射文件，即使 main() 中的代码也不会直接调用 mmap()，因为 Linux 将代码从可执行文件和共享库代码加载到内存中。下面是 pmap 命令行工具的（高度缩写）输出，它显示了哪些不同的映射构成了正在运行的程序（shell，在本例中为 tcsh）的虚拟地址空间。输出显示四列：映射的虚拟地址、其大小、区域的保护位以及映射源： 映射的虚拟地址 大小 区域的保护位 映射源 0000000000400000 372K r-x– tcsh 00000000019d5000 1780K rw— [anon] 00007f4e7cf06000 1792K r-x– libc-2.23.so 00007f4e7d2d0000 36K r-x– libcrypt-2.23.so 00007f4e7d508000 148K r-x– libtinfo.so.5.9 00007f4e7d731000 152K r-x– ld-2.23.so 00007f4e7d932000 16K rw— [stack] 正如你可以看到的输出中，来自 tcsh 二进制文件的代码以及来自 libc、libcrypt、libtinfo 的代码以及来自动态链接器本身 (ld.so) 的代码都映射到地址空间。还存在两个匿名区域：堆（第二个条目，标记为 anon）和栈（标记为 stack）。内存映射文件为操作系统构建现代地址空间提供了一种简单有效的方法 页面缓存会跟踪条目是否干净（读取但未更新）或脏（又称修改）。脏数据由后台线程（称为 pdflush）定期写入后备存储（即，写入文件数据的特定文件，或交换匿名区域的空间），从而确保修改后的数据最终被写回持久存储。此后台活动要么在特定时间段后发生，要么在太多页面被视为脏页时发生（均为可配置参数）。 在某些情况下，系统运行时内存不足，Linux 必须决定从内存中剔除哪些页面以释放空间。为此，Linux 使用 2Q 替换的改进形式，我们在此进行描述。 基本思想很简单：标准 LRU 替换是有效的，但可能会被某些常见的访问模式颠覆。例如，如果一个进程重复访问一个大文件（尤其是接近内存大小或更大的文件），LRU 会将所有其他文件踢出内存。更糟糕的是：将该文件的部分内容保留在内存中没有用，因为它们在被踢出内存之前永远不会被重新引用。 Linux 版本的 2Q 替换算法通过保留两个列表并在它们之间划分内存来解决这个问题。第一次访问时，一个页面被放入一个队列（原论文中称为A1，但Linux中为非活动列表）；当它被重新引用时，该页面会被提升到另一个队列（原来称为Aq，但在Linux中称为活动列表）。当需要进行替换时，从非活动列表中取出替换候选者。 Linux 还定期将页面从活动列表底部移动到非活动列表，使活动列表保持在总页面缓存大小的三分之二左右。 理想情况下，Linux 会以完美的 LRU 顺序管理这些列表，但是，正如前面章节中所讨论的，这样做的成本很高。因此，与许多操作系统一样，使用 LRU 的近似值（类似于时钟替换）。 这种 2Q 方法的行为通常与 LRU 非常相似，但在处理循环访问大文件的情况时，其显著特点是将循环访问的页面限制在非活动列表中。由于这些页面在被踢出内存之前从未被重新引用过，因此它们不会冲掉活动列表中的其他有用页面。 ","date":"2024-04-25","objectID":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/:3:4","tags":["OS"],"title":"完整VM系统","uri":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3.5 安全和缓冲区溢出 现代 VM 系统（Linux、Solaris 或 BSD 变体之一）与古代 VM 系统（VAX/VMS）之间的最大区别可能是现代对安全性的重视。保护一直是操作系统的一个严重问题，但随着机器的互联程度比以往任何时候都更加紧密，开发人员实施了各种防御对策来阻止那些狡猾的黑客获得系统控制权也就不足为奇了。 缓冲区溢出攻击是一种主要威胁，它可以针对普通用户程序甚至内核本身。这些攻击的目的是找到目标系统中的错误，使攻击者可以将任意数据注入目标的地址空间。有时会出现此类漏洞，因为开发人员（错误地）假设输入不会太长，因此（可信地）将输入复制到缓冲区中；因为输入实际上太长，所以它会溢出缓冲区，从而覆盖目标的内存。像下面这样无辜的代码可能是问题的根源： int some_function(char *input) { char dest_buffer[100]; strcpy(dest_buffer, input); // oops, unbounded copy! } 在许多情况下，这种溢出并不会造成灾难性后果，例如，无意地向用户程序甚至操作系统提供不良输入可能会导致系统崩溃，但不会更糟。然而，恶意程序员可以精心设计使缓冲区溢出的输入，以便将自己的代码注入目标系统，从而接管系统并为所欲为。如果攻击网络连接的用户程序成功，攻击者就可以在被攻击的系统上运行任意计算，甚至出租计算资源；如果攻击操作系统本身成功，攻击者就可以访问更多资源，这就是所谓的权限升级（即用户代码获得内核访问权限）。 防止缓冲区溢出的第一道也是最简单的一道防线就是防止在地址空间的特定区域（如栈内）执行任何代码。AMD 在其 x86 版本中引入的 NX 位（No-eXecute 的缩写）（英特尔版本中也有类似的 XD 位）就是这样一种防御措施；它只需阻止在相应页表条目中设置了该位的任何页面的执行。这种方法可以防止攻击者注入目标栈的代码被执行，从而减轻了问题。 然而，聪明的攻击者是……聪明的，即使攻击者不能显示添加注入的代码，恶意代码也能执行任意代码序列。这种想法以其最普遍的形式被称为返回导向编程（return-oriented programming, ROP）[S07]，它确实非常出色。ROP 背后的原理是，任何程序的地址空间中都有大量的代码位（用 ROP 术语来说就是小工具），尤其是与庞大的 C 库链接的 C 程序。因此，攻击者可以覆盖栈，使当前执行函数中的返回地址指向所需的恶意指令（或一系列指令），然后再返回指令。通过串联大量小工具（即确保每次返回都跳转到下一个小工具），攻击者可以执行任意代码。 为了抵御 ROP（包括其早期形式，返回到库攻击（return-to-libc 攻击）），Linux（和其他系统）增加了另一种防御手段，即地址空间布局随机化（ASLR）。操作系统不是将代码、栈和堆放在虚拟地址空间内的固定位置，而是将它们的位置随机化，从而使实现这类攻击所需的复杂代码序列变得相当具有挑战性。因此，针对易受攻击的用户程序的大多数攻击都会导致程序崩溃，但无法控制运行中的程序。 有趣的是，在实践中可以很容易地观察到这种随机性。下面是一段在现代 Linux 系统上演示的代码： int main(int argc, char *argv[]) { int stack = 0; printf(\"%p\\n\", \u0026stack); return 0; } 这段代码只是打印出堆栈中变量的（虚拟）地址。在较早的非 ASLR 系统中，该值每次都是相同的。但如下所示，每次运行时，该值都会发生变化： \u003e ./random 0x7ffd3e55d2b4 \u003e ./random 0x7ffe1033b8f4 \u003e ./random 0x7ffe45522e94 ASLR 对于用户级程序来说是一种非常有用的防御手段，因此它也被纳入了内核，并被称为内核地址空间布局随机化（KASLR）。然而，事实证明，内核可能有更大的问题需要处理，正如我们接下来要讨论的那样。 ","date":"2024-04-25","objectID":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/:3:5","tags":["OS"],"title":"完整VM系统","uri":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"3.6 其他安全问题：熔断漏洞和幽灵漏洞 系统安全世界已经被两个新的相关攻击颠覆了。第一个叫做 “熔毁”（Meltdown），第二个叫做 “幽灵”（Spectre）。它们是由四组不同的研究人员/工程师在差不多同一时间发现的，并引发了对计算机硬件和上述操作系统所提供的基本保护措施的深刻质疑。有关每种攻击的详细描述，请参见 meltdownattack.com 和 spectreattack.com。幽灵被认为是这两种攻击中问题较多的一种。 这些攻击所利用的一般弱点是，现代系统中的 CPU 会在幕后执行各种疯狂的技巧来提高性能。其中一类技术是问题的核心，被称为 “预测执行”，即 CPU 猜测哪些指令将在未来执行，并提前开始执行。如果猜测正确，程序运行速度就会加快；如果猜测不正确，CPU就会撤消这些指令对架构状态（如寄存器）的影响，并再次尝试执行，这一次会沿着正确的路径运行。 预测的问题在于，它往往会在系统的各个部分（如处理器缓存、分支预测器等）留下执行痕迹。因此，问题就出现了：正如攻击事件的作者所展示的，这种状态会使内存内容变得脆弱，甚至是我们认为受到 MMU 保护的内存。 因此，加强内核保护的一个途径就是尽可能地将内核地址空间从每个用户进程中移除，转而为大多数内核数据建立一个独立的内核页表（称为内核页表隔离，或 KPTI）[G+17]。这样，内核的代码和数据结构就不再映射到每个进程中，而是只保留最基本的部分；当切换到内核时，就需要切换到内核页表。这样做提高了安全性，避免了一些攻击向量，但也付出了代价：性能。切换页表的代价很高。安全的代价：方便和性能。 不幸的是，KPTI 并不能解决上述所有安全问题，只能解决部分问题。而简单的解决方案，如关闭预测功能，也没有多大意义，因为系统运行速度会降低数千倍。 ","date":"2024-04-25","objectID":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/:3:6","tags":["OS"],"title":"完整VM系统","uri":"/posts/18.%E5%AE%8C%E6%95%B4vm%E7%B3%BB%E7%BB%9F/"},{"categories":["系统架构"],"content":"在虚拟内存管理器中，当您拥有大量可用内存时，生活会很容易。发生页面错误时，您在空闲页面列表中找到一个空闲页面，并将其分配给发生错误的页面。嘿，操作系统，恭喜！你又这么做了。 不幸的是，当空闲内存很少时，事情就会变得更有趣。在这种情况下，这种内存压力会迫使操作系统开始调出页面，为主动使用的页面腾出空间。决定调出哪个页面（或哪些页面）封装在操作系统的替换策略中；从历史上看，这是早期虚拟内存系统做出的最重要的决定之一，因为较旧的系统几乎没有物理内存。至少，这是一套值得更多了解的有趣政策。因此我们的问题关键是：操作系统如何决定从内存中驱逐哪一页（或多页）？这一决定是由系统的替换策略做出的，该策略通常遵循一些一般原则（如下所述），但也包括某些调整以避免极端情况行为。 ","date":"2024-04-25","objectID":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/:0:0","tags":["OS"],"title":"交换策略","uri":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/"},{"categories":["系统架构"],"content":"1 缓存管理 在深入讨论策略之前，我们首先更详细地描述我们试图解决的问题。鉴于主内存保存系统中所有页面的某些子集，它可以正确地被视为系统中虚拟内存页面的缓存。因此，我们为此缓存选择替换策略的目标是最小化缓存未命中的次数，即最小化我们必须从磁盘获取页面的次数。或者，我们的目标可以视为最大化缓存命中数，即在内存中找到被访问页面的次数。 了解缓存命中和未命中的次数后，我们可以计算程序的平均内存访问时间 (average memory access time, AMAT)（计算机架构师计算硬件缓存的度量标准]）。具体来说，给定这些值，我们可以计算程序的 AMAT，如下所示： $$ \\text{AMAT}=\\text{T}M+\\text{P}{Miss}\\cdot\\text{T}\\text{D} $$ 其中$\\text{T}M$表示访问内存的成本，$\\text{T}D$表示访问磁盘的成本，$\\text{T}\\text{Miss}$是在缓存中找不到数据的概率（未命中）； $\\text{T}\\text{Miss}$ 从 0.0 到 1.0 不等，有时我们指的是丢失率百分比而不是概率（例如，10% 的丢失率意味着 $\\text{T}\\text{Miss}=0.10$）。请注意，您总是要为访问内存中的数据付出代价；然而，当您未命中时，您必须额外支付从磁盘获取数据的成本。 例如，让我们想象一台具有（微小）地址空间的机器：4KB，具有 256 字节页面。因此，虚拟地址有两个组成部分：4 位 VPN（最高有效位）和 8 位偏移量（最低有效位）。因此，该示例中的进程总共可以访问 $2^4$ 或 16 个虚拟页。在此示例中，进程生成以下内存引用（即虚拟地址）：0x000、0x100、0x200、0x300、0x400、0x500、0x600、0x700、0x800、0x900。这些虚拟地址指的是地址空间前十页中每一页的第一个字节（页号是每个虚拟地址的第一个十六进制数字）。 让我们进一步假设除虚拟页 3 之外的所有页都已在内存中。因此，我们的内存引用序列将遇到以下行为：命中，命中，命中，未命中，命中，命中，命中，命中，命中，命中。我们可以计算命中率（在内存中找到的引用的百分比）：90%，因为十分之九的引用在内存中。因此，为命中率率为 10%（$\\text{P}\\text{Miss}=0.10$）。一般情况下，$\\text{P}\\text{Hit}+\\text{P}_\\text{Miss}=0.10=1.0$；命中率加上未命中率之和为 100%。 为了计算AMAT，我们需要知道访问内存的成本和访问磁盘的成本。假设访问内存的成本 (TM ) 约为 100 纳秒，访问磁盘的成本 (TD ) 约为 10 毫秒，则我们有以下 AMAT：100ns + 0.1 · 10ms，即 100ns + 1ms，即 1.0001 ms，或大约1毫秒。如果我们的命中率为 99.9%（Pmiss = 0.001），结果就完全不同：AMAT 为 10.1 微秒，或者大约快 100 倍。当命中率接近 100% 时，AMAT 接近 100 纳秒。 不幸的是，正如您在此示例中所看到的，现代系统中磁盘访问的成本非常高，即使很小的未命中率也会很快主导正在运行的程序的整体 AMAT。显然，我们需要尽可能避免未命中或以磁盘速率缓慢运行。解决这个问题的一种方法是仔细制定明智的策略，就像我们现在所做的那样。 ","date":"2024-04-25","objectID":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/:1:0","tags":["OS"],"title":"交换策略","uri":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/"},{"categories":["系统架构"],"content":"2 最佳替换策略 为了更好地理解特定替换策略的工作原理，最好将其与最佳替换策略进行比较。事实证明，Belady多年前就提出了这样一种最佳策略（他最初称之为 MIN）。最佳替换策略会导致总体未命中次数最少。Belady 证明了一种简单（但不幸的是，很难实现！）的方法，即替换未来访问距离最远的页面是最佳策略，它能带来尽可能少的缓存缺失。 TIP：与最优算法进行比较是有用的 虽然最优算法作为实际策略并不实用，但在模拟或其他研究中作为比较点却非常有用。如果说你的新算法有 80% 的命中率，这并没有任何意义；如果说最优算法有 82% 的命中率（因此你的新方法非常接近最优算法），这将使结果更有意义，并赋予其背景。因此，在你进行的任何研究中，知道最佳值是什么可以让你进行更好的比较，显示还有多少改进的可能，以及什么时候你可以停止改进你的策略，因为它已经足够接近理想值了。 希望最优策略背后的直觉是有道理的。你可以这样想：如果你必须扔掉某个页面，为什么不扔掉离现在最远的那个页面呢？这样做实质上是在说，缓存中的所有其他页面都比最远的那一页更重要。原因很简单：在访问最远的那一页之前，你会先访问其他页面。 让我们通过一个简单的例子来了解最优策略的决策。假设一个程序访问以下虚拟页面流：0, 1, 2, 0, 1, 3, 0, 3, 1, 2, 1。下图显示了最优策略的行为，假设缓存可以容纳三个页面。 从图中可以看到以下操作。毫不奇怪，前三次访问都是未命中，因为高速缓存一开始是空的；这种未命中有时被称为冷启动未命中（或强制未命中）。然后我们再次访问第 0 页和第 1 页，它们都在缓存中被命中。最后，我们又发生了一次缺失（第 3 页），但这次缓存已满，必须进行替换！这就引出了一个问题：我们应该替换哪一页？根据最优策略，我们可以检查当前缓存中每个页面（0、1 和 2）的未来访问情况，发现 0 页面几乎会立即被访问，1 页面会稍后被访问，而 2 页面在未来会被访问得最远。因此，最优策略很容易做出选择：删除第 2 页，这样缓存中就有了第 0、1 和 3 页。接下来的三个引用都是命中的，但我们到了 2 页时，却又遭遇了一次未命中。在这里，最优策略再次检查了缓存中每个页面（0、1 和 3）的未来访问情况，发现只要不驱逐第 1 页（即将被访问），我们就不会有问题。示例显示第 3 页被驱逐，尽管第 0 页也可以被驱逐。最后，我们命中了第 1 页，跟踪完成。 我们还可以计算缓存的命中率：在 6 次命中和 5 次未命中的情况下，命中率为$\\frac{\\text{Hits}}{\\text{Hits+Misses}}$命中+未命中，即 $\\frac{6}{6+5}$或 54.5%。我们还可以计算强制未命中的命中率（即忽略对给定页面的第一次未命中），结果是命中率为 85.7%。 遗憾的是，正如我们之前在开发调度策略时所看到的，未来并不普遍为人所知；你不可能为通用操作系统构建最优策略。因此，在开发真正的、可部署的策略时，我们将重点关注那些能找到其他方法来决定驱逐哪个页面的方法。因此，最佳策略只能作为一个比较点，以了解我们离 “完美 “还有多远。 缓存未命中的类型 在计算机体系结构领域，架构师有时发现按类型将未命中特征分为以下三类之一很有用：强制、容量和冲突未命中，有时称为 3 C。发生强制未命中（或冷启动未命中）是因为缓存一开始就是空的，并且这是对该项目的第一次引用；相反，由于缓存空间不足，必须逐出一个项目才能将新项目放入缓存，因此会发生容量未命中。第三种类型的未命中（冲突未命中）出现在硬件中，因为由于所谓的“组关联性”（setassociativity），项目可以放置在硬件缓存中的位置受到限制。它不会出现在操作系统页面缓存中，因为此类缓存始终是完全关联的，即页面可以放置在内存中的位置没有限制。 ","date":"2024-04-25","objectID":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/:2:0","tags":["OS"],"title":"交换策略","uri":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/"},{"categories":["系统架构"],"content":"3 FIFO（先进先出策略） 许多早期系统避免了尝试接近最优的复杂性，而是采用了非常简单的替换策略。例如，一些系统使用 FIFO（先进先出）替换，其中页面在进入系统时被简单地放置在队列中；当发生替换时，队列尾部的页面（“先入”页面）将被逐出。 FIFO 有一个很大的优点：实现起来非常简单。 如下图所示，为 FIFO 在我们的示例引用流上的表现。我们再次以对页面 0、1 和 2 的三个强制未命中开始跟踪，然后命中 0 和 1。接下来，引用第 3 页，导致未命中；使用 FIFO 进行替换决策很容易：选择第一个页面（图中的缓存状态按 FIFO 顺序保存，第一个页面位于左侧），即第 0 页。不幸的是，我们的下一个访问是页 0，导致另一次丢失和替换（页 1）。然后我们命中了第 3 页，但第 1 和第 2 页未命中，最后命中了第 1 页。 将 FIFO 与最佳值相比，FIFO 的命中率明显更差：36.4% 的命中率（或 57.1%，不包括强制命中率）。 FIFO 根本无法确定块的重要性：即使页 0 已被访问多次，FIFO 仍然会将其踢出，仅仅因为它是第一个进入内存的块。 BELADY 的异常 Belady（最优策略提出者）和同事发现了一个有趣的引用流，其行为有点出乎意料。内存引用流：1,2,3,4,1,2,5,1,2,3,4,5。他们研究的替换策略是先进先出。有趣的部分是：当缓存大小从 3 页移动到 4 页时，缓存命中率如何变化。一般来说，当缓存变大时，您会期望缓存命中率会增加（变得更好）。但在这种情况下，如果使用 FIFO，情况会变得更糟！这种奇怪的行为通常被称为BELADY 的异常。其他一些策略，例如 LRU，不会遇到这个问题。事实证明，LRU 具有所谓的堆栈属性 。对于具有此属性的算法，大小为 N + 1 的缓存自然包含大小为 N 的缓存的内容。因此，当增加缓存大小时，命中率将保持不变或提高。 FIFO 和 Random（以及其他）显然不遵守堆栈属性，因此容易受到异常行为的影响。 ","date":"2024-04-25","objectID":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/:3:0","tags":["OS"],"title":"交换策略","uri":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/"},{"categories":["系统架构"],"content":"4 随机策略 另一种类似的替换策略是随机策略，它只是在内存压力下选择随机页面进行替换。 Random 具有与 FIFO 类似的属性；它实现起来很简单，但它并没有真正尝试太智能地选择要驱逐的块。如下图所示，让我们看看 Random 在我们著名的示例引用流上的表现如何。 当然，Random 的表现完全取决于 Random 在其选择中的幸运（或不幸）程度。在上面的例子中，Random 的表现比 FIFO 好一点，比最优的差一点。事实上，我们可以运行随机实验数千次并确定它的总体表现。 下图显示了 Random 在 10,000 多次试验中实现了多少次命中，每次试验都有不同的随机种子。正如您所看到的，有时（仅超过 40% 的时间），Random 与最佳效果一样好，在示例跟踪上实现了 6 个命中；有时效果更糟，达到 2 次或更少。随机抽奖的效果如何取决于抽奖的运气。 ","date":"2024-04-25","objectID":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/:4:0","tags":["OS"],"title":"交换策略","uri":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/"},{"categories":["系统架构"],"content":"5 使用历史记录：LRU 不幸的是，任何像 FIFO 或 Random 这样简单的策略都可能存在一个常见问题：它可能会踢出一个重要的页面，而该页面将被再次引用。 FIFO踢出最先带入的页面；如果这恰好是一个带有重要代码或数据结构的页面，那么它无论如何都会被丢弃，即使它很快就会被分页回来。因此，FIFO、Random和类似的策略不太可能达到最佳效果；需要更智能的东西。 正如我们对调度策略所做的那样，为了改善我们对未来的猜测，我们再次依靠过去并以历史为指导。例如，如果一个程序在不久的过去访问过一个页面，那么它很可能在不久的将来再次访问它。 页面替换策略可以使用的一类历史信息是频率。如果一个页面已被访问多次，也许它不应该被替换，因为它显然具有某些价值。页面的一个更常用的属性是访问时间；页面被访问的时间越近，也许就越有可能被再次访问。 这一系列策略基于人们所说的局部性原则 ，这基本上只是对程序及其行为的观察。这个原则的意思很简单，就是程序倾向于非常频繁地访问某些代码序列（例如，在循环中）和数据结构（例如，循环访问的数组）；因此，我们应该尝试使用历史记录来找出哪些页面是重要的，并在驱逐时将这些页面保留在内存中。 因此，一系列简单的基于历史的算法诞生了。当必须进行逐出时，最不常用 (LFU) 策略会替换最不常用的页面。类似地，最近最少使用（LRU）策略替换最近最少使用的页面。这些算法很容易记住：一旦您知道名称，您就确切地知道它的作用，这是名称的一个极好的属性。 为了更好地理解 LRU，我们来看看 LRU 在示例引用流上的表现，如下图所示。 从图中，您可以看到 LRU 如何利用历史记录比 Random 或 FIFO 等无状态策略做得更好。在示例中，LRU 在第一次必须替换页面时会逐出页面 2，因为最近访问过页面 0 和 1。然后它会替换第 0 页，因为最近访问了第 1 页和第 3 页。在这两种情况下，LRU 基于历史的决定都被证明是正确的，因此下一个引用会被命中。因此，在我们的示例中，LRU 表现得尽可能好，其性能达到最佳水平。 我们还应该注意到，这些算法存在相反的情况：最常用（MFU）和最近使用（MRU）。在大多数情况下（不是全部！），这些策略效果不佳，因为它们忽略了大多数程序所展示的局部性，而不是利用它。 局部性的类型 程序往往会表现出两种局部性。第一种是空间局部性，即如果一个页面 P 被访问，那么它周围的页面（如 P - 1 或 P + 1）也很可能被访问。第二种是时间局部性，即在不久的将来，在过去被访问过的页面很可能会再次被访问。存在这些类型的局部性的假设在硬件系统的缓存层次结构中发挥着重要作用，硬件系统部署多个级别的指令、数据和地址转换缓存，以帮助程序在存在此类局部性时快速运行。 当然，通常所说的局部性原则并不是所有程序都必须遵守的硬性规定。事实上，有些程序以相当随机的方式访问内存（或磁盘），在其访问流中并不表现出太多或任何局部性。因此，在设计任何类型的缓存（硬件或软件）时，虽然局部性是一个值得牢记的好东西，但它并不能保证成功。相反，它是一种启发式方法，在计算机系统设计中经常被证明是有用的。 ","date":"2024-04-25","objectID":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/:5:0","tags":["OS"],"title":"交换策略","uri":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/"},{"categories":["系统架构"],"content":"6 工作负载实例 让我们再看几个例子，以便更好地理解其中一些策略的行为方式。在这里，我们将检查更复杂的工作负载而不是小跟踪。然而，即使是这些工作负载也被大大简化了；更好的研究将包括应用程序跟踪。 我们的第一个工作负载没有局部性，这意味着每个引用都是对访问页面集中的随机页面。在这个简单的示例中，工作负载随着时间的推移访问 100 个唯一页面，随机选择下一个页面进行引用；总共访问了 10,000 个页面。在实验中，我们将缓存大小从非常小（1 页）更改为足以容纳所有唯一页面（100 页），以便了解每个策略在缓存大小范围内的行为方式。 下图绘制了最优、LRU、随机和 FIFO 的实验结果。图中的y轴表示每个策略达到的命中率； x 轴改变缓存大小。 我们可以从图中得出许多结论。首先，当工作负载不存在局部性时，您使用哪种实际策略并不重要； LRU、FIFO 和 Random 的执行方式都是相同的，命中率完全由缓存的大小决定。其次，当缓存足够大以适应整个工作负载时，使用哪种策略也并不重要；当所有引用的块都适合缓存时，所有策略（甚至随机）都会收敛到 100% 命中率。最后，您可以看到最优策略的性能明显优于现实策略；如果可能的话，展望未来可以更好地进行替代。 我们研究的下一个工作负载称为“80-20”工作负载，它表现出局部性：80% 的引用是针对 20% 的页面（“热门”页面）；其余 20% 的引用是针对其余 80% 的页面（“冷”页面）。在我们的工作负载中，总共有 100 个不同的页面；因此，大部分时间都引用“热”页面，其余时间引用“冷”页面。下图显示了策略如何在此工作负载下执行。 从图中可以看出，虽然随机和 FIFO 都表现得相当好，但 LRU 表现更好，因为它更有可能保留热点页；由于这些页面过去曾被频繁引用，因此很可能在不久的将来再次被引用。 Optimal 再次表现更好，说明 LRU 的历史信息并不完美。 您现在可能想知道：LRU 相对于 Random 和 FIFO 的改进真的有那么大吗？答案是“视情况而定”。如果每次未命中的成本都非常高（并不罕见），那么即使命中率小幅增加（为命中率降低）也会对性能产生巨大影响。如果未命中的代价不那么高，那么 LRU 可能带来的好处当然就不那么重要了。 让我们看一下最终的工作负载。我们将其称为“循环顺序”工作负载，因为在其中，我们按顺序引用 50 个页面，从 0 开始，然后是 1，…，直到第 49 页，然后我们循环，重复这些访问，以获得对 50 个唯一页面的总共 10,000 次访问。下图显示了该工作负载下策略的行为。 这种工作负载在许多应用程序（包括重要的商业应用程序，例如数据库）中很常见，代表了 LRU 和 FIFO 的最坏情况。这些算法在循环顺序工作负载下会踢出旧页面；不幸的是，由于工作负载的循环性质，这些较旧的页面将比策略希望保留在缓存中的页面更早被访问。事实上，即使缓存大小为 49，50 页的循环顺序工作负载也会导致 0% 的命中率。有趣的是，随机的效果明显更好，虽然还没有完全接近最佳，但至少实现了非零命中率。事实证明随机有一些很好的特性；其中一个属性就是没有奇怪的极端行为。 ","date":"2024-04-25","objectID":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/:6:0","tags":["OS"],"title":"交换策略","uri":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/"},{"categories":["系统架构"],"content":"7 实现历史算法 正如您所看到的，LRU 等算法通常比 FIFO 或随机等简单策略做得更好，后者可能会丢弃重要的页面。不幸的是，历史策略给我们带来了新的挑战：我们如何实现它们？ 我们以 LRU 为例。为了完美地实现它，我们需要做大量的工作。具体来说，在每次页面访问（即每次内存访问，无论是指令提取还是加载或存储）时，我们必须更新某些数据结构以将此页面移动到列表的前面（即 MRU 侧）。与 FIFO 相比，只有当页面被逐出（通过删除最先进入的页面）或将新页面添加到列表（最后进入的一侧）时，才会访问 FIFO 页面列表。为了跟踪哪些页面被最少和最近使用，系统必须在每次内存引用上进行一些统计工作。显然，如果不小心处理，这种统计工作可能会大大降低性能。 一种有助于加快速度的方法是添加一点硬件支持。例如，机器可以在每次页面访问时更新内存中的时间字段（例如，这可能位于每个进程的页表中，或者仅位于内存中的某个单独的数组中，系统中的每个物理页有一个条目）。因此，当访问页面时，时间字段将由硬件设置为当前时间。然后，当替换页面时，操作系统可以简单地扫描系统中的所有时间字段以找到最近最少使用的页面。 不幸的是，随着系统中页面数量的增长，扫描大量的时间只是为了找到绝对最近最少使用的页面是非常昂贵的。想象一下一台具有 4GB 内存的现代机器，被分成 4KB 页面。这台机器有 100 万个页面，因此即使在现代 CPU 速度下，找到 LRU 页面也需要很长时间。这就引出了一个问题：我们真的需要找到绝对最旧的页面来替换吗？我们可以通过近似来代替吗？ ","date":"2024-04-25","objectID":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/:7:0","tags":["OS"],"title":"交换策略","uri":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/"},{"categories":["系统架构"],"content":"8 近似LRU 事实证明，答案是肯定的：从计算开销的角度来看，近似 LRU 更可行，而且实际上许多现代系统都是这么做的。这个想法需要一些硬件支持，以使用位（有时称为引用位）的形式，其中第一个是在第一个具有分页的系统，Atlas one-level store中实现的。系统的每一页都有一个使用位，并且使用位存在于内存中的某个位置（例如，它们可能位于每个进程的页表中，或者只是位于某个数组中）。每当引用页面（即读取或写入）时，硬件都会将使用位设置为 1。不过，硬件永远不会清除该位（即将其设置为 0）；这是操作系统的责任。 操作系统如何利用使用位位来近似LRU？嗯，可能有很多方法，但时钟算法提出了一种简单的方法。想象一下系统的所有页面排列在一个循环列表中。时钟指针首先指向某个特定的页面（哪一页并不重要）。当必须进行替换时，操作系统会检查当前指向的页面 P 的使用位是否为 1 或 0。如果为 1，则意味着页面 P 最近被使用过，因此不是替换的良好候选者。因此，P 的使用位设置为 0（清除），并且时钟指针递增到下一页 (P + 1)。该算法继续进行，直到找到一个设置为 0 的使用位，这意味着该页面最近没有被使用过（或者，在最坏的情况下，所有页面都已被使用过，并且我们现在已经搜索了整个页面集，从而清除了所有位）。 请注意，此方法并不是使用使用位来近似 LRU 的唯一方法。事实上，任何定期清除使用位，然后区分哪些页面使用 1 与 0 的位来决定替换哪个的方法都可以。 Corbato 的时钟算法只是一种早期方法，它取得了一些成功，并且具有不重复扫描所有内存寻找未使用页面的良好特性。 时钟算法变体的行为如下图所示。 该变体在进行替换时随机扫描页面；当它遇到引用位设置为 1 的页面时，它会清除该位（即将其设置为 0）；当它发现引用位设置为 0 的页面时，它会选择它作为受害者。正如您所看到的，虽然它的表现不如完美的 LRU，但它比根本不考虑历史的方法要好。 ","date":"2024-04-25","objectID":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/:8:0","tags":["OS"],"title":"交换策略","uri":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/"},{"categories":["系统架构"],"content":"9 考虑脏位（在时钟算法中） 对时钟算法（最初也是由 Corbato提出的）的一个小修改是，在内存中额外考虑页面是否被修改。这样做的原因是：如果一个页面被修改过，因而是脏的，就必须将其写回磁盘以将其剔除，而这是很昂贵的。如果页面未被修改（因此是干净的），则剔除是免费的；物理页可以简单地重新用于其他目的，而无需额外的 I/O。因此，一些虚拟机系统更倾向于驱逐干净的页面，而不是脏页面。 为支持这种行为，硬件应包含一个修改位（又称脏位）。该位在任何页面被写入时都会被设置，因此可被纳入页面替换算法中。例如，时钟算法可以修改为首先扫描未使用且干净的页面，然后再扫描未使用且脏的页面，以此类推。 ","date":"2024-04-25","objectID":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/:9:0","tags":["OS"],"title":"交换策略","uri":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/"},{"categories":["系统架构"],"content":"10 其他VM策略 页面替换并不是VM子系统采用的唯一策略（尽管它可能是最重要的）。例如，操作系统还必须决定何时将页面放入内存。该策略有时称为页面选择策略，为操作系统提供了一些不同的选项。 对于大多数页面，操作系统仅使用按需分页，这意味着操作系统在访问页面时将页面调入内存，可以说是“按需”。当然，操作系统可以猜测某个页面即将被使用，从而提前将其引入；这种行为称为预取，只有在有合理的成功机会时才应执行。例如，某些系统会假设如果将代码页 P 放入内存中，则该代码页 P+1 可能很快就会被访问，因此也应该放入内存中。 另一个策略决定操作系统如何将页面写入磁盘。当然，它们可以简单地一次写出一个；然而，许多系统反而将大量待处理的写入集中在内存中，并通过一次（更有效的）写入将它们写入磁盘。这种行为通常称为集群或简单的写入分组，并且由于磁盘驱动器的性质而有效，磁盘驱动器执行单个大写操作比许多小写操作更有效。 ","date":"2024-04-25","objectID":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/:10:0","tags":["OS"],"title":"交换策略","uri":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/"},{"categories":["系统架构"],"content":"11 抖动 当内存被过度占用，运行进程的内存需求超过了可用的物理内存时，操作系统该怎么办？在这种情况下，系统会不断地分页，这种情况有时被称为 “抖动”（thrashing）。 一些早期的操作系统有一套相当复杂的机制，可以检测并处理发生的抖动。例如，在给定一组进程的情况下，系统可以决定不运行其中的一个子进程集，希望减少的进程集的工作集（它们正在积极使用的页面）能够适合内存，从而取得进展。这种方法通常被称为 “准入控制”（acmission control），它指出，有时少做一点工作比什么都做不好要好，这是我们在现实生活和现代计算机系统中经常遇到的情况。 当前的一些系统对内存超载采取了更为严厉的措施。例如，某些版本的 Linux 会在内存被超量占用时运行一个 “内存不足杀手”；这个守护进程会选择一个内存密集型进程并将其杀死，从而以一种不太明显的方式减少内存。这种方法虽然能成功减少内存压力，但也会带来一些问题，例如，它可能会杀死 X 服务器，从而导致任何需要显示的应用程序无法使用。 ","date":"2024-04-25","objectID":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/:11:0","tags":["OS"],"title":"交换策略","uri":"/posts/17.%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5/"},{"categories":["系统架构"],"content":"到目前为止，我们假设地址空间小得不切实际，并且适合物理内存。事实上，我们一直假设每个正在运行的进程的每个地址空间都适合内存。现在，我们将放宽这些重大假设，并假设我们希望支持许多并发运行的大型地址空间。 为此，我们需要在内存层次结构中增加一个级别。到目前为止，我们假设所有页面都驻留在物理内存中。然而，为了支持大地址空间，操作系统需要一个地方来存放当前需求不大的部分地址空间。一般来说，这样的位置的特点是容量要大于内存；因此，它通常会比较慢（如果它更快，我们就会将它用作内存，不是吗？）。在现代系统中，此角色通常由硬盘驱动器担任。因此，在我们的内存层次结构中，大而慢的硬盘驱动器位于底部，内存位于上面。 因此，我们找到了问题的关键： 如何超越物理内存？操作系统如何利用更大、更慢的设备来透明地提供大虚拟地址空间的假象？ 您可能有一个问题：为什么我们要为进程支持单个大地址空间？答案再次是方便和易用。有了大的地址空间，您就不必担心内存中是否有足够的空间来容纳程序的数据结构；相反，您只需自然地编写程序，根据需要分配内存即可。这是操作系统提供的强大幻觉，使您的生活变得更加简单。与此形成鲜明对比的是使用内存覆盖的旧系统，它要求程序员在需要时手动将代码或数据移入或移出内存。试着想象一下这将会是什么样子：在调用函数或访问某些数据之前，你需要首先安排代码或数据进入内存。 除了单个进程之外，添加交换空间还允许操作系统为多个并发运行的进程提供大虚拟内存的假象。多道程序设计（“同时”运行多个程序，以更好地利用机器）的发明几乎需要交换某些页面的能力，因为早期的机器显然无法同时容纳所有进程所需的所有页面。因此，多道程序设计和易用性的结合使我们希望支持使用比物理可用内存更多的内存。这是所有现代 VM 系统都会做的事情；现在我们将进一步了解这一点。 ","date":"2024-04-25","objectID":"/posts/16.%E9%A1%B5%E9%9D%A2%E4%BA%A4%E6%8D%A2/:0:0","tags":["OS"],"title":"页面交换","uri":"/posts/16.%E9%A1%B5%E9%9D%A2%E4%BA%A4%E6%8D%A2/"},{"categories":["系统架构"],"content":"1 交换空间 我们需要做的第一件事是在磁盘上保留一些空间用于来回移动页面。在操作系统中，我们通常将此类空间称为交换空间，因为我们将内存中的页面交换出来，又将内存中的页面交换进去。因此，我们简单地假设操作系统可以以页面大小为单位读取和写入交换空间。为此，操作系统需要记住给定页面的磁盘地址。 交换空间的大小很重要，因为它最终决定了系统在给定时间可以使用的最大内存页数。为了简单起见，我们假设它现在非常大。 如下图所示，，您可以看到一个 4 页物理内存和 8 页交换空间的小例子。在示例中，三个进程（Proc 0、Proc 1 和 Proc 2）正在主动共享物理内存；然而，这三个页面中的每一个都只有一些有效页面位于内存中，其余部分位于磁盘上的交换空间中。第四个进程 (Proc 3) 已将其所有页面换出到磁盘，因此显然当前未运行。一区块的交换仍然是空闲的。即使从这个小例子中，希望您可以看到使用交换空间如何让系统假装内存比实际更大。 我们应该注意，交换空间并不是交换流量的唯一磁盘位置。例如，假设您正在运行一个程序二进制文件（例如 ls 或您自己编译的主程序）。该二进制文件中的代码页最初在磁盘上找到，当程序运行时，它们被加载到内存中（或者在程序开始执行时一次全部加载，或者像在现代系统中一样，在需要时一次加载一页）。但是，如果系统需要在物理内存中腾出空间来满足其他需求，它可以安全地重新使用这些代码页的内存空间，因为它知道以后可以从文件系统中的磁盘二进制文件中再次交换它们。 ","date":"2024-04-25","objectID":"/posts/16.%E9%A1%B5%E9%9D%A2%E4%BA%A4%E6%8D%A2/:1:0","tags":["OS"],"title":"页面交换","uri":"/posts/16.%E9%A1%B5%E9%9D%A2%E4%BA%A4%E6%8D%A2/"},{"categories":["系统架构"],"content":"2 存在位 现在我们在磁盘上有了一些空间，我们需要在系统中添加一些更高级别的机器，以支持与磁盘之间的页面交换。为简单起见，我们假设我们有一个带有硬件管理的 TLB 的系统。 首先回想一下内存引用上发生的情况。运行的进程生成虚拟内存引用（用于指令获取或数据访问），在这种情况下，硬件在从内存中获取所需数据之前将它们转换为物理地址。 请记住，硬件首先从虚拟地址中提取 VPN，检查 TLB 是否匹配（TLB 命中），如果命中，则生成结果物理地址并从内存中获取它。这希望是常见情况，因为它速度很快（不需要额外的内存访问）。 如果在 TLB 中未找到 VPN（即 TLB 未命中），硬件将在内存中定位页表（使用页表基址寄存器），并使用 VPN 查找该页的页表条目 (PTE)：一个索引。如果该页有效并且存在于物理内存中，则硬件从 PTE 中提取 PFN，将其安装到 TLB 中，并重试该指令，这次生成 TLB 命中；到目前为止，一切都很好。 然而，如果我们希望允许页面交换到磁盘，我们必须添加更多的机器。具体来说，当硬件查看PTE时，它可能会发现物理内存中不存在该页。硬件（或操作系统，在软件管理的 TLB 方法中）确定这一点的方式是通过每个页表条目中的一条新信息（称为存在位，the present bit）。如果存在位设置为 1，则意味着该页存在于物理内存中，并且一切按上述进行；如果它设置为零，则该页面不在内存中，而是在磁盘上的某个位置。访问不在物理内存中的页面的行为通常称为页面错误。 出现页面错误时，将调用操作系统来处理页面错误。正如我们现在所描述的，运行一段称为页面错误处理程序的特定代码，并且必须为页面错误提供服务。 ","date":"2024-04-25","objectID":"/posts/16.%E9%A1%B5%E9%9D%A2%E4%BA%A4%E6%8D%A2/:2:0","tags":["OS"],"title":"页面交换","uri":"/posts/16.%E9%A1%B5%E9%9D%A2%E4%BA%A4%E6%8D%A2/"},{"categories":["系统架构"],"content":"3 页面错误 回想一下，对于 TLB 未命中，我们有两种类型的系统：硬件管理的 TLB（硬件在页表中查找所需的转换）和软件管理的 TLB（操作系统执行的操作）。在任一类型的系统中，如果页面不存在，操作系统将负责处理页面错误。操作系统页面错误处理程序将运行以确定要做什么。几乎所有系统都通过软件来处理页面错误；即使使用硬件管理的 TLB，硬件也会信任操作系统来管理这项重要职责。 如果页面不存在并且已交换到磁盘，操作系统将需要将该页面交换到内存中以解决页面错误。因此，出现了一个问题：操作系统如何知道在哪里可以找到所需的页面？在许多系统中，页表是存储此类信息的自然位置。因此，操作系统可以使用 PTE 中通常用于数据的位，例如磁盘地址页面的 PFN。当操作系统收到页面的缺页错误时，它会在 PTE 中查找地址，并向磁盘发出请求以将该页面提取到内存中。 当磁盘 I/O 完成时，操作系统将更新页表以将页面标记为存在，更新页表项 (PTE) 的 PFN 字段以记录新获取的页面在内存中的位置，并重试该指令。下一次尝试可能会生成 TLB 未命中，然后将对其进行处理并通过转换更新 TLB（可以在处理页错误时交替更新 TLB，以避免此步骤）。最后，最后一次重新启动将在 TLB 中找到转换，从而继续从内存中转换后的物理地址获取所需的数据或指令。 请注意，当 I/O 正在进行时，进程将处于阻塞状态。因此，在处理页面错误时，操作系统将可以自由地运行其他就绪进程。由于 I/O 的成本很高，因此一个进程的 I/O（页面错误）与另一个进程的执行的重叠是多道程序系统最有效地利用其硬件的另一种方式。 ","date":"2024-04-25","objectID":"/posts/16.%E9%A1%B5%E9%9D%A2%E4%BA%A4%E6%8D%A2/:3:0","tags":["OS"],"title":"页面交换","uri":"/posts/16.%E9%A1%B5%E9%9D%A2%E4%BA%A4%E6%8D%A2/"},{"categories":["系统架构"],"content":"4 如果内存已满怎么办？ 在上述过程中，您可能会注意到，我们假设有足够的可用内存可从交换空间调入页面。当然，情况也可能并非如此；内存可能已满（或接近满）。因此，操作系统可能希望首先调出一个或多个页面，以便为操作系统即将引入的新页面腾出空间。选择要踢出或替换的页面的过程称为页面替换策略。 事实证明，我们在创建良好的页面替换策略时花费了很多心思，因为踢出错误的页面可能会给程序性能带来巨大的损失。做出错误的决定可能会导致程序以类似磁盘的速度而不是类似内存的速度运行；在当前技术中，这意味着程序的运行速度可能会慢 10,000 或 100,000 倍。所以，这样的策略是值得我们仔细研究的。事实上，这正是我们在下一章中要做的事情。现在，只要理解这样的政策的存在就足够了，它建立在此处描述的机制之上。 ","date":"2024-04-25","objectID":"/posts/16.%E9%A1%B5%E9%9D%A2%E4%BA%A4%E6%8D%A2/:4:0","tags":["OS"],"title":"页面交换","uri":"/posts/16.%E9%A1%B5%E9%9D%A2%E4%BA%A4%E6%8D%A2/"},{"categories":["系统架构"],"content":"5 页面错误控制流 有了这些知识，我们现在就可以大致勾勒出内存访问的完整控制流程，如下图所示。 换句话说，当有人问你 “当程序从内存中获取一些数据时会发生什么？“时，你应该对所有不同的可能性有一个相当好的概念，如下面两段代码所示。 // Page-Fault Control Flow Algorithm (Hardware) 1 VPN = (VirtualAddress \u0026 VPN_MASK) \u003e\u003e SHIFT 2 (Success, TlbEntry) = TLB_Lookup(VPN) 3 if (Success == True) // TLB Hit 4 if (CanAccess(TlbEntry.ProtectBits) == True) 5 Offset = VirtualAddress \u0026 OFFSET_MASK 6 PhysAddr = (TlbEntry.PFN \u003c\u003c SHIFT) | Offset 7 Register = AccessMemory(PhysAddr) 8 else 9 RaiseException(PROTECTION_FAULT) 10 else // TLB Miss 11 PTEAddr = PTBR + (VPN * sizeof(PTE)) 12 PTE = AccessMemory(PTEAddr) 13 if (PTE.Valid == False) 14 RaiseException(SEGMENTATION_FAULT) 15 else 16 if (CanAccess(PTE.ProtectBits) == False) 17 RaiseException(PROTECTION_FAULT) 18 else if (PTE.Present == True) 19 // assuming hardware-managed TLB 20 TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits) 21 RetryInstruction() 22 else if (PTE.Present == False) 23 RaiseException(PAGE_FAULT) // Page-Fault Control Flow Algorithm (Software) 1 PFN = FindFreePhysicalPage() 2 if (PFN == -1) // no free page found 3 PFN = EvictPage() // run replacement algorithm 4 DiskRead(PTE.DiskAddr, PFN) // sleep (waiting for I/O) 5 PTE.present = True // update page table with present bit 6 PTE.PFN = PFN // and translation (PFN) 7 RetryInstruction() // retry instruction 第一段代码显示了硬件在转换过程中的操作，第二段代码显示了操作系统在发生页面错误时的操作。 从第一段代码中的硬件控制流程可以看出，当发生 TLB 未命中时，有三种重要情况需要了解。第一种情况是页面既存在又有效（第 18-21 行）；在这种情况下，TLB 未命中处理程序可以简单地从 PTE 中获取 PFN，重试指令（这次会导致 TLB 命中），然后继续之前（多次）描述的操作。在第二种情况下（第 22-23 行），必须运行页面错误处理程序；虽然进程访问的页面是合法的（毕竟是有效的），但它不在物理内存中。第三种（也是最后一种）情况是访问的页面无效，例如由于程序中的错误（第 13-14 行）。在这种情况下，PTE 中的其他位都不重要；硬件会捕获这种无效访问，操作系统中断处理程序也会运行，从而终止违规进程。 从第二段代码的软件控制流中我们可以看到操作系统处理页面错误的大致步骤。首先，操作系统必须为即将发生错误的页面找到一个物理页号；如果没有这样的页面，我们就必须等待替换算法运行，将一些页面踢出内存，从而释放出这些页面供此处使用。有了物理页，处理程序就会发出 I/O 请求以从交换空间读入页面。最后，当缓慢的操作完成时，操作系统会更新页表并重试该指令。重试将导致 TLB 未命中，然后，在另一次重试时，TLB 命中，此时硬件将能够访问所需的项。 ","date":"2024-04-25","objectID":"/posts/16.%E9%A1%B5%E9%9D%A2%E4%BA%A4%E6%8D%A2/:5:0","tags":["OS"],"title":"页面交换","uri":"/posts/16.%E9%A1%B5%E9%9D%A2%E4%BA%A4%E6%8D%A2/"},{"categories":["系统架构"],"content":"6 当替换真正发生时 到目前为止，我们描述替换如何发生的方式是假设操作系统等待内存完全满，然后才替换（逐出）页面为其他页面腾出空间。正如您可以想象的那样，这有点不现实，操作系统主动保留一小部分内存的原因有很多。 为了保持少量内存空闲，大多数操作系统都有某种高水位线（HW）和低水位线（LW）来帮助决定何时开始从内存中逐出页面。其工作原理如下：当操作系统注意到可用的 LW 页数较少时，负责释放内存的后台线程就会运行。该线程逐出页面，直到有可用的硬件页面。**后台线程（有时称为交换守护程序或页面守护程序）**然后进入睡眠状态，很高兴它释放了一些内存供正在运行的进程和操作系统使用。 通过同时执行多个替换，新的性能优化成为可能。例如，许多系统会将多个页面聚集或分组并立即将它们写入交换分区，从而提高磁盘的效率；正如我们稍后更详细地讨论磁盘时将看到的那样，这种集群减少了磁盘的查找和旋转开销，从而显着提高了性能。 为了与后台分页线程一起工作，上面的第二段代码控制流应该稍微修改一下；该算法不会直接执行替换，而是简单地检查是否有可用的空闲页面。如果没有，它会通知后台分页线程需要空闲页面；当线程释放一些页面时，它会重新唤醒原始线程，然后原始线程可以调入所需的页面并继续其工作。 ","date":"2024-04-25","objectID":"/posts/16.%E9%A1%B5%E9%9D%A2%E4%BA%A4%E6%8D%A2/:6:0","tags":["OS"],"title":"页面交换","uri":"/posts/16.%E9%A1%B5%E9%9D%A2%E4%BA%A4%E6%8D%A2/"},{"categories":["系统架构"],"content":"现在我们解决分页带来的第二个问题：页表太大，因此消耗太多内存。让我们从线性页表开始。您可能还记得，线性页表变得相当大。再次假设 32 位地址空间（$2^{32}$字节），具有 4KB（$2^{12}$ 字节）页面和 4 字节页表条目。因此，地址空间中大约有一百万个虚拟页（$\\frac{2^{32}}{2^{12}}$）；乘以页表条目大小，您会看到页表大小为 4MB。 另回想一下：我们通常为系统中的每个进程都有一个页表！对于一百个活动进程（在现代系统上并不罕见），我们将为页表分配数百兆字节的内存！因此，我们正在寻找一些技术来减轻这种沉重的负担。它们有很多，所以让我们开始吧。但在之前我们的问题关键是：简单的基于数组的页表（通常称为线性页表）太大，在典型系统上占用太多内存。如何才能让页表变小呢？关键的想法是什么？这些新的数据结构会导致哪些低效率？ ","date":"2024-04-25","objectID":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/:0:0","tags":["OS"],"title":"高级页表","uri":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/"},{"categories":["系统架构"],"content":"1 简单的解决方案：更大的页面 我们可以通过一种简单的方法来减小页表的大小：使用较大的页面。再次使用我们的 32 位地址空间，但这次假设页面为 16KB。因此，我们将拥有一个 18 位 VPN 加上一个 14 位偏移量。假设每个 PTE 的大小相同（4 字节），我们的线性页表中现在有 $2^{18}$ 个条目，因此每个页表的总大小为 1MB，页表大小减少了四倍（毫不奇怪，减少恰好反映了页面大小四倍的增加）。 然而，这种方法的主要问题是大页面会导致每个页面内的浪费，这个问题称为内部碎片（因为浪费是分配单元内部的）。因此，应用程序最终会分配页面，但只使用每个页面的一小部分，并且内存很快就会被这些过大的页面填满。因此，大多数系统在常见情况下使用相对较小的页面大小：4KB（如在 x86 中）或 8KB（如在 SPARCv9 中）。我们的问题不会这么简单地解决。 ","date":"2024-04-25","objectID":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/:1:0","tags":["OS"],"title":"高级页表","uri":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/"},{"categories":["系统架构"],"content":"2 混合方法：分页和分段 每当你对生活中的某件事有两种合理但不同的方法时，你应该始终检查两者的结合，看看是否能获得两全其美的效果。我们将这种组合称为混合体。 多年前，Multics 的创建者（特别是 Jack Dennis）在构建 Multics 虚拟内存系统时偶然想到了这样的想法。具体来说，Dennis 提出了将分页和分段相结合的想法，以减少页表的内存开销。通过更详细地检查典型的线性页表，我们可以明白为什么这可能起作用。假设我们有一个地址空间，其中堆和栈的已使用部分很小。例如，如下图所示，我们使用 16KB 的微小地址空间和 1KB 页面； 该地址空间的页表如图下图所示。 本例假定单个代码页（VPN 0）映射到物理页 10，单个堆页（VPN 4）映射到物理页 23，地址空间另一端的两个栈页（VPN 14 和 15）分别映射到物理页 28 和 4。从图中可以看出，大部分页表都未使用，充满了无效条目。非常浪费空间，且这只是一个 16KB 的小地址空间，如果是32位，会浪费的更多。 因此，我们的混合方法是：与其为进程的整个地址空间制作一个页表，为什么不为每个逻辑段制作一个页表呢？在这个例子中，我们可能会有三个页表，分别用于地址空间的代码、堆和栈部分。 现在，请记住分段，我们有一个基址寄存器告诉我们每个段在物理内存中的位置，还有一个边界或限制寄存器告诉我们所述段的大小。在我们的混合中，我们在 MMU 中仍然有这些结构；在这里，我们使用基址不是指向段本身，而是保存该段页表的物理地址。边界寄存器用于指示页表的末尾（即，它有多少个有效页）。 让我们举一个简单的例子来说明。假设 32 位虚拟地址空间有 4KB 页面，地址空间分为四个段。在本例中，我们只使用三个段：一个用于代码，一个用于堆，一个用于栈。 为了确定地址引用哪个段，我们将使用地址空间的前两位。假设 00 是未使用的段，01 表示代码，10 表示堆，11 表示堆栈。因此，虚拟地址如下所示： 在硬件中，假设有三个基寄存器/边界对，代码、堆和栈各一个。当进程运行时，每个分段的基寄存器都包含该分段线性页表的物理地址；因此，系统中的每个进程现在都有三个与之相关的页表。在上下文切换时，必须更改这些寄存器，以反映新运行进程的页表位置。 在 TLB 未命中时（假设 TLB 由硬件管理，即由硬件负责处理 TLB 未命中），硬件会使用段位（SN）来确定要使用的基址和边界对。然后，硬件将其中的物理地址与 VPN 进行如下组合，形成页表项 (PTE) 的地址： SN = (VirtualAddress \u0026 SEG_MASK) \u003e\u003e SN_SHIFT VPN = (VirtualAddress \u0026 VPN_MASK) \u003e\u003e VPN_SHIFT AddressOfPTE = Base[SN] + (VPN * sizeof(PTE)) 这个序列看起来应该很熟悉；它实际上与我们之前看到的线性页表相同。当然，唯一的区别是使用三个段基址寄存器之一而不是单页表基址寄存器。 我们的混合方案的关键区别是每个段都存在一个边界寄存器；每个边界寄存器保存段中最大有效页的值。例如，如果代码段正在使用其前三页（0、1 和 2），则代码段页表将仅分配有三个条目，并且边界寄存器将设置为 3；超出段末尾的内存访问将生成异常，并可能导致进程终止。通过这种方式，与线性页表相比，我们的混合方法实现了显著的内存节省；栈和堆之间未分配的页面不再占用页表中的空间（只是将它们标记为无效）。 然而，正如您可能注意到的，这种方法并非没有问题。首先，它仍然需要我们使用分段；正如我们之前讨论的，分段并不像我们希望的那么灵活，因为它假设地址空间有某种使用模式；例如，如果我们有一个大但很少使用的堆，我们仍然可能会产生大量页表浪费。其次，这种混合导致外部碎片再次出现。虽然大多数内存都是以页大小为单位进行管理的，但页表现在可以是任意大小（PTE 的倍数）。因此，在内存中为它们找到可用空间更加复杂。由于这些原因，人们不断寻找更好的方法来实现更小的页表。 ","date":"2024-04-25","objectID":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/:2:0","tags":["OS"],"title":"高级页表","uri":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/"},{"categories":["系统架构"],"content":"3 多级页表 ","date":"2024-04-25","objectID":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/:3:0","tags":["OS"],"title":"高级页表","uri":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/"},{"categories":["系统架构"],"content":"3.1 介绍 另一种方法不依赖于分段，但解决了同样的问题：如何摆脱页表中的所有无效区域，而不是将它们全部保留在内存中？我们将这种方法称为多级页表，因为它将线性页表变成了类似树的东西。这种方法非常有效，以至于许多现代系统都采用它（例如 x86 [BOH10]）。我们现在详细描述这种方法。 多级页表背后的基本思想很简单。首先，将页表切分成页大小的单元；然后，如果页表条目 (PTE) 的整个页无效，则根本不分配页表的该页。要跟踪页表的页面是否有效（以及如果有效，则它在内存中的位置），则使用称为页目录的新结构。因此，页目录可以用来告诉您页表的某个页在哪里，或者页表的整个页不包含有效页。 下图展示了一个示例。图左边是经典的线性页表；即使地址空间的大多数中间区域无效，我们仍然需要为这些区域分配页表空间（即页表的中间两页）。右边是多级页表。页目录仅将页表的两页标记为有效（第一页和最后一页）；因此，只有页表的那两页驻留在内存中。因此，您可以看到一种可视化多级表正在执行的操作的方法：它只是使部分线性页表消失（释放这些页以供其他用途），并跟踪页表的哪些页分配了该页目录。 页目录在一个简单的两级表中，页表的每一页包含一个条目。它由许多页目录项（PDE）组成。 PDE（至少）具有有效位和物理页框号 (PFN)，与 PTE 类似。然而，正如上面所暗示的，该有效位的含义略有不同：如果 PDE 有效，则意味着该条目（通过 PFN）指向的页表中的至少一页是有效的，即，在该PDE指向的该页上的至少一个PTE中，该PTE中的有效位被设置为1。如果 PDE 无效（即等于 0），则 PDE 的其余部分未定义。 与我们迄今为止看到的方法相比，多级页表具有一些明显的优势。首先，也许最明显的是，多级表仅根据您正在使用的地址空间量按比例分配页表空间；因此它通常是紧凑的并且支持稀疏地址空间。 其次，如果精心构建，页表的每个部分都可以整齐地容纳在一个页面中，从而更容易管理内存；当操作系统需要分配或增长页表时，它可以简单地获取下一个空闲页面。将此与简单（非分页）线性页表 进行对比，后者只是由 VPN 索引的 PTE 数组；采用这样的结构，整个线性页表必须连续地驻留在物理内存中。对于大页表（例如 4MB），找到这么大块未使用的连续空闲物理内存可能是一个相当大的挑战。对于多级结构，我们通过使用页目录来添加间接层，页目录指向页表的各个部分；这种间接允许我们将页表页面放置在物理内存中的任何位置。 需要注意的是，多级表是有成本的；如果 TLB 未命中，则需要从内存加载两次才能从页表获取正确的转换信息（一次用于页目录，一次用于 PTE 本身），而线性页表只需加载一次。因此，多级表是时空权衡的一个小例子。我们想要更小的表（并且得到了），但不是免费的；虽然在常见情况下（TLB 命中），性能显然是相同的，但是对于这个较小的表，TLB 未命中会遭受更高的成本。 另一个明显的负面因素是复杂性。无论是硬件还是操作系统处理页表查找（在 TLB 未命中时），这样做无疑比简单的线性页表查找更复杂。通常我们愿意增加复杂性以提高性能或减少开销；对于多级表，我们使页表查找更加复杂，以节省宝贵的内存。 ","date":"2024-04-25","objectID":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/:3:1","tags":["OS"],"title":"高级页表","uri":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/"},{"categories":["系统架构"],"content":"3.2 多级页表示例 为了更好地理解多级页表背后的想法，让我们举一个例子。想象一个大小为 16KB、具有 64 字节页面的小地址空间。因此，我们有一个 14 位虚拟地址空间，其中 8 位用于 VPN，6 位用于偏移量。即使仅使用一小部分地址空间，线性页表也将具有 $2^8$ (256) 个条目。下图展示了此类地址空间的一个示例。 在此示例中，虚拟页 0 和 1 用于代码，虚拟页 4 和 5 用于堆，虚拟页 254 和 255 用于堆栈；地址空间的其余页面未使用。 为了为此地址空间构建两级页表，我们从完整的线性页表开始，并将其分解为页面大小的单元。回想一下我们的完整表（在本例中）有 256 个条目；假设每个 PTE 的大小为 4 字节。因此，我们的页表大小为 1KB（256 × 4 字节）。假设我们有64字节的页面，那么1KB的页表可以分为16个64字节的页面；每页可容纳 16 个 PTE。 我们现在需要了解的是如何使用VPN并使用它首先索引到页目录，然后索引到页表的页面。请记住，每个都是一个条目数组；因此，我们需要弄清楚的是如何为 VPN 的每个部分构建索引。 让我们首先索引到页面目录。本例中的页表很小：256 个条目，分布在 16 个页面上。页目录需要页表的每一页一个条目；因此，它有 16 个条目。因此，我们需要 VPN 的四位来索引目录；我们使用VPN的前四位，如下： 一旦我们从VPN中提取出页目录索引（简称PDIndex），我们就可以通过简单的计算来找到页目录条目（PDE）的地址： PDEAddr = PageDirBase + (PDIndex * sizeof(PDE) ）。这就产生了我们的页面目录，现在我们对其进行研究，以进一步推进我们的转换工作 如果页目录条目被标记为无效，我们就知道访问无效，从而引发异常。然而，如果PDE有效，我们还有更多工作要做。具体来说，我们现在必须从该页目录项指向的页表页中获取页表项（PTE）。为了找到这个 PTE，我们必须使用 VPN 的剩余位来索引页表的部分： 然后可以使用此页表索引（简称 PTIndex）对页表本身进行索引，从而为我们提供 PTE 的地址： PTEAddr = (PDE.PFN \u003c\u003c SHIFT) + (PTIndex * sizeof(PTE)) 请注意，从页目录项获得的物理页框号 (PFN) 必须先左移到位，然后才能与页表索引组合以形成 PTE 的地址。为了看看这一切是否有意义，我们现在将用一些实际值填充多级页表，并转换单个虚拟地址。让我们从本例的页面目录开始（如下图左侧）。 在图中，您可以看到每个页目录项 (PDE) 描述了有关地址空间页表中的一页的信息。在此示例中，我们在地址空间中有两个有效区域（位于开头和结尾），以及中间的许多无效映射。在物理页100（页表第0页的物理帧号）中，我们有地址空间中前16个VPN的16个页表条目的第一页。这部分页表的内容见上图（中间部分）。 页表的该页包含前 16 个 VPN 的映射；在我们的示例中，VPN 0 和 1 有效（代码段），4 和 5（堆）也是有效的。因此，该表具有每个页面的映射信息。其余条目被标记为无效。 页表的另一个有效页位于 PFN 101 内。该页包含地址空间最后 16 个 VPN 的映射；如上图所示（右）。 在示例中，VPN 254 和 255（堆栈）具有有效映射。希望我们可以从这个示例中看到，使用多级索引结构可以节省多少空间。在此示例中，我们没有为线性页表分配完整的 16 个页面，而是仅分配三个页面：一个用于页目录，两个用于具有有效映射的页表块。对于大型（32 位或 64 位）地址空间来说，节省的成本显然要大得多。 最后，让我们使用这些信息来执行转换。这是一个引用 VPN 254 第 0 个字节的地址：0x3F80，或二进制的 11 1111 1000 0000。 回想一下，我们将使用 VPN 的前 4 位来索引页面目录。因此，1111 将选择上面页目录的最后一个（如果从第 0 个开始，则为第 15 个）条目。这将我们指向位于地址 101 的页表的有效页面。然后，我们使用 VPN (1110) 的接下来 4 位来索引页表的该页面并找到所需的 PTE。 1110 是页面上的倒数第二个（第 14 个）条目，它告诉我们虚拟地址空间的第 254 页映射到物理页 55。通过将 PFN=55（或十六进制 0x37）与 offset=000000 连接，我们因此可以形成我们想要的物理地址并向内存系统发出请求：PhysAddr = (PTE.PFN \u003c\u003c SHIFT) + offset = 00 1101 1100 0000 = 0x0DC0。您现在应该了解如何使用指向页表页面的页目录来构造两级页表。然而不幸的是，我们的工作还没有完成。正如我们现在将讨论的，有时两级页表是不够的！ ","date":"2024-04-25","objectID":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/:3:2","tags":["OS"],"title":"高级页表","uri":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/"},{"categories":["系统架构"],"content":"3.3 不止两级 到目前为止，在我们的示例中，我们假设多级页表只有两个级别：页目录，然后是页表的各个部分。在某些情况下，更深的树是可能的（而且确实是需要的）。 让我们举一个简单的例子，并用它来说明为什么更深的多级表会很有用。在此示例中，假设我们有一个 30 位虚拟地址空间和一个小（512 字节）页面。因此，我们的虚拟地址有一个 21 位虚拟页号组件和一个 9 位偏移量。 请记住我们构建多级页表的目标：使页表的每一部分都适合单个页面。到目前为止，我们只考虑了页表本身；但是，如果页面目录变得太大怎么办？ 为了确定多级表中需要多少级才能使页表的所有部分都适合一个页面，我们首先确定一个页面适合多少个页表条目。鉴于我们的页面大小为 512 字节，并假设 PTE 大小为 4 字节，您应该会发现单个页面上可以容纳 128 个 PTE。当我们对页表的某个页面进行索引时，我们可以得出结论，我们需要 VPN 的最低有效 7 位 ($\\log _2{128}$) 作为索引： 从上图中您还可能注意到，（大）页目录中还剩下多少位： 14。如果我们的页目录有 $2^{14}$个条目，那么它跨越的不是一页而是 128，因此，我们将多级页表的每一部分都放入一个页面的目标就消失了。 为了解决这个问题，我们通过将页面目录本身拆分为多个页面来构建树的更高级别，然后在其顶部添加另一个页面目录，以指向页面目录的页面。因此，我们可以将虚拟地址拆分如下： 现在，在索引上层页面目录时，我们使用虚拟地址的最顶层位（图中的 PD 索引 0）；该索引可用于从上层页面目录中获取页面目录条目。如果有效，则结合顶层 PDE 的物理页号和 VPN 的下一部分（PD 索引 1)，查询页面目录的第二层。最后，如果有效，就可以使用页表索引与二级 PDE 中的地址相结合，形成 PTE 地址。啧啧这可是个大工程。而这一切仅仅是为了在多级表中查找某个内容。 ","date":"2024-04-25","objectID":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/:3:3","tags":["OS"],"title":"高级页表","uri":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/"},{"categories":["系统架构"],"content":"3.4 转换过程：记住 TLB 为了总结使用二级页表进行地址转换的整个过程，我们再次以算法形式呈现控制流，如下面这段代码所示。 VPN = (VirtualAddress \u0026 VPN_MASK) \u003e\u003e SHIFT; (Success, TlbEntry) = TLB_Lookup(VPN); if (Success == True) { // TLB Hit if (CanAccess(TlbEntry.ProtectBits) == True) { Offset = VirtualAddress \u0026 OFFSET_MASK; PhysAddr = (TlbEntry.PFN \u003c\u003c SHIFT) | Offset; Register = AccessMemory(PhysAddr); } else { RaiseException(PROTECTION_FAULT); } } else { // TLB Miss // first, get page directory entry PDIndex = (VPN \u0026 PD_MASK) \u003e\u003e PD_SHIFT; PDEAddr = PDBR + (PDIndex * sizeof(PDE)); PDE = AccessMemory(PDEAddr); if (PDE.Valid == False) { RaiseException(SEGMENTATION_FAULT); } else { // PDE is valid: now fetch PTE from page table PTIndex = (VPN \u0026 PT_MASK) \u003e\u003e PT_SHIFT; PTEAddr = (PDE.PFN \u003c\u003c SHIFT) + (PTIndex * sizeof(PTE)); PTE = AccessMemory(PTEAddr); if (PTE.Valid == False) { RaiseException(SEGMENTATION_FAULT); } else if (CanAccess(PTE.ProtectBits) == False) { RaiseException(PROTECTION_FAULT); } else { TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits); RetryInstruction(); } } } 该段代码显示了每次内存引用时硬件（假设有硬件管理的 TLB）中发生的情况。从代码中可以看出，在任何复杂的多级页表访问发生之前，硬件首先会检查TLB；一旦命中，物理地址就直接形成，而无需像以前一样访问页表。仅当 TLB 未命中时，硬件才需要执行完整的多级查找。在此路径上，您可以看到传统两级页表的成本：两次额外的内存访问来查找有效的转换。 ","date":"2024-04-25","objectID":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/:3:4","tags":["OS"],"title":"高级页表","uri":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/"},{"categories":["系统架构"],"content":"3.5 真实的多级页表 真实多级页面表（$2^{48}$B=256TB） 如上图所示，线性地址的结构包含48位，这些位被划分为几个关键部分，每部分负责指向下一级的内存映射结构或确定页内的偏移量。 PML4 (Page Map Level 4): 线性地址的最高9位（位39-47）用于索引PML4（Page Map Level 4）表。PML4表是一个包含着页映射表指针的数组，每个指针指向一个页目录指针表（PDPT）。 Directory Pointer (PDPT): 接下来的9位（位30-38）用于在PDPT中索引一个条目，该条目指向一个页目录。 Directory (PD): 紧接着的9位（位21-29）用于在页目录中索引一个条目，该条目指向一个页表。 Page Table (PT): 再下来的9位（位12-20）用于在页表中索引一个页表项（PTE），该页表项包含了最终物理页面的地址信息。 Page Offset: 最后的12位（位0-11）是页内偏移量，用于确定在物理页面内的具体地址。 通过这种分层的索引机制，操作系统可以从线性地址生成对应的物理地址，从而允许更有效地管理内存，并实现诸如虚拟内存和内存保护等高级功能 自2021年起（$2^{56}$B=128PB） 相比之前的48位线性地址结构，现在的线性地址结构包含57位，多出了一个PML5级别，这使得页表层次结构更加深入，从而能够管理更大的地址空间。PML5 (Page Map Level 5): 新增的最高9位（位48-56）用于索引PML5表。PML5表是一个包含着页映射表指针的数组，每个指针指向一个PML4表。这一级页表的存在允许系统支持更大的物理内存，因为它增加了地址转换的层次，使得能够映射的地址空间成倍增长。PML5的引入进一步扩展了这种机制，使得系统能够处理更多的内存，这对于现代计算机系统处理大量数据和运行大型应用程序是非常重要的。 ","date":"2024-04-25","objectID":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/:3:5","tags":["OS"],"title":"高级页表","uri":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/"},{"categories":["系统架构"],"content":"4 反向页表 在页表的世界里，反向页表可以节省更多的空间。在这种情况下，我们不需要许多页表（系统的每个进程一个），而只需保存一个页表，该页表为系统的每个物理页提供一个条目。这个条目告诉我们哪个进程在使用这个页面，以及该进程的哪个虚拟页面映射到这个物理页面。 要找到正确的条目，只需在这个数据结构中进行搜索。线性扫描的成本很高，因此通常会在基础结构上建立一个哈希表，以加快查找速度。PowerPC 就是这种架构的一个例子。 更广泛地说，反向页表说明了我们从一开始就说过的：页表只是一种数据结构。你可以用数据结构做很多疯狂的事情，让它们变小或变大，变慢或变快。多级页表和倒转页表只是其中的两个例子。 ","date":"2024-04-25","objectID":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/:4:0","tags":["OS"],"title":"高级页表","uri":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/"},{"categories":["系统架构"],"content":"5 将页表交换到磁盘 最后，我们讨论放宽最后一个假设的问题。到目前为止，我们一直假设页表位于内核所有的物理内存中。即使我们采用了许多技巧来缩小页表的大小，但仍有可能出现页表过大，无法一次性放入内存的情况。因此，有些系统会将这些页表放在内核虚拟内存中，这样当内存压力有点紧张时，系统就可以将其中一些页表交换到磁盘上。我们将在以后的章节（即有关 VAX/VMS 的案例研究）中进一步讨论这个问题，届时我们将更详细地了解如何将页面移入和移出内存。 ","date":"2024-04-25","objectID":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/:5:0","tags":["OS"],"title":"高级页表","uri":"/posts/15.%E9%AB%98%E7%BA%A7%E9%A1%B5%E8%A1%A8/"},{"categories":["系统架构"],"content":"使用分页作为支持虚拟内存的核心机制可能会导致较高的性能开销。通过将地址空间分割成小的、固定大小的单元（即页），分页需要大量的映射信息。由于映射信息通常存储在物理内存中，因此分页逻辑上需要对程序生成的每个虚拟地址进行额外的内存查找。在每次取指令或显式加载或存储之前访问内存以获取地址转换信息的速度非常慢。 因此我们的问题关键是：我们如何才能加快地址转换，并从总体上避免分页似乎需要的额外内存引用？需要什么硬件支持？需要什么操作系统参与？ 当我们想让事情变得更快时，操作系统通常需要一些帮助。帮助通常来自操作系统的老朋友：硬件。为了加速地址转换，我们将添加一个叫做快表（translation-lookaside buffer, TLB）的硬件缓存。 TLB 是芯片内存管理单元 (MMU) 的一部分，只是常用的虚拟到物理地址转换的硬件缓存；因此，更好的名称是地址转换缓存（address-translation cache）。在每次虚拟内存引用时，硬件首先检查 TLB 以查看其中是否保存了所需的转换；如果是这样，则（快速）执行转换，而无需查阅页表（其中包含所有转换）。由于其巨大的性能影响，TLB 真正意义上使虚拟内存成为可能。 ","date":"2024-04-25","objectID":"/posts/14.%E5%BF%AB%E8%A1%A8/:0:0","tags":["OS"],"title":"快表","uri":"/posts/14.%E5%BF%AB%E8%A1%A8/"},{"categories":["系统架构"],"content":"1 TLB基本算法 下段代码粗略显示了硬件如何处理虚拟地址转换，假定有一个简单的线性页表（即页表是一个数组）和一个硬件管理的 TLB（即硬件处理页表访问的大部分责任）。 1: VPN = (VirtualAddress \u0026 VPN_MASK) \u003e\u003e SHIFT 2: (Success, TlbEntry) = TLB_Lookup(VPN) 3: if (Success == True) // TLB Hit 4: if (CanAccess(TlbEntry.ProtectBits) == True) 5: Offset = VirtualAddress \u0026 OFFSET_MASK 6: PhysAddr = (TlbEntry.PFN \u003c\u003c SHIFT) | Offset 7: Register = AccessMemory(PhysAddr) 8: else 9: RaiseException(PROTECTION_FAULT) 10: else // TLB Miss 11: PTEAddr = PTBR + (VPN * sizeof(PTE)) 12: PTE = AccessMemory(PTEAddr) 13: if (PTE.Valid == False) 14: RaiseException(SEGMENTATION_FAULT) 15: else if (CanAccess(PTE.ProtectBits) == False) 16: RaiseException(PROTECTION_FAULT) 17: else 18: TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits) 19: RetryInstruction() 硬件遵循的算法是这样工作的：首先，从虚拟地址中提取虚拟页码（VPN）（第一行），然后检查 TLB 是否持有该 VPN 的转换（第 2 行）。如果是，我们就有一个 TLB 命中，这意味着 TLB 保留了转换。成功！现在我们可以从相关的 TLB 条目中提取物理页码 (PFN)，将其与原始虚拟地址的偏移量连接起来，形成所需的物理地址 (PA)，然后访问内存（第 5-7 行），前提是保护检查没有失败（第 4 行）。 如果 CPU 在 TLB 中没有找到转换（TLB 未命中），我们还需要做一些工作。在此示例中，硬件会访问页表以查找转换（第 11-12 行），并假设进程生成的虚拟内存引用有效且可访问（第 13、15 行），然后用转换更新 TLB（第 18 行）。这一系列操作代价高昂，主要是因为访问页表需要额外的内存引用（第 12 行）。最后，一旦更新了 TLB，硬件就会重试指令；这一次，转换可以在 TLB 中找到，内存引用也会得到快速处理。 TLB 和所有缓存一样，其建立的前提是在一般情况下，转换都能在缓存中找到（即命中）。在这种情况下，由于 TLB 位于处理核心附近，而且设计得相当快，因此几乎不会增加开销。当出现未命中时，就会产生高昂的分页成本；必须访问页表才能找到转换，这就会产生额外的内存引用（或更多，如果页表更复杂）。如果这种情况经常发生，程序的运行速度可能会明显变慢；相对于大多数 CPU 指令而言，内存访问的成本相当高，而 TLB 未命中会导致更多的内存访问。因此，我们希望尽可能避免 TLB 未命中。 ","date":"2024-04-25","objectID":"/posts/14.%E5%BF%AB%E8%A1%A8/:1:0","tags":["OS"],"title":"快表","uri":"/posts/14.%E5%BF%AB%E8%A1%A8/"},{"categories":["系统架构"],"content":"2 示例：访问数组 为了弄清楚 TLB 的操作，让我们研究一个简单的虚拟地址跟踪，看看 TLB 如何提高其性能。在此示例中，假设内存中有一个由 10 个 4 字节整数组成的数组，从虚拟地址 100 开始。进一步假设我们有一个小的 8 位虚拟地址空间，具有 16 字节大小的页面；因此，虚拟地址分为 4 位 VPN（有 16 个虚拟页面）和 4 位偏移量（每个页面有 16 个字节）。 下图显示了系统 16 个 16 字节页面上的布局。如图所示，数组的第一个条目（a[0]）开始于（VPN=06，偏移量=04）；在这一页上只能容纳三个 4 字节的整数。数组继续进入下一页（VPN=07），在这一页上找到接下来四个条目（a[3] … a[6]）。最后，10 个条目数组的最后三个条目（a[7] … a[9]）位于地址空间的下一页（VPN=08）。 现在让我们考虑一个访问每个数组元素的简单循环，在 C 中看起来像这样： int sum = 0; for (i = 0; i \u003c 10; i++) { sum += a[i]; } 为了简单起见，我们假设循环生成的唯一内存访问是数组（忽略变量 i 和 sum，以及指令本身）。当访问第一个数组元素 (a[0]) 时，CPU 将看到对虚拟地址 100 的加载。硬件从中提取 VPN (VPN=06)，并使用它来检查 TLB 的有效转换。假设这是程序第一次访问数组，结果将是 TLB 未命中。 下一次访问是 a[1]，这里有一个好消息：TLB 命中！因为数组的第二个元素紧挨着第一个元素，所以它位于同一个页面上；因为我们在访问数组的第一个元素时已经访问了这个页面，所以转换已经加载到TLB中。这就是我们成功的原因。访问 a[2] 会遇到类似的成功（另一个命中），因为它也与 a[0] 和 a[1] 位于同一页面上。 不幸的是，当程序访问a[3]时，我们遇到了另一个TLB未命中。然而，下一个条目 (a[4] … a[6]) 将再次命中 TLB，因为它们都驻留在内存中的同一页上。 最后，访问 a[7] 会导致最后一次 TLB 未命中。硬件再次查询页表以找出该虚拟页在物理内存中的位置，并相应地更新TLB。最后两次访问（a[8] 和 a[9]）受益于该 TLB 更新；当硬件在 TLB 中查找转换时，会产生另外两次命中。 让我们总结一下在对数组进行十次访问期间 TLB 的活动：miss、hit、hit、miss、hit、hit、hit、miss、hit、hit。因此，我们的 TLB 命中率（即命中次数除以总访问次数）为 70%。虽然这不是太高（事实上，我们希望命中率接近 100%），但它是非零的，这可能会令人惊讶。尽管这是程序第一次访问数组，但 TLB 由于空间局部性而提高了性能。数组的元素被紧密地打包到页面中（即，它们在空间上彼此靠近），因此只有第一次访问页面上的元素才会产生 TLB 未命中。 还要注意页面大小在本例中的作用。如果页面大小是原来的两倍（32 字节，而不是 16 字节），那么阵列访问的未命中次数就会更少。由于典型的页面大小更接近 4KB，这些类型的密集、基于数组的访问实现了出色的 TLB 性能，每页访问只出现一次未命中。 关于 TLB 性能的最后一点：如果程序在循环结束后不久再次访问数组，我们很可能会看到更好的结果，前提是我们有足够大的 TLB 来缓存所需的转换：hit、hit、hit、hit、hit、hit、hit、hit、hit、hit。在这种情况下，TLB 命中率会很高，这是因为时间局部性，即在时间上快速重新引用内存项。与其他高速缓存一样，TLB 的成功依赖于空间和时间的局部性，而空间和时间的局部性是程序的属性。如果相关程序具有这种局部性（许多程序都具有这种局部性），那么 TLB 的命中率很可能会很高。 ","date":"2024-04-25","objectID":"/posts/14.%E5%BF%AB%E8%A1%A8/:2:0","tags":["OS"],"title":"快表","uri":"/posts/14.%E5%BF%AB%E8%A1%A8/"},{"categories":["系统架构"],"content":"3 谁处理TLB未命中？ 我们必须回答一个问题：谁来处理 TLB 未命中？有两个可能的答案：硬件或软件（操作系统）。在过去，硬件具有复杂的指令集（有时称为CISC，用于复杂指令集计算机），而构建硬件的人不太信任那些鬼鬼祟祟的操作系统人员。因此，硬件将完全处理 TLB 未命中。为此，硬件必须确切地知道页表在内存中的位置（通过页表基址寄存器），以及它们的确切格式；如果未命中，硬件将“遍历”页表，找到正确的页表条目并提取所需的转换，用转换更新 TLB，然后重试指令。具有硬件管理 TLB 的“旧”架构的一个示例是 Intel x86 架构，它使用固定的多级页表；当前页表由CR3寄存器指向。 更现代的架构（例如，MIPS R10k 或 Sun 的 SPARC v9，RISC 或精简指令集计算机）具有所谓的软件管理 TLB。当 TLB 未命中时，硬件只会引发异常，该异常会暂停当前指令流，将特权级别提升到内核模式，并跳转到中断处理程序。您可能会猜到，此中断处理程序是操作系统中的代码，其编写的明确目的是处理 TLB 未命中。运行时，代码将在页表中查找转换，使用特殊的“特权”指令来更新TLB，然后从中断返回；此时，硬件会重试该指令（导致 TLB 命中）。 让我们讨论几个重要的细节。首先，从中断返回指令需要与我们之前在服务系统调用时看到的从中断返回指令略有不同。在后一种情况下，从中断返回应该在中断进入操作系统后的指令处恢复执行，就像从过程调用返回到紧随过程调用之后的指令一样。在前一种情况下，当从 TLB 未命中处理中断返回时，硬件必须在导致中断的指令处恢复执行；因此，此重试让指令再次运行，这一次导致 TLB 命中。因此，根据中断或异常的引发方式，硬件在中断进入操作系统时必须保存不同的 PC，以便在时间到来时正确恢复。 其次，当运行 TLB 未命中处理代码时，操作系统需要格外小心，不要导致发生无限的 TLB 未命中链。存在许多解决方案；例如，您可以将 TLB 未命中处理程序保留在物理内存中（它们未映射且不受地址转换影响），或者在 TLB 中保留一些条目以进行永久有效的转换，并将其中一些永久转换槽用于处理程序代码本身;这些有线转换总是命中 TLB。 软件管理方法的主要优点是灵活性：操作系统可以使用它想要实现页表的任何数据结构，而无需更改硬件。另一个优点是简单。如下面这段代码所示，硬件在未命中时不会做太多事情：只是引发异常，然后让操作系统 TLB 未命中处理程序完成其余的工作。 1: VPN = (VirtualAddress \u0026 VPN_MASK) \u003e\u003e SHIFT 2: (Success, TlbEntry) = TLB_Lookup(VPN) 3: if (Success == True) // TLB Hit 4: if (CanAccess(TlbEntry.ProtectBits) == True) 5: Offset = VirtualAddress \u0026 OFFSET_MASK 6: PhysAddr = (TlbEntry.PFN \u003c\u003c SHIFT) | Offset 7: Register = AccessMemory(PhysAddr) 8: else 9: RaiseException(PROTECTION_FAULT) 10: else // TLB Miss 11: RaiseException(TLB_MISS) ","date":"2024-04-25","objectID":"/posts/14.%E5%BF%AB%E8%A1%A8/:3:0","tags":["OS"],"title":"快表","uri":"/posts/14.%E5%BF%AB%E8%A1%A8/"},{"categories":["系统架构"],"content":"4 TLB 内容：里面有什么？ 让我们详细了解一下硬件 TLB 的内容。典型的 TLB 可能有 32、64 或 128 个条目，并且被称为全关联。基本上，这意味着任何给定的转换都可以在 TLB 的任何位置，硬件将并行搜索整个 TLB 以找到所需的转换。一个 TLB 条目可能是这样的： 请注意，VPN 和 PFN 都存在于每个条目中，因为转换可能最终位于这些位置中的任何一个（在硬件术语中，TLB 称为全关联缓存）。硬件并行搜索条目以查看是否存在匹配。 更有趣的是“其他位”。例如，TLB通常有一个有效位，它表示该条目是否具有有效的转换。同样常见的是保护位，它决定如何访问页面（如在页表中）。例如，代码页可能被标记为读取和执行，而堆页可能被标记为读取和写入。还可能有一些其他字段，包括地址空间标识符、脏位等。 ","date":"2024-04-25","objectID":"/posts/14.%E5%BF%AB%E8%A1%A8/:4:0","tags":["OS"],"title":"快表","uri":"/posts/14.%E5%BF%AB%E8%A1%A8/"},{"categories":["系统架构"],"content":"5 TLB 问题：上下文切换 对于 TLB，在进程（以及地址空间）之间切换时会出现一些新问题。具体来说，TLB 包含仅对当前运行的进程有效的虚拟到物理的转换；这些转换对于其他进程没有意义。因此，当从一个进程切换到另一个进程时，硬件或操作系统（或两者）必须小心，以确保即将运行的进程不会意外使用某些先前运行的进程的转换。 为了更好地理解这种情况，让我们看一个例子。当一个进程 (P1) 运行时，它假设 TLB 可能正在缓存对其有效的转换，即来自 P1 的页表的转换。对于此示例，假设 P1 的第 10 个虚拟页映射到物理页 100。 在此示例中，假设存在另一个进程 (P2)，并且操作系统很快可能决定执行上下文切换并运行它。这里假设 P2 的第 10 个虚拟页映射到物理页 170。如果两个进程的条目都在 TLB 中，则 TLB 的内容将为： 在上面的 TLB 中，我们显然遇到了一个问题：VPN 10 转换为 PFN 100 (P1) 或 PFN 170 (P2)，但硬件无法区分哪个条目适用于哪个进程。因此，为了让TLB能够正确、高效地支持跨多进程的虚拟化，我们还需要做更多的工作。因此，关键在于：当在进程之间进行上下文切换时，最后一个进程的 TLB 中的转换对于即将运行的进程没有意义。为了解决这个问题，硬件或操作系统应该做什么？ 对于这个问题有多种可能的解决方案。一种方法是简单地在上下文切换时刷新 TLB，从而在运行下一个进程之前清空它。在基于软件的系统上，这可以通过显式（且特权）的硬件指令来完成；使用硬件管理的 TLB，当页表基址寄存器更改时可以执行刷新（请注意，操作系统无论如何都必须在上下文切换时更改 PTBR）。无论哪种情况，刷新操作都只是将所有有效位设置为 0，本质上是清除 TLB 的内容。 通过在每次上下文切换时刷新 TLB，我们现在有了一个可行的解决方案，因为进程永远不会意外地遇到 TLB 中的错误转换。然而，这是有代价的：每次进程运行时，它在接触其数据和代码页时都必须导致 TLB 未命中。如果操作系统频繁地在进程之间切换，这个成本可能会很高。 为了减少这种开销，一些系统添加了硬件支持以实现跨上下文切换的 TLB 共享。特别地，一些硬件系统在TLB中提供地址空间标识符(ASID)字段。您可以将 ASID 视为进程标识符 (PID)，但通常它的位数较少（例如，ASID 为 8 位，而 PID 为 32 位）。 如果我们采用上面的示例 TLB 并添加 ASID，很明显进程可以轻松共享 TLB：仅需要 ASID 字段来区分其他相同的转换。以下是添加了 ASID 字段的 TLB 的描述： 因此，利用地址空间标识符，TLB 可以同时保存来自不同进程的转换，而不会产生任何混淆。当然，硬件还需要知道当前正在运行哪个进程才能执行转换，因此操作系统必须在上下文切换时将某些特权寄存器设置为当前进程的 ASID。 您可能还想到了另一种情况，其中 TLB 的两个条目非常相似。在此示例中，两个不同进程的两个条目具有指向同一物理页面的两个不同 VPN：例如，当两个进程共享一个页面（例如代码页）时，可能会出现这种情况。 在上面的示例中，进程 1 与进程 2 共享物理页 101； P1 将此页映射到其地址空间的第 10 页，而 P2 将此页映射到其地址空间的第 50 页。共享代码页（在二进制文件或共享库中）很有用，因为它减少了使用的物理页数量，从而减少了内存开销。 ","date":"2024-04-25","objectID":"/posts/14.%E5%BF%AB%E8%A1%A8/:5:0","tags":["OS"],"title":"快表","uri":"/posts/14.%E5%BF%AB%E8%A1%A8/"},{"categories":["系统架构"],"content":"6 TLB 替换策略 与任何缓存一样，对于 TLB 来说也是如此，我们必须考虑的另一个问题是缓存替换。具体来说，当我们在 TLB 中安装新条目时，我们必须替换旧条目，因此问题的关键是：要替换哪一个？如何设计 TLB 替换策略？ 当我们添加新的 TLB 条目时，应该替换哪个 TLB 条目？当然，目标是最大限度地减少未命中率（或提高命中率），从而提高性能。 当我们解决将页面交换到磁盘的问题时，我们将详细研究这些策略；这里我们只重点介绍一些典型的政策。 一种常见的方法是逐出最近最少使用的条目或 LRU 条目。 LRU 尝试利用内存引用流中的局部性，假设最近未使用的条目可能是驱逐的良好候选者。 另一种典型的方法是使用随机策略，随机驱逐 TLB 映射。这种策略非常有用，因为它简单并且能够避免极端情况行为；例如，当程序在 TLB 大小为 n 的 n + 1 个页面上循环时，诸如 LRU 之类的“合理”策略就会表现得非常不合理；在这种情况下，LRU 会错过每次访问，而随机则做得更好。 ","date":"2024-04-25","objectID":"/posts/14.%E5%BF%AB%E8%A1%A8/:6:0","tags":["OS"],"title":"快表","uri":"/posts/14.%E5%BF%AB%E8%A1%A8/"},{"categories":["系统架构"],"content":"7 实际系统里的TLB 最后，让我们简单看一下真正的TLB。此示例来自 MIPS R4000 ，这是一个使用软件管理的 TLB 的现代系统；如下图所示，可以看到稍微简化的 MIPS TLB 条目。 MIPS R4000 支持具有 4KB 页的 32 位地址空间。因此，我们期望在我们的经典虚拟地址中有 20 位 VPN 和 12 位偏移量。然而，正如您在 TLB 中看到的，VPN 只有 19 位；事实证明，用户地址仅来自一半的地址空间（其余部分为内核保留），因此只需要 19 位的 VPN。 VPN 最多可转换为 24 位物理页号 (PFN)，因此可以支持具有高达 64GB（物理）主内存（224 个 4KB 页）的系统。 MIPS TLB 中还有一些其他有趣的位。我们看到一个全局位（G），它用于在进程之间全局共享的页面。因此，如果设置了全局位，则 ASID 将被忽略。我们还看到 8 位 ASID，操作系统可以使用它来区分地址空间（如上所述）。最后，我们看到 3 个 Coherence (C) 位，它们决定硬件如何缓存页面；当页面被写入时标记的脏位；一个有效位，告诉硬件条目中是否存在有效的转换。还有一个页面掩码字段（未显示），支持多种页面大小；稍后我们会看到为什么更大的页面可能有用。最后，还有部分未使用。 Flag Content 19-bit VPN 剩余部分保留给内核。 24-bit PFN 系统支持最多64GB的主存储（$2^{24}\\times 4\\text{KB pages}$页面）。 Global bit(G) 用于在进程间共享的页面（忽略ASID）。 ASID 操作系统用于区分地址空间的标识。 Coherence bit(C) 确定页面如何被硬件缓存 Dirty bit(D) 标记页面是否已被写入 Valid bit(V) 告诉硬件条目中是否存在有效的转换 MIPS TLB 通常有 32 或 64 个这样的条目，其中大部分由用户进程在运行时使用。然而，有一些是为操作系统保留的。操作系统可以设置一个有线寄存器来告诉硬件TLB要为操作系统保留多少个插槽；操作系统将这些保留的映射用于它想要在关键时刻访问的代码和数据，此时 TLB 未命中会出现问题（例如，在 TLB 未命中处理程序中）。 由于 MIPS TLB 是由软件管理的，因此需要有更新 TLB 的指令。 MIPS 提供了四种这样的指令： TLBP：它探测 TLB 以查看其中是否存在特定的转换； TLBR：将 TLB 条目的内容读入寄存器； TLBWI：替换特定的 TLB 条目； TLBWR：它替换随机 TLB 条目。操作系统使用这些指令来管理 TLB 的内容。 当然，至关重要的是这些指令具有特权；想象一下，如果用户进程可以修改 TLB 的内容，它会做什么（提示：几乎任何事情，包括接管机器、运行自己的恶意“操作系统”，甚至让 Sun 消失）。 ","date":"2024-04-25","objectID":"/posts/14.%E5%BF%AB%E8%A1%A8/:7:0","tags":["OS"],"title":"快表","uri":"/posts/14.%E5%BF%AB%E8%A1%A8/"},{"categories":["系统架构"],"content":"8 总结 我们已经看到硬件如何帮助我们更快地进行地址转换。通过提供小型专用片上 TLB 作为地址转换缓存，大多数内存引用有望在无需访问主内存中的页表的情况下得到处理。因此，在常见情况下，程序的性能几乎就像内存根本没有被虚拟化一样，这对于操作系统来说是一项出色的成就，并且对于现代系统中分页的使用当然至关重要。 然而，TLB 并没有让每个现有的程序都变得美好。特别是，如果程序在短时间内访问的页数超过了TLB所能容纳的页数，则程序将产生大量的TLB未命中，从而运行速度会变得相当慢。我们将这种现象称为超出 TLB 覆盖范围，对于某些程序来说这可能是一个很大的问题。一个解决方案是支持更大的页面大小；通过将关键数据结构映射到程序地址空间中由较大页面映射的区域，可以增加 TLB 的有效覆盖范围。对大页面的支持通常由诸如数据库管理系统（DBMS）之类的程序利用，这些程序具有某些既大又随机访问的数据结构。 另一个值得一提的 TLB 问题是：TLB 访问很容易成为 CPU 管道中的瓶颈，特别是对于所谓的物理索引缓存。对于这样的缓存，必须在访问缓存之前进行地址转换，这会大大减慢速度。由于这个潜在的问题，人们研究了各种巧妙的方法来使用虚拟地址访问缓存，从而避免缓存命中时昂贵的转换步骤。这种虚拟索引缓存解决了一些性能问题，但也给硬件设计带来了新问题。 巨型页面（2MB 页面） 千兆页面（1GB 页面） 最先进的 TLB（AMD Zen4） ","date":"2024-04-25","objectID":"/posts/14.%E5%BF%AB%E8%A1%A8/:8:0","tags":["OS"],"title":"快表","uri":"/posts/14.%E5%BF%AB%E8%A1%A8/"},{"categories":["系统架构"],"content":"有时有人说，操作系统在解决大多数空间管理问题时会采用两种方法之一。第一种方法是将事物切成可变大小的块，正如我们在虚拟内存中的分段中看到的那样。不幸的是，这个解决方案有其固有的困难。特别是，当将空间划分为不同大小的块时，空间本身可能会变得碎片化，因此随着时间的推移，分配变得更具挑战性。 因此，可能值得考虑第二种方法：将空间切成固定大小的块。在虚拟内存中，我们将这种想法称为分页，它可以追溯到一个早期且重要的系统，Atlas。我们不是将进程的地址空间划分为一定数量的可变大小的逻辑段（例如代码、堆、栈），而是将其划分为固定大小的单元，每个单元称为页面。相应地，我们将物理内存视为一组固定大小的槽（称为页框）；每个框都可以包含一个虚拟内存页；每个进程都需要页表来将虚拟地址转换为物理地址。。我们的挑战： 关键：如何使用页面虚拟化内存 ? 如何使用页面虚拟化内存，从而避免分段问题？有哪些基本技术？我们如何以最小的空间和时间开销使这些技术发挥良好作用？ ","date":"2024-04-25","objectID":"/posts/13.%E9%A1%B5/:0:0","tags":["OS"],"title":"页","uri":"/posts/13.%E9%A1%B5/"},{"categories":["系统架构"],"content":"1 示例：一个简单的分页 为了更清楚地说明这种方法，让我们来看一个简单的例子。下图展示了一个很小的地址空间，总大小只有 64 字节，有四个 16 字节的页面（虚拟页面 0、1、2 和 3）。 当然，真实的地址空间要大得多，通常为 32 位，因此有 4GB 的地址空间，甚至 64 位。 如下图所示，物理内存也由许多固定大小的槽组成，在本例中是 8 个页框（对于 128 字节的物理内存来说，也小得离谱）。虚拟地址空间的页面被放置在整个物理内存的不同位置；该图还显示操作系统自身使用一些物理内存。 正如我们将看到的，分页比我们以前的方法有许多优点。最重要的改进可能是灵活性：通过完全开发的分页方法，系统将能够有效地支持地址空间的抽象，无论进程如何使用地址空间；例如，我们不会对堆和栈的增长方向以及它们的使用方式做出假设。 另一个优点是分页提供的可用空间管理的简单性。例如，当操作系统希望将我们微小的 64 字节地址空间放入我们的八页物理内存中时，它只会找到四个空闲页；也许操作系统为此保留了所有空闲页面的空闲列表，并且只从该列表中获取前四个空闲页面。在示例中，操作系统已将地址空间 (AS) 的虚拟页 0 放置在物理页 3 中，将 AS 的虚拟页 1 放置在物理页7 中，将页 2 放置在物理页 5 中，将页 3 放置在物理页 2 中。 页框 1 、4 和 6 目前空闲。 为了记录地址空间的每个虚拟页在物理内存中的位置，操作系统通常会为每个进程保存一个名为页表的数据结构。页表的主要作用是存储地址空间中每个虚拟页的地址转换，从而让我们知道每个页位于物理内存中的位置。对于我们的简单示例，页表将具有以下四个条目：（虚拟页 0 → 物理页3）、（VP 1 → PF 7）、（VP 2 → PF 5）和（VP 3 → PF 2）。 重要的是要记住，这个页表是一个每个进程的数据结构（我们讨论的大多数页表结构都是每个进程的结构；我们将提到一个例外，即反向页表）。如果在上面的示例中运行另一个进程，则操作系统必须为其管理不同的页表，因为它的虚拟页面显然映射到不同的物理页面（除非有任何共享正在进行）。 现在，我们知道足够多以执行地址转换示例。让我们想象一下具有微小地址空间（64字节）的进程正在执行内存访问： movl \u003cvirtual address\u003e, %eax 具体来说，让我们注意将数据从地址\u003cvirtual address\u003e显式加载到寄存器 eax 中（从而忽略之前必须发生的指令获取）。 为了转换进程生成的虚拟地址，我们必须首先将其分为两个部分：虚拟页号（Vitrual page number,VPN）和页面内的偏移量。对于此示例，由于进程的虚拟地址空间为 64 字节，因此我们的虚拟地址总共需要 6 位 ($2^6 = 64$)。因此，我们的虚拟地址可以概念化如下： 其中，Va5是虚拟地址的最高位，Va0是最低位。因为我们知道页面大小（16字节），则前两位代表虚拟页号，后四位代表页面偏移量。在 64 字节地址空间中，页面大小为 16 字节；因此我们需要能够选择 4 个页面，地址的前 2 位就可以做到这一点。因此，我们有一个 2 位虚拟页码 (VPN)。剩余的位则表示页面偏移量。 当进程生成虚拟地址时，操作系统和硬件必须结合起来将其转换为有意义的物理地址。例如，假设上述加载到虚拟地址 21： movl 21, %eax 将“21”转换为二进制形式，我们得到“010101”，因此我们可以检查这个虚拟地址并查看它如何分解为虚拟页号（VPN）和偏移量： 因此，虚拟地址“21”位于虚拟页“01”（或1）的第5（“0101”）字节。有了虚拟页号，我们现在可以索引页表并找到虚拟页 1 所在的物理页。在上面的页表中，物理页号 (Physical page number, PPN)（有时也称为物理帧号或 PFN）为 7（二进制 111）。因此，我们可以通过用 PPN 替换 VPN 来转换这个虚拟地址，然后向物理内存加载数据，如下图所示。 请注意，偏移量保持不变（即，它没有被转换），因为偏移量只是告诉我们我们想要页面中的哪个字节。我们的最终物理地址是 1110101（十进制为 117），这正是我们希望加载获取数据的位置。 ","date":"2024-04-25","objectID":"/posts/13.%E9%A1%B5/:1:0","tags":["OS"],"title":"页","uri":"/posts/13.%E9%A1%B5/"},{"categories":["系统架构"],"content":"2 页表存储在哪？ 页表可以变得非常大，比我们之前讨论的小分段表或基址/边界对大得多。例如，想象一个典型的 32 位地址空间，具有 4KB 页面。该虚拟地址分为 20 位 VPN 和 12 位偏移量（回想一下，1KB 页面大小需要 10 位，只需再添加两位即可达到 4KB）。 20 位 VPN 意味着操作系统必须为每个进程管理 $2^{20}$ 个转换（大约一百万个）；假设每个页表项 (page table entry, PTE) 需要 4 个字节来保存物理转换以及任何其他有用的内容，那么每个页表需要 4MB 的巨大内存！那是相当大的。现在假设有 100 个进程正在运行：这意味着操作系统需要 400MB 内存来用于所有这些地址转换！即使在机器拥有千兆字节内存的现代，将大量内存用于地址转换似乎也有点疯狂，不是吗？我们甚至没有考虑对于 64 位地址空间来说这样的页表有多大；那太可怕了，也许会把你完全吓跑。 由于页表太大，我们没有在MMU中保留任何特殊的片上硬件来存储当前运行进程的页表。相反，我们将每个进程的页表存储在内存中的某个位置。现在我们假设页表位于操作系统管理的物理内存中，下图是操作系统内存中页表的图片。 ","date":"2024-04-25","objectID":"/posts/13.%E9%A1%B5/:2:0","tags":["OS"],"title":"页","uri":"/posts/13.%E9%A1%B5/"},{"categories":["系统架构"],"content":"3 页表中到底有什么？ 让我们来谈谈页表的组织结构。页表只是一种数据结构，用于将虚拟地址（或实际上是虚拟页码）映射到物理地址（物理页号）。因此，任何数据结构都可以使用。最简单的形式称为线性页表，它只是一个数组。操作系统根据虚拟页码（VPN）对数组进行索引，并查找该索引下的页表项（PTE），以找到所需的物理页号（PFN）。目前，我们将假设这种简单的线性结构；在后面的章节中，我们将使用更高级的数据结构来帮助解决分页中的一些问题。 至于每个 PTE 的内容，我们有许多不同的bit位值得在一定程度上了解。有效位通常用于指示特定转换是否有效。例如，当程序开始运行时，其地址空间的一端是代码和堆，另一端是栈。中间所有未使用的空间都会被标记为无效，如果进程试图访问这些内存，就会向操作系统发出中断，操作系统很可能会终止进程。因此，有效位对于支持稀疏地址空间至关重要；只需将地址空间中所有未使用的页面标记为无效，我们就无需为这些页面分配物理页号，从而节省了大量内存。 我们还可以使用保护位来表明是否可以读取、写入或执行页面。同样，如果以这些位不允许的方式访问页面，就会向操作系统发出中断。 还有一些其他的位也很重要，但我们现在就不多说了。存在位表示该页面是在物理内存中还是在磁盘上（即已被换出）。当我们研究如何将部分地址空间交换到磁盘以支持比物理内存更大的地址空间时，我们将进一步了解这一机制；交换允许操作系统通过将很少使用的页面移动到磁盘来释放物理内存。**脏位（dirty bit）**也很常见，表示页面进入内存后是否被修改过。 参考位（又称访问位）有时用于跟踪页面是否被访问过，它有助于确定哪些页面受欢迎，因此应保留在内存中；在页面替换过程中，这种知识至关重要。 下图显示了 x86 架构中的一个页表条目示例。它包含一个存在位 (P)；一个读/写位 (R/W)，用于确定是否允许写入该页面；一个用户/监管者位 (U/S)，用于确定用户模式进程是否可以访问该页面；几个位（PWT、PCD、PAT 和 G），用于确定这些页面的硬件缓存工作方式；一个已访问位 (A) 和一个脏位 (D)；最后是物理页号（PFN）本身。 ","date":"2024-04-25","objectID":"/posts/13.%E9%A1%B5/:3:0","tags":["OS"],"title":"页","uri":"/posts/13.%E9%A1%B5/"},{"categories":["系统架构"],"content":"4 分页：也太慢 对于内存中的页表，我们已经知道它们可能过大。事实证明，它们也会拖慢运行速度。举个简单的例子： movl 21, %eax 同样，我们只检查对地址 21 的显式引用，而不用担心取指令。在这个例子中，我们假设硬件为我们执行地址转换。为了获取所需的数据，系统必须首先将虚拟地址（21）转换为正确的物理地址（117）。因此，在从地址 117 获取数据之前，系统必须首先从进程的页表中获取正确的页表条目，执行转换，然后从物理内存加载数据。 为此，硬件必须知道当前运行进程的页表在哪里。现在我们假设单个页表基址寄存器包含页表起始位置的物理地址。为了找到所需 PTE 的位置，硬件将执行以下功能： VPN = (VirtualAddress \u0026 VPN_MASK) \u003e\u003e SHIFT PTEAddr = PageTableBaseRegister + (VPN * sizeof(PTE)) 在我们的示例中，VPN_MASK 将设置为 0x30（十六进制 30，或二进制 110000），它从完整虚拟地址中挑选出 VPN 位； SHIFT 设置为 4（偏移量中的位数），以便我们将 VPN 位向下移动以形成正确的整数虚拟页号。例如，对于虚拟地址21（010101），掩码将该值变成010000；根据需要，移位会将其变为 01 或虚拟页 1。然后，我们使用该值作为页表基址寄存器指向的 PTE 数组的索引。 一旦知道这个物理地址，硬件就可以从内存中获取 PTE，提取 PFN，并将其与虚拟地址的偏移量连接起来，形成所需的物理地址。具体来说，可以认为 PFN 通过 SHIFT 左移，然后与偏移量按位或运算形成最终地址，如下所示： offset = VirtualAddress \u0026 OFFSET_MASK PhysAddr = (PFN \u003c\u003c SHIFT) | offset 最后，硬件可以从内存中取出所需的数据并将其放入寄存器eax中。程序现在已成功从内存加载一个值！ 总而言之，我们现在描述每个内存引用上发生的情况的初始协议。下面这段代码显示了基本方法。 # Extract the VPN from the virtual address VPN = (VirtualAddress \u0026 VPN_MASK) \u003e\u003e SHIFT # Form the address of the page-table entry (PTE) PTEAddr = PTBR + (VPN * sizeof(PTE)) # Fetch the PTE PTE = AccessMemory(PTEAddr) # Check if process can access the page if (PTE.Valid == False) RaiseException(SEGMENTATION_FAULT) else if (CanAccess(PTE.ProtectBits) == False) RaiseException(PROTECTION_FAULT) else # Access is OK: form physical address and fetch it offset = VirtualAddress \u0026 OFFSET_MASK PhysAddr = (PTE.PFN \u003c\u003c PFN_SHIFT) | offset Register = AccessMemory(PhysAddr) 对于每个内存引用（无论是指令获取还是显式加载或存储），分页要求我们执行一次额外的内存引用，以便首先从页表中获取。这是很多工作！额外的内存引用成本高昂，在这种情况下可能会使进程减慢两倍或更多。 现在您有望看到我们必须解决两个真正的问题。如果没有仔细设计硬件和软件，页表会导致系统运行速度过慢，并且占用过多的内存。虽然这似乎是满足我们内存虚拟化需求的一个很好的解决方案，但必须首先克服这两个关键问题。 ","date":"2024-04-25","objectID":"/posts/13.%E9%A1%B5/:4:0","tags":["OS"],"title":"页","uri":"/posts/13.%E9%A1%B5/"},{"categories":["系统架构"],"content":"5 内存跟踪 在结束之前，我们现在通过一个简单的内存访问示例来演示使用分页时发生的所有结果内存访问。我们感兴趣的代码片段（在 C 语言中，在名为 array.c 的文件中）如下： int array[1000]; ... for (i = 0; i \u003c 1000; i++) array[i] = 0; 我们编译 array.c 并使用以下命令运行它： gcc -o array array.c -Wall -O ./array 当然，为了真正理解内存访问此代码片段（它只是初始化一个数组）会产生什么，我们必须知道（或假设）更多的事情。首先，我们必须反汇编生成的二进制文件（在 Linux 上使用 objdump，在 Mac 上使用 otool）以查看使用哪些汇编指令来初始化循环中的数组。这是生成的汇编代码： 0x1024 movl $0x0,(%edi,%eax,4) #Power of CISC! edi+eax*4 0x1028 incl %eax #Increase counter 0x102c cmpl $0x03e8,%eax #Check if last element 0x1030 jne 0x1024 #Implicit (eflags) Zero bit access 如果您了解一点 x86，该代码实际上很容易理解。第一条指令将值零（显示为 $0x0）移动到数组位置的虚拟内存地址中；该地址是通过获取 %edi 的内容并添加 %eax 乘以四来计算的。因此，%edi 保存数组的基地址，而 %eax 保存数组索引 (i)；我们乘以四，因为该数组是整数数组，每个整数大小为四个字节。 第二条指令递增 %eax 中保存的数组索引，第三条指令将该寄存器的内容与十六进制值 0x03e8 或十进制 1000 进行比较。如果比较显示两个值还不相等（这就是 jne 指令测试的结果），第四条指令跳回循环顶部。 为了了解该指令序列访问哪些内存（在虚拟和物理级别），我们必须假设代码片段和数组在虚拟内存中的位置，以及页表的内容和位置。对于此示例，我们假设虚拟地址空间大小为 64KB（小得不切实际）。我们还假设页面大小为 1KB。 我们现在需要知道的是页表的内容及其在物理内存中的位置。假设我们有一个线性（基于数组）页表，并且它位于物理地址 1KB (1024)。 至于其内容，我们只需要担心在本示例中映射了几个虚拟页面。首先，代码所在的虚拟页面。由于页面大小为 1KB，因此虚拟地址 1024 驻留在虚拟地址空间的第二页上（VPN=1，因为 VPN=0 是第一页）。我们假设该虚拟页面映射到物理帧 4 (VPN 1 → PFN 4)。 接下来是数组本身。它的大小是 4000 字节（1000 个整数），我们假设它驻留在虚拟地址 40000 到 44000（不包括最后一个字节）。此十进制范围的虚拟页面为 VPN=39 … VPN=42。因此，我们需要这些页面的映射。我们假设以下虚拟到物理映射为示例：(VPN 39 → PFN 7)、(VPN 40 → PFN 8)、(VPN 41 → PFN 9)、(VPN 42 → PFN 10)。 我们现在准备跟踪程序的内存引用。当它运行时，每个指令获取都会生成两个内存引用：一个到页表以查找指令所在的物理页，另一个到指令本身以将其获取到 CPU 进行处理。此外，还有一个以 mov 指令形式出现的显式内存引用；这首先增加了另一个页表访问（将数组虚拟地址转换为正确的物理地址），然后才是数组访问本身。 下图描述了前五个循环迭代的整个过程。最下面的图以黑色显示 y 轴上的指令内存引用（左边是虚拟地址，右边是实际物理地址）；中间的图以深灰色显示数组访问（同样是左边是虚拟地址，右边是物理地址）；最后，最上面的图以浅灰色显示页表内存访问（只是物理访问，因为本例中的页表位于物理内存中）。整个跟踪的 x 轴显示了循环前五次迭代的内存访问；每个循环有 10 次内存访问，其中包括四次指令取回、一次内存显式更新和五次页表访问，以转换这四次取回和一次显式更新。 ","date":"2024-04-25","objectID":"/posts/13.%E9%A1%B5/:5:0","tags":["OS"],"title":"页","uri":"/posts/13.%E9%A1%B5/"},{"categories":["系统架构"],"content":"1 假设 本讨论的大部分内容将集中于用户级内存分配库中分配器的伟大历史。 我们假设有一个基本接口，例如 malloc() 和 free() 提供的接口。具体来说，void *malloc(size t size) 采用单个参数 size，它是应用程序请求的字节数；它返回一个指向该大小（或更大）的区域的指针（没有特定类型，或者 C 语言中的 void 指针）。补充例程 void free(void *ptr) 接受一个指针并释放相应的块。注意该接口的含义：用户在释放空间时，并不告知库其大小；因此，当只提供指向内存块的指针时，库必须能够计算出内存块有多大。 该库管理的空间历史上称为堆，用于管理堆中空闲空间的通用数据结构是某种空闲列表。该结构包含对托管内存区域中所有空闲空间块的引用。当然，该数据结构本身不必是列表，而只是某种用于跟踪可用空间的数据结构。 我们进一步假设我们主要关注外部碎片。分配器当然也可能存在内部碎片的问题；如果分配器分配的内存块大于请求的内存块，则此类块中任何未请求的（因此未使用的）空间都被视为内部碎片（因为浪费发生在分配的单元内），并且是空间浪费的一种情况。然而，为了简单起见，并且因为它是两种类型的碎片中更有趣的一种，所以我们将主要关注外部碎片。 我们还假设一旦内存被分发给客户端，它就不能被重新定位到内存中的另一个位置。例如，如果程序调用 malloc() 并获得一个指向堆内某个空间的指针，则该内存区域本质上由程序“拥有”（并且不能由库移动），直到程序通过相应的free()调用返回它为止。因此，不可能压缩可用空间，而压缩有助于消除碎片。然而，在实现分段时，可以在操作系统中使用压缩来处理碎片。 最后，我们假设分配器管理一个连续的字节区域。在某些情况下，分配者可能会要求该区域增长；例如，当空间不足时，用户级内存分配库可能会调用内核来增加堆（通过 sbrk 等系统调用）。然而，为了简单起见，我们假设该区域在其整个生命周期中都是单一的固定大小。 ","date":"2024-04-25","objectID":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/:1:0","tags":["OS"],"title":"空闲空间管理","uri":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/"},{"categories":["系统架构"],"content":"2 低级机制 ","date":"2024-04-25","objectID":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/:2:0","tags":["OS"],"title":"空闲空间管理","uri":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/"},{"categories":["系统架构"],"content":"2.1 分割与合并 空闲列表包含一组元素，这些元素描述堆中仍剩余的空闲空间。因此，假设有以下 30 字节堆： 该堆的空闲列表上有两个元素。一个条目描述第一个 10 字节空闲段（字节 0-9），一个条目描述另一个空闲段（字节 20-29）： 如上所述，任何大于 10 字节的请求都会失败（返回 NULL），只是没有该大小的连续内存块可用。任何一个空闲块都可以轻松满足对该大小（10 字节）的请求。但如果请求的内容小于 10 个字节，会发生什么情况？ 假设我们只请求一个字节的内存。在这种情况下，分配器将执行称为分割的操作：它将找到可以满足请求的空闲内存块并将其分割为两部分。它将返回给调用者的第一个块；第二块将保留在列表中。因此，在上面的示例中，如果发出了 1 个字节的请求，并且分配器决定使用列表中两个元素中的第二个来满足请求，则对 malloc() 的调用将返回 20（分配器的地址）。 1 字节分配区域），列表最终将如下所示： 从图中可以看到列表基本保持完整；唯一的变化是空闲区域现在从 21 而不是 20 开始，并且该空闲区域的长度现在仅为 9。因此，当请求小于任何特定空闲块的大小时，分配器通常会使用分割方法。许多分配器中都有一个推论机制，称为空闲空间合并。再次以上面的例子为例（空闲 10 个字节，已用 10 个字节，还有另外一个空闲 10 个字节）。 给定这个（很小的）堆，当应用程序调用 free(10) 时会发生什么，从而返回堆中间的空间？如果我们只是简单地将这个可用空间添加回我们的列表中而不需要太多思考，我们最终可能会得到一个如下所示的列表： 虽然整个堆现在是空闲的，但它似乎被分为三个块，每个块 10 字节。因此，如果用户请求 20 个字节，简单的列表遍历将找不到这样的空闲块，并返回失败。 为了避免这个问题，分配器所做的就是在释放一块内存时合并可用空间。这个想法很简单：当返回内存中的空闲块时，仔细查看要返回的块的地址以及附近的空闲空间块；如果新释放的空间紧邻一个（或两个，如本示例中所示）现有空闲块，请将它们合并为一个更大的空闲块。因此，通过合并，我们的最终列表应该如下所示： 事实上，这就是在进行任何分配之前堆列表最初的样子。通过合并，分配器可以更好地确保大的空闲范围可供应用程序使用。 ","date":"2024-04-25","objectID":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/:2:1","tags":["OS"],"title":"空闲空间管理","uri":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/"},{"categories":["系统架构"],"content":"2.2 跟踪分配区域的大小 您可能已经注意到 free(void *ptr) 的接口不采用大小参数；因此，假设给定一个指针，malloc 库可以快速确定正在释放的内存区域的大小，从而将空间合并回空闲列表中。 为了完成此任务，大多数分配器在header块中存储一些额外信息，该header块保存在内存中，通常就在分配的内存块之前。让我们再看一个例子，如下图所示。 在此示例中，我们正在检查由 ptr 指向的大小为 20 字节的已分配块；想象一下用户调用 malloc() 并将结果存储在 ptr 中，例如 ptr = malloc(20); header至少包含分配区域的大小（在本例中为 20）；它还可能包含用于加速释放的附加指针、用于提供附加完整性检查的幻数以及其他信息。让我们假设一个简单的标头，其中包含区域的大小和一个幻数，如下所示： typedef struct __header_t { int size; int magic; } header_t; 上面的示例如下图所示： 当用户调用 free(ptr)，然后库使用简单的指针算术来确定标头的开始位置： void free(void *ptr) { header_t *hptr = (void *)ptr - sizeof(header_t); assert(hptr-\u003emagic == 1234567 \u0026\u0026 “Heap is corrupt”); ... 获得这样一个指向header的指针后，库可以轻松确定幻数是否与预期值匹配作为健全性检查（assert(hptr-\u003emagic == 1234567)），并通过简单的数学运算（即，将header的大小添加到区域的大小）计算新释放区域的总大小。请注意最后一句中的小但关键的细节：空闲区域的大小是header的大小加上分配给用户的空间的大小。因此，当用户请求 N 字节的内存时，库不会搜索大小为 N 的空闲块；相反，它会搜索大小为 N 加上header大小的空闲块。 ","date":"2024-04-25","objectID":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/:2:2","tags":["OS"],"title":"空闲空间管理","uri":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/"},{"categories":["系统架构"],"content":"2.3 嵌入空闲列表 到目前为止，我们已经将简单的空闲列表视为一个概念实体；它只是一个描述堆中空闲内存块的列表。但是我们如何在空间空间本身内构建这样的列表呢？ 在更典型的列表中，分配新节点时，只需在需要该节点的空间时调用 malloc() 即可。不幸的是，在内存分配库中，你不能这样做！相反，您需要在可用空间本身内构建列表。如果这听起来有点奇怪，请不要担心；是的，但并不奇怪到你做不到！ 假设我们有一个 4096 字节的内存块需要管理（即堆为 4KB）。要将其作为空闲列表进行管理，我们首先必须初始化该列表；最初，列表应该有一个条目，大小为 4096（减去header大小）。以下是链表节点的描述： typedef struct __node_t { int size; struct __node_t *next; } node_t; 现在让我们看一些初始化堆并将空闲列表的第一个元素放入该空间的代码。我们假设堆是在通过调用系统调用 mmap() 获得的一些可用空间内构建的；这不是构建此类堆的唯一方法，但在本例中对我们很有帮助。这是代码： // mmap() returns a pointer to a chunk of free space node_t *head = mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_ANON|MAP_PRIVATE, -1, 0); head-\u003esize = 4096 - sizeof(node_t); head-\u003enext = NULL; 运行这段代码后，列表的状态是只有一个条目，大小为 4088。是的，这是一个很小的堆，但它为我们提供了一个很好的例子。 head指针包含该范围的起始地址；我们假设它是 16KB（尽管任何虚拟地址都可以）。从视觉上看，堆看起来就像下面这样。 现在，我们假设请求一块内存，大小为 100 字节。为了服务这个请求，库将首先找到一个足够大的块来容纳该请求；因为只有一个空闲块（大小：4088），所以将选择该块。然后，该块将被分割成两部分：一个足够大以服务请求（和header，如上所述），以及剩余的空闲块。假设有一个 8 字节的header（整数大小和整数幻数），堆中的空间现在看起来如下图所示： 因此，在请求 100 字节时，库从现有的一个空闲块中分配了 108 字节，返回一个指向它的指针（上图中标记为 ptr），将header信息存储在分配的空间之前，以便之后供free()使用，并将链表中的一个空闲节点缩小到 3980 字节（4088 减 108）。 现在让我们看看有 3 个分配区域的堆，每个区域 100 个字节（或 108 个字节，包括header）。该堆的可视化如下图所示。 正如您在其中看到的，堆的前 324 字节现已分配，因此我们在该空间中看到三个header以及调用程序正在使用的三个 100 字节区域。空闲列表仍然无趣：只是一个节点（由head指向），但在三个分割之后现在大小只有 3764 字节。但是当调用程序通过 free() 返回一些内存时会发生什么？ 在此示例中，应用程序通过调用 free(16500)（值16500是通过将内存区域的起始地址16384与前一个块的108相加以及此块头部的8字节来得到的。） 返回已分配内存的中间块。该值在上图中由指针 sptr 显示。 库立即计算出空闲区域的大小，然后将空闲块添加回空闲列表。假设我们在空闲列表的头部插入，空间现在看起来如下图所示。 现在，我们有了一个以小空闲块（100 字节，由列表首部指向）和大空闲块（3764 字节）开始的列表。我们的列表终于多了一个元素！是的，空闲空间是支离破碎的，这是一种不幸但常见的现象。 最后一个例子：现在让我们假设最后两个正在使用的块已被释放。如果不进行合并，您最终可能会得到一个高度碎片化的空闲列表，如下图所示。 从图中可以看出，我们现在一团糟！为什么？很简单，我们忘记合并列表。虽然所有的内存都是空闲的，但它却被分割成碎片，因此不是完整的内存，而是呈现出碎片化的内存。解决方案很简单：遍历列表并合并相邻块；完成后，堆将再次完整。 ","date":"2024-04-25","objectID":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/:2:3","tags":["OS"],"title":"空闲空间管理","uri":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/"},{"categories":["系统架构"],"content":"2.4 增加堆 我们应该讨论许多分配库中的最后一种机制。具体来说，如果堆空间不足该怎么办？最简单的方法就是失败。在某些情况下，这是唯一的选择，因此返回 NULL 是一种值得尊敬的方法。 大多数传统分配器都从一个小堆开始，然后在内存耗尽时向操作系统请求更多内存。通常，这意味着它们进行某种系统调用（例如，大多数 UNIX 系统中的 sbrk）来增加堆，然后从那里分配新的块。为了服务 sbrk 请求，操作系统查找空闲物理页，将它们映射到请求进程的地址空间，然后返回新堆末尾的值；此时，可以使用更大的堆，并且可以成功地处理请求，如下图所示。 ","date":"2024-04-25","objectID":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/:2:4","tags":["OS"],"title":"空闲空间管理","uri":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/"},{"categories":["系统架构"],"content":"3 管理空闲空间：基本策略 ","date":"2024-04-25","objectID":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/:3:0","tags":["OS"],"title":"空闲空间管理","uri":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/"},{"categories":["系统架构"],"content":"3.1 最佳适应算法 最佳适应算法的策略非常简单：首先，搜索空闲列表并找到与请求大小一样大或更大的空闲内存块。然后，返回该组候选者中最小的那个；这就是所谓的最佳适应块（也可以称为最小适应）。遍历一次空闲列表就足以找到要返回的正确块。 最佳适应背后的直觉很简单：通过返回接近用户要求的块，最佳适应尝试减少浪费的空间。然而，这是有代价的；当对正确的空闲块执行详尽的搜索时，幼稚的实现会带来严重的性能损失。 ","date":"2024-04-25","objectID":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/:3:1","tags":["OS"],"title":"空闲空间管理","uri":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/"},{"categories":["系统架构"],"content":"3.2 最差适应算法 最差适应算法与最佳适应算法相反；找到最大的块并返回请求的数量；将剩余的（大）块保留在空闲列表中。因此，最差适应尝试留下大块，而不是最佳适应方法可能产生的大量小块。然而，再次需要对可用空间进行全面搜索，因此这种方法的成本可能很高。更糟糕的是，大多数研究表明它的性能很差，导致过多的碎片，同时仍然具有很高的开销。 ","date":"2024-04-25","objectID":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/:3:2","tags":["OS"],"title":"空闲空间管理","uri":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/"},{"categories":["系统架构"],"content":"3.3 首次适应算法 首次适应算法只需找到第一个足够大的区块，并将请求的大小返回给用户。与之前一样，剩余的空闲空间将保留给后续请求。 首次适应算法的优点是速度快，无需穷举搜索所有空闲空间，但有时会用小对象污染空闲列表的开头部分。因此，分配器如何管理空闲列表的顺序就成了一个问题。一种方法是使用基于地址的排序；通过保持列表按空闲空间的地址排序，凝聚变得更容易，碎片也会减少。 ","date":"2024-04-25","objectID":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/:3:3","tags":["OS"],"title":"空闲空间管理","uri":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/"},{"categories":["系统架构"],"content":"3.4 循环首次适应算法 循环首次适应算法并不总是在列表的开头开始首次适应搜索，而是保留一个额外的指针，指向列表中最后一次查找的位置。这个想法是在整个列表中更均匀地分布对可用空间的搜索，从而避免列表开头的分割。这种方法的性能与首次适应算法非常相似，因为再次避免了穷举搜索。 ","date":"2024-04-25","objectID":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/:3:4","tags":["OS"],"title":"空闲空间管理","uri":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/"},{"categories":["系统架构"],"content":"3.5 四种算法实例对比 以下是上述策略的一些示例。设想一个空闲列表，其中包含三个元素，大小分别为 10、30 和 20（这里我们将忽略headers和其他细节，而只关注策略的运作方式）： 假设分配请求大小为 15。最佳适应算法会搜索整个列表并发现 20 是最适合的，因为它是可以容纳请求的最小可用空间。生成的空闲列表： 正如本例中发生的情况，也是最佳适应方法经常发生的情况，现在剩下了一个小的空闲块。最差拟合方法与此类似，但它找到的是最大的块，在本例中为 30。结果列表如下： 在本例中，首次适应算法与最差适应算法执行相同的操作，也是查找可以满足请求的第一个空闲块。区别在于搜索成本；最佳算法和最差算法都会浏览整个列表； 首次适应算法 仅检查空闲块，直到找到适合的块，从而降低搜索成本。 ","date":"2024-04-25","objectID":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/:3:5","tags":["OS"],"title":"空闲空间管理","uri":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/"},{"categories":["系统架构"],"content":"4 其他方法 ","date":"2024-04-25","objectID":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/:4:0","tags":["OS"],"title":"空闲空间管理","uri":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/"},{"categories":["系统架构"],"content":"4.1 隔离列表：slab分配器 一种已经存在一段时间的有趣方法是使用隔离列表。基本思想很简单：如果特定应用程序发出一个（或几个）常见大小的请求，则保留一个单独的列表来管理该大小的对象；所有其他请求都转发到更通用的内存分配器。 这种方法的好处是显而易见的。通过将一块内存专用于特定大小的请求，碎片就不再是一个问题。此外，当分配和释放请求的大小合适时，可以非常快速地处理它们，因为不需要复杂的列表搜索。 但这种方法也会给系统带来新的复杂性。例如，与通用内存池相比，应该将多少内存专门用于服务给定大小的特殊请求的内存池？一个特殊的分配器，由超级工程师 Jeff Bonwick 设计的slab 分配器（设计用于 Solaris 内核），以一种相当好的方式处理这个问题。 具体来说，当内核启动时，它会为可能被频繁请求的内核对象（例如锁、文件系统 inode 等）分配一些对象缓存。因此，对象缓存都是给定大小的隔离空闲列表，并快速服务内存分配和空闲请求。当给定的缓存可用空间不足时，它会从更通用的内存分配器请求一些内存块（slab）（请求的总量是页面大小和相关对象的倍数）。相反，当给定slab内的对象的引用计数全部变为零时，通用分配器可以从专用分配器中回收它们，这通常在VM系统需要更多内存时执行。 通过将列表上的空闲对象保持在预初始化状态，slab 分配器还超越了大多数隔离列表方法。 Bonwick 表明数据结构的初始化和销毁代价高昂 ，通过将特定列表中的已释放对象保持在其初始化状态，slab 分配器因此避免了每个对象的频繁初始化和销毁周期，从而显着降低了开销。 ","date":"2024-04-25","objectID":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/:4:1","tags":["OS"],"title":"空闲空间管理","uri":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/"},{"categories":["系统架构"],"content":"4.2 伙伴分配器 由于合并对于分配器至关重要，因此设计了一些方法来简化合并。二进制伙伴分配器就是一个很好的例子。 在这样的系统中，空闲内存首先在概念上被认为是大小为 $2^N$ 的大空间。当发出内存请求时，对可用空间的搜索会递归地将可用空间一分为二，直到找到足够大以容纳请求的块（进一步分成两部分将导致空间太小）。此时，所请求的块就返回给用户了。以下是在搜索 7KB 块时划分 64KB 可用空间的示例： 在示例中，最左边的 8KB 块被分配（如较深的蓝色阴影所示）并返回给用户；请注意，该方案可能会受到内部碎片的影响，因为您只能给出两倍大小的块。 伙伴分配的美妙之处在于释放该块时发生的情况。当将8KB块返回到空闲列表时，分配器检查“伙伴”8KB是否空闲；如果是，它将把两个块合并成一个 16KB 的块。然后分配器检查 16KB 块的伙伴是否仍然空闲；如果是这样，它将合并这两个块。这种递归合并过程沿着树继续进行，要么恢复整个可用空间，要么在发现伙伴正在使用时停止。 伙伴分配工作如此顺利的原因是确定特定块的伙伴很简单。想想上面空闲空间中块的地址。如果您仔细思考，您会发现每个好友对的地址仅相差一位；哪一位由好友树中的级别决定。这样您就对二进制好友分配方案的工作原理有了基本的了解。 ","date":"2024-04-25","objectID":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/:4:2","tags":["OS"],"title":"空闲空间管理","uri":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/"},{"categories":["系统架构"],"content":"4.3 其他方法 上述许多方法的一个主要问题是它们缺乏扩展性。具体来说，搜索列表可能会非常慢。因此，高级分配器使用更复杂的数据结构来解决这些成本，以简单性换取性能。例如平衡二叉树、展开树或部分排序树等。 鉴于现代系统通常具有多个处理器并运行多线程工作负载，因此在基于多处理器的系统上花费大量精力使分配器正常工作也就不足为奇了。 Understanding glibc malloc ","date":"2024-04-25","objectID":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/:4:3","tags":["OS"],"title":"空闲空间管理","uri":"/posts/12.%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86/"},{"categories":["系统架构"],"content":"1 分段：广义基数/边界 到目前为止，我们已经将每个进程的整个地址空间放入内存中。通过基址寄存器和边界寄存器，操作系统可以轻松地将进程重新定位到物理内存的不同部分。然而，您可能已经注意到我们的这些地址空间有一些有趣的地方：在栈和堆之间的中间有一大块“空闲”空间，如下图所示。 虽然栈和堆之间的空间没有被进程使用，但当我们将整个地址空间重新定位到物理内存中的某个位置时，它仍然占用物理内存；因此，使用基址和边界寄存器对来虚拟化内存的简单方法是浪费的。当整个地址空间无法放入内存时，它也会使程序的运行变得非常困难；因此，基数和边界并不像我们希望的那样灵活。因此：关键：如何支持大地址空间 我们如何支持大地址空间以及栈和堆之间（可能）有大量可用空间？ 为了解决这个问题，一个想法应运而生，它就是分段。这是一个相当古老的想法，至少可以追溯到 1960 年代初。这个想法很简单：与其在我们的 MMU 中只有一个基址和边界对，为什么不在地址空间的每个逻辑段都有一个基址和边界对呢？段只是特定长度的地址空间的连续部分，在我们的规范地址空间中，我们有三个逻辑上不同的段：代码、栈和堆。分段允许操作系统做的是将每个段放置在物理内存的不同部分，从而避免用未使用的虚拟地址空间填充物理内存。 让我们看一下例子，假设我们要将下图中的地址空间放入物理内存中。由于每个段都有一个基址和边界对，我们可以将每个段独立地放置在物理内存中。您可以看到 64KB 物理内存，其中包含这三个段（还有 16KB 为操作系统保留） 从图中可以看到，代码段放置在物理地址32KB，大小为2KB，堆段放置在34KB，大小也为2KB。假设对虚拟地址 100（位于代码段中，代码段从地址空间中的虚拟地址0开始。）进行了引用。当发生引用时（例如，在指令获取时），硬件会将基址值添加到该段的偏移量（本例中为 100），以达到所需的物理地址：100 + 32KB，或 32868。然后检查该地址是否在范围内（100小于2KB），发现它在范围内，然后发出对物理内存地址32868的引用。 现在让我们看一下堆中的一个地址，虚拟地址 4200，如下图所示。如果我们只是将虚拟地址 4200 添加到堆基址 (34KB)，我们会得到物理地址 39016，这不是正确的物理地址。我们首先需要做的是将偏移量提取到堆中，即地址引用了该段中的哪个字节。因为堆从虚拟地址 4KB (4096) 开始，所以 4200 的偏移量实际上是 4200 减去 4096，即 104。然后我们将这个偏移量 (104) 添加到基址寄存器物理地址 (34K) 以获得所需的结果：34920。 如果我们尝试引用非法地址，例如超出堆末尾的7KB，如下图所示，该怎么办？您可以想象会发生什么：硬件检测到地址越界，进入操作系统中断，可能导致违规进程终止。现在您知道了所有 C 程序员都害怕的著名术语的由来：分段违规或分段错误。 “分段错误”或“违规”是由分段机器上对非法地址的内存访问引起的。有趣的是，这个术语仍然存在，即使在根本不支持分段的机器上也是如此。或者，如果你无法弄清楚为什么你的代码总是出错，那就不那么幽默了。 ","date":"2024-04-25","objectID":"/posts/11.%E6%AE%B5/:1:0","tags":["OS"],"title":"段","uri":"/posts/11.%E6%AE%B5/"},{"categories":["系统架构"],"content":"2 引用段 硬件在转换期间使用段寄存器。它如何知道段中的偏移量以及地址引用哪个段？ 一种常见的方法（有时称为显式方法）是根据虚拟地址的前几位将地址空间分成多个段；该技术用于 VAX/VMS 系统。在上面的例子中，我们有三个部分；因此我们需要两个位来完成我们的任务。如果我们使用 14 位虚拟地址的前两位来选择段，我们的虚拟地址如下所示： 在我们的示例中，如果前两位是 00，则硬件知道虚拟地址位于代码段中，因此使用代码基址和边界对将地址重新定位到正确的物理位置。如果前两位是 01，则硬件知道该地址在堆中，因此使用堆基址和边界。让我们以上面的示例堆虚拟地址 (4200) 为例并对其进行转换，只是为了确保这一点是清楚的。二进制形式的虚拟地址 4200 可以在这里看到： 从图中可以看出，前两位 (01) 告诉硬件我们正在引用哪个段。底部 12 位是段中的偏移量：0000 0110 1000，或十六进制 0x068，或十进制 104。因此，硬件只需使用前两位来确定要使用哪个段寄存器，然后将接下来的 12 位作为段中的偏移量。通过将基址寄存器与偏移量相加，硬件得出最终的物理地址。请注意，偏移量也简化了边界检查：我们可以简单地检查偏移量是否小于边界；如果不是，则该地址是非法的。因此，如果基址和边界是数组（每个段一个条目），硬件将执行类似以下操作来获取所需的物理地址： // get top 2 bits of 14-bit VA Segment = (VirtualAddress \u0026 SEG_MASK) \u003e\u003e SEG_SHIFT; // now get offset Offset = VirtualAddress \u0026 OFFSET_MASK; if (Offset \u003e= Bounds[Segment]) { RaiseException(PROTECTION_FAULT); } else { PhysAddr = Base[Segment] + Offset; Register = AccessMemory(PhysAddr); } 在我们的运行示例中，我们可以填写上面常量的值。具体来说，SEG MASK 将设置为 0x3000，SEG SHIFT 设置为 12，OFFSET MASK 设置为 0xFFF。您可能还注意到，当我们使用前两位时，并且只有三个段（代码、堆、栈），地址空间的一个段未被使用。因此，一些系统将代码放在与堆相同的段中，从而仅使用一位来选择要使用的段。 硬件还有其他方法来确定特定地址位于哪个段。在隐式方法中，硬件通过注意地址的形成方式来确定段。例如，如果地址是从程序计数器生成的（即，它是指令提取），则该地址在代码段内；如果地址基于栈或基址指针，则它必须位于栈段中；任何其他地址则都位于堆中。 ","date":"2024-04-25","objectID":"/posts/11.%E6%AE%B5/:2:0","tags":["OS"],"title":"段","uri":"/posts/11.%E6%AE%B5/"},{"categories":["系统架构"],"content":"3 关于栈 到目前为止，我们遗漏了地址空间的一个重要组成部分：栈。上图中，栈已重新定位到物理地址 28KB，但有一个关键区别：它向后增长。在物理内存中，从28KB开始，增长到26KB，对应虚拟地址16KB到14KB；地址转换必须以不同的方式进行。 我们首先需要的是一些额外的硬件支持。硬件不仅需要知道基址值和边界值，还需要知道段增长的方式（例如，当段沿正方向增长时设置为 1，当段沿负方向增长时设置为 0）。我们对硬件跟踪内容的更新视图如下表所示： Segment Base Size Grows Positive? Protection Code 32K 2K 1 Read-Execute Heap 34K 2K 1 Read-Write Stack 28K 2K 0 Read-Write 由于硬件了解段可以向负方向增长，因此硬件现在必须稍微不同地转换此类虚拟地址。让我们举一个栈虚拟地址的例子，并转换它来理解这个过程。 在此示例中，假设我们希望访问虚拟地址 15KB，该地址应映射到物理地址 27KB。我们的二进制形式的虚拟地址如下所示：11 1100 0000 0000（十六进制0x3C00）。硬件使用前两位 (11) 来指定段，但我们留下了 3KB 的偏移量。为了获得正确的负偏移量，我们必须从 3KB 中减去最大段大小：在本例中，一个段可以是 4KB，因此正确的负偏移量是 3KB 减去 4KB，等于 -1KB。我们只需将负偏移量 (-1KB) 添加到基址 (28KB) 即可得到正确的物理地址：27KB。可以通过确保负偏移的绝对值小于段的大小来计算边界检查。 ","date":"2024-04-25","objectID":"/posts/11.%E6%AE%B5/:3:0","tags":["OS"],"title":"段","uri":"/posts/11.%E6%AE%B5/"},{"categories":["系统架构"],"content":"4 支持段共享 随着对分段的支持不断增长，系统设计人员很快意识到，他们可以通过更多的硬件支持来实现新型效率。具体来说，为了节省内存，有时在地址空间之间共享某些内存段很有用。特别是，代码共享很常见，并且在当今的系统中仍在使用。 为了支持共享，我们需要硬件以保护位的形式提供一些额外的支持。基本支持为每个段添加一些位，指示程序是否可以读取或写入段，或者是否可以执行段内的代码。通过将代码段设置为只读，可以在多个进程之间共享相同的代码，而不必担心损害隔离性；虽然每个进程仍然认为它正在访问自己的私有内存，但操作系统正在秘密共享该进程无法修改的内存，因此保留了这种错觉。 上表显示了硬件（和操作系统）跟踪的附加信息的示例。可以看到，代码段被设置为读取和执行，因此内存中的同一物理段可以映射到多个虚拟地址空间。 有了保护位，前面描述的硬件算法也必须改变。除了检查虚拟地址是否在范围内之外，硬件还必须检查是否允许特定访问。如果用户进程尝试写入只读段，或从不可执行段执行，则硬件应引发异常，从而让操作系统处理违规进程。 ","date":"2024-04-25","objectID":"/posts/11.%E6%AE%B5/:4:0","tags":["OS"],"title":"段","uri":"/posts/11.%E6%AE%B5/"},{"categories":["系统架构"],"content":"5 细粒度分段与粗粒度分段 迄今为止，我们的大多数示例都集中在只有几个分段（即代码、栈、堆）的系统上；我们可以将这种分段视为粗粒度分段，因为它将地址空间分割成相对较大、较粗的块。然而，一些早期的系统（如 Multics）更加灵活，允许地址空间由大量较小的段组成，称为细粒度分段。 支持多分段需要更多硬件支持，在内存中存储某种分段表。这种段表通常支持创建大量的段，从而使系统能够以比我们迄今为止讨论的更灵活的方式使用段。例如，早期的机器（如 Burroughs B5000）支持数千个分段，并期望编译器将代码和数据切分成独立的分段，然后操作系统和硬件将支持这些分段。当时的想法是，通过细化分段，操作系统可以更好地了解哪些分段正在使用，哪些没有使用，从而更有效地利用主内存。 ","date":"2024-04-25","objectID":"/posts/11.%E6%AE%B5/:5:0","tags":["OS"],"title":"段","uri":"/posts/11.%E6%AE%B5/"},{"categories":["系统架构"],"content":"6 操作系统支持 您现在应该对分段的工作原理有一个基本的了解。当系统运行时，地址空间的各个部分会被重新定位到物理内存中，因此，相对于整个地址空间仅使用单个基址/边界对的更简单方法，可以节省大量物理内存。具体来说，栈和堆之间所有未使用的空间都不需要分配在物理内存中，从而允许我们将更多的地址空间放入物理内存中。 然而，分段引发了许多新问题。我们将首先描述必须解决的新操作系统问题。 第一个是旧的：操作系统在上下文切换时应该做什么？现在您应该有一个很好的猜测：必须保存和恢复段寄存器。显然，每个进程都有自己的虚拟地址空间，操作系统必须确保在让进程再次运行之前正确设置这些寄存器。 第二个也是更重要的问题是管理物理内存中的可用空间。当创建新的地址空间时，操作系统必须能够在物理内存中为其段找到空间。以前，我们假设每个地址空间的大小相同，因此物理内存可以被认为是进程可以容纳的一堆插槽。现在，每个进程有多个段，每个段可能是不同的尺寸。 出现的普遍问题是物理内存很快就会充满可用空间的小孔，使得分配新段或增加现有段变得困难。我们称这个问题为外部碎片；如下图所示（左）。 在示例中，一个进程出现并希望分配一个 20KB 的段。在该示例中，有 24KB 空闲空间，但不是在一个连续的段中（而是在三个不连续的块中）。因此，操作系统无法满足 20KB 请求。 该问题的一种解决方案是通过重新排列现有段来压缩物理内存。例如，操作系统可以停止正在运行的进程，将其数据复制到一个连续的内存区域，更改其段寄存器值以指向新的物理位置，从而拥有大量可用的可用内存。通过这样做，操作系统使新的分配请求能够成功。然而，压缩的成本很高，且因为复制段是内存密集型的，并且通常会占用相当多的处理器时间。如上图所示（右），可查看压缩物理内存后的结果。 一种更简单的方法是使用空闲列表管理算法，该算法尝试保持大范围的内存可用于分配。人们实际上已经采用了数百种方法，包括经典算法，例如最佳适应（保留可用空间列表并返回满足请求者所需分配的最接近大小的算法）、最差适应、首次适应，以及更复杂的方案，如伙伴算法 。但不幸的是，无论算法多么聪明，外部碎片仍然存在；因此，一个好的算法只是尝试将其最小化。 TIP：如果存在 1000 种解决方案，那么没有一个是最好的解决方案 存在如此多不同的算法来尝试最大限度地减少外部碎片这一事实表明了一个更强有力的潜在事实：没有一种“最佳”方法可以解决问题。因此，我们选择合理的东西，并希望它足够好。唯一真正的解决方案是完全避免这个问题，永远不要以可变大小的块分配内存。 ","date":"2024-04-25","objectID":"/posts/11.%E6%AE%B5/:6:0","tags":["OS"],"title":"段","uri":"/posts/11.%E6%AE%B5/"},{"categories":["系统架构"],"content":"7 总结 分段解决了许多问题，并帮助我们构建更有效的内存虚拟化。除了动态重定位之外，分段还可以通过避免地址空间的逻辑段之间潜在的巨大内存浪费来更好地支持稀疏地址空间。它也很快，因为进行算术分段所需的操作很容易并且非常适合硬件；地址转换费用很少。还出现了一个附带好处：代码共享。如果代码放置在单独的段中，则这样的段可能会在多个正在运行的程序之间共享。 然而，正如我们所知，在内存中分配可变大小的段会导致一些我们希望克服的问题。如上所述，第一个是外部碎片。因为段是可变的，所以可用内存被分成奇数大小的块，因此满足内存分配请求可能很困难。人们可以尝试使用智能算法或定期压缩内存，但问题是根本性的且难以避免。 第二个也许更重要的问题是分段仍然不够灵活，无法支持我们完全通用的稀疏地址空间。例如，如果我们在一个逻辑段中有一个大但很少使用的堆，则整个堆必须仍然驻留在内存中才能被访问。换句话说，如果我们的地址空间使用方式模型与底层分段的设计支持方式不完全匹配，分段就不能很好地工作。因此我们需要寻找一些新的解决方案。 ","date":"2024-04-25","objectID":"/posts/11.%E6%AE%B5/:7:0","tags":["OS"],"title":"段","uri":"/posts/11.%E6%AE%B5/"},{"categories":["系统架构"],"content":"虚拟化内存使用的通用技术被称为基于硬件的地址转换，或者简称为地址转换，您可以将其视为对有限直接执行的通用方法的补充。通过地址转换，硬件可以转换每个内存访问（例如，指令提取、加载或存储），将指令提供的虚拟地址更改为所需信息实际所在的物理地址。因此，对于每个存储器引用，硬件都会执行地址转换，以将应用程序存储器引用重定向到它们在存储器中的实际位置。当然，硬件本身无法虚拟化内存，因为它只是提供了有效地虚拟化内存的低级机制。操作系统必须在关键点参与设置硬件，以便进行正确的转换；因此，它必须管理内存，跟踪哪些位置是空闲的，哪些位置正在使用，并明智地进行干预以保持对内存使用方式的控制。 所有这些工作的目标再次是创造一个美丽的幻觉：程序拥有自己的私有内存，其中驻留着自己的代码和数据。虚拟现实的背后隐藏着丑陋的物理事实：当 CPU（或多个 CPU）在运行一个程序和下一个程序之间切换时，许多程序实际上同时共享内存。通过虚拟化，操作系统（在硬件的帮助下）将丑陋的机器现实转变为有用、强大且易于使用的抽象。 ","date":"2024-04-25","objectID":"/posts/10.%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2/:0:0","tags":["OS"],"title":"地址转换","uri":"/posts/10.%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2/"},{"categories":["系统架构"],"content":"1 假设（第一次尝试） 用户地址空间在内存中是连续的 用户地址空间小于物理内存（最大64KB） 每个地址空间具有相同的大小（最大16KB） ","date":"2024-04-25","objectID":"/posts/10.%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2/:1:0","tags":["OS"],"title":"地址转换","uri":"/posts/10.%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2/"},{"categories":["系统架构"],"content":"2 例子 我们看一个简单的例子。假设有一个进程，其地址空间如下图所示。 我们要研究的是一个简短的代码序列：从内存中加载一个值，将其增加 3，然后将该值存储回内存中。 void func() { int x = 3000; x = x + 3; // this is the line of code we are interested in ... 编译器将这行代码转换为汇编语言，可能看起来像这样（在 x86 汇编语言中）。在 Linux 上使用 objdump 或在 Mac 上使用 otool 来反汇编它： 128: movl 0x0(%ebx), %eax ;load 0+ebx into eax 132: addl $0x03, %eax ;add 3 to eax register 135: movl %eax, 0x0(%ebx) ;store eax back to mem 这段代码相对简单；它假定 x 的地址已放入寄存器 ebx 中，然后使用 movl 指令（用于“长字”移动）将该地址处的值加载到通用寄存器 eax 中。下一条指令将 eax 加 3，最后一条指令将 eax 中的值存储回内存中的同一位置。 在上图中，观察代码和数据在进程地址空间中的布局方式；三指令代码序列位于地址 128（在靠近顶部的代码段中），变量 x 的值位于地址 15 KB（在靠近底部的堆栈中）。图中，x的初始值为3000，如其在堆栈中的位置所示。当这些指令运行时，从进程的角度来看，会发生以下内存访问。 取地址 128 的指令 执行该指令（从地址 15 KB 加载） 取地址 132 的指令 - 执行该指令（无内存引用） 取地址 135 的指令 执行该指令（存储到地址 15 KB） 从程序的角度来看，它的地址空间从地址0开始，最大增长到16KB；它生成的所有内存引用都应该在这些范围内。然而，为了虚拟化内存，操作系统希望将进程放置在物理内存中的其他位置，而不一定是地址0。因此，我们遇到了问题：如何以对进程透明的方式在内存中重新定位该进程？当实际上地址空间位于其他物理地址时，我们如何提供从 0 开始的虚拟地址空间的假象？ 下图展示了进程的地址空间放入内存后物理内存可能是什么样子。在图中，您可以看到操作系统为自己使用物理内存的第一个插槽，并且它已将上例中的进程重新定位到从物理内存地址 32 KB 开始的插槽中。另外两个插槽是空闲的（16 KB-32 KB 和 48 KB-64 KB）。 ","date":"2024-04-25","objectID":"/posts/10.%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2/:2:0","tags":["OS"],"title":"地址转换","uri":"/posts/10.%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2/"},{"categories":["系统架构"],"content":"3 动态（基于硬件）重定位 为了对基于硬件的地址转换有一定的了解，我们首先讨论它的第一个版本。 1950 年代末的第一台分时机中引入了一个简单的概念，称为基数和边界；该技术也称为动态重定位；我们将交替使用这两个术语。 具体来说，每个 CPU 中我们需要两个硬件寄存器：一个称为基址寄存器，另一个称为边界寄存器（有时称为限制寄存器）。这个基址和边界对将允许我们将地址空间放置在物理内存中的任何位置，并同时确保进程只能访问自己的地址空间。 在此设置中，每个程序都被编写和编译，就好像它被加载到地址零一样。但是，当程序开始运行时，操作系统会决定应将其加载到物理内存中的何处，并将基址寄存器设置为该值。 在上面的示例中，操作系统决定在物理地址 32 KB 处加载进程，从而将基址寄存器设置为该值，如下图所示。 当进程运行时，有趣的事情开始发生。现在，当进程生成任何内存引用时，处理器会按以下方式对其进行转换： physical address = virtual address + base 进程生成的每个内存引用都是一个虚拟地址；硬件依次将基址寄存器的内容添加到该地址，结果是内存系统的物理地址。 为了更好地理解这一点，让我们追踪一下执行单个指令时会发生什么。具体来说，让我们看一下前面序列中的一条指令： asm 128: movl 0x0(%ebx), %eax 程序计数器 (PC) 设置为 128；当硬件需要取该指令时，首先将该值与基址寄存器值32 KB（32768）相加，得到物理地址32896；然后硬件从该物理地址获取指令。 接下来，处理器开始执行指令。在某个时刻，进程会从虚拟地址 15 KB 发出加载，处理器将其获取并再次添加到基址寄存器 (32 KB)，从而获得 47 KB 的最终物理地址，从而获得所需的内容。 将虚拟地址转换为物理地址正是我们所说的地址转换技术；也就是说，硬件获取进程认为它正在引用的虚拟地址，并将其转换为数据实际驻留的物理地址。因为这种地址重定位发生在运行时，并且即使在进程开始运行后我们也可以移动地址空间，所以该技术通常称为动态重定位。 现在您可能会问：边界（限制）寄存器发生了什么，起到了什么作用？毕竟，这不是基数和边界方法吗？它的确是。正如您可能已经猜到的，边界寄存器是为了帮助保护。具体来说，处理器会首先检查内存引用是否在范围内，以确保它是合法的；在上面的简单示例中，边界寄存器将始终设置为 16 KB。如果进程生成的虚拟地址大于边界，或者为负数，CPU 将引发异常，并且该进程可能会被终止。因此，边界的目的是确保进程生成的所有地址都是合法的并且在进程的“边界”内。 我们应该注意，基址寄存器和边界寄存器是保存在芯片上的硬件结构（每个 CPU 一对）。有时人们将处理器中帮助进行地址转换的部分称为内存管理单元（MMU）；随着我们开发更复杂的内存管理技术，我们将为 MMU 添加更多电路。如下图所示。 为了更详细地理解通过基址和边界进行的地址转换，让我们来看一个例子。想象一下，一个地址空间大小为 4 KB的进程被加载到物理地址 16 KB。下面是一些地址转换的结果： Virtual Address Physical Address 0 16 KB 1 KB 17 KB 3000 19384 4400 Fault (Out of Bounds) 从示例中可以看出，只需将基地址与虚拟地址相加（可以正确地将其视为地址空间的偏移量），就可以轻松得到物理地址。只有当虚拟地址 “过大 “或为负数时，结果才会是一个错误，从而引发异常。 ","date":"2024-04-25","objectID":"/posts/10.%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2/:3:0","tags":["OS"],"title":"地址转换","uri":"/posts/10.%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2/"},{"categories":["系统架构"],"content":"4 内存虚拟化的操作系统问题 正如硬件提供了支持动态重定位的新功能一样，操作系统现在也有必须处理的新问题；硬件支持和操作系统管理的结合导致了简单虚拟内存的实现。具体来说，有几个关键时刻，操作系统必须参与其中，以实现我们的虚拟内存的基址和边界版本。 首先，操作系统必须在创建进程时采取行动，为其在内存中的地址空间找到空间。幸运的是，考虑到我们假设每个地址空间（a）小于物理内存的大小以及（b）相同的大小，这对于操作系统来说非常容易；它可以简单地将物理内存视为一组插槽，并跟踪每个插槽是否空闲或正在使用。创建新进程时，操作系统必须搜索数据结构（通常称为空闲列表）来为新地址空间找到空间，然后将其标记为已使用。对于可变大小的地址空间，情况会更加复杂。 让我们看一个例子。如下图所示，您可以看到操作系统为自己使用物理内存的第一个插槽，并且它已将上面示例中的进程重新定位到从物理内存地址 32 KB 开始的插槽中。另外两个插槽是空闲的（16 KB-32 KB 和 48 KB-64 KB）；因此，空闲列表应该由这两个条目组成。 第二，当进程终止时（即，当它正常退出或由于行为不当而被强制终止时），操作系统必须做一些工作，回收其所有内存以供其他进程或操作系统使用。进程终止后，操作系统会将其内存放回到空闲列表中，并根据需要清理任何关联的数据结构，如下图所示。 第三，当发生上下文切换时，操作系统还必须执行一些额外的步骤。毕竟，每个 CPU 上只有一对基址和边界寄存器，并且每个正在运行的程序的值都不同，因为每个程序都加载到内存中不同的物理地址。因此，操作系统在进程之间切换时必须保存和恢复基址和边界对。 具体来说，当操作系统决定停止运行某个进程时，它必须将基址寄存器和边界寄存器的值保存到内存中的某些每个进程的结构中，例如进程结构或进程控制块 (PCB)。同样，当操作系统恢复正在运行的进程（或第一次运行它）时，它必须将 CPU 上的基数和边界值设置为该进程的正确值，如下图所示。 我们应该注意到，当进程停止（即不运行）时，操作系统可以很容易地将地址空间从内存中的一个位置移动到另一个位置。要移动进程的地址空间，操作系统首先会对进程取消调度；然后，操作系统会将地址空间从当前位置复制到新位置；最后，操作系统会更新（进程结构中的）保存基址寄存器，使其指向新位置。当进程恢复时，它的（新）基址寄存器会被恢复，然后它又开始运行，全然不顾它的指令和数据现在在内存中一个全新的位置。 第四，如上所述，操作系统必须提供异常处理程序或调用函数；操作系统在启动时（通过特权指令）安装这些处理程序。例如，如果一个进程试图访问超出其边界的内存，CPU 就会引发异常；操作系统必须做好准备，在出现这种异常时采取行动。操作系统的通常反应是敌意：它可能会终止违规进程。操作系统应高度保护它所运行的机器，因此它不会善待试图访问内存或执行不该执行指令的进程。 下表以时间轴的形式展示了硬件与操作系统之间的交互。表中显示了操作系统在启动时为准备使用机器所做的工作，以及进程（进程 A）开始运行时发生的情况；请注意其内存转换是如何在没有操作系统干预的情况下由硬件处理的。此时，操作系统必须介入，终止进程并清理 B 的内存，将其从进程表中删除。从表中可以看出，我们仍然遵循有限直接执行的基本方法。在大多数情况下，操作系统只需适当设置硬件，让进程直接在 CPU 上运行；只有当进程出现异常时，操作系统才会介入。 OS @ boot (kernel mode) Hardware Program (user mode) 初始化中断表 记住系统调用处理程序、定时器处理程序 、非法内存访问处理程序、非法指令处理程序……的地址 - 启动中断定时器 启动计时器；X 毫秒后中断 - 初始化进程表；初始化空闲列表 - - OS @ run (kernel mode) Hardware Program (user mode) 启动进程 A： 分配进程表中的条目；为进程分配内存；设置基准/边界寄存器 ；从中断返回（进入 A） - - 恢复 A 的寄存器；移动到用户模式；跳转到 A 的（初始）PC 进程 A 运行；取指令 转换虚拟地址并执行提取 执行指令 如果是显式加载/存储：确保地址在边界内；转换虚拟地址并执行加载/存储 定时器中断转入内核模式；跳转到中断处理程序 处理中断； 调用 switch() 例程 ；将 regs(A) 保存到 proc-struct(A)（包括基址/边界） ；从 proc-struct(B)（包括基址/边界）恢复 regs(B) ；从中断返回 (进入B） 恢复B的寄存器；转移到用户模式； 跳转到B的PC 进程B运行；执行错误加载 加载越界；转入内核模式，跳转到中断处理程序 处理中断；决定终止进程 B；释放 B 的内存；释放 B 在进程表中的条目 ","date":"2024-04-25","objectID":"/posts/10.%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2/:4:0","tags":["OS"],"title":"地址转换","uri":"/posts/10.%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2/"},{"categories":["系统架构"],"content":"5 总结 在本章中，我们用虚拟内存中使用的一种特定机制（即地址转换）扩展了有限直接执行的概念。通过地址转换，操作系统可以控制进程的每次内存访问，确保访问不超出地址空间的范围。硬件支持是这项技术高效的关键，它能为每次访问快速执行转换，将虚拟地址（进程对内存的看法）转换为物理地址（实际看法）。所有这些都是以对被重定位的进程透明的方式进行的，进程根本不知道其内存引用正在被转换，这就造成了一种奇妙的错觉。 我们还看到了一种特殊形式的虚拟化，即基址边界虚拟化或动态重定位。基址边界虚拟化相当高效，因为只需要多一点硬件逻辑，就能在虚拟地址中添加一个基址寄存器，并检查进程生成的地址是否在边界内。基址边界虚拟化还能提供保护；操作系统和硬件相结合，确保任何进程都无法在自身地址空间之外生成内存引用。保护无疑是操作系统最重要的目标之一；如果没有保护，操作系统就无法控制机器（如果进程可以随意覆盖内存，它们就能轻易做出一些令人讨厌的事情，比如覆盖中断表并接管系统）。 不过，这种简单的动态重定位技术确实存在效率低下的问题。例如，如上图所示，重定位后的进程使用的物理内存从 32 KB 增加到 48 KB，但由于进程堆栈和堆并不太大，两者之间的所有空间都被浪费掉了。这种浪费通常被称为内部碎片，因为分配单元内部的空间没有被全部使用（即被碎片化），从而造成浪费。在我们目前的方法中，虽然可能有足够的物理内存来容纳更多进程，但我们目前只能将地址空间放置在固定大小的插槽中，因此可能会出现内部碎片。因此，我们需要更复杂的机制来更好地利用物理内存，避免内部碎片。 ","date":"2024-04-25","objectID":"/posts/10.%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2/:5:0","tags":["OS"],"title":"地址转换","uri":"/posts/10.%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2/"},{"categories":["系统架构"],"content":"github地址 首先，编写一个名为 null.c 的简单程序，该程序创建一个指向整数的指针，将其设置为 NULL，然后尝试取消引用它。将其编译为名为 null 的可执行文件。当你运行这个程序时会发生什么？ #include \u003cstdio.h\u003e int main() { int *p = NULL; printf(\"Value of p: %d\\n\", *p); return 0; } ❯ gcc null.c -o null ❯ ./null [1] 67350 segmentation fault ./null 接下来，在编译程序时加入符号信息（使用 -g 标志）。这样做可以在可执行文件中加入更多信息，使调试器可以访问更多有用的变量名等信息。在调试器下运行程序，键入 gdb null，然后在 gdb 运行后键入 run。gdb 会显示什么？ \u003e gcc null.c -g -o null \u003e gdb null GNU gdb (Ubuntu 12.1-0ubuntu1~22.04) 12.1 Copyright (C) 2022 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later \u003chttp://gnu.org/licenses/gpl.html\u003e This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-linux-gnu\". Type \"show configuration\" for configuration details. For bug reporting instructions, please see: \u003chttps://www.gnu.org/software/gdb/bugs/\u003e. Find the GDB manual and other documentation resources online at: \u003chttp://www.gnu.org/software/gdb/documentation/\u003e. For help, type \"help\". Type \"apropos word\" to search for commands related to \"word\"... Reading symbols from null... (gdb) run Starting program: /home/zfhe/null [Thread debugging using libthread_db enabled] Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\". Program received signal SIGSEGV, Segmentation fault. 0x0000555555555161 in main () at null.c:5 5 printf(\"Value of p: %d\\n\", *p); 最后，在这个程序上使用 valgrind 工具。我们将使用 valgrind 中的 memcheck 工具来分析发生的情况。运行时输入以下内容：valgrind --leak-check=yes ./null。运行时会发生什么？你能解释该工具的输出吗？ \u003e valgrind --leak-check=yes ./null ==1316115== Memcheck, a memory error detector ==1316115== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==1316115== Using Valgrind-3.18.1 and LibVEX; rerun with -h for copyright info ==1316115== Command: ./null ==1316115== ==1316115== Invalid read of size 4 ==1316115== at 0x109161: main (null.c:5) ==1316115== Address 0x0 is not stack'd, malloc'd or (recently) free'd ==1316115== ==1316115== ==1316115== Process terminating with default action of signal 11 (SIGSEGV) ==1316115== Access not within mapped region at address 0x0 ==1316115== at 0x109161: main (null.c:5) ==1316115== If you believe this happened as a result of a stack ==1316115== overflow in your program's main thread (unlikely but ==1316115== possible), you can try to increase the size of the ==1316115== main thread stack using the --main-stacksize= flag. ==1316115== The main thread stack size used in this run was 8388608. ==1316115== ==1316115== HEAP SUMMARY: ==1316115== in use at exit: 0 bytes in 0 blocks ==1316115== total heap usage: 0 allocs, 0 frees, 0 bytes allocated ==1316115== ==1316115== All heap blocks were freed -- no leaks are possible ==1316115== ==1316115== For lists of detected and suppressed errors, rerun with: -s ==1316115== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0) [1] 1316115 segmentation fault (core dumped) valgrind --leak-check=yes ./null 输出的解释： Invalid read of size 4：程序尝试读取一个无效的内存地址，该地址的大小为 4 字节。这表明在程序执行过程中发生了一次无效的内存读取操作。 Address 0x0 is not stack'd, malloc'd or (recently) free'd：Valgrind 报告了试图访问的内存地址是 0x0，即空指针。程序尝试读取了一个空指针，这是非法操作，因为空指针通常不指向任何有效的内存位置。 Process terminating with default action of signal 11 (SIGSEGV)：由于程序尝试访问无效的内存地址导致了段错误，程序被终止，并且默认行为是发送信号 11 (SIGSEGV)。 Access not within mapped region at address 0x0：Valgrind 报告了访问的内存地址不在映射区域内，即程序试图访问未分配或未初始化的内存区域。 HEAP SUMMARY 和 ERROR SUMMARY：Valgrind 提供了堆内存使用情况的总结和错误摘要。在这个例子中，堆内存中没有分配任何内存块，也没有发生内存泄漏。 All heap blocks were freed -- no leaks are possible：Valgrind 告诉我们在程序结束时所有的堆内存都已被释放，因此不存在内存泄漏的可能性。 编写一个简单的程序，使用 malloc() 分配内存，但在退出前忘记释放内存。程序运行时会发生什么？你能用 gdb 查找出任何问题吗？使用 valgrind（同样使用 –leak-check=yes 标志）如何？ #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e void malloc_but_nofree() { int *p = (int *)malloc(sizeof(int)); } int main() { malloc_but_nofree(); return 0; } 程序正常运行正常结束，gdb也无法发现内存泄漏，但valgrind可以。 编写一个程序，使用 malloc 创建一个大小为 100 的名为 data 的整数数组，然后将 data[100] 设置为零。运行这个程序时会发生什么？使用 va","date":"2024-04-25","objectID":"/posts/09.%E5%86%85%E5%AD%98api/:0:0","tags":["OS"],"title":"内存API","uri":"/posts/09.%E5%86%85%E5%AD%98api/"},{"categories":["系统架构"],"content":" 什么是内存虚拟化？ 操作系统虚拟其物理内存。 操作系统为每个进程提供一个虚拟内存空间。 看起来每个进程都使用整个内存。 内存虚拟化的好处 易于编程 在时间和空间方面提高内存效率 保证进程和操作系统的隔离，防止其他进程的错误访问 ","date":"2024-04-25","objectID":"/posts/08.%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/:0:0","tags":["OS"],"title":"地址空间","uri":"/posts/08.%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/"},{"categories":["系统架构"],"content":"1 早期操作系统 从内存的角度来看，早期的机器并没有为用户提供太多的抽象概念。基本上，机器的物理内存如下图所示。 操作系统是一组位于内存（本例中从物理地址 0 开始）中的例程（实际上是一个库），而当前位于物理内存（本例中从物理地址 64k 开始）中的一个正在运行的程序（进程）则使用内存的其余部分。用户对操作系统的期望值并不高。 ","date":"2024-04-25","objectID":"/posts/08.%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/:1:0","tags":["OS"],"title":"地址空间","uri":"/posts/08.%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/"},{"categories":["系统架构"],"content":"2 多道程序设计和分时 一段时间后，由于机器价格昂贵，人们开始更有效地共享机器。因此，多道程序设计的时代诞生了，其中多个进程准备在给定时间运行，并且操作系统将在它们之间切换，例如当一个进程决定执行 I/O 时。这样做提高了 CPU 的有效利用率。在当时每台机器的成本高达数十万甚至数百万美元（而且您认为您的 Mac 很昂贵！），这种效率的提高尤其重要。 然而，很快，人们开始对机器提出更多要求，分时时代诞生了。具体来说，许多人意识到批处理计算的局限性，特别是对程序员本身而言，他们厌倦了长的程序调试周期。交互性的概念变得很重要，因为许多用户可能同时使用一台机器，每个用户都等待（或希望）当前正在执行的任务及时响应。实现分时的一种方法是运行一个进程一小会儿，赋予它对所有内存的完全访问权限，然后停止它，将其所有状态保存到某种磁盘（包括所有物理内存），加载其他进程的状态，运行一段时间，从而实现某种机器的粗略共享。 但这种方法有一个大问题：它太慢了，尤其是当内存增长时。虽然保存和恢复寄存器级状态（PC、通用寄存器等）相对较快，但将内存的全部内容保存到磁盘的性能却非常低。因此，我们宁愿做的是将进程留在内存中，同时在它们之间切换，从而允许操作系统有效地实现时间共享，如下图所示。 图中，有三个进程（A、B 和 C），每个进程都有为其分配的 512KB 物理内存的一小部分。假设只有一个 CPU，操作系统选择运行其中一个进程（例如 A），而其他进程（B 和 C）则位于就绪队列中等待运行。但允许多个程序同时驻留在内存中使得保护成为一个重要问题；你不希望一个进程能够读取，或者更糟糕的是，写入其他进程的内存。 ","date":"2024-04-25","objectID":"/posts/08.%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/:2:0","tags":["OS"],"title":"地址空间","uri":"/posts/08.%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/"},{"categories":["系统架构"],"content":"3 地址空间 这样就需要操作系统创建一个易于使用的物理内存抽象。我们将这种抽象称为地址空间，它是正在运行的程序对系统中内存的视图。了解操作系统对内存的基本抽象是理解内存如何虚拟化的关键。 进程的地址空间包含正在运行的程序的所有内存状态。例如，程序的代码（指令）必须位于内存中的某个位置，因此它们位于地址空间中。程序在运行时使用栈来跟踪它在函数调用链中的位置，以及分配局部变量和向例程传递参数和返回值。最后，堆用于动态分配、用户管理的内存，例如您可能从 C 中调用 malloc() 或面向对象语言（例如 C++ 或 Java）中的 new 调用中接收到的内存。当然，其中还有其他东西（例如静态初始化变量），但现在我们只假设这三个组件：代码、栈和堆。 在上图的示例中，我们有一个很小的地址空间（只有 16KB）。程序代码位于地址空间的顶部（在本例中从 0 开始，并被打包到地址空间的前 1KB 中）。代码是静态的（因此很容易放置在内存中），因此我们可以将其放置在地址空间的顶部，并且知道程序运行时它不会需要更多空间。 接下来，我们有两个在程序运行时可能会增长（和收缩）的地址空间区域。这些是堆（在顶部）和栈（在底部）。我们这样放置它们是因为每个都希望能够增长，并且通过将它们放在地址空间的两端，我们可以允许这样的增长：它们只需要向相反的方向增长即可。因此，堆在代码之后开始（1KB）并向下增长（例如，当用户通过 malloc() 请求更多内存时）；堆栈从 16KB 开始并向上增长（例如当用户进行过程调用时）。然而，栈和堆的这种放置只是一种约定；如果您愿意，可以以不同的方式安排地址空间（正如我们稍后将看到的，当多个线程共存于一个地址空间中时，没有像这样划分地址空间的好方法了）。 当然，当我们描述地址空间时，我们描述的是操作系统为正在运行的程序提供的抽象。该程序实际上并不位于物理地址 0 到 16KB 的内存中；相反，它被加载到某个任意的物理地址。我们可以看到上图 中的进程 A、B 和 C，每个进程如何加载到不同地址的内存中。因此出现了问题：怎么虚拟化内存？操作系统如何在单个物理内存之上为多个正在运行的进程（所有共享内存）构建私有的、可能很大的地址空间的抽象？ 当操作系统执行此操作时，我们说操作系统正在虚拟化内存，因为正在运行的程序认为它已加载到内存中的特定地址（例如 0），并且具有潜在的非常大的地址空间（例如 32 位或 64 位） ，但现实却截然不同。 例如，当上图的进程 A 尝试在地址 0（我们将其称为虚拟地址）处执行加载时，操作系统与某些硬件支持相结合，必须确保加载实际上不是到物理地址 0，而是转到物理地址 320KB（A 被加载到内存中）。这是内存虚拟化的关键，内存虚拟化是世界上每个现代计算机系统的基础。 TIP 隔离原则 隔离是构建可靠系统的关键原则。如果两个实体适当地相互隔离，这意味着其中一个实体发生故障时不会影响到另一个实体。操作系统努力将进程相互隔离，从而防止一个进程损害另一个进程。 通过使用内存隔离，操作系统进一步确保运行中的程序不会影响底层操作系统的运行。一些现代操作系统甚至更进一步，将操作系统的各个部分与操作系统的其他部分隔离开来。因此，这种微内核比典型的单片内核设计更可靠。 ","date":"2024-04-25","objectID":"/posts/08.%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/:3:0","tags":["OS"],"title":"地址空间","uri":"/posts/08.%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/"},{"categories":["系统架构"],"content":"4 目标 因此，我们在这组笔记中找到了操作系统的工作：虚拟化内存。不过，操作系统不仅会虚拟化内存；它会很有风格地做到这一点。为了确保操作系统做到这一点，我们需要一些目标来指导我们。 虚拟内存 (VM) 系统的主要目标之一是透明度。操作系统应该以对正在运行的程序不可见的方式实现虚拟内存。因此，程序不应该意识到内存是虚拟化的；相反，程序的行为就好像它有自己的私有物理内存一样。操作系统（和硬件）在背后完成了在许多不同作业之间复用内存的所有工作，从而实现了这种错觉。 VM的另一个目标是效率。操作系统应努力使虚拟化尽可能高效，无论是在时间（即不使程序运行得更慢）还是在空间（即不为支持虚拟化所需的结构使用太多内存）方面。在实现高效虚拟化时，操作系统必须依赖硬件支持，包括TLB等硬件功能。 最后，第三个VM目标是保护。操作系统应确保进程免受其他进程的影响以及操作系统本身免受进程的影响。当一个进程执行加载、存储或取指令时，它不应该能够以任何方式访问或影响任何其他进程或操作系统本身的内存内容（即其地址空间之外的任何内容）。因此，保护使我们能够提供进程之间的隔离特性；每个进程都应该在自己隔离的茧中运行，免受其他错误甚至恶意进程的破坏。 ","date":"2024-04-25","objectID":"/posts/08.%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/:4:0","tags":["OS"],"title":"地址空间","uri":"/posts/08.%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/"},{"categories":["系统架构"],"content":"5 虚拟地址 事实上，作为用户级程序的程序员，你能看到的任何地址都是虚拟地址。只有操作系统通过其巧妙的虚拟内存技术，才能知道这些指令和数据值在机器物理内存中的位置。因此，千万不要忘记：如果你在程序中打印出一个地址，那只是一个虚拟地址，是内存中事物布局的假象；只有操作系统（和硬件）才知道真正的真相。下面是一个小程序 (va.c)，它可以打印出 main() 例程（代码所在位置）的位置、全局变量的位置、malloc() 返回的堆分配值以及堆栈中整数的位置： #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e int global = 1; int main(int argc, char *argv[]) { // Declaring a variable x on the stack int x = 3; // Printing the location of the code printf(\"location of code : %p\\n\", (void *) main); // Printing the location of global variable printf(\"location of data : %p\\n\", (void *) \u0026global); // Printing the location of heap memory printf(\"location of heap : %p\\n\", (void *) malloc(1)); // Printing the location of stack variable x printf(\"location of stack : %p\\n\", (void *) \u0026x); return x; } 当运行在64位的Linux，我们得到如下输出： location of code: 0x40057d location of data : 0x401010 location of heap : 0xcf2010 location of stack : 0x7fff9ca45fcc 如下图所示，可以看到代码首先出现在地址空间中，其次是静态数据，然后是堆，而栈一直位于这个大虚拟空间的另一端。所有这些地址都是虚拟的，并且将由操作系统和硬件进行转换，以便从其真实的物理位置获取值。 ","date":"2024-04-25","objectID":"/posts/08.%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/:5:0","tags":["OS"],"title":"地址空间","uri":"/posts/08.%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/"},{"categories":["系统架构"],"content":"6 总结 我们已经看到了一个主要操作系统子系统的引入：虚拟内存。 VM系统负责为程序提供一个大的、稀疏的、私有的地址空间的假象，其中保存了它们的所有指令和数据。在一些硬件的帮助下，操作系统将获取每个虚拟内存引用，并将它们转换为物理地址，可以将其呈现给物理内存以获取所需的信息。操作系统将同时对许多进程执行此操作，确保保护程序免受彼此的侵害，并保护操作系统。 VM的目标如下： 透明度 VM 对于正在运行的程序应该是不可见的 效率 最小化时间和空间方面的开销 保护 隔离进程（和操作系统本身）[但允许选择性“通信”] ","date":"2024-04-25","objectID":"/posts/08.%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/:6:0","tags":["OS"],"title":"地址空间","uri":"/posts/08.%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/"},{"categories":["系统架构"],"content":"1 多处理器架构 要理解围绕多处理器调度的新问题，我们必须了解单 CPU 硬件与多 CPU 硬件之间的一个新的根本区别。这种区别主要围绕硬件缓存的使用（如下图所示），以及多个处理器之间共享数据的具体方式。 在单个CPU系统中，硬件缓存（Cache）的层次结构通常有助于处理器更快地运行程序。Cache是一种小型快速存储器，（一般来说）保存系统主存储器中常用数据的副本。相比之下，主存储器保存了所有数据，但访问这个较大的内存时速度较慢。通过将频繁访问的数据保存在高速缓存中，系统可以让又大又慢的内存看起来很快。 例如，一个程序要从内存中获取一个值，需要发出一条显式加载指令，而一个简单的系统只有一个 CPU；CPU 有一个小缓存（比如 64 KB）和一个大主存。程序首次发出加载指令时，数据位于主内存中，因此需要很长时间（可能是几十纳秒，甚至几百纳秒）才能获取。处理器预计数据可能会被重复使用，因此会将加载数据的副本放入 CPU 缓存。如果程序稍后再次提取相同的数据项，CPU 会首先检查缓存中是否有该数据项；如果在缓存中找到了该数据项，提取数据的速度就会快得多（比如只需几纳秒），从而加快程序的运行速度。 因此，缓存是以局部性概念为基础的，局部性有两种：时间局部性和空间局部性。时间局部性背后的理念是，当一个数据被访问时，它很可能在不久的将来再次被访问；想象一下变量甚至指令本身在循环中被反复访问的情景。空间局部性背后的理念是，如果程序访问了地址为 x 的数据项，那么它很可能也会访问 x 附近的数据项；在这里，可以想象程序在数组中流水作业，或者指令被一条接一条地执行。由于许多程序都存在这些类型的局部性，因此硬件系统可以很好地猜测哪些数据应放入高速缓存，从而很好地工作。 但如果在一个系统中使用多个处理器和一个共享主存储器，如下图所示，会发生什么情况？ 事实证明，多 CPU 缓存要复杂得多。如下图所示，假设在 CPU 1 上运行的程序读取并更新了地址 A 上的一个数据项（值为 D）；由于 CPU 1 的缓存中没有该数据，系统会从主存中获取该数据项，并得到值 D。然后假设操作系统决定停止运行程序，并将其移至 CPU 2。然后程序重新读取地址 A 处的值，发现缓存没有这样的数据 ，因此系统从主内存中获取值，并获取旧值 D 而不是正确值 D ′。这个普遍问题称为缓存一致性问题。 硬件提供了基本的解决方案：通过监控内存访问，硬件可以确保基本上 “正确的事情 “发生了，并且单个共享内存的视图得以保留。在基于总线的系统（如上所述）上实现这一点的一种方法是使用一种称为总线窥探（bus snooping）的古老技术；每个高速缓存通过观察连接内存和主内存的总线来关注内存更新。当 CPU 看到其缓存中的数据项有更新时，就会注意到这一变化，要么使其副本失效（即从自己的缓存中删除），要么进行更新（即把新值也放入自己的缓存中）。如上文述，回写缓存会使这一过程变得更加复杂（因为写入主内存的内容要到稍后才能看到），但你可以想象一下基本方案是如何工作的。 ","date":"2024-04-25","objectID":"/posts/07.%E5%A4%9Acpu%E8%B0%83%E5%BA%A6/:1:0","tags":["OS"],"title":"多CPU调度","uri":"/posts/07.%E5%A4%9Acpu%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"2 不要忘记同步 既然缓存为提供一致性做了所有这些工作，那么程序（或操作系统本身）在访问共享数据时还需要担心什么吗？答案是肯定的，程序（或操作系统）在访问共享数据时仍然需要考虑一些问题： 竞争条件（Race Conditions）：即当多个进程或线程试图同时访问共享资源时可能出现的问题。 原子性操作：某些操作可能涉及多个步骤，需要确保这些步骤的执行是原子的。 内存栅栏和同步：在某些情况下，需要使用内存栅栏（memory barriers）或者同步机制来确保在不同处理器上的操作执行顺序。这是因为缓存一致性只保证了缓存之间和缓存与内存之间的一致性，而不是对所有指令的执行顺序做出保证。 在跨 CPU 访问（尤其是更新）共享数据项或结构时，应使用互斥原语（如锁）来保证正确性（其他方法，如构建无锁数据结构，比较复杂，只能偶尔使用）。例如，假设多个 CPU 同时访问一个共享队列。如果没有锁，即使使用了底层一致性协议，并发添加或删除队列中的元素也无法达到预期效果；我们需要用锁将数据结构原子更新到新状态。 为了更具体地说明这一点，我们可以看下面这段用于从共享链表中删除一个元素的代码序列。想象一下，如果两个 CPU 上的线程同时进入这个例程。如果线程 1 执行了第一行，它的 tmp 变量中将存储 head 的当前值；如果线程 2 也执行了第一行，它的私有 tmp 变量中也将存储 head 的相同值（tmp 在栈中分配，因此每个线程都有自己的私有存储空间）。这样，每个线程就不会从列表头部删除一个元素了，而是尝试删除这相同的头元素，就会导致各种问题（例如第 4 行中试图对头部元素进行双重释放，以及可能两次返回相同的数据值）。 typedef struct __Node_t { int value; struct __Node_t *next; } Node_t; int List_Pop() { Node_t *tmp = head; // remember old head ... int value = head-\u003evalue; // ... and its value head = head-\u003enext; // advance head to next pointer free(tmp); // free old head return value; // return value at head } 当然，解决方案是通过锁定来使此类例程正确。在这种情况下，分配一个简单的互斥体（例如，pthread mutex t m;），然后在例程的开头添加一个 lock(\u0026m) 并在末尾添加一个 unlock(\u0026m) 将解决问题，确保代码能够执行如预期的。不幸的是，正如我们将看到的，这种方法并非没有问题，特别是在性能方面。具体来说，随着CPU数量的增加，对同步共享数据结构的访问变得相当慢。 pthread_mutex_t m; typedef struct __Node_t { int value; struct __Node_t *next; } Node_t; int List_Pop() { lock(\u0026m); Node_t *tmp = head; // remember old head ... int value = head-\u003evalue; // ... and its value head = head-\u003enext; // advance head to next pointer free(tmp); // free old head unlock(\u0026m); return value; // return value at head } ","date":"2024-04-25","objectID":"/posts/07.%E5%A4%9Acpu%E8%B0%83%E5%BA%A6/:2:0","tags":["OS"],"title":"多CPU调度","uri":"/posts/07.%E5%A4%9Acpu%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"3 最后一个问题：缓存亲和性 最后一个问题是在构建多处理器缓存调度程序时出现的，称为缓存亲和性。这个概念很简单：进程在特定 CPU 上运行时，会在 CPU 的缓存（和 TLB）中构建相当多的状态。下一次进程运行时，在同一个 CPU 上运行它通常是有利的，因为如果它的某些状态已经存在于该 CPU 上的缓存中，那么它会运行得更快。相反，如果每次在不同的 CPU 上运行一个进程，则该进程的性能会更差，因为每次运行时都必须重新加载状态（注意，由于硬件的缓存一致性协议，它可以在不同的 CPU 上正常运行）。因此，多处理器调度程序在做出调度决策时应考虑缓存关联性，如果可能的话，可能更愿意将进程保留在同一 CPU 上。 ","date":"2024-04-25","objectID":"/posts/07.%E5%A4%9Acpu%E8%B0%83%E5%BA%A6/:3:0","tags":["OS"],"title":"多CPU调度","uri":"/posts/07.%E5%A4%9Acpu%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"4 Single queue Multiprocessor Scheduling (SQMS) 有了这个背景，我们现在讨论如何为多处理器系统构建调度程序。最基本的方法是简单地重用单处理器调度的基本框架，将所有需要调度的作业放入单个队列中；我们将此称为单队列多处理器调度或简称为 SQMS。这种方法的优点是简单；不需要太多工作就可以采用现有策略来选择接下来运行的最佳作业，并将其调整为在多个 CPU 上工作（例如，如果有两个 CPU，它可能会选择最好的两个作业来运行） 。 然而，SQMS 也有明显的缺点。 第一个问题是缺乏可扩展性。为了确保调度程序在多个 CPU 上正常工作，开发人员将在代码中插入某种形式的锁，如上所述。锁确保当 SQMS 代码访问单个队列（例如，查找下一个要运行的作业）时，会出现正确的结果。但锁会大大降低性能，尤其是当系统中的 CPU 数量增加。随着对单个锁的争夺增加，系统花在锁开销上的时间越来越多，而花在系统本应完成的工作上的时间却越来越少。 SQMS 的第二个主要问题是缓存亲和性。例如，假设我们有五个作业（A、B、C、D、E）和四个处理器。因此，我们的调度队列看起来是这样的： 随着时间的推移，假设每个作业运行一个时间片，然后选择另一个作业，下面是一个可能的跨 CPU 作业时间表： 由于每个 CPU 只需从全局共享队列中选择下一个要运行的作业，因此每个作业最终都会在 CPU 之间来回跳转，这与缓存亲和性的观点恰恰相反。 为了解决这个问题，大多数 SQMS 调度器都包含某种亲和性机制，以尽可能使进程更有可能继续在同一 CPU 上运行。具体来说，调度器可能会为某些作业提供亲和性，但会移动其他作业以平衡负载。例如，设想同样的五个工作调度如下： 在这种安排下，作业 A 到 D 不会跨处理器迁移，只有作业 E 会从 CPU 迁移到 CPU，从而保留了大部分的亲和性。然后，你可以决定在下一次迁移时迁移不同的作业，从而实现某种亲和性公平性。不过，实施这样的方案可能会很复杂。因此，我们可以看到 SQMS 方法有其优点和缺点。对于现有的单 CPU 调度器（顾名思义，它只有一个队列）来说，它可以直接实施。但是，它的扩展性不佳（由于同步开销），而且不能轻易保留高速缓存亲和性。 ","date":"2024-04-25","objectID":"/posts/07.%E5%A4%9Acpu%E8%B0%83%E5%BA%A6/:4:0","tags":["OS"],"title":"多CPU调度","uri":"/posts/07.%E5%A4%9Acpu%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"5 Multi-queue Multiprocessor Scheduling (MQMS) 由于单队列调度器所带来的问题，一些系统选择了多队列，例如每个 CPU 一个队列。我们称这种方法为多队列多处理器调度（或 MQMS）。 在 MQMS 中，我们的基本调度框架由多个调度队列组成。每个队列都可能遵循特定的调度规则，如循环调度（RR），当然也可以使用任何算法。当作业进入系统时，会根据某种启发式（如随机，或挑选作业数量少于其他队列的队列），将其恰好置于一个调度队列中。然后，它基本上被独立调度，从而避免了单队列方法中的信息共享和同步问题。 例如，假设系统中只有两个 CPU（CPU 0 和 CPU 1），有若干作业进入系统：例如 A、B、C 和 D。鉴于每个 CPU 现在都有一个调度队列，操作系统必须决定将每个作业放入哪个队列。操作系统可能会这样做： 根据队列调度策略的不同，现在每个 CPU 在决定运行什么作业时都有两个作业可供选择。例如，如果采用循环调度，系统可能会产生如下调度： 与 SQMS 相比，MQMS 有一个明显的优势，那就是它本质上更具可扩展性。随着 CPU 数量的增加，队列的数量也会增加，因此锁和缓存争用不会成为核心问题。此外，MQMS 本身还提供缓存亲和性，这些工作都在同一个 CPU 上运行，因此可以获得重复使用其中缓存内容的优势。 但是，你可能会发现我们遇到了一个新问题，这也是基于多队列方法的基本问题：负载不平衡。假设我们有与上述相同的设置（四个工作、两个 CPU），但其中一个工作（比如 C）完成了。现在我们有以下调度队列： 如果我们在系统的每个队列上运行轮循策略，就会看到这样的调度表： 从图中可以看出，A 获得的 CPU 资源是 B 和 D 的两倍，这并不是我们想要的结果。更糟的是，假设 A 和 C 都完成了工作，系统中只剩下工作 B 和 D。调度队列将如下所示： 因此，CPU 0 将处于闲置状态！ 那么，关键是怎么解决负载不均衡的问题呢？MQMS应如何处理负载不平衡问题，从而更好地实现预期调度目标？ 对于这个问题，显而易见的答案就是移动作业，我们（再次）将这种技术称为迁移。通过将作业从一个 CPU 迁移到另一个 CPU，可以实现真正的负载平衡。让我们看几个例子来进一步说明。我们再一次遇到这样的情况：一个 CPU 空闲，另一个 CPU 有一些作业。 在这种情况下，所需的迁移很容易理解：操作系统只需将 B 或 D 中的一个迁移到 CPU 0。 这种单一作业迁移的结果是负载均衡，大家都很高兴。 在我们之前的示例中出现了一个更棘手的情况，其中 A 单独留在 CPU 0 上，而 B 和 D 交替出现在 CPU 1 上： 在这种情况下，一次迁移并不能解决问题。在这种情况下该怎么办呢？答案是连续迁移一个或多个工作。一种可能的解决方案是不断切换工作，如下图所示。在图中，首先 A 单独运行在 CPU 0 上，B 和 D 交替运行在 CPU 1 上。几个时间片后，B 被转移到 CPU 0 上与 A 竞争，而 D 则在 CPU 1 上单独运行几个时间片。这样，负载就平衡了： 当然，还存在许多其他可能的迁移模式。但现在是棘手的部分：系统应该如何决定实施这样的迁移？ 一种基本方法是使用一种称为工作窃取（work stealing）的技术。通过工作窃取方法，作业量较低的（源）队列偶尔会查看另一个（目标）队列，看看它有多满。如果目标队列（特别是）比源队列更满，则源队列将从目标“窃取”一个或多个作业以帮助平衡负载。 当然，这种方法自然会产生矛盾。如果过于频繁地查看其他队列，就会造成高开销和扩展困难，而实施多队列调度的目的就是为了解决这个问题！！另一方面，如果不经常查看其他队列，就有可能出现严重的负载不平衡。在系统策略设计中，找到合适的阈值仍然是一门黑科技。 ","date":"2024-04-25","objectID":"/posts/07.%E5%A4%9Acpu%E8%B0%83%E5%BA%A6/:5:0","tags":["OS"],"title":"多CPU调度","uri":"/posts/07.%E5%A4%9Acpu%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"6 Linux 多处理器调度器 有趣的是，Linux 社区在构建多处理器调度程序方面没有通用的解决方案。随着时间的推移，出现了三种不同的调度器： O(1)调度器 基于优先级的调度程序 使用多队列（类似于MLFQ） 随着时间的推移改变流程的优先级 调度优先级高的进程 交互性是关注的重点 完全公平调度器（CFS） 使用多队列 确定性比例份额方法 基于阶梯截止日期（公平是重点） 红黑树可扩展性 BF调度器（BFS） 单队列调度方法 使用比例份额方法 基于最早符合条件的虚拟截止时间优先（EEVDF） 侧重于交互式（不能很好地扩展内核）。已被 MuQSS 取代，以解决这一问题 ","date":"2024-04-25","objectID":"/posts/07.%E5%A4%9Acpu%E8%B0%83%E5%BA%A6/:6:0","tags":["OS"],"title":"多CPU调度","uri":"/posts/07.%E5%A4%9Acpu%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"7 总结 我们已经看到了多种多处理器调度方法。单队列方法 (SQMS) 构建起来相当简单，并且可以很好地平衡负载，但本质上难以扩展到许多处理器和缓存亲和力。多队列方法（MQMS）可扩展性更好，并且可以很好地处理缓存亲和性，但存在负载不平衡的问题，并且更复杂。无论您采用哪种方法，都没有简单的答案：构建通用调度器仍然是一项艰巨的任务，因为小的代码更改可能会导致大的行为差异。 ","date":"2024-04-25","objectID":"/posts/07.%E5%A4%9Acpu%E8%B0%83%E5%BA%A6/:7:0","tags":["OS"],"title":"多CPU调度","uri":"/posts/07.%E5%A4%9Acpu%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"在本章中，我们将研究一种不同类型的调度器，称为比例份额（Proportional-share）调度器，有时也称为公平共享调度器。比例共享基于一个简单的概念：调度器可能会尝试保证每个作业获得一定百分比的 CPU 时间，而不是针对周转时间或响应时间进行优化。 比例份额调度有一个非常出色的早期例子是彩票调度（lottery scheduling），由 Waldspurger 和 Weihl 发现。其基本思想非常简单，每隔一段时间，就会举行一次彩票抽奖，来确定接下来该运行哪个进程。更频繁运行的进程则更有机会中奖。 在处理细节前先抛出我们的关键问题：如何按比例共享CPU？我们如何设计一个调度器以按比例共享 CPU？这样做的关键机制是什么？它们的效果如何？ ","date":"2024-04-25","objectID":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/:0:0","tags":["OS"],"title":"比例份额调度","uri":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"1 基本概念：彩票代表份额 彩票调度背后是一个非常基本的概念：彩票数，代表了进程（或用户或其他）占有某个资源的份额。一个一个进程拥有的彩票数占总彩票数的百分比，就是它占有系统资源的份额。 例如，有两个进程A和B，其中A有75张彩票，而B只有25张彩票。因此，我们希望A占有$75%$的CPU，B占有$25%$的CPU。 彩票调度通过每隔一段时间（比如每个时间片）举行一次抽奖，以概率方式（而非确定方式）实现这一目标。举行抽奖很简单：调度器必须知道总共有多少张彩票（在我们的例子中，有 100 张彩票），调度器接下来随机抽取中奖彩票，是$[0,99]$的数字。假设 A 持有 0 到 74 号彩票，B 持有 75 到 99 号彩票，中奖彩票就决定了运行A或B。然后调度程序加载中奖进程的状态，并运行它。 下面是彩票调度程序输出的中奖彩票和对应的调度结果: 63 85 70 39 76 17 29 41 36 39 10 99 68 83 63 62 43 0 49 49 A A A A A A A A A A A A A A A A B B B B 从这个例子中我们可以看出，彩票调度的随机性导致了从概率上满足期望的比例，但不能确保。在上面的例子中，工作 B 运行了 20 个时间片中的 4 个，只是占了$20%$，而不是期望的$25%$。但是，这两个工作运行得时间越长，它们得到的 CPU 时间比例就会越接近期望。 随机性决策有优势也有劣势： 优势 避免最差情况 轻量，不需要记录过多状态，传统公平调度需要记录进程的大量状态 随机方法很快，决策也快 劣势 系统行为可能不可预测，因为它们不受先前状态或输入的直接影响，这可能导致一些进程等待时间过长，而另一些则过短。 可能导致性能波动 TIP：使用彩票数代表份额 彩票（和步幅）调度设计中最强大（也是基本）的机制之一就是彩票数机制。在这些示例中，彩票数用于表示进程对 CPU 的份额，但其应用范围可以更广泛。例如，在虚拟机管理程序虚拟内存管理的最新研究中，Waldspurger 展示了如何使用彩票数来表示客户操作系统的内存份额。因此，如果您需要一种机制来代表一定比例的所有权，这个概念可能就是……（等等）……彩票数。 ","date":"2024-04-25","objectID":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/:1:0","tags":["OS"],"title":"比例份额调度","uri":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"2 彩票机制 彩票调度还提供了许多机制，以不同的方式（有时是有用的方式）操纵彩票。一种机制是彩票货币（ticket currency）。这种机制允许拥有一组彩票的用户在自己的工作中以任意货币分配彩票；然后系统会自动将所述货币转换为正确的全局彩票。 例如，假设用户A和用户B都有100张彩票，A正在运行两个作业：A1和A2，然后用 A 的货币给它们每人 500 张彩票（总共 1000 张）。用户B正在运行一个作业，然后用B的货币给它分配10张彩票（总共10张）。系统将 A1 和 A2 的分配从 A 货币各 500 转换为全球货币各 50；同样，B1的10张票折算为100张票。然后在全球彩票货币（共 200 个）上进行抽签，以决定哪个工作运行。A1的具体计算方法是$\\frac{\\text{Ticket}{A1}}{\\text{Ticket}{A1}+\\text{Ticket}{A2}}\\times \\text{Ticket}{A}$，其他同理。 User A -\u003e 500 (A's ticket currency) to A1 -\u003e 50 (global currency) -\u003e 500 (A's ticket currency) to A2 -\u003e 50 (global currency) User B -\u003e 10 (B's ticket currency) to B1 -\u003e 100 (global currency) 另一个有用的机制是彩票转让（ticket transfer）。通过转让，一个进程可以暂时将其彩票转让给另一个进程。这种能力在客户端/服务器设置中特别有用，其中客户端进程向服务器发送消息，要求服务器代表客户端执行一些工作。为了加快工作速度，客户端可以将彩票转让给服务器，并尝试最大化服务器的性能，同时处理客户端的请求。完成后，服务器将票据归还给客户端，一切如旧。 最后，彩票通胀（ticket inflation）机制有时也很有用。通过通货膨胀，进程可以暂时增加或减少其拥有的彩票数。当然，在进程相互不信任的竞争场景中，这是没有意义的；一个贪婪的进程可以给自己大量的彩票从而接管机器。但是，通胀可以应用于一组进程相互信任的环境中。在这种情况下，如果任何一个进程知道它需要更多的 CPU 时间，它可以增加自己的彩票数，作为向系统反映该需求的一种方式，而无需与任何其他进程进行通信。 ","date":"2024-04-25","objectID":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/:2:0","tags":["OS"],"title":"比例份额调度","uri":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"3 实现 彩票调度最令人惊叹的地方可能就是其实施的简单性。你只需要一个好的随机数生成器来挑选中奖彩票，一个跟踪系统进程的数据结构（如列表），以及彩票总数。 假设我们将进程保存在一个列表中。下面是一个由 A、B 和 C 三个进程组成的示例，每个进程都有一定数量的彩票数。 为了做出调度决策，我们首先要从门票总数（400） 中随机抽取一个数字（中奖号码）。然后，我们只需遍历列表，用一个简单的计数器帮助我们找到中奖者。 # counter: used to track if we've found the winner yet counter = 0 # winner: use some call to a random number generator to get a value, between 0 and the total # of tickets winner = random.randint(0, totaltickets) # current: use this to walk through the list of jobs current = head # loop until the sum of ticket values is \u003e the winner while current: counter = counter + current.tickets if counter \u003e winner: break # found the winner current = current.next # 'current' is the winner: schedule it... 该代码从前往后遍历进程列表，将每个彩票值添加到计数器中，直到该值超过获胜者。一旦出现这种情况，当前列表进程就是中奖者。以中奖彩票为 300 的示例为例，会发生以下情况。首先，计数器增加到 100 以计算 A 的票；因为 100 小于 300，所以循环继续。然后计数器会更新为 150（B 的票），仍然少于 300，因此我们再次继续。最后，计数器更新为 400（明显大于 300），因此我们跳出循环，当前指向 C（中奖者）。 要让这个过程更有效率，建议将列表项按照彩票数递减排序。这个顺序并不会影响算法的正确性，但能保证用最小的迭代次数找到需要的结点，尤其当大多彩票被少数进程掌握时。 ","date":"2024-04-25","objectID":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/:3:0","tags":["OS"],"title":"比例份额调度","uri":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"4 评估指标 为了更容易理解动态彩票调度，我们现在对两个相互竞争的作业的完成时间进行简要研究，每个作业都有相同数量的彩票 (100) 和相同的运行时间 (R，我们将改变它) 。 在这种情况下，我们希望每个作业大致在同一时间完成，但由于彩票调度的随机性，有时一个作业会先于另一个作业完成。为了量化这种差异，我们定义了一个简单的不公平指标（unfairness metric） $U$，它就是第一个作业完成的时间除以第二个作业完成的时间。 例如，如果 R = 10，并且第一个作业在 10 完成（第二个作业在 20 完成），则 $U=\\frac{10}{20}=0.5$。当两个作业几乎同时完成时，$U$ 将非常接近 1。在这种情况下，这就是我们的目标：完全公平的调度程序将实现 $U = 1$。 下图描绘了在30次试验中，两个作业（R）的长度从1到1000不等时的平均不公平性。从图中可以看出，当工作时间不长时，平均不公平现象可能相当严重。只有当作业运行了大量的时间片时，彩票调度程序才能接近所需的结果。 ","date":"2024-04-25","objectID":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/:4:0","tags":["OS"],"title":"比例份额调度","uri":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"5 如何分配彩票 在彩票调度方面，我们尚未解决的一个问题是：如何为作业分配彩票？这是一个棘手的问题，因为系统如何运行当然在很大程度上取决于如何分配彩票。一种方法是假定用户最了解情况；在这种情况下，每个用户都会得到一定数量的门票，用户可以根据需要将门票分配给他们运行的任何作业。然而，这种解决方案不是解决方案：它并没有告诉你该怎么做。因此，在给定一系列工作的情况下，“彩票分配问题 “仍然悬而未决。 ","date":"2024-04-25","objectID":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/:5:0","tags":["OS"],"title":"比例份额调度","uri":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"6 步幅调度 你可能还想知道：为什么要使用随机性呢？如上所述，虽然随机性可以为我们提供一个简单（且近似正确）的调度器，但它偶尔无法提供精确正确的比例，尤其是在短时间内。为此，Waldspurger 发明了一种确定性公平分配调度器—步幅调度器 。 步幅调度也很简单，系统中每个作业都有一个步幅，这与它拥有的彩票数成反比。在上面的示例中，对于作业 A、B 和 C，分别有 100、50 和 250 张彩票，我们可以通过将某个较大的数字除以每个进程分配的彩票数量来计算每个作业的步幅。例如，如果我们用 10,000 除以每个彩票值，我们将获得 A、B 和 C 的步幅值：100、200 和 40。我们将此值称为每个进程的步幅；每次进程运行时，我们都会按其步幅增加它的计数器（称为其行程值），以跟踪其全局进度。 然后，调度程序使用步幅和行程值来确定接下来应该运行哪个进程。基本思想很简单：在任何给定时间，选择迄今为止具有最低行程值的进程来运行；当您运行一个进程时，按其步幅增加其行程值。 Waldspurger 提供了伪代码实现： curr = remove_min(queue); // pick client with min pass schedule(curr); // run for quantum curr-\u003epass += curr-\u003estride; // update pass using stride insert(queue, curr); // return curr to queue 在我们的示例中，一开始有三个进程（A、B 和 C），它们的步幅分别为 100、200 和 40，所有进程的行程值最初都是 0。假设我们选择 A（任意选择；可以选择任何一个行程值同样低的进程）。A 运行后，在完成时间片后，我们将其行程值更新为 100。然后运行 B，将其行程值设置为 200。最后运行 C，其行程值递增到 40。此时，算法将选择最低的行程值，即 C的行程值，然后运行C，将其行程值更新为 80（C 的步幅为 40）。然后 C 将再次运行（仍然是最低的行程值），将其行程值提升至 120。A 现在运行，将其行程值更新为 200（现在等于 B 的行程值）。然后 C 再运行两次，将其行程值更新为 160，然后是 200。此时，所有行程值再次相等，这个过程将无限重复。下表跟踪了调度器随时间变化的行为。 Pass(A) Pass(B) Pass(C) Who Runs? 0 0 0 A 100 0 0 B 100 200 0 C 100 200 40 C 100 200 80 C 100 200 120 A 200 200 120 C 200 200 160 C 200 200 200 … 从上表可以看出，C运行了5次，A2次，B只有一次，正好与它们的彩票值 250、100 和 50 成比例。彩票调度是随着时间的推移概率性地实现比例的，而步幅调度则是在每个调度周期结束时精确地实现比例。 所以你可能想知道：跨步调度这么精准，为什么还要使用彩票调度呢？嗯，彩票调度有一个步幅调度没有的好特性：没有全局状态。想象一下，在上面的跨步调度示例中，有一个新作业进入；它的行程值应该是多少？应该设置为0吗？如果是的话，就会独占CPU。对于彩票调度，每个进程没有全局状态；我们只需添加一个新进程及其拥有的任何彩票，更新单个全局变量以跟踪我们总共拥有多少彩票，然后从那里开始。通过这种方式，彩票以合理的方式合并新进程更加容易。 ","date":"2024-04-25","objectID":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/:6:0","tags":["OS"],"title":"比例份额调度","uri":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"7 Linux完全公平调度器（CFS） 尽管在公平份额调度方面已有早期工作，但当前的Linux方法以另一种方式实现了类似的目标。名为完全公平调度器（或CFS）的调度器实施了公平份额调度，但是以高效且可扩展的方式进行。 为了实现其效率目标，CFS通过其固有设计和对任务非常适合的数据结构巧妙地使用极少时间做出调度决策。最近研究表明，调度器效率非常重要；具体而言，在对谷歌数据中心进行研究时，Kanev等人发现，即使经过积极优化，调度仍然占用整个数据中心约5%的CPU时间。因此，尽可能减少开销是现代调度程序架构的一个关键目标。 ","date":"2024-04-25","objectID":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/:7:0","tags":["OS"],"title":"比例份额调度","uri":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"7.1 基本操作 大多数调度程序都基于固定时间片的概念，而 CFS 的运行方式则有些不同。它的目标很简单：将 CPU 公平地平均分配给所有竞争进程。它通过一种简单的基于计数的技术来实现这一目标，这种技术被称为虚拟运行时间（vruntime）。 每个进程运行时，都会累积vruntime。在最基本的情况下，每个进程的 vruntime 都以相同的速率增长，与物理（实际）时间成比例。在进行调度决策时，CFS 会选择 vruntime 最低的进程作为下一个运行进程。 那这就提出了一个问题：调度器怎么知道何时停止正在运行的进程，并运行下一个进程呢？这里矛盾就很明显：如果 CFS 切换过于频繁，公平性就会提高，因为 CFS 将确保每个进程即使在极小的时间窗口内也能获得其 CPU 份额，但代价是性能降低（上下文切换过多）；如果 CFS 切换频率降低，性能就会提高（上下文切换减少），但代价是近期公平性降低。 CFS通过各种控制参数来管理这种矛盾。第一个是sched_latency（调度延迟），CFS使用该值来确定一个进程在考虑切换之前应运行多长时间（以动态方式有效确定其时间片）。典型的sched_latency值为$48$（毫秒），CFS 将该值除以 CPU 上运行的进程数（n），以确定进程的时间片，从而确保在这段时间内，CFS 完全公平。 例如，如果这有$n=4$的进程在运行，CFS将sched_latency的值除以$n$得出每个进程的时间片为$12\\text{ms}$。然后，CFS 会调度第一个作业并运行它，直到用完 $12\\text{ms}$ 的（虚拟）运行时间，然后检查是否有 vruntime 更低的作业可替代运行。在这种情况下，如果有，CFS 就会切换到其他三个作业中的一个，依此类推。下图展示了这样一个例子：四个作业（A、B、C、D）以这种方式各运行两个时间片；其中两个作业（C、D）完成后，只剩下两个作业，然后它们以循环方式各运行 $12\\text{ms}$。 但如果有 “太多 “进程在运行呢？这会不会导致时间片太小，从而导致太多的上下文切换？答案是肯定的。 为了解决这个问题，CFS增加了另一个参数min_granularity，通常设置为 6 ms。CFS绝不会设置进程的时间片小于值，确保不会在调度开销上花费太多时间。 例如，这有10个进程正在运行，我们原来的计算会用sched_latency除以$10$得出进程时间片（结果为$4.8\\text{ms}$）。但因为min_granularity，CFS会每个进程的时间片设置为$6\\text{ms}$。虽然 CFS 的公平性不会超过在 $4.8\\text{ms}$ 的目标调度延迟（sched_latency），但它将接近目标值，同时仍能实现较高的 CPU 效率。 需要的注意是，CFS 使用的是周期性定时器中断，这意味着它只能在固定的时间间隔内做出决定。该中断会频繁响起（例如，每 1 ms响一次），让 CFS 有机会唤醒并确定当前作业是否已运行结束。如果作业的时间片不是定时器中断间隔的整数倍，也没关系；CFS 会精确跟踪 vruntime，这意味着从长远来看，它最终会接近理想的 CPU 共享状态。 ","date":"2024-04-25","objectID":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/:7:1","tags":["OS"],"title":"比例份额调度","uri":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"7.2 权重（优先级） CFS 还可以控制进程优先级，使用户或管理员能够为某些进程提供更高的 CPU 份额。它不是通过彩票来实现这一点，而是通过经典 UNIX 机制—进程的nice级别的来实现这一点。对于进程，nice 参数可以设置为 -20 到 +19 之间的任意值，默认值为 0。正的 Nice 值意味着较低的优先级，负值意味着较高的优先级；当你太好的时候，你就不会得到那么多（安排）关注，唉。 CFS将每个进程的nice值映射到一个权重，如下所示： static const int prio_to_weight[40] = { /* -20 */ 88761, 71755, 56483, 46273, 36291, /* -15 */ 29154, 23254, 18705, 14949, 11916, /* -10 */ 9548, 7620, 6100, 4904, 3906, /* -5 */ 3121, 2501, 1991, 1586, 1277, /* 0 */ 1024, 820, 655, 526, 423, /* 5 */ 335, 272, 215, 172, 137, /* 10 */ 110, 87, 70, 56, 45, /* 15 */ 36, 29, 23, 18, 15, }; 有了这些权重，我们就可以计算每个进程的有效时间片（就像我们之前所做的），但现在要考虑它们的优先级差异。计算公式如下： $$ \\text{time_slice}_k= \\frac {\\text{weight}k}{\\sum _ {i=0}^ {n-1}\\text{weight} {i}} \\cdot \\text{sched_latency} $$ 让我们举个例子来看看它是如何工作的。假定有两个工作，A 和 B。A 因为是我们最宝贵的工作，所以优先级较高，nice值为$-5$；B 因为我们不喜欢它，所以优先级为默认值（nice值等于 0）。这意味着$\\text{weight}_A$（来自权重表）为 3121，而$\\text{weight}_B$ 为 1024。如果计算每个作业的时间片，就会发现 A 的时间片约为sched_latency的 $\\frac{3}{4}$（即 $36\\text{ms}$），而 B 约为$\\frac{1}{4}$（即 $12\\text{ms}$）。 除了泛化时间片计算外，CFS计算vruntime的方式也必须进行调整，以下是新公式： $$ \\text{vruntime}_i=\\text{vruntime}_i+\\frac{\\text{weight}_0}{\\text{weight}_i}\\cdot \\text{runtime}_i $$ 它根据进程$i$累积的实际运行时间（$\\text{runtime}_i$），并与进程的权重成反比。在我们的运行示例中，A 的 vruntime 累积速度是 B 的三分之一。 构建上述权重表的一个巧妙之处在于，当 nice 值的差异恒定时，该表保留了 CPU 比例。例如，如果进程 A 的 nice 值为 5（不是 -5），进程 B 的 nice 值为 10（不是 0），则 CFS 将以与之前完全相同的方式调度它们。 ","date":"2024-04-25","objectID":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/:7:2","tags":["OS"],"title":"比例份额调度","uri":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"7.3 使用红黑树 如上所述，CFS 的一个重点是效率。对于调度器来说，效率有很多方面，但其中一个方面非常简单：当调度器需要查找下一个要运行的作业时，它应该尽可能快地找到该作业。简单的数据结构（如列表）不具扩展性：现代系统有时由上千个进程组成，因此每隔几毫秒搜索一次长列表会非常浪费。 CFS 通过将进程保留在红黑树上来解决这个问题。红黑树是多种类型的平衡树之一；与简单的二叉树（在最糟糕的插入模式下，它的性能会退化到类似于列表）不同，平衡树需要做一些额外的工作来保持较低的深度，从而确保操作在时间上是$\\log$（而非线性）的。 CFS 不会将所有进程都保存在此结构中；相反，只有正在运行（或可运行）的进程才会保存在此结构中。如果某个进程进入休眠状态（例如，等待 I/O 完成或等待网络数据包到达），它就会从进程树中删除，并在其他地方跟踪。 让我们看一个例子来更清楚地说明这一点。假设有十个作业，它们的 vruntime 值分别为：1、5、9、10、14、18、17、21、22 和 24。如果我们将这些作业保存在一个有序列表中，那么查找下一个要运行的作业就很简单了：只需删除第一个元素即可。但是，如果将该作业按顺序放回列表中，我们必须扫描这个列表，寻找正确的位置插入，这是一个 $O(n)$ 运算。任何搜索的效率也很低，平均也需要线性时间。 而在红黑树上保持相同的值可以提高大多数操作的效率，如下图所示。 进程在树中按 vruntime 排序，大多数操作（如插入和删除）的时间都是对数级别，即 $O(\\log n)$。当 n 越来越大，对数效率明显高于线性效率。 ","date":"2024-04-25","objectID":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/:7:3","tags":["OS"],"title":"比例份额调度","uri":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"7.4 处理I/O和休眠进程 对于已经进入休眠状态很长一段时间的作业来说，选择下一个运行的最低 vruntime 会出现一个问题。例如有两个进程 A 和 B，其中一个 (A) 连续运行，另一个 (B) 已经进入休眠状态很长一段时间（例如 10 秒）。当 B 醒来时，它的 vruntime 将落后 A 10 秒，因此（如果我们不小心的话），B 现在将在接下来的 10 秒内独占 CPU，同时赶上 A，这实际上会让A饥饿。 CFS 通过在作业唤醒时更改其 vruntime来处理这种情况。具体来说，CFS 会将该作业的 vruntime 设置为在树中找到的最小值（记住，树中只包含正在运行的作业）。通过这种方式，CFS 避免了饥饿，但也并非没有代价：短时间睡眠的作业往往无法获得公平的 CPU 份额。 ","date":"2024-04-25","objectID":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/:7:4","tags":["OS"],"title":"比例份额调度","uri":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"8 总结 我们介绍了比例份额调度的概念，并简要讨论了三种方法：彩票调度、步幅调度和 Linux 的完全公平调度器（CFS）。彩票调度巧妙地利用随机性来实现比例份额，而步幅调度则是确定性地实现比例份额。CFS 是本章讨论的唯一一种 “真正的 “调度程序，有点像带有动态时间片的加权循环调度程序，但其设计可在负载情况下进行扩展并表现良好；据我们所知，它是目前使用最广泛的公平分配调度程序。 任何调度器都不是万能的，公平共享调度器也有自己的问题。其中一个问题是，这种方法与 I/O 并不十分匹配；如上所述，偶尔执行 I/O 的作业可能无法获得公平分配的 CPU。另一个问题是，它们没有解决彩票或优先级分配的难题，也就是说，你怎么知道应该给你的浏览器分配多少彩票，或者给你的文本编辑器设置nice的值呢？其他通用调度程序（如我们之前讨论过的 MLFQ 和其他类似的 Linux 调度程序）会自动处理这些问题，因此可能更容易部署。 好消息是，在许多领域中，这些问题并不是主要问题，比例份额调度器的使用效果很好。例如，在虚拟化数据中心（或云计算）中，你可能希望将四分之一的 CPU 周期分配给 Windows VM，其余的分配给基本的 Linux 安装，按比例份额可以简单而有效地做到这一点。这个想法还可以扩展到其他地方。 ","date":"2024-04-25","objectID":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/:8:0","tags":["OS"],"title":"比例份额调度","uri":"/posts/06.%E6%AF%94%E4%BE%8B%E4%BB%BD%E9%A2%9D%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"github地址 ","date":"2024-04-25","objectID":"/posts/05.%E5%A4%9A%E7%BA%A7%E5%8F%8D%E9%A6%88%E9%98%9F%E5%88%97/:0:0","tags":["OS"],"title":"多级反馈队列","uri":"/posts/05.%E5%A4%9A%E7%BA%A7%E5%8F%8D%E9%A6%88%E9%98%9F%E5%88%97/"},{"categories":["系统架构"],"content":"1 Note/Translation 基本规则 MLFQ有许多不同的队列，每个队列分配了不同的优先级。在任何给定时间，准备运行的作业都位于单个队列上。 MLFQ 使用优先级来决定在给定时间应运行哪个作业：选择运行具有较高优先级的作业（即较高队列上的作业）。当然，一个队列上可能有多个作业，即具有相同的优先级，这种情况则对这些工作使用RR调度。则MLFQ基本规则如下： $\\text{Rule}\\space1:\\text{If Priority(A)\u003ePriority(B),A runs (B doesn’t).}$ $\\text{Rule}\\space1:\\text{If Priority(A)=Priority(B),A and B run in RR.}$ MLFQ例子 如果我们要展示给定时刻队列的样子，我们可能会看到如下所示的内容（图 8.1）。图中，两个作业（A 和 B）的优先级最高，作业 C 处于中间，作业 D 的优先级最低。鉴于我们目前对 MLFQ 工作原理的了解，调度程序只会在 A 和 B 之间交替时间片，因为它们是系统中优先级最高的作业；可怜的工作 C 和 D 根本无法运行！ 尝试#1：怎么改变作业的优先级 现在，我们必须决定 MLFQ 将如何在作业的生命周期内更改作业的优先级（以及它所在的队列）。为此，我们必须牢记我们的工作负载：短期运行的交互式作业（可能经常放弃 CPU），以及一些需要大量 CPU 时间但运行时间较长的“CPU 密集型”作业。其中响应时间并不重要。这是我们对优先级调整算法的第一次尝试： $\\text{Rule 3: When a job enters the system, it is placed at the highest priority (the topmost queue).}$ $\\text{Rule 4a: If a job uses up an entire time slice while running, its pri- ority is reduced (i.e., it moves down one queue).}$ $\\text{Rule 4b: If a job gives up the CPU before the time slice is up, it stays at the same priority level.}$ 例子#1.1：单个长时间运行的作业 首先，我们来看看当系统中有一项长期运行的工作时会发生什么情况。下图显示了在三队列调度程序中该作业随时间发生的变化。 如示例所示，作业以最高优先级（Q2）进入。经过 $\\text{10ms}$ 的单个时间片后，调度程序将作业的优先级降低了一个，因此作业的优先级为 Q1。在 Q1 上运行一个时间片后，作业最终被降到系统中的最低优先级（Q0），并保持不变。 例子#1.2：加入一个短作业 在这个例子中，有两个作业：A是一个长期运行的CPU密集型作业，B是一个短期运行的交互作业。假设A已经运行了一段时间，然后B才到达，这样会发生什么？MLFQ是否会近似于B的SJF？ 如下图所示，A（黑色显示）在最低优先级队列中运行（任何长期运行的 CPU 密集型作业都是如此）；B（灰色显示）在 T = 100 时到达，因此会插入到最高队列，由于其运行时间很短（仅20ms），B 在到达底层队列之前完成，分两个时间片；然后 A 恢复运行（低优先级）。 从这个例子中，你有望理解算法的一个主要目标：因为它不知道一项作业是短作业还是长期作业，所以它首先假定它可能是短作业，从而给予该作业高优先级。如果它确实是短作业，它就会快速运行并完成；如果它不是短作业，它就会在队列中缓慢移动，从而很快证明自己是一个长期运行的更类似批处理的进程。通过这种方式，MLFQ 近似于 SJF。 例子#1.3：关于I/O 如上文规则 4b 所述，如果进程在用完其时间片之前放弃了处理器，我们会将其保持在相同的优先级。这条规则的用意很简单：例如，如果一个交互式作业正在进行大量的 I/O（比如等待键盘或鼠标的用户输入），那么它就会在其时间片完成之前放弃 CPU；在这种情况下，我们不希望惩罚该作业，因此只需将其保持在同一优先级即可。 下图举例说明了这种方法的工作原理，交互式作业 B（灰色显示）只需要 CPU 1 ms，然后执行 I/O，与长期运行的批处理作业 A（黑色显示）争夺 CPU。MLFQ 方法将 B 保持在最高优先级，因为 B 一直在释放 CPU；如果 B 是交互式作业，MLFQ 将进一步实现快速运行交互式作业的目标。 我们现在设计的MLFQ存在的问题 这样，我们就有了一个基本的 MLFQ。它似乎做得相当不错，在长时间运行的作业之间公平地共享 CPU，并让短时间或 I/O 密集型交互式作业快速运行。遗憾的是，我们迄今为止开发的方法存在严重缺陷。 饥饿问题：如果系统存在太多交互作业，它们将会共同消耗所有CPU时间，这样长时间运行的作业将不会获得任何CPU时间（即饥饿）。 欺骗调度程序：聪明的用户可以重写程序，玩弄调度程序。即是指偷偷摸摸地欺骗调度程序，让调度程序给你分配更多的资源。我们所描述的算法很容易受到以下攻击：在时间片结束前，进行一次 I/O 操作（对某个你并不关心的文件），从而放弃 CPU；这样做可以让你保持在同一队列中，从而获得更多的 CPU 时间。如果操作得当（例如，运行 99% 的时间片后才放弃 CPU），作业几乎可以垄断 CPU。 程序行为改变：一个程序可能会随着时间的推移而改变其行为；原来的 CPU 约束可能会过渡到交互阶段。采用我们目前的方法，这样的作业就会倒霉，不会像系统中的其他交互式作业一样得到处理。 尝试#2：优先级提升 让我们试着改变规则，看看能否避免 “饥饿 “问题。为了保证占用 CPU 的作业能取得一些进展（即使进展不大），我们可以做些什么？简单来说，就是定期提升系统中所有作业的优先级。实现这一点的方法有很多，但我们只需做一件简单的事：把所有作业都扔到最上面的队列中；因此，我们需要一条新规则： $\\text{Rule 5: After some time period S, move all the jobs in the system to the topmost queue.}$ 我们的新规则同时解决了两个问题。首先，保证了进程不会饥饿：作业排在队列的最前面，就能与其他高优先级作业以循环方式共享 CPU，从而最终获得服务。其次，如果受 CPU 限制的作业已开始交互，调度程序会在其获得优先级提升后对其进行适当处理。 例子#2.1：竞争CPU 在这种情况下，我们仅展示一个长时间运行的作业与两个短时间运行的交互式作业竞争 CPU 时的行为。下图显示了两个图表。在左边，没有优先级提升，因此一旦两个短期作业到达，长期运行的作业就会陷入饥饿；右边，每 50 毫秒就有一次优先级提升（这个值可能太小，但这里用于示例），因此我们至少保证长时间运行的作业会取得一些进展，提升到每 50 毫秒设置一次最高优先级，从而定期运行。 当然，增加时间段S会带来一个明显的问题：S应该设置为什么？ John Ousterhout，一位受人尊敬的系统研究员 ，过去常常将系统中的此类值称为“巫术常量”，因为它们似乎需要某种形式的黑魔法才能正确设置它们。不幸的是，S有那种味道。如果设置得太高，长时间运行的作业可能会陷入困境；太低，交互式作业可能无法获得适当的 CPU 份额。 尝试#3：更好的计算 现在，我们还有一个问题要解决：如何防止调度程序被玩弄？正如你可能已经猜到的，真正的罪魁祸首是Rule 4a 和 4b，它们允许作业在时间片到期前放弃 CPU，从而保留其优先级。那么我们该怎么办呢？解决办法是在 MLFQ 的每一级更好地计算 CPU 时间。调度程序不应该忘记进程在特定级别上使用了多少时间片，而应该进行跟踪；一旦进程用完了分配的时间片，就会被降级到下一个优先级队列。至于进程是在一个长的时间段内使用时间片，还是在许多小的时间段内使用时间片，这并不重要。因此，我们将规则 4a 和 4b 重写为以下单一规则： $\\text{Rule 4: Once a job uses up its time allotment at a given level (re- gardless of how many times it has given up the CPU), its priority is reduced (i.e., it moves down one queue).}$ 例子#3.1：旧规则和新规则对比 下图显示了当工作负载试图利用旧规则 4a 和 4b（左侧）以及新的反玩弄规则 4 来玩弄调度程序时会发生的情况。如果没有任何防止玩弄的保护措施，进程可以在时间片结束前发出 I/O，从而支配 CPU 时间。有了这种保护措施，无论进程的 I/O 行为如何，它都会在队列中缓慢移动，从而无法获得不公平的 CPU 占有率。 调整 MLFQ 及其他问题 MLFQ 调度还存在其他一些问题。一个大问题是如何为这样的调度器设置参数。例如，应该有多少个队列？每个队列的时间片应该有多大？为了避免饥饿并考虑到行为的变化，应该多久提升一次优先级？这些问题都没有简单的答案，因此只有在工作负载方面积累一定的经验，然后对调度程序进行调整，才能取得令人满意的平衡。 例如，大多数 MLFQ 变体都允许在不同队列中使用不同的时间片长度。高优先级队列的时间片通常较短；毕竟它们由交互式作业组成，因此在它们之间快速交替是合理的（例如","date":"2024-04-25","objectID":"/posts/05.%E5%A4%9A%E7%BA%A7%E5%8F%8D%E9%A6%88%E9%98%9F%E5%88%97/:1:0","tags":["OS"],"title":"多级反馈队列","uri":"/posts/05.%E5%A4%9A%E7%BA%A7%E5%8F%8D%E9%A6%88%E9%98%9F%E5%88%97/"},{"categories":["系统架构"],"content":"2 Program Explanation 这个程序 mlfq.py 允许您查看本章中介绍的 MLFQ 调度程序的行为方式。和以前一样，您可以使用它来使用随机种子为自己生成问题，或者使用它构建一个精心设计的实验，以了解 MLFQ 在不同情况下的工作原理。要运行该程序，请键入： ❯ python mlfq.py 使用参数-h查看选项帮助： ❯ python mlfq.py -h Usage: mlfq.py [options] Options: -h, --help show this help message and exit -s SEED, --seed=SEED the random seed -n NUMQUEUES, --numQueues=NUMQUEUES number of queues in MLFQ (if not using -Q) -q QUANTUM, --quantum=QUANTUM length of time slice (if not using -Q) -a ALLOTMENT, --allotment=ALLOTMENT length of allotment (if not using -A) -Q QUANTUMLIST, --quantumList=QUANTUMLIST length of time slice per queue level, specified as x,y,z,... where x is the quantum length for the highest priority queue, y the next highest, and so forth -A ALLOTMENTLIST, --allotmentList=ALLOTMENTLIST length of time allotment per queue level, specified as x,y,z,... where x is the # of time slices for the highest priority queue, y the next highest, and so forth -j NUMJOBS, --numJobs=NUMJOBS number of jobs in the system -m MAXLEN, --maxlen=MAXLEN max run-time of a job (if randomly generating) -M MAXIO, --maxio=MAXIO max I/O frequency of a job (if randomly generating) -B BOOST, --boost=BOOST how often to boost the priority of all jobs back to high priority -i IOTIME, --iotime=IOTIME how long an I/O should last (fixed constant) -S, --stay reset and stay at same priority level when issuing I/O -I, --iobump if specified, jobs that finished I/O move immediately to front of current queue -l JLIST, --jlist=JLIST a comma-separated list of jobs to run, in the form x1,y1,z1:x2,y2,z2:... where x is start time, y is run time, and z is how often the job issues an I/O request -c compute answers for me 使用模拟器有几种不同的方法，一种方法是生成一些随机作业，然后看看您是否可以弄清楚它们在给定 MLFQ 调度程序的情况下将如何表现。例如，如果您想创建随机生成的三作业工作负载，您只需运行 ❯ python mlfq.py -j 3 Here is the list of inputs: OPTIONS jobs 3 OPTIONS queues 3 OPTIONS allotments for queue 2 is 1 OPTIONS quantum length for queue 2 is 10 OPTIONS allotments for queue 1 is 1 OPTIONS quantum length for queue 1 is 10 OPTIONS allotments for queue 0 is 1 OPTIONS quantum length for queue 0 is 10 OPTIONS boost 0 OPTIONS ioTime 5 OPTIONS stayAfterIO False OPTIONS iobump False For each job, three defining characteristics are given: startTime : at what time does the job enter the system runTime : the total CPU time needed by the job to finish ioFreq : every ioFreq time units, the job issues an I/O (the I/O takes ioTime units to complete) Job List: Job 0: startTime 0 - runTime 84 - ioFreq 7 Job 1: startTime 0 - runTime 42 - ioFreq 3 Job 2: startTime 0 - runTime 51 - ioFreq 4 Compute the execution trace for the given workloads. If you would like, also compute the response and turnaround times for each of the jobs. Use the -c flag to get the exact results when you are finished. 这会在具有多个默认设置的默认数量的队列上生成三个作业（根据指定）的随机工作负载。如果您使用 (-c) 上的求解选项再次运行，您将看到与上面相同的打印输出，以及以下内容： Execution Trace: [ time 0 ] JOB BEGINS by JOB 0 [ time 0 ] JOB BEGINS by JOB 1 [ time 0 ] JOB BEGINS by JOB 2 [ time 0 ] Run JOB 0 at PRIORITY 2 [ TICKS 9 ALLOT 1 TIME 83 (of 84) ] [ time 1 ] Run JOB 0 at PRIORITY 2 [ TICKS 8 ALLOT 1 TIME 82 (of 84) ] [ time 2 ] Run JOB 0 at PRIORITY 2 [ TICKS 7 ALLOT 1 TIME 81 (of 84) ] [ time 3 ] Run JOB 0 at PRIORITY 2 [ TICKS 6 ALLOT 1 TIME 80 (of 84) ] [ time 4 ] Run JOB 0 at PRIORITY 2 [ TICKS 5 ALLOT 1 TIME 79 (of 84) ] [ time 5 ] Run JOB 0 at PRIORITY 2 [ TICKS 4 ALLOT 1 TIME 78 (of 84) ] [ time 6 ] Run JOB 0 at PRIORITY 2 [ TICKS 3 ALLOT 1 TIME 77 (of 84) ] [ time 7 ] IO_START by JOB 0 IO DONE [ time 7 ] Run JOB 1 at PRIORITY 2 [ TICKS 9 ALLOT 1 TIME 41 (of 42) ] [ time 8 ] Run JOB 1 at PRIORITY 2 [ TICKS 8 ALLOT 1 TIME 40 (of 42) ] [ time 9 ] Run JOB 1 at PRIORITY 2 [ TICKS 7 ALLOT 1 TIME 39 (of 42) ] ... Final statistics: Job 0: startTime 0 - response 0 - turnaround 175 Job 1: startTime 0 - response 7 - turnaround 191 Job 2: startTime 0 - response 9 - turnaround 168 Avg 2: startTime n/a - response 5.33 - turnaround 178.00 该跟踪以毫秒为单位准确显示了调度程序决定执行的操作。在此示例中，它首先运行作业 0 7 毫秒，直到作业 0 发出 I/O；这是","date":"2024-04-25","objectID":"/posts/05.%E5%A4%9A%E7%BA%A7%E5%8F%8D%E9%A6%88%E9%98%9F%E5%88%97/:2:0","tags":["OS"],"title":"多级反馈队列","uri":"/posts/05.%E5%A4%9A%E7%BA%A7%E5%8F%8D%E9%A6%88%E9%98%9F%E5%88%97/"},{"categories":["系统架构"],"content":"3 QA 仅使用两个作业和两个队列运行一些随机生成的问题；计算每个的 MLFQ 执行轨迹。通过限制每个作业的长度和关闭 I/O 让您的生活更轻松。 例子：python mlfq.py -n 2 -j 2 -m 20 -M 0 -s 66 Job List: Job 0: startTime 0 - runTime 2 - ioFreq 0 Job 1: startTime 0 - runTime 5 - ioFreq 0 Execution Trace: [ time 0 ] JOB BEGINS by JOB 0 [ time 0 ] JOB BEGINS by JOB 1 [ time 0 ] Run JOB 0 at PRIORITY 1 [ TICKS 9 ALLOT 1 TIME 1 (of 2) ] [ time 1 ] Run JOB 0 at PRIORITY 1 [ TICKS 8 ALLOT 1 TIME 0 (of 2) ] [ time 2 ] FINISHED JOB 0 [ time 2 ] Run JOB 1 at PRIORITY 1 [ TICKS 9 ALLOT 1 TIME 4 (of 5) ] [ time 3 ] Run JOB 1 at PRIORITY 1 [ TICKS 8 ALLOT 1 TIME 3 (of 5) ] [ time 4 ] Run JOB 1 at PRIORITY 1 [ TICKS 7 ALLOT 1 TIME 2 (of 5) ] [ time 5 ] Run JOB 1 at PRIORITY 1 [ TICKS 6 ALLOT 1 TIME 1 (of 5) ] [ time 6 ] Run JOB 1 at PRIORITY 1 [ TICKS 5 ALLOT 1 TIME 0 (of 5) ] [ time 7 ] FINISHED JOB 1 Final statistics: Job 0: startTime 0 - response 0 - turnaround 2 Job 1: startTime 0 - response 2 - turnaround 7 Avg 1: startTime n/a - response 1.00 - turnaround 4.50 您将如何运行调度程序来重现本章中的每个示例？ // Figure 8.2 Long-running Job Over Time \u003epython mlfq.py -n 3 -q 10 -l 0,200,0 -c // Figure 8.3 Along Came An Interactive Job \u003epython mlfq.py -n 3 -q 10 -l 0,180,0:100,20,0 -c // Figure 8.4 A Mixed I/O-intensive and CPU-intensive Workload \u003epython mlfq.py -n 3 -q 10 -l 0,175,0:50,25,1 -i 5 -S -c // Figure 8.5 without priority boost \u003epython mlfq.py -n 3 -q 10 -l 0,120,0:100,50,1:100,50,1 -i 1 -S -c // Figure 8.5 with priority boost python mlfq.py -n 3 -q 10 -l 0,120,0:100,50,1:100,50,1 -i 1 -S -B 50 -c // Figure 8.6 without gaming tolerance \u003e python mlfq.py -n 3 -q 10 -i 1 -S -l 0,200,0:80,100,9 -c // Figure 8.6 with gaming tolerance python mlfq.py -n 3 -q 10 -i 1 -l 0,200,0:80,100,9 -c // Figure 8.7 Lower Priority, Longer Quanta python mlfq.py -n 3 -a 2 -Q 10,20,40 -l 0,200,0:0,200,0 -c 如何配置调度程序参数以使其像循环调度程序一样运行？ 同一队列上的作业是按时间分片的，因此答案是只有一个队列。 使用两个作业和调度程序参数制作一个工作负载，以便一个作业利用旧的规则 4a 和 4b（使用 -S 参数打开）来欺骗调度程序并在特定的情况下获得 99% 的 CPU 占用率时间间隔。 首先，使用 -i 将 I/O 时间设置为 1，然后确保 CPU hog 在 100 个点击时间片长度的第 99 个点击时调用 I/O 操作。另外，包含 -I 标志以确保 CPU 占用者在 I/O 请求完成时重新获得控制权： python mlfq.py -S -i 1 -l 0,297,99:0,60,0 -q 100 -n 3 -I -c 给定一个系统，其最高队列的时间片长度为 10 毫秒，您需要多久将作业提升回最高优先级（使用 -B 标志）才能保证单个长时间运行的作业（并且可能会饥饿）作业至少获得 5% 的 CPU 资源？ 如果每 10 毫秒就有一个新的 10 毫秒长作业到达 - 如图 8.5（左）所示，每 200 个时钟周期提升可确保长进程将运行 10/200 个 CPU 周期 = 5%。 调度中出现的一个问题是在队列的哪一端添加刚刚完成 I/O 的作业； -I 参数更改此调度模拟器的此行为。尝试一些工作负载，看看是否可以看到此参数的效果。 python mlfq.py -n 2 -q 10 -l 0,50,0:0,50,11 -i 1 -S -c python mlfq.py -n 2 -q 10 -l 0,50,0:0,50,11 -i 1 -S -I -c 使用-I的周转时间下降了很多。 ","date":"2024-04-25","objectID":"/posts/05.%E5%A4%9A%E7%BA%A7%E5%8F%8D%E9%A6%88%E9%98%9F%E5%88%97/:3:0","tags":["OS"],"title":"多级反馈队列","uri":"/posts/05.%E5%A4%9A%E7%BA%A7%E5%8F%8D%E9%A6%88%E9%98%9F%E5%88%97/"},{"categories":["系统架构"],"content":"github代码 ","date":"2024-04-25","objectID":"/posts/04.cpu%E8%B0%83%E5%BA%A6/:0:0","tags":["OS"],"title":"CPU调度","uri":"/posts/04.cpu%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"1 Program Explanation 程序scheduler.py允许您查看不同调度程序在响应时间、周转时间和总等待时间等调度指标下的执行情况。 “实现”了三个调度程序：FIFO、SJF 和 RR。 要运行该程序获取其选项，可执行以下操作： ./scheduler.py -h 或者 python scheduler.py -h 得到： ❯ python scheduler.py -h Usage: scheduler.py [options] Options: -h, --help show this help message and exit -s SEED, --seed=SEED the random seed -j JOBS, --jobs=JOBS number of jobs in the system -l JLIST, --jlist=JLIST instead of random jobs, provide a comma-separated list of run times -m MAXLEN, --maxlen=MAXLEN max length of job -p POLICY, --policy=POLICY sched policy to use: SJF, FIFO, RR -q QUANTUM, --quantum=QUANTUM length of time slice for RR policy -c compute answers for me 首先，在不带 -c 选项的情况下运行：这会向您显示要解决的问题而不透露答案。例如，如果您想要使用 FIFO 策略计算响应、周转和等待三个作业，请运行以下命令： python scheduler.py -p FIFO -j 3 -s 100 这指定了具有三个作业的 FIFO 策略，而且重要的是，指定了 100 的特定随机种子。如果您想查看该问题的解决方案，则必须再次指定该完全相同的随机种子。让我们运行一下，看看会发生什么。这是您应该看到的： ❯ python scheduler.py -p FIFO -j 3 -s 100 ARG policy FIFO ARG jobs 3 ARG maxlen 10 ARG seed 100 Here is the job list, with the run time of each job: Job 0 ( length = 2 ) Job 1 ( length = 5 ) Job 2 ( length = 8 ) Compute the turnaround time, response time, and wait time for each job. When you are done, run this program again, with the same arguments, but with -c, which will thus provide you with the answers. You can use -s \u003csomenumber\u003e or your own job list (-l 10,15,20 for example) to generate different problems for yourself. 计算每个作业的周转时间、响应时间和等待时间。完成后，使用相同的参数再次运行该程序，但使用 -c选项，这将为您提供答案。您可以使用 -s 或您自己的作业列表（例如 -l 10,15,20）为自己生成不同的问题。 从这个例子中可以看出，生成了三个作业：长度为 2 的作业 0、长度为 5 的作业 1 和长度为 8 的作业 2。正如程序所述，您现在可以使用它来计算一些统计数据，看看是否可以掌握基本概念。 完成后，您可以使用相同的程序来“解决”问题并查看您的工作是否正确。为此，请使用“-c”选项。输出： ❯ python scheduler.py -p FIFO -j 3 -s 100 -c ARG policy FIFO ARG jobs 3 ARG maxlen 10 ARG seed 100 Here is the job list, with the run time of each job: Job 0 ( length = 2 ) Job 1 ( length = 5 ) Job 2 ( length = 8 ) ** Solutions ** Execution trace: [ time 0 ] Run job 0 for 2.00 secs ( DONE at 2.00 ) [ time 2 ] Run job 1 for 5.00 secs ( DONE at 7.00 ) [ time 7 ] Run job 2 for 8.00 secs ( DONE at 15.00 ) Final statistics: Job 0 -- Response: 0.00 Turnaround 2.00 Wait 0.00 Job 1 -- Response: 2.00 Turnaround 7.00 Wait 2.00 Job 2 -- Response: 7.00 Turnaround 15.00 Wait 7.00 Average -- Response: 3.00 Turnaround 8.00 Wait 3.00 从上述输出我们可以看到，作业0首先运行了2秒，作业2接着运行了5秒，最后作业2运行了8秒。 最终的统计数据也很有用：它们计算“响应时间”（作业到达后第一次运行之前等待所花费的时间）、“周转时间”（自第一次到达以来完成作业所花费的时间）以及总时间。 “等待时间”（准备好但未运行的任何时间）。统计数据按作业显示，然后显示所有作业的平均值。当然，您应该在使用“-c”选项运行之前计算出所有这些内容！ 如果您想尝试相同类型的问题但使用不同的输入，请尝试更改作业数量或随机种子或同时更改两者。不同的随机种子基本上为您提供了一种为自己生成无数不同问题的方法，并且“-c”选项可以让您检查自己的工作。继续这样做，直到您觉得自己真正理解了这些概念。 另一个有用的选项是“-l”（这是一个小写的 L），它可以让您指定您希望看到的计划的确切作业。例如，如果您想了解 SJF 如何执行长度为 5、10 和 15 的三个作业，您可以运行： ❯ python scheduler.py -p SJF -l 5,10,15 ARG policy SJF ARG jlist 5,10,15 Here is the job list, with the run time of each job: Job 0 ( length = 5.0 ) Job 1 ( length = 10.0 ) Job 2 ( length = 15.0 ) Compute the turnaround time, response time, and wait time for each job. When you are done, run this program again, with the same arguments, but with -c, which will thus provide you with the answers. You can use -s \u003csomenumber\u003e or your own job list (-l 10,15,20 for example) to generate different problems for yourself. 计算完后还是通过-c选项获得答案。指定确切的作业时，无须指定随机种子或者作业数量。 我们最后测试一下RR，可以运行： ❯ python scheduler.py -p RR -l 5,10,15 -c ARG policy RR ARG jlist 5,10,15 Here is the job list, with the run time of each job: Job 0 ( length = 5.0 ) Job 1 ( length = 10.0 ) Job 2 ( length = 15.0 ) ** Solutions ** Execution trace: [ time 0 ] Run job 0 for 1.00 secs [ time 1 ] Run job 1 for 1.00 secs [ time 2 ] Run job 2 for 1.00 secs [ time 3 ] Run job 0 for 1.00 secs [ time 4 ] Run job 1 for 1.00 secs [ time 5 ] Run job 2 for 1.00 secs [ time 6 ] Run job 0 for 1.00 secs [ time 7 ] Run job 1 for 1.00 secs [ time 8 ] Run job 2 for 1.00 secs [ time 9 ] Run job 0 for 1.00 secs [ time 10 ] Run job 1 for 1.00 secs [ time 11 ] Run job 2 for 1.00 secs [ time 12 ] Run job 0 for 1.00 secs ( DONE at 13.00 ) [ time 13 ] Run job 1 fo","date":"2024-04-25","objectID":"/posts/04.cpu%E8%B0%83%E5%BA%A6/:1:0","tags":["OS"],"title":"CPU调度","uri":"/posts/04.cpu%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"2 QA 以下问题都可以通过scheduler.py进行验证 使用 SJF 和 FIFO 调度器运行长度为 200 的三个作业时，计算响应时间和周转时间 SJF $turnaround = \\frac{200-0+400-0+600-0}{3}=400$ $response=\\frac{0+200+400}{3}=200$ FIFO 跟SJF一样 现在执行相同的操作，但使用不同长度的作业：100、200 和 300。 SJF $turnaround = \\frac{100-0+300-0+600-0}{3}=333$ $response=\\frac{0+100+300}{3}=133$ FIFO 由于到达时间是一样，所以调度具有不确定性，最佳方案就是和SJF一样。 现在执行相同的操作，但也使用 RR 调度程序和时间片 1 对于RR，$response=\\frac{0+1+2}{3}=1$ $turnaround=\\frac{298+499+600}{3}=265.67$ 在哪些类型的工作负载中，SJF 的周转时间与 FIFO 相同？ SJF 始终提供与 FIFO 相同的周转时间，除非较短的作业在较长的作业之后到达。只要所有作业长度相等或按升序到达，周转时间就会相同。 在哪些类型的工作负载和时间片长度下，SJF 可以提供与 RR 相同的响应时间？ 如果所有作业长度(x)相同，且时间片长度(q)=x，在这种情况下，SJF提供与RR相同的响应时间。通过运行以下代码验证： ./scheduler.py -p SJF -l 100,100,100 -c ./scheduler.py -p RR -l 100,100,100 -c -q 100 随着作业长度的增加，SJF 的响应时间会发生什么变化？您能否使用模拟器来演示这一趋势？ 如果我们将每个工作的长度加倍，平均响应时间也会加倍。这意味着工作长度和响应时间之间存在线性关系。 随着时间片长度的增加，RR 的响应时间会发生什么变化？你能写出一个方程，在给定 N 个作业的情况下给出最坏情况的响应时间吗？ 响应时间随着时间片长度的增加而线性增加。令 N 为作业数量，q 为时间片长度，则最坏情况的响应时间为 $\\frac{(N-1)q}{N}$。 ","date":"2024-04-25","objectID":"/posts/04.cpu%E8%B0%83%E5%BA%A6/:2:0","tags":["OS"],"title":"CPU调度","uri":"/posts/04.cpu%E8%B0%83%E5%BA%A6/"},{"categories":["系统架构"],"content":"github代码 在本作业中，您将测量系统调用和上下文切换的成本。测量系统调用的成本相对容易。例如，您可以反复调用一个简单的系统调用（如执行 0 字节读取），并计算所需时间；将时间除以迭代次数，就能估算出系统调用的成本。 您必须考虑的一件事是计时器的精度和准确性。可以使用的典型计时器是 gettimeofday()；阅读手册页了解详细信息。您将看到 gettimeofday() 返回 1970 年以来的时间（以微秒为单位）；然而，这并不意味着计时器精确到微秒。测量对 gettimeofday() 的连续调用，以了解计时器的精确度；这将告诉您必须运行多少次空系统调用测试迭代才能获得良好的测量结果。如果 gettimeofday() 对您来说不够精确，您可以考虑使用 x86 机器上可用的 rdtsc 指令。 测量上下文切换的成本比较麻烦。lmbench 基准测试的方法是在单个 CPU 上运行两个进程，并在它们之间设置两个 UNIX 管道；管道只是 UNIX 系统中进程相互通信的众多方式之一。第一个进程向第一个管道发出写操作，并等待第二个管道的读操作；当看到第一个进程在等待从第二个管道读取数据时，操作系统会将第一个进程置于阻塞状态，并切换到另一个进程，后者从第一个管道读取数据，然后向第二个管道写操作。当第二个进程再次尝试从第一个管道读取数据时，它就会阻塞，这样来回循环的通信就继续进行。通过测量这样反复通信的成本，lmbench 可以很好地估算出上下文切换的成本。您可以尝试使用管道或其他通信机制（如 UNIX 套接字）在这里重新创建类似的功能。 在拥有多个 CPU 的系统中，测量上下文切换成本是个难题；在这样的系统中，你需要做的是确保上下文切换进程位于同一个处理器上。幸运的是，大多数操作系统都有将进程绑定到特定处理器的调用；例如，在 Linux 系统中，调用 sched_setaffinity() 就是你要找的。通过确保两个进程位于同一处理器上，就能确保衡量操作系统在同一 CPU 上停止一个进程并恢复另一个进程的成本。 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e #include \u003csys/time.h\u003e #define ITERATIONS 1000 // Measure the cost of a system call void measure_system_call() { struct timeval start, end; gettimeofday(\u0026start, NULL); for (int i = 0; i \u003c ITERATIONS; i++) { read(0, NULL, 0); // Example of a simple system call } gettimeofday(\u0026end, NULL); double time_per_call = ((double)(end.tv_sec - start.tv_sec) * 1000000 + (end.tv_usec - start.tv_usec)) / ITERATIONS; printf(\"Estimated cost of a system call: %f microseconds\\n\", time_per_call); } // Measure the precision of gettimeofday() void measure_gettimeofday_precision() { struct timeval start, end; gettimeofday(\u0026start, NULL); for (int i = 0; i \u003c ITERATIONS; i++) { gettimeofday(\u0026end, NULL); } double precision = ((double)(end.tv_sec - start.tv_sec) * 1000000 + (end.tv_usec - start.tv_usec)) / ITERATIONS; printf(\"Precision of gettimeofday(): %f microseconds\\n\", precision); } // Measure the cost of a context switch void measure_context_switch() { int pipefd[2]; if (pipe(pipefd) == -1) { perror(\"pipe\"); exit(EXIT_FAILURE); } pid_t pid = fork(); if (pid == -1) { perror(\"fork\"); exit(EXIT_FAILURE); } if (pid == 0) { // Child process close(pipefd[1]); struct timeval start, end; gettimeofday(\u0026start, NULL); read(pipefd[0], NULL, 0); gettimeofday(\u0026end, NULL); double time_diff = (end.tv_sec - start.tv_sec) * 1000000 + (end.tv_usec - start.tv_usec); printf(\"Child process context switch time: %f microseconds\\n\", time_diff); exit(EXIT_SUCCESS); } else { // Parent process close(pipefd[0]); struct timeval start, end; gettimeofday(\u0026start, NULL); write(pipefd[1], \"\", 1); wait(NULL); gettimeofday(\u0026end, NULL); double time_diff = (end.tv_sec - start.tv_sec) * 1000000 + (end.tv_usec - start.tv_usec); printf(\"Parent process context switch time: %f microseconds\\n\", time_diff); } } int main() { measure_system_call(); measure_gettimeofday_precision(); measure_context_switch(); return 0; } 输出结果如下： Estimated cost of a system call: 0.333000 microseconds Precision of gettimeofday(): 0.014000 microseconds Child process context switch time: 1.000000 microseconds Parent process context switch time: 160.000000 microseconds ","date":"2024-04-25","objectID":"/posts/03.%E6%9C%89%E9%99%90%E7%9B%B4%E6%8E%A5%E6%89%A7%E8%A1%8C/:0:0","tags":["OS"],"title":"有限直接执行","uri":"/posts/03.%E6%9C%89%E9%99%90%E7%9B%B4%E6%8E%A5%E6%89%A7%E8%A1%8C/"},{"categories":["系统架构"],"content":"github代码 编写一个调用 fork() 的程序。在调用 fork() 之前，让主进程访问一个变量（如 x）并将其值设为某个值（如 100）。子进程中的变量值是多少？当子进程和父进程都改变 x 的值时，变量会发生什么变化？ 调用fork会创建一个与父进程几乎完全一样的副本，且会复制当前执行的上下文，所以子进程中的变量值是100，它们改变x的值都是互不影响的。执行python q1.py可得到结果如下： Parent process - x: 100 Parent process - x after modification: 150 Child process - x: 100 Child process - x after modification: 50 编写一个程序，打开一个文件（使用 open() 系统调用），然后调用 fork() 创建一个新进程。子进程和父进程都能访问 open() 返回的文件描述符吗？当它们同时（即同时）向文件写入时会发生什么情况？ 父进程的文件描述符也会继承，所以子进程也可以往 test.txt写入消息，虽然父进程和子进程的文件描述符是相同的，但是它们各自的文件描述符指向的是相同文件的不同偏移位置。在写入文件时，操作系统会维护两个进程的文件偏移，确保它们互不干扰。执行python q2.py可验证。 使用fork()编写另一个程序。子进程应打印“hello”，父进程应打印“goodbye”。您应尽量确保子进程始终先打印；您能在不在父进程中调用wait()的情况下实现吗？ 如果不使用wait，则可以使用time.sleep()通过短暂的休眠来实现。执行python q3.py可验证结果。 编写一个调用fork()然后调用某种形式的exec()来运行程序/bin/ls的程序。看看你能否尝试所有的exec()变体，包括（在Linux上）execl()、execle()、execlp()、execv()、execvp()和execvpe(). 为什么你认为同一基本调用有这么多变体？ q4.py尝试了所有的变体。这些变体的存在主要是为了提供不同的参数传递方式和环境设置，以满足不同的编程需求和场景。具体如下： execl()和execlp()： execl()接受一个可变数量的参数，用于指定执行文件的路径以及命令行参数，参数列表以NULL结尾。 execlp()函数接受与execl()相同的参数列表，但它还会在系统的PATH环境变量中搜索可执行文件。 execv()和execvp()： execv()接受两个参数，第一个参数是要执行的文件的路径，第二个参数是一个字符串数组，表示命令行参数，数组的第一个元素通常是执行文件的名称。 execvp()函数与execv()类似，但它会在系统的PATH环境变量中搜索可执行文件。 execle()和execvpe()： execle()函数允许指定新程序的环境变量，它接受一个额外的参数environ，用于传递环境变量数组。 execvpe()函数允许指定新程序的环境变量，并且会在系统的PATH环境变量中搜索可执行文件。 现在编写一个程序，在父进程中使用wait()等待子进程完成。wait()返回什么？如果在子进程中使用wait()会发生什么？ wait()返回的状态信息通常是一个16位的整数，其中高8位存储了子进程的退出状态码，低8位存储了终止信号的编号（如果子进程是由信号终止的话）。如果在子进程中调用wait()函数，由于子进程没有子进程，wait()函数会立即返回-1，并设置 errno 为 ECHILD。实验见q5.py 对之前的程序稍作修改，这次使用 waitpid() 而不是 wait()。 waitpid() 什么时候有用？ 当您想要等待特定子进程完成而不是像 wait() 那样等待任何子进程完成时，waitpid() 非常有用。它允许您指定您有兴趣等待的子进程的 PID。这在父进程生成多个子进程并需要单独处理它们的情况下非常有用。 编写一个程序，创建一个子进程，然后在子进程中关闭标准输出（STDOUT FILENO）。如果子进程在关闭描述符后调用 printf() 来打印一些输出，会发生什么？ 如果我们关闭 stdout 文件描述符，我们将无法使用 printf() 在屏幕上写入内容。但不会发生任何错误。 编写一个程序，创建两个子进程，并使用pipe()系统调用将一个子进程的标准输出连接到另一个子进程的标准输入。 我们使用 pipe() 系统调用创建一个管道，如果不成功则退出。我们通过 fork() 调用创建第一个子进程（我们称之为 A），然后，在为父进程运行的代码部分中，我们进行第二个 fork() 调用来创建第二个子进程（我们称之为 B）。 A 使用 dup2 使 stdout 指向管道的写入端，并向管道的写入端传递一个字符串。B使用dup2使stdin指向管道的读取端，并从管道的读取端读取。这将 A 的标准输出连接到 B 的标准输入。 ","date":"2024-04-25","objectID":"/posts/02.%E8%BF%9B%E7%A8%8Bapi/:0:0","tags":["OS"],"title":"进程API","uri":"/posts/02.%E8%BF%9B%E7%A8%8Bapi/"},{"categories":["系统架构"],"content":"github代码 ","date":"2024-04-25","objectID":"/posts/01.%E8%BF%9B%E7%A8%8B%E4%BB%8B%E7%BB%8D/:0:0","tags":["OS"],"title":"进程介绍","uri":"/posts/01.%E8%BF%9B%E7%A8%8B%E4%BB%8B%E7%BB%8D/"},{"categories":["系统架构"],"content":"1 Program Explanation process-run.py：可以查看进程状态在CPU上运行时如何变化。 进程可以处于以下几种不同的状态： RUNNING：进程正在使用CPU READY：进程现在可以使用CPU但其他进程正在使用 BLOCKED：进程正在等待I/O（例如，它向磁盘发送请求） DONE：进程已经执行完成 要运行该程序获取其选项，可执行以下操作 ./process-run.py -h 或者 python process-run.py -h 得到： Usage: process-run.py [options] Options: -h, --help show this help message and exit -s SEED, --seed=SEED the random seed -l PROCESS_LIST, --processlist=PROCESS_LIST a comma-separated list of processes to run, in the form X1:Y1,X2:Y2,... where X is the number of instructions that process should run, and Y the chances (from 0 to 100) that an instruction will use the CPU or issue an IO -L IO_LENGTH, --iolength=IO_LENGTH how long an IO takes -S PROCESS_SWITCH_BEHAVIOR, --switch=PROCESS_SWITCH_BEHAVIOR when to switch between processes: SWITCH_ON_IO, SWITCH_ON_END -I IO_DONE_BEHAVIOR, --iodone=IO_DONE_BEHAVIOR type of behavior when IO ends: IO_RUN_LATER, IO_RUN_IMMEDIATE -c compute answers for me -p, --printstats print statistics at end; only useful with -c flag (otherwise stats are not printed) 要理解的最重要的选项是 PROCESS_LIST（由 -l 或 –processlist 参数指定），它准确指定每个正在运行的程序（或“进程”）将执行的操作。一个进程由指令组成，每条指令只能执行以下两件事之一： 使用CPU 请求IO（并等待其完成） 当进程使用 CPU（不执行 IO）时，它应该简单地在 CPU 上运行或准备运行之间交替。例如，这是一个简单的运行，仅运行一个程序，并且该程序仅使用 CPU（不执行 IO）。 ❯ python process-run.py -l 5:100 Produce a trace of what would happen when you run these processes: Process 0 cpu cpu cpu cpu cpu Important behaviors: System will switch when the current process is FINISHED or ISSUES AN IO After IOs, the process issuing the IO will run LATER (when it is its turn) 这里，我们指定的进程是“5:100”，这意味着它应该由5条指令组成，并且每条指令是CPU指令的机会是100%。 我们可以使用-c参数来查看进程发生了什么： ❯ python process-run.py -l 5:100 -c Time PID: 0 CPU IOs 1 RUN:cpu 1 2 RUN:cpu 1 3 RUN:cpu 1 4 RUN:cpu 1 5 RUN:cpu 1 这个结果并不是太有趣：该过程在 RUNNING 状态下很简单，然后完成，始终使用 CPU，从而使 CPU 在整个运行过程中保持忙碌，并且不执行任何 I/O。 我们可以运行三个进程看看结果： ❯ python process-run.py -l 5:100,5:100,5:100 -c Time PID: 0 PID: 1 PID: 2 CPU IOs 1 RUN:cpu READY READY 1 2 RUN:cpu READY READY 1 3 RUN:cpu READY READY 1 4 RUN:cpu READY READY 1 5 RUN:cpu READY READY 1 6 DONE RUN:cpu READY 1 7 DONE RUN:cpu READY 1 8 DONE RUN:cpu READY 1 9 DONE RUN:cpu READY 1 10 DONE RUN:cpu READY 1 11 DONE DONE RUN:cpu 1 12 DONE DONE RUN:cpu 1 13 DONE DONE RUN:cpu 1 14 DONE DONE RUN:cpu 1 15 DONE DONE RUN:cpu 1 首先首先“进程 ID”（或“PID”）为 0 的进程运行，而进程 1 和进程2已准备好运行，但只是等待 0 完成。当0完成时，它进入DONE状态，而1则运行，2继续等待。当 1 完成时，则2才开始运行。 我们继续看一个例子，在此示例中，进程仅发出I/O请求。我们使用-L参数指定I/O需要5个时间单位才能完成。 ❯ python process-run.py -l 3:0 -L 5 Produce a trace of what would happen when you run these processes: Process 0 io io_done io io_done io io_done Important behaviors: System will switch when the current process is FINISHED or ISSUES AN IO After IOs, the process issuing the IO will run LATER (when it is its turn) 我们设置跟踪参数看看会是什么样子： ❯ python process-run.py -l 3:0 -L 5 -c Time PID: 0 CPU IOs 1 RUN:io 1 2 BLOCKED 1 3 BLOCKED 1 4 BLOCKED 1 5 BLOCKED 1 6 BLOCKED 1 7* RUN:io_done 1 8 RUN:io 1 9 BLOCKED 1 10 BLOCKED 1 11 BLOCKED 1 12 BLOCKED 1 13 BLOCKED 1 14* RUN:io_done 1 15 RUN:io 1 16 BLOCKED 1 17 BLOCKED 1 18 BLOCKED 1 19 BLOCKED 1 20 BLOCKED 1 21* RUN:io_done 1 ❯ python process-run.py -l 3:0 -L 5 -c Time PID: 0 CPU IOs 1 RUN:io 1 2 BLOCKED 1 3 BLOCKED 1 4 BLOCKED 1 5 BLOCKED 1 6 BLOCKED 1 7* RUN:io_done 1 8 RUN:io 1 9 BLOCKED 1 10 BLOCKED 1 11 BLOCKED 1 12 BLOCKED 1 13 BLOCKED 1 14* RUN:io_done 1 15 RUN:io 1 16 BLOCKED 1 17 BLOCKED 1 18 BLOCKED 1 19 BLOCKED 1 20 BLOCKED 1 21* RUN:io_done 1 如上所示，该程序仅发出三个 I/O。当发出每个 I/O 时，进程将进入 BLOCKED 状态，当设备忙于为 I/O 提供服务时，CPU 处于空闲状态。 为了处理 I/O 的完成，还会发生一项 CPU 操作。请注意，处理 I/O 启动和完成的单个指令并不是特别现实，但这里只是为了简单起见而使用。让我们打印一些统计信息（运行与上面相同的命令，但使用 -p 参数）来查看一些总体行为： Stats: Total Time 21 Stats: CPU Busy 6 (28.57%) Stats: IO Busy 15 (71.43%) 如上所示，跟踪运行需要 21 个时钟周期，但 CPU 忙碌的时间不到 30%。另一方面，I/O 设备却相当忙碌。一般来说，我们希望让所有设备保持忙碌，因为这样可以更好地利用资源。 ","date":"2024-04-25","objectID":"/posts/01.%E8%BF%9B%E7%A8%8B%E4%BB%8B%E7%BB%8D/:1:0","tags":["OS"],"title":"进程介绍","uri":"/posts/01.%E8%BF%9B%E7%A8%8B%E4%BB%8B%E7%BB%8D/"},{"categories":["系统架构"],"content":"2 QA 运行 process-run.py，指定参数：-l 5:100。CPU 利用率应该是多少（例如，CPU 使用时间的百分比）？使用 -c 和 -p 参数来查看你是否正确。 CPU利用率为100%，因为有5条指令，使用CPU的指令机会为100%。 ❯ python process-run.py -l 5:100 -c -p Time PID: 0 CPU IOs 1 RUN:cpu 1 2 RUN:cpu 1 3 RUN:cpu 1 4 RUN:cpu 1 5 RUN:cpu 1 Stats: Total Time 5 Stats: CPU Busy 5 (100.00%) Stats: IO Busy 0 (0.00%) 运行：./process-run.py -l 4:100,1:0。这些参数指定一个具有 4 条指令的进程（全部使用 CPU），以及一个仅发出 I/O 并等待其完成的进程。完成这两个过程需要多长时间？使用 -c 和 -p 来看看你是否正确。 PID为0的进程运行四条指令需要4，PID为1的进程完成IO需要5，但是发出IO指令以及完成IO指令需要CPU，所以为4+5+2=11。 ❯ python process-run.py -l 4:100,1:0 -c -p Time PID: 0 PID: 1 CPU IOs 1 RUN:cpu READY 1 2 RUN:cpu READY 1 3 RUN:cpu READY 1 4 RUN:cpu READY 1 5 DONE RUN:io 1 6 DONE BLOCKED 1 7 DONE BLOCKED 1 8 DONE BLOCKED 1 9 DONE BLOCKED 1 10 DONE BLOCKED 1 11* DONE RUN:io_done 1 Stats: Total Time 11 Stats: CPU Busy 6 (54.55%) Stats: IO Busy 5 (45.45%) 改变进程的顺序： ./process-run.py -l 1:0,4:100。现在会发生什么？切换顺序重要吗？为什么？（像往常一样，使用 -c 和 -p 查看你是否正确） 这样进程0就可以先获得CPU发起IO请求，然后进行I/O。此时CPU空闲，进程1则可以获得CPU。在2中，进程0则需要等到进程1运行完成才可以获得。这节省了时间。 ❯ python process-run.py -l 1:0,4:100 -c -p Time PID: 0 PID: 1 CPU IOs 1 RUN:io READY 1 2 BLOCKED RUN:cpu 1 1 3 BLOCKED RUN:cpu 1 1 4 BLOCKED RUN:cpu 1 1 5 BLOCKED RUN:cpu 1 1 6 BLOCKED DONE 1 7* RUN:io_done DONE 1 Stats: Total Time 7 Stats: CPU Busy 6 (85.71%) Stats: IO Busy 5 (71.43%) 现在我们来看看其他一些参数。其中一个重要的参数是 -S，它决定了当一个进程发出 I/O 时系统的反应。将该标志设置为 SWITCH ON END 时，当一个进程正在进行 I/O 时，系统不会切换到另一个进程，而是等待该进程完全结束。如果运行以下两个进程（-l 1:0,4:100 -c -S SWITCH_ON_END），其中一个正在执行 I/O 操作，另一个正在执行 CPU 操作，会发生什么情况？ 此时进程0会一直占用CPU，直到I/O操作完成。用时也是11。 ❯ python process-run.py -l 1:0,4:100 -c -S SWITCH_ON_END -p Time PID: 0 PID: 1 CPU IOs 1 RUN:io READY 1 2 BLOCKED READY 1 3 BLOCKED READY 1 4 BLOCKED READY 1 5 BLOCKED READY 1 6 BLOCKED READY 1 7* RUN:io_done READY 1 8 DONE RUN:cpu 1 9 DONE RUN:cpu 1 10 DONE RUN:cpu 1 11 DONE RUN:cpu 1 Stats: Total Time 11 Stats: CPU Busy 6 (54.55%) Stats: IO Busy 5 (45.45%) 现在，运行相同的进程，但将切换行为设置为每当一个进程等待 I/O 时就切换到另一个进程（-l 1:0,4:100 -c -S SWITCH_ON_IO）。现在会发生什么？使用 -c 和 -p 来确认是否正确。 此时进程0发起I/O请求后，操作系统就会切换进程，总用时为7 ❯ python process-run.py -l 1:0,4:100 -c -S SWITCH_ON_IO -p Time PID: 0 PID: 1 CPU IOs 1 RUN:io READY 1 2 BLOCKED RUN:cpu 1 1 3 BLOCKED RUN:cpu 1 1 4 BLOCKED RUN:cpu 1 1 5 BLOCKED RUN:cpu 1 1 6 BLOCKED DONE 1 7* RUN:io_done DONE 1 Stats: Total Time 7 Stats: CPU Busy 6 (85.71%) Stats: IO Busy 5 (71.43%) 另一个重要的行为是在 I/O 完成时该做什么。使用 -I IO RUN LATER 选项时，当 I/O 完成时，发出它的进程不一定会立即运行；相反，正在运行的内容将继续运行。当您运行这组进程组合时会发生什么？（运行 python process-run.py -l 3:0,5:100,5:100,5:100 -S SWITCH_ON_IO -I IO_RUN_LATER -c -p）系统资源是否得到有效利用？ 此时系统资源没有得到有效利用。因为CPU处理I/O完成越早，进程就可以继续处理I/O，它可以在不占用CPU的时候进行。 ❯ python process-run.py -l 3:0,5:100,5:100,5:100 -S SWITCH_ON_IO -I IO_RUN_LATER -c -p Time PID: 0 PID: 1 PID: 2 PID: 3 CPU IOs 1 RUN:io READY READY READY 1 2 BLOCKED RUN:cpu READY READY 1 1 3 BLOCKED RUN:cpu READY READY 1 1 4 BLOCKED RUN:cpu READY READY 1 1 5 BLOCKED RUN:cpu READY READY 1 1 6 BLOCKED RUN:cpu READY READY 1 1 7* READY DONE RUN:cpu READY 1 8 READY DONE RUN:cpu READY 1 9 READY DONE RUN:cpu READY 1 10 READY DONE RUN:cpu READY 1 11 READY DONE RUN:cpu READY 1 12 READY DONE DONE RUN:cpu 1 13 READY DONE DONE RUN:cpu 1 14 READY DONE DONE RUN:cpu 1 15 READY DONE DONE RUN:cpu 1 16 READY DONE DONE RUN:cpu 1 17 RUN:io_done DONE DONE DONE 1 18 RUN:io DONE DONE DONE 1 19 BLOCKED DONE DONE DONE 1 20 BLOCKED DONE DONE DONE 1 21 BLOCKED DONE DONE DONE 1 22 BLOCKED DONE DONE DONE 1 23 BLOCKED DONE DONE DONE 1 24* RUN:io_done DONE DONE DONE 1 25 RUN:io DONE DONE DONE 1 26 BLOCKED DONE DONE DONE 1 27 BLOCKED DONE DONE DONE 1 28 BLOCKED DONE DONE DONE 1 29 BLOCKED DONE DONE DONE 1 30 BLOCKED DONE DONE DONE 1 31* RUN:io_done DONE DONE DONE 1 Stats: Total Time 31 Stats: CPU Busy 21 (67.74%) Stats: IO Busy 15 (48.39%) 现在运行相同的进程，但使用 -I IO_RUN_IMMEDIATE 设置，该设置会立即运行发出 I/O 的进程。这种行为有何不同？为什么再次运行刚完成 I/O 的进程可能是个好主意？ 这种行为会让进程处理I/O请求的时候还给其他CPU，但完成后立即获得CPU，能让I/O处理和CPU处理一起进行，节省总时间，有效提高CPU利用率。 ❯ python process-run.py -l 3:0,5:100,5:100,5:100 -S SWITCH_ON_IO -I IO_RUN_IMMEDIATE -c -p Time PID: 0","date":"2024-04-25","objectID":"/posts/01.%E8%BF%9B%E7%A8%8B%E4%BB%8B%E7%BB%8D/:2:0","tags":["OS"],"title":"进程介绍","uri":"/posts/01.%E8%BF%9B%E7%A8%8B%E4%BB%8B%E7%BB%8D/"},{"categories":["技术基础"],"content":"出处 如何使用C语言生成随机数？例如希望生成一段特定范围的随机数，如$[1,6]$来模拟掷骰子。 到目前为止，所有答案在数学上都是错误的。返回 rand() % N 并不统一给出 [0, N) 范围内的数字，除非 N 除以 rand() 返回的区间长度（即是 2 的幂）。此外，我们不知道 rand() 的模数是否独立：它们有可能是 0, 1, 2, ... ，这是均匀的但不是很随机。唯一似乎合理的假设是 rand() 给出泊松分布：任何两个相同大小的非重叠子区间均可能且独立。对于一组有限的值，这意味着均匀分布，并且还确保 rand() 的值很好地分散。 这意味着更改 rand() 范围的唯一正确方法是将其分为多个框；例如，如果 RAND_MAX == 11 并且您想要 1..6 的范围，则应将 {0,1} 分配给 1，将 {2,3} 分配给 2，依此类推在。这些是不相交的、大小相等的区间，因此是均匀且独立分布的。 使用浮点除法的建议在数学上是合理的，但原则上存在舍入问题。也许 double 的精度足以使其工作；也许不是。我不知道，也不想弄清楚；无论如何，答案取决于系统。 正确的方法是使用整数运算。也就是说，您想要如下所示的内容： #include \u003cstdlib.h\u003e // For random(), RAND_MAX // Assumes 0 \u003c= max \u003c= RAND_MAX // Returns in the closed interval [0, max] long random_at_most(long max) { unsigned long // max \u003c= RAND_MAX \u003c ULONG_MAX, so this is okay. num_bins = (unsigned long) max + 1, num_rand = (unsigned long) RAND_MAX + 1, bin_size = num_rand / num_bins, defect = num_rand % num_bins; long x; do { x = random(); } // This is carefully written not to overflow while (num_rand - defect \u003c= (unsigned long)x); // Truncated division is intentional return x/bin_size; } 为了获得完全均匀的分布，循环是必要的。例如，如果给你 0 到 2 之间的随机数，而你只想要 0 到 1 之间的数字，你就继续拉，直到没有 2 为止；不难检查这是否以相同的概率给出 0 或 1。 这里使用 random() 而不是 rand() 因为它具有更好的分布（如 rand() 的手册页所述）。 如果你想获得默认范围 [0, RAND_MAX] 之外的随机值，那么你必须做一些棘手的事情。也许最方便的方法是定义一个函数 random_extended() 提取 n 位（使用 random_at_most() ）并返回 [0, 2**n) ，然后应用 random_at_most() 用 random_extended() 代替 random() （并用 2**n - 1 代替 RAND_MAX ）来提取随机值小于 2**n ，假设您有一个可以保存这样的值的数字类型。最后，当然，您可以使用 min + random_at_most(max - min) 获取 [min, max] 中的值，包括负值。 这段代码通过以下方式确保生成的随机数在闭区间 [0, max] 内均匀分布： 确定随机数的范围和数量： num_bins 表示生成的随机数的数量，即 max 的值加一，因为随机数生成器的范围是左闭右开的。 num_rand 表示随机数生成器的最大值加一，表示总的可能的随机数的数量。 计算每个区间的大小： bin_size 表示每个区间的大小，即将随机数的总数量除以可能的随机数的数量，以确保每个随机数的概率相等。 处理不能均匀分配的情况： defect 表示随机数总数量除以可能的随机数数量的余数，用于处理不能均匀分配的情况。 生成随机数并检查范围： 使用 do-while 循环来生成随机数，并检查生成的随机数是否在指定的范围内，如果不在范围内则重新生成，直到生成的随机数在指定范围内。 返回均匀分布的随机数： 将生成的随机数除以区间大小得到的结果，即在闭区间 [0, max] 内均匀分布的随机数。 通过以上步骤，代码确保了生成的随机数在指定范围内且分布均匀。 ","date":"2024-03-27","objectID":"/posts/02.c%E8%AF%AD%E8%A8%80%E5%A6%82%E4%BD%95%E4%BB%8E%E4%B8%80%E5%AE%9A%E8%8C%83%E5%9B%B4%E5%86%85%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B4%E6%95%B0/:0:0","tags":["C++","随机数"],"title":"如何使用C语言从一定范围内生成随机整数？","uri":"/posts/02.c%E8%AF%AD%E8%A8%80%E5%A6%82%E4%BD%95%E4%BB%8E%E4%B8%80%E5%AE%9A%E8%8C%83%E5%9B%B4%E5%86%85%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B4%E6%95%B0/"},{"categories":["资源收藏"],"content":"清华大学Pypi镜像站 Docker镜像代理 Github镜像代理 ","date":"2024-03-20","objectID":"/posts/02.%E9%95%9C%E5%83%8F/:0:0","tags":["镜像"],"title":"镜像网站","uri":"/posts/02.%E9%95%9C%E5%83%8F/"},{"categories":["资源收藏"],"content":"1 MacOS Mac命令行命令 这个网站收集各种有用的 Mac 命令行的命令。 ","date":"2024-03-19","objectID":"/posts/01.%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/:1:0","tags":["工具"],"title":"实用工具汇总","uri":"/posts/01.%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/"},{"categories":["资源收藏"],"content":"2 Linux ","date":"2024-03-19","objectID":"/posts/01.%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/:2:0","tags":["工具"],"title":"实用工具汇总","uri":"/posts/01.%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/"},{"categories":["系统架构"],"content":"1 基本介绍 #include \u003cunistd.h\u003e int execve(const char *pathname, char *const argv[], char *const envp[]); 描述 execve()执行由pathname引用的程序。这会导致当前由调用进程运行的程序被一个新程序替换，该新程序具有新初始化的堆栈、堆和（已初始化和未初始化）数据段。 pathname必须是二进制可执行文件或以形式为#!interpreter [optional-arg]开头的脚本。 argv是传递给新程序作为其命令行参数的字符串指针数组。按照惯例，这些字符串中第一个（即argv[0]）应包含与正在执行文件相关联的文件名。argv数组必须以NULL指针结尾。（因此，在新程序中，argv[argc]将为NULL）。 envp是传递给新程序环境变量的字符串指针数组。该数组包含了环境变量。每个环境变量都是一个 char* 指针，格式为 “name=value”。envp数组同样必须以NULL指针结尾。 char *envp[] = { \"PATH=/bin\", \"HOME=/home/user\", \"USER=user\", NULL // 终止环境变量数组 }; argv和envp可以从新程序的主函数访问。例如我们编写的C程序，实际上是由操作系统通过execve()系统调用执行（这里是操作系统先执行fork系统调用，创建一个新的子进程，然后在新的子进程中，操作系统执行execve()系统调用），它会传递这些参数给新程序的主函数，即 main 函数。这些参数定义了新程序执行时的环境和命令行参数，在程序启动时由操作系统设置，并在整个程序执行期间保持不变。这使得程序能够根据传递给它的参数和环境变量来执行不同的任务或调整其行为。 返回值 成功时，execve() 不返回任何值，当 execve 成功替换当前进程的映像并开始执行新的程序时，原来的进程（即调用 execve 的进程）已经不再存在，因此无法返回任何值。 在出错时返回 -1，并设置适当的 errno。 重点 execve实际上就是将当前运行的状态机重置成另一个程序的初始状态 允许对新状态机设置参数 argv (v) 和环境变量 envp (e) 在程序启动时，操作系统首先执行 fork 系统调用，创建一个新的子进程。然后，操作系统在子进程中执行 execve 系统调用，以替换子进程的程序映像并开始执行新的程序。原来的父进程继续执行 fork 之后的代码。 在调用 execve 之前，确保释放所有不再需要的资源，如打开的文件描述符、锁等。 在调用 execve 之前，确保子进程已经处理了所有待处理的信号，除非你希望信号处理程序在新程序中执行。 如果 execve 失败，子进程通常应该终止。 在父进程中，通常会在 fork 之后立即调用 wait 或 waitpid 来等待子进程结束，以确保父进程不会过早退出，从而导致子进程的僵尸进程。 ","date":"2024-03-13","objectID":"/posts/05.linux-execve%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/:1:0","tags":["Linux"],"title":"Linux execve函数详解","uri":"/posts/05.linux-execve%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"2 execve实例 ","date":"2024-03-13","objectID":"/posts/05.linux-execve%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/:2:0","tags":["Linux"],"title":"Linux execve函数详解","uri":"/posts/05.linux-execve%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"2.1 自定义argv和envp #include \u003cunistd.h\u003e #include \u003cstdio.h\u003e int main() { char * const argv[] = { \"/bin/bash\", \"-c\", \"env\", NULL, }; char * const envp[] = { \"HELLO=WORLD\", NULL, }; execve(argv[0], argv, envp); printf(\"Hello, World!\\n\"); return 0; } 在这段代码中，我们显式的设置了argv和envp，其中参数 \"/bin/bash\", \"-c\", \"env\", NULL，这里的参数实际上是在告诉 bash 执行一个命令（由 -c 后面的字符串指定），在这个例子中是 env，它打印当前的环境变量。 我们运行代码，得到如下输出： 如果我们不传 -c 参数和随后的命令，即只传入 \"/bin/bash\", NULL 作为参数，bash 会默认进入交互式模式。在这种模式下，它不会执行任何命令并立即退出，而是会等待用户输入，表现为进入了 shell 环境。 我们发现，打印的当前环境变量除了自定的envp，还有一些其他的输出。这是因为除了我们设定的环境变量外，还有一些系统或者 shell 默认的环境变量会被添加到新进程中，例如 PWD 表示当前工作目录，SHLVL 表示 shell 层级，_ 是上一个执行的命令。这就是为什么我们会看到额外的环境变量出现在输出中。 ","date":"2024-03-13","objectID":"/posts/05.linux-execve%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/:2:1","tags":["Linux"],"title":"Linux execve函数详解","uri":"/posts/05.linux-execve%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"2.2 fork后再通过子进程执行execve #include \u003cstdio.h\u003e #include \u003csys/types.h\u003e #include \u003csys/wait.h\u003e int main() { pid_t pid = fork(); if (pid == 0) { // 子进程 char * const argv[] = {\"/bin/echo\", \"Hello, World!\", NULL}; char * const envp[] = {NULL}; execve(\"/bin/echo\", argv, envp); } else if (pid \u003e 0) { // 父进程 wait(NULL); // 等待子进程结束 printf(\"Child process finished.\\n\"); } else { // fork失败 perror(\"fork\"); return 1; } return 0; } 这段代码演示了如何使用 fork() 系统调用创建一个新的子进程，然后在子进程中执行 execve() 系统调用。这是在 Unix-like 系统中常见的操作模式，因为 execve() 系统调用有一些关键的限制： 一次机会：execve() 系统调用只能用于替换当前进程的映像一次。如果一个进程已经调用了 execve()，它就不能再调用 fork() 或再次执行 execve()。 无返回值：execve() 成功执行时，原来的进程映像被新程序映像替换，原来的进程不再存在，因此无法返回任何值。如果在 execve() 执行之前有任何返回值，那么这个返回值是在 fork() 调用之后，由父进程获得的。 因此，在实际应用中，我们通常会先使用 fork() 创建一个子进程，然后在子进程中调用 execve() 执行新的程序。父进程在 fork() 之后会继续执行，并通过调用 wait(NULL) 来等待子进程结束。这样，父进程可以知道子进程已经成功执行了 execve()，并且可以继续执行其他任务或退出。 在多线程程序中，如果一个线程执行了 fork() 并尝试在子进程中执行 execve()，那么其他线程将继续执行，不受 fork() 和 execve() 的影响。只有调用 fork() 的线程会进入子进程，而其他线程则继续在父进程中运行。 得到的运行结果： ","date":"2024-03-13","objectID":"/posts/05.linux-execve%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/:2:2","tags":["Linux"],"title":"Linux execve函数详解","uri":"/posts/05.linux-execve%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"1 fork ","date":"2024-03-12","objectID":"/posts/04.linux_fork%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/:1:0","tags":["Linux"],"title":"Linux 系统调用函数fork、vfork、clone详解","uri":"/posts/04.linux_fork%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"1.1 基本介绍 #include \u003csys/types.h\u003e #include \u003cunistd.h\u003e pid_t fork(void) 描述 fork用于创建一个子进程，它与父进程的唯一区别在于其PID和PPID，以及资源利用设置为0。文件锁和挂起信号（指已经被内核发送给一个进程，但尚未被该进程处理的信号）不会被继承，其他和父进程几乎完全相同：会获得父进程的内存空间、栈、数据段、堆、打开的文件描述符、信号处理函数、进程优先级、环境变量等资源的副本。 返回值 成功时，在父进程中返回子进程的 PID，在子进程中返回 $0$。失败时，父进程返回 $-1$，不创建子进程，并适当设置 errno。 其中errno是一个全局变量，它用于表示最近一次系统调用或库函数调用产生的错误代码。当系统调用或库函数失败时，它们通常会设置 errno 以指示错误的原因。 以下是一些常见的 errno 错误代码及其含义： EAGAIN：资源暂时不可用，通常是因为达到了系统限制，如文件描述符或内存限制。 ENOMEM：内存不足，无法分配请求的资源。 EACCES：权限不足，无法访问某个资源。 EINTR：系统调用被信号中断。 EINVAL：无效的参数。 重点 fork() 函数创建的子进程会从父进程复制执行顺序。具体来说，子进程会从父进程复制当前的执行上下文，包括指令指针（instruction pointer）和寄存器的状态。这意味着子进程将从 fork() 系统调用之后的指令开始执行，与父进程在 fork() 之后应该执行的指令完全相同。因此，fork() 之后通常会有一个基于返回值的分支结构，以区分父进程和子进程的执行路径。 ","date":"2024-03-12","objectID":"/posts/04.linux_fork%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/:1:1","tags":["Linux"],"title":"Linux 系统调用函数fork、vfork、clone详解","uri":"/posts/04.linux_fork%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"1.2 fork实例 1.2.1 1.2.1多个fork返回值 #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e int main() { pid_t pid1 = fork(); pid_t pid2 = fork(); pid_t pid3 = fork(); pid_t pid = getpid(); printf(\"The PID of the current process is %d\\n Hello World from (%d, %d, %d)\\n\", pid, pid1, pid2, pid3); return 0; } 这段程序包含了三个 fork() 调用，每个 fork() 都会创建一个新的子进程。由于每次 fork() 调用都会导致进程数翻倍，所以总共会有$2^3=8$个进程 （包括最初的父进程）。每个进程都会打印出它的进程 ID (pid) 以及三个 fork() 调用的返回值 (pid1, pid2, pid3)。 得到的输出结果如下： 我们画个状态机来理解它们的输出，假设最初的父进程PID为291871： 1.2.2 C语言 fork与输出 #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003csys/wait.h\u003e int main(int argc, char *argv[]) { int n = 2; for (int i = 0; i \u003c n; i++) { fork(); printf(\"Hello\\n\"); } for (int i = 0; i \u003c n; i++) { wait(NULL); } } 这段代码中，按我们的理解，第一次fork后有2个进程，然后一起执行printf输出，得到两个Hello，然后第二次fork后有4个进程，然后执行printf，得到四个Hello，则会有6个``Hello`，如下： 但是当我们将输出通过管道传给cat等命令时，会看到8个Hello： 这是因为标准输出一般是行缓冲的，碰到\\n，缓冲区中的内容会被刷新，即输出到终端或文件中。这种缓冲方式的目的是为了提高效率，因为这样可以减少对磁盘 I/O 的调用次数。 如果标准输出被重定向到管道，它可能不再是行缓冲的，而是变为全缓冲的。这意味着缓冲区可能会在填满时刷新，而不是在每次遇到换行符时刷新。如果缓冲区足够大，以至于可以容纳所有的 Hello 输出，那么fork的时候子进程也会复制缓冲区，导致最后每个进程中的缓冲区都有2个Hello，最后输出为8个。 如果为了确保缓冲区在需要的时候被刷新，可以在 printf 调用之后显式地调用 fflush(stdout) 来刷新标准输出缓冲区。这样可以确保所有的输出都被立即写入，而不会受到缓冲行为的影响。 #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003csys/wait.h\u003e int main(int argc, char *argv[]) { int n = 2; for (int i = 0; i \u003c n; i++) { fork(); printf(\"Hello\\n\"); fflush(stdout); } for (int i = 0; i \u003c n; i++) { wait(NULL); } return 0; } 1.2.3 fork 💣 #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003csys/wait.h\u003e int main(int argc, char *argv[]) { while(1) { fork(); } return 0; } 这段代码会无限循环地调用 fork() 函数，每次循环都会创建一个新进程。由于每次 fork() 调用都会成功创建一个新进程，而且这个新进程又会立即进入下一次循环并再次调用 fork()，因此进程的数量会以指数速度增长，很快就会耗尽系统的可用资源。 绝对不要在任何生产环境或您没有权限的任何系统上运行fork炸弹。 ","date":"2024-03-12","objectID":"/posts/04.linux_fork%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/:1:2","tags":["Linux"],"title":"Linux 系统调用函数fork、vfork、clone详解","uri":"/posts/04.linux_fork%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"2 vfork ","date":"2024-03-12","objectID":"/posts/04.linux_fork%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/:2:0","tags":["Linux"],"title":"Linux 系统调用函数fork、vfork、clone详解","uri":"/posts/04.linux_fork%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"2.1 基本介绍 描述 #include \u003csys/types.h\u003e #include \u003cunistd.h\u003e pid_t vfork(void); vfork() 系统调用用于创建一个子进程，与 fork() 类似，但它使用父进程的地址空间，而不是复制父进程的地址空间。vfork() 调用后，父进程会阻塞，直到子进程调用 exec 函数或执行了 exit 函数。这是因为子进程需要独占父进程的地址空间，以确保数据一致性。一。在子进程调用 exec 函数或执行了 exit 函数之后，子进程将获得自己的内存空间。 返回值 和fork一致 重点 vfork() 创建的子进程会继承父进程的环境，但不会继承父进程的堆栈。 在子进程执行这些exec或exit操作之前，父进程和子进程可能会访问相同的内存地址，这可能导致数据竞争和不一致。 在 vfork() 调用成功后，子进程应该立即调用 exec 函数或执行 exit 函数。如果在子进程中修改除了用于存储从 vfork() 返回值的 pid_t 类型变量之外的任何数据，或者从调用 vfork() 的函数返回，或在成功调用 _exit() 或 exec() 函数族中的一个函数之前调用其他任何函数，则行为是未定义的。这可能会导致程序崩溃或表现出不可预测的行为。 因此，使用 vfork() 时，必须确保子进程在调用 exec 函数或执行 exit 函数之前不执行任何可能影响共享内存的操作。 vfork() 系统调用会阻塞父进程，直到子进程完成 exec 调用或 exit 调用。父进程不需要显式调用 wait() 或 waitpid() 来等待子进程结束。 ","date":"2024-03-12","objectID":"/posts/04.linux_fork%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/:2:1","tags":["Linux"],"title":"Linux 系统调用函数fork、vfork、clone详解","uri":"/posts/04.linux_fork%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"2.2 验证vfork共享内存 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e #include \u003csys/wait.h\u003e #include \u003cstring.h\u003e #include \u003cassert.h\u003e int main() { // 在父进程中分配内存并初始化 char *buffer = malloc(1024); assert(buffer != NULL); memset(buffer, 'A', 1024); // 使用vfork创建子进程 pid_t pid = vfork(); if (pid \u003c 0) { perror(\"vfork error\"); exit(EXIT_FAILURE); } else if (pid == 0) { // 子进程 printf(\"Child process: PID = %d\\n\", getpid()); // 修改内容 memset(buffer, 'B', 1024); // 子进程 char * const argv[] = {\"/bin/echo\", \"Hello, Linux!\", NULL}; char * const envp[] = {NULL}; // 执行exec函数 execve(argv[0], argv, envp); } else { // 父进程 printf(\"Parent process: PID = %d, child's PID = %d\\n\", getpid(), pid); // 验证内存内容是否被子进程修改 for (int i = 0; i \u003c 1024; i++) { if (buffer[i] != 'B') { printf(\"Memory corruption detected at index %d\\n\", i); exit(EXIT_FAILURE); } } printf(\"Memory is consistent\\n\"); } return 0; } 这个程序的目的是验证在 vfork() 之后，子进程和父进程是否共享内存。首先在父进程中分配一块内存 ，并将其初始化为字符 ‘A’。然后，父进程调用 vfork() 创建一个子进程。在子进程中，程序试图将内容修改为字符 ‘B’，并执行 execve()。在父进程中，程序检查缓冲区的内容是否被修改为字符 ‘B’，以验证内存是否被正确共享。 程序运行结果如下： ","date":"2024-03-12","objectID":"/posts/04.linux_fork%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/:2:2","tags":["Linux"],"title":"Linux 系统调用函数fork、vfork、clone详解","uri":"/posts/04.linux_fork%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"3 clone ","date":"2024-03-12","objectID":"/posts/04.linux_fork%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/:3:0","tags":["Linux"],"title":"Linux 系统调用函数fork、vfork、clone详解","uri":"/posts/04.linux_fork%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"3.1 基本介绍 描述 #define _GNU_SOURCE #include \u003csched.h\u003e int clone(int (*fn)(void *), void *child_stack, int flags, void *arg, ... /* pid_t *parent_tid, void *tls, pid_t *child_tid */ ); clone与fork类似，是用于创建新进程的系统调用，但clone提供了更精确的控制，可以确定在调用进程（父进程）和子进程之间共享哪些执行上下文的部分。例如，调用者可以控制两个进程是否共享虚拟地址空间、文件描述符表和信号处理程序表。这些系统调用还允许将新的子进程放置在单独的命名空间中。 参数 fn是指向新进程要执行的函数的指针，这个函数接受一个 void* 参数，并返回一个 int 类型的值，这个返回值将被 clone 系统调用捕获，并作为子进程的退出状态； child_stack是新进程的堆栈地址，由于子进程和调用进程可能共享内存，因此子进程不可能与调用进程在同一堆栈中执行。调用进程必须为子堆栈设置内存空间，并将指向该空间的指针传递给clone()。 flags可以设置新进程的属性（通过二进制位设置），包括是否与原进程共享地址空间（CLONE_VM）、是否共享文件描述符表（CLONE_FILES）、是否共享信号处理器（CLONE_SIGHAND）等等； int flags = CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND | CLONE_THREAD | CLONE_SYSVSEM | CLONE_SETTLS; 标志 含义 CLONE_PARENT 创建的子进程的父进程是调用者的父进程，新进程与创建它的进程成了“兄弟”而不是“父子” CLONE_FS 子进程与父进程共享相同的文件系统，包括root、当前目录、umask CLONE_FILES 子进程与父进程共享相同的文件描述符（file descriptor）表 CLONE_NEWNS 在新的namespace启动子进程，namespace描述了进程的文件hierarchy CLONE_SIGHAND 子进程与父进程共享相同的信号处理（signal handler）表 CLONE_PTRACE 若父进程被trace，子进程也被trace CLONE_VFORK 父进程被挂起，直至子进程释放虚拟内存资源 CLONE_VM 子进程与父进程运行于相同的内存空间 CLONE_PID 子进程在创建时PID与父进程一致 CLONE_THREAD Linux 2.4中增加以支持POSIX线程标准，子进程与父进程共享相同的线程群 arg是传递给新进程的参数； 可选参数，包括 pid_t *parent_tid等。 返回值 成功时，在父进程中返回子进程的 PID。失败时，父进程返回 $-1$，不创建子进程，并适当设置 errno。 重点 clone 可以创建新的进程或线程，Linux创建线程使用的系统调用就是clone。而 fork 和vfork只能创建进程。这意味着 clone 可以在单个进程中创建多个线程，而 fork 则总是创建一个新的进程。 clone 提供比 fork 和 vfork 更多的选项，可以指定子进程或线程的堆栈、信号处理、权限等。 clone 的使用比 fork 和 vfork 更复杂，需要正确设置 flags、child_stack、parent_pidptr、ptr、stack_size 和 tls 等参数。 ","date":"2024-03-12","objectID":"/posts/04.linux_fork%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/:3:1","tags":["Linux"],"title":"Linux 系统调用函数fork、vfork、clone详解","uri":"/posts/04.linux_fork%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"3.2 clone使用 #define _GNU_SOURCE #include \u003csched.h\u003e #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cstring.h\u003e #include \u003csys/wait.h\u003e #include \u003cunistd.h\u003e #define STACK_SIZE (1024 * 1024) /* Stack size for cloned child */ // 宏，简化错误处理 #define ERREXIT(msg) { perror(msg); exit(EXIT_FAILURE); } // 安全分配内存函数，分配失败报告错误 #define CHECKALLOC(ptr, msg) ({ void *p = ptr; if (p == NULL) {ERREXIT(msg);} p;}) /* * 子进程函数 * params: 接受一个void *类型参数，但是没有被使用过，后面的声明是用于告诉编译器这个参数是未被使用的 */ static int childFunc(void *arg __attribute__((unused))) { puts(\"child: start\"); sleep(2); puts(\"child: terminate\"); return 0; /* Child terminates now */ } int main(int argc, char *argv[]) { /* Start of stack buffer */ char **stacks; /* Child process's pids */ pid_t *pids; size_t nproc, i; // 接受两个参数 if (argc != 2) { puts(\"Wrong way to execute the program:\\n\" \"\\t\\t./waitpid nProcesses\\n\" \"example:\\t./waitpid 2\"); return EXIT_FAILURE; } // 初始化nproc，表示要创建的子进程数 nproc = atol(argv[1]); /* Process count */ // 分配内存空间 stacks = CHECKALLOC(malloc(nproc * sizeof(void *)), \"malloc\"); pids = CHECKALLOC(malloc(nproc * sizeof(pid_t)), \"malloc\"); for (i = 0; i \u003c nproc; i++) { char *stackTop; /* End of stack buffer */ stacks[i] = CHECKALLOC(malloc(STACK_SIZE), \"stack malloc\"); // 得到栈顶位置 stackTop = stacks[i] + STACK_SIZE; /* * 创建子进程 * 第一个标志表示在子进程清除线程组ID（TID），目的是为了避免子进程与父进程或其他子进程的线程组ID冲突 * 第二个表示告诉在子进程中设置线程ID，目的是为了允许父进程在子进程中追踪线程 * 告诉 clone 系统调用在子进程中重新安装信号处理程序，目的是为了允许子进程捕获和处理信号，而不是传递给父进程。 */ pids[i] = clone(childFunc, stackTop, CLONE_CHILD_CLEARTID | CLONE_CHILD_SETTID | SIGCHLD, NULL); if (pids[i] == -1) ERREXIT(\"clone\"); printf(\"clone() returned %ld\\n\", (long)pids[i]); } sleep(1); // 等待所有子进程 for (i = 0; i \u003c nproc; i++) { // 第一个参数为子进程id，第二个参数表示不关心子进程的退出状态，第三个参数表示等待任何子进程 if (waitpid(pids[i], NULL, 0) == -1) ERREXIT(\"waitpid\"); printf(\"child %ld has terminated\\n\", (long)pids[i]); } // 回收内存空间 for (i = 0; i \u003c nproc; i++) free(stacks[i]); free(stacks); free(pids); return EXIT_SUCCESS; } 运行：gcc clone-example.c \u0026\u0026 ./a.out 5，其中5为nproc，表示要创建的进程数。 运行结果如下： ","date":"2024-03-12","objectID":"/posts/04.linux_fork%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/:3:2","tags":["Linux"],"title":"Linux 系统调用函数fork、vfork、clone详解","uri":"/posts/04.linux_fork%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/"},{"categories":["资源收藏"],"content":" Go 语言优秀资源整理，为项目落地加速🏃 转载分享，出处如下，谢谢 😆 原文地址: https://shockerli.net/post/go-awesome GitHub: https://github.com/shockerli/go-awesome 官网: https://golang.org 国内官网镜像(访问快): https://golang.google.cn GitHub: https://github.com/golang/go 开发者平台: https://go.dev Wiki: https://github.com/golang/go/wiki 官方博客: https://blog.golang.org ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:0:0","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"1 指导原则 简单性 复杂性把可读的程序变得不可读，复杂性终结了很多软件项目。 可读性 代码是给人看的，代码阅读时长远超编写。程序必须可维护，那可读是第一步。 生产率 拥有众多的工具集和基础库，可以很简单方便的完成绝大多数工作。 编译速度足够快，拥有动态语言的高效，但却不会面临动态语言不可靠的问题。 自带编程规范，使得团队代码一致，也帮助开发者发现和避免潜在的错误。 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:1:0","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"2 Awesome GitHub Topic for Go Awesome Go golang-open-source-projects - 含描述的中文版 Awesome Go Awesome Go Storage - Go 存储相关开源项目 awesome-go-China - 专门收集华人写的开源项目 Go Patterns - Go 版本的设计模式 sevenelevenlee/go-patterns - 设计模式 GoF 设计模式 greyireland/algorithm-pattern - 算法模板 go-algorithms - Go 版本的数据结构和算法 Go 学习之路 - Go 学习资料汇集 Go 开发者路线图 ReposHub-Go VisuAlgo - 数据结构和算法动态可视化 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:2:0","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"3 大牛/组织 Go 语言方面的大牛，或者优秀 Go 项目的组织 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:3:0","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"3.1 大牛 mattn - 写了数百个 Go 项目，盛产优质项目 Unknwon - gogs/macaron 等项目作者，《The Way to Go》译者 Jinzhu - gorm/QOR 等作者 valyala - fasthttp/fastjson 等作者 vmihailenco - go-redis/go-pg 等作者 kataras - iris 作者 bep spf13 tidwall ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:3:1","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"3.2 组织 Gorilla web toolkit loov HashiCorp lestrrat-go Uber - Open Source Software at Uber Stretchr - Tame your unstructured data Containous Charm - 提供一系列优秀的命令行工具和库 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:3:2","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"4 文档 Proposing Changes to Go - Go 语言设计文档 Go 语言设计与实现 Go 语言原本 Go 101 （中文版） Go 官方入门指南 Go 语言高级编程 Go 专家编程 Go 编程语言 Golang 标准库文档(官方/中文) Go 语言标准库 在线阅读 《The Way to Go》中文版 Go 语言圣经（中文版） Go语言入门教程 Go 实战开发 Go Web 应用开发 Go 学习技能树 实效 Go 编程 Go 语言语法详解笔记 Go 语言学习资料与社区索引 Go database/sql tutorial GO 命令教程 深入解析 Go Go 语言博客实践 学习 Go 语言 Go2编程指南 Go database/sql tutorial - Go 数据库(database/sql)开发使用教程 Go Web Examples - Go Web 开发示例 Go Assembly - 通过示例介绍 Go 汇编功能 Ultimate Go - 终极 Go 学习指南，包含大量文档化的代码和程序分析 Go 教程 - 腾讯云开发者手册 Golang 开发笔记 golang-notes - Go 源码阅读笔记 The Little Go Book （中文版） Learning Go — from zero to hero go-internals - 深入理解 Go Learn Go with Tests Go基础教程 7天用Go从零实现系列 Go 语言高性能编程 Golang - 100天从新手到大师 - 某培训机构的部分教程内容 hoanhan101/algo - 107+ 编码面试问题，包括详细的解决方案，测试用例和程序分析 over-golang - Go 学习笔记 over-algorithm - Go 算法笔记 learngo - 1000+ Go 示例、练习和测试 go-leetcode - LeetCode 实现 玩转 GO - 《Mastering GO》中文译本 leetcode-cookbook - LeetCode in Go Golang修养之路 Go语法树入门 Go Concurrency Patterns - Go 并发模式场景集合 yezihack/algo - 数据结构与算法 golang-cheat-sheet-cn - GitHub上最流行的Golang代码速查表中文翻译版本 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:4:0","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"5 指南 Uber Go Style Guide The Go Programming Language Specification （中文老版） 实效 Go 编程 Go Code Review Comments Go Code Convention Go FAQ 101 Go Details 101 Go Tips 101 Go Quizzes 101 go-advices go-perfbook - 编写和优化Go代码 Practical Go: Real world advice for writing maintainable Go programs （Go 语言实践：编写可维护的程序的建议） Go 安全指南 - 腾讯发布的《代码安全指南》Go 语言篇 Go Concurrency Guide Go Recipes - 一些技巧 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:5:0","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"6 文章 Go Training - 大量优质 Go 相关文章、视频等资料 Go语言爱好者周刊 Go 夜读 - Go 标准包、开源项目源代码阅读讲解 Go-Questions - Go 语言学习入门和进阶知识 Go的50度灰：Golang新开发者要注意的陷阱和常见错误 Go 程序的性能优化及 pprof 的使用 gops - Go语言程序查看和诊断工具 Go源码分析——http.ListenAndServe()是如何工作的 GoConvey 框架使用指南 GoStub 框架使用指南 GoMock 框架使用指南 Monkey 框架使用指南 The Evolution of a Go Programmer - Go 程序员的进化之路 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:6:0","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"7 付费教程 基于 Go 语言构建企业级的 RESTful API 服务 - 掘金小册 Go语言核心36讲 - 极客时间 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:7:0","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"8 成品项目 Shiori - 书签管理 studygolang - Go 语言中文网 mkcert - 生成本地 HTTPS 加密证书的工具 cfssl - Cloudflare 开源的 PKI 和 TLS 工具集 Rainbond - 基于Docker、Kubernetes等容器技术的开源PaaS NYADB2 - Go 实现的关系型数据库, 值得用于学习 EiBlog - 博客 pan-light - 不限速的百度网盘客户端, 基于 Go + Qt5 开发 BaiduPCS-Go - 百度网盘客户端（命令行） daily-warm - 每天定时发邮件给你关心的人 pipe - 博客平台 mdr - 命令行下的 Markdown 阅读工具 miniflux - Feed 阅读器 golinks - 创建自定义书签、命令、搜索等 链滴笔记 - 桌面端笔记应用 wayback - 网页快照备份 bbs-go - 开源社区 OpenSCRM - 基于Go和React的企业微信私域流量管理系统 Answer - 问答社区 listmonk - 资讯、邮件列表管理工具（Web） 1Panel - Linux 服务器运维管理面板 Artalk - 自托管评论系统 memos - 笔记服务，具有移动客户端、浏览器扩展等生态 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:8:0","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"8.1 静态网站生成器 Hugo jrnl plenti verless ink moul - 生成照片站点 zas ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:8:1","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"9 学习项目 1m-go-websockets - 该项目演示了如何用 Go 编写一个可以提供超过一百万个 websockets 连接、运行内存小于 1GB 的服务器 Go by Example - 通过实例学习 Go IAM - 身份识别与访问管理系统（教学项目） 100-go-mistakes - 100 个 Go 常见错误 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:9:0","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10 开源类库 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:0","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.1 Web 框架 Macaron - 一款具有高生产力和模块化设计的 Go Web 框架 国产 Beego - 一个使用 Go 的思维来帮助您构建并开发 Go 应用程序的开源框架 国产 Gin - 轻量 Web 框架 Iris - Web 开发框架 Revel echo Faygo - 国产 Teleport - Socket 框架 GoFrame - 国产 QOR - 系列应用开发组件包 DotWeb - 国产 REST Layer - REST API framework Honeytrap Ponzu utron muxie Buffalo - 快速生成 Web 项目的开发工具 go-web-framework-benchmark fiber - 一种 Express 风格的、基于 fasthttp 的 HTTP Web 框架 aah go-zero - 好未来开源的 Web 框架 pingcap/fn - 支持绑定任何方法，构建成 POST+JSON 接口 flamego - unknwon 开发的又一款 Web 框架 REST Layer - REST API 框架 rk-boot ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:1","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.2 业务框架 YAO - 使用 JSON 即可创建数据库模型、编写 API 接口、描述管理后台界面的应用引擎 GoAdminGroup/go-admin - 后台管理快速开发框架，与 laravel-admin 类似 wenjianzhang/go-admin - 基于 Gin + Vue 实现的后台框架 gin-vue-admin - 基于 Gin + Vue 实现的后台框架 goxygen - 基于 Go, React, MongoDB 技术实现的全栈应用生成器 nging - Go语言通用后台管理框架 snake - 业务API框架 PocketBase - 带有后台管理面板、文件和权限管理、集成 SQLite 数据库的单一文件后端服务开发框架，支持 Dart 和 JS SDK 快速开发 APP DoTenX - 低代码框架 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:2","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.3 项目骨架 Standard Go Project Layout - Go 项目目录结构示例 go-starter - Adobe 的 Go 工程模板 go-clean-arch go-rest-api - Go RESTful API Starter Kit Create Go App CLI - 通过命令行创建前后端项目的开发骨架 clean-gin - 基于 Gin 构建的整洁架构项目骨架 golang-repo-template - 一个包含了很多实践的项目模板 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:3","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.4 DDD 框架 Wild Workouts - DDD、整洁架构、CQRS的示例项目 Clean Architecture in Go - 整洁架构示例 freedom - 基于六边形架构的框架 esim - 基于六边形架构的微服务框架 go-cleanarch - Go 整洁架构规则校验工具 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:4","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.5 TCP 框架 zinx - TCP并发服务器框架 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:5","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.6 中间件 Negroni - Web 中间件 csrf - CSRF 中间件 handlers - A collection of useful handlers for Go’s net/http package ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:6","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.7 并发 SizedWaitGroup - 并发控制 concurrent - concurrency utilities ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:7","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.8 命令行 10.8.1 参数解析 urfave/cli - 命令行程序构建工具 Cobra - 命令行构建包 flaggy - 命令参数解析 pflag - 命令行参数处理 kong - 命令行解析 clop - 命令行解析包 go-flags - 命令行参数解析 mow.cli go-arg - 基于结构体Tag解析命令行参数 10.8.2 输出展示 progressbar - 在终端上输出进度条 cheggaaa/pb - 终端进度条 mpb - 支持多个进度条 Color - 命令行文字颜色 gookit/color - 命令行色彩使用库 termui - 终端仪表盘 tui - 终端 UI termenv - 终端应用程序的高级 ANSI 样式和颜色支持 asciigraph - 在终端中绘制 ASCII 字符的图表 spinner - 涵盖70多种符号或进度条的控制器 tablewriter - 终端中输出表格内容 PIXterm - 在命令行终端中绘图 WTF - 一个命令行的信息仪表盘，可以定制显示内容 termdash - 基于 Go Terminal 的仪表板系统 bubbles - TUI 组件 bubbletea - TUI 框架 PTerm - 支持图表、表格、进度条、树等终端输出展示 Lip Gloss - 终端布局、样式 gum glow - 终端渲染展示 Markdown Slides - 终端渲染展示 Markdown tview - Terminal UI ASCIIPlayer - 在终端中通过 ASCII 输出图片或视频，支持 png、jpeg、gif、mp4、avi 等格式 go-pretty - 终端渲染表格、列表、进度条等 tcell 10.8.3 其他 gosu - 以指定的用户权限来运行脚本 gotop - 类 top 系统监控显示 go-colorable - Colorable writer for Windows go-isatty - TTY 环境判断 fzf - 终端模糊查询神器，支持多平台 go-daemon - daemon 进程包 go-prompt - 命令行交互式输入 peco - 交互式过滤工具 pty - PTY for Go vtclean - 从终端输出字符串中解析出纯文本 Survey - 交互式输入 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:8","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.9 终端工具 vgrep - 支持滚动分页的 grep GoTTY - 基于Web的命令行实时共享 Jump - 根据习惯快速跳转目录 GoFish - 一个受 Homebrew 启发的跨平台软件管理工具，支持 Linux 和 Windows viddy - 增强版 watch 命令 miller - 一个类似 sed、awk、cut、join 和 sort 的工具，用来处理基于命名索引的数据 assh - SSH 增强工具 duf - 比 df 更好用的磁盘使用率工具 ov - 终端文本阅读器，可替代 less、more、tail -f 等 trdsql - 可对 CSV/LTSV/JSON/TBLN 等文件执行 SQL 查询和导出 vhs - 终端录像工具，提供了在终端中录制和回放终端会话的功能，类似于将终端会话记录为视频的方式 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:9","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.10 路由 HttpRouter mux - URL 路由和调度器 chi gocraft/web go-querystring - 转换结构体为URL请求参数 gorilla/schema - converts structs to and from form values CleverGo rewrite - rewrite 中间件 BunRouter - 支持中间件、错误处理、路由优先级、兼容 net/http 接口 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:10","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.11 网络 DNS - DNS 库 CoreDNS - DNS 服务器 RoadRunner - PHP 应用服务器、进程管理器、负载均衡，用于替代 Nginx + FPM FrankenPHP - PHP 应用服务器 GoReplay - 流量收集\u0026回放 Sharingan - 滴滴开源的流量录制回放工具 Glorp - HTTP 拦截\u0026重放的 CLI 工具 p2pspider - 种子嗅探器 torrent - BitTorrent 相关工具库 rain - BitTorrent 客户端和库 httpteleport - Teleports 10Gbps http traffic over 1Gbps networks FIND3 - WiFi 设备发现 SubFinder - 子域名发现工具 ggz - 短网址服务 httpstat grab - 文件下载 go-getter - 可使用 URL 作为输入的主要形式从各种来源下载文件或目录 go-netty - 网络框架 gnet - 事件驱动 Go 网络框架 netpoll - 专注于 RPC 场景的 Non-blocking I/O 网络库 httplab - The interactive web server yamux - Multiplexer sftp - SFTP support for the go.crypto/ssh package goftp - FTP 客户端 SFTPGo - 功能齐全且可高度配置的SFTP服务器，可选择支持HTTP/S、FTP/S和WebDAV。支持的存储后端包括：本地文件系统、加密的本地文件系统、S3（兼容）对象存储、Google Cloud Storage、Azure Blob Storage以及其他SFTP服务器。 evio - 事件驱动网络框架（reactor 模式） gaio - 事件驱动网络框架（proactor 模式） httpretty - 在终端上漂亮地打印出 HTTP 请求 blocky - 作为局域网 DNS 代理拦截广告 lossy - 模拟 net.PacketConn 和 net.Conn 接口的带宽，延迟和数据包丢失 go-libp2p - P2P go-ipfs-api - IPFS gomobile-ipfs - 为移动终端提供IPFS网络访问支持 go-multiaddr - multiaddr kcp-go - 可靠的 UDP 通讯包 gliderlabs/ssh - 像 net/http 一样轻松搭建 SSH 服务器 netaddr - 网络地址处理 sx - 网络扫描命令工具 echoip - IP 地址查找服务 EasyTCP - TCP Server 框架 GoPacket - 网络捕获抓包 croc - 两台电脑之间传输文件 cmux - 监听同一个端口，启动多种协议服务 GeoIP2 Reader for Go - 解析\u0026读取 MaxMind GeoLite2 和 GeoIP2 数据库 dns.toys - DNS 服务器 Apache Traffic Control - CDN 流量控制 NextTrace - 可视化路由追踪工具 pget - 文件下载工具，可多连接下载 CloudflareSpeedTest - 测试 Cloudflare CDN 延迟和速度，获取最快 IP 10.11.1 LDAP go-ldap GLAuth - LDAP Server gldap - LDAP Service 10.11.2 网络代理 Caddy - 类似 Nginx 的 Web 服务器 Traefik - 反向代理\u0026负载均衡 snail007/goproxy - golang 实现的高性能代理服务器 ProxyPool - 采集免费的代理资源为爬虫提供有效的IP代理 frp - 可用于内网穿透的高性能的反向代理应用 nps - 一款轻量级、高性能、功能强大的内网穿透代理服务器 Pomerium - 基于身份的反向代理 V2Ray V2Fly - V2Ray 的社区版本 Tailscale - WireGuard 解决方案 Clash - 支持多种协议的多平台代理客户端 elazarl/goproxy - HTTP 代理 oxy - Go middlewares for HTTP servers \u0026 proxies ouqiang/goproxy - Go HTTP(S)代理库, 支持中间人代理解密HTTPS pgrok - 提供给穷人的内网穿透 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:11","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.12 HTTP压测 Vegeta - HTTP 负载压测工具 hey - Web 压测工具 bombardier - Web 压测工具 go-wrk plow Ddosify ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:12","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.13 HTTP fasthttp - 比 net/http 快 10 倍的 HTTP 工具包 Resty - HTTP \u0026 REST 客户端包 gout - HTTP 客户端 gentleman - HTTP 客户端 goz UserAgent - 解析 HTTP User Agent purell - URL 规范工具包 go-autorest - HTTP 管道请求方式的客户端 Req - HTTP 客户端 cors - CORS Handler CertMagic - 为任意 Go 程序自动加上 HTTPS，TLS 证书签发、更新全自动 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:13","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.14 WebSocket gorilla/websocket nhooyr/websocket - 官方推荐的包 websocketd - Go 开发的一键搭建 WebSocket 服务器命令行工具 ws - WebSocket 开发包 melody - WebSocket 服务框架 neffos - 一个快速且可扩展的 WebSocket 框架 fastws ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:14","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.15 即时通信 Centrifugo - 实时消息服务器，可以与任何语言编写的应用程序后端结合使用 goim - 支持集群的 im 及实时推送服务 Tinode - 即时消息服务器，通过 websocket/JSON 或 gRPC/TCP 等协议传输 WebRTC - WebRTC 实现 Berty - 安全的点对点通讯软件 Keybase - 即时通讯工具 Keybase 全平台客户端 gotify - 基于 WebSocket 的 PUSH 通知服务 nakama - 用于社交/实时游戏/实时应用的分布式服务端程序，自带面板、用户、聊天、存储、社交等功能 OpenIM ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:15","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.16 网关 GoKu API Gateway CE - eoLinker 开源的 API 网关 Easegress Manba Tpk BFE - 基于百度统一接入前端开源的七层流量接入系统 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:16","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.17 序列化 vmihailenco/msgpack - 支持 msgpack go/codec - 支持 msgpack/binc/cbor/json golang/protobuf - Go 版本的 Protocol Buffers gogo/protobuf - golang/protobuf 的扩展替代品 Objx - 操作 map, slice, JSON 等数据的包 msgp - MessagePack 代码生成器 Buf - protoc 替代品 protoc-gen-doc - Google Protocol Buffers 文档生成插件，支持 HTML、JSON、DocBook、Markdown 和自定义模板 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:17","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.18 解压缩 snappy - Go 语言版本的 Snappy cae - 实现 ZIP/TAR.GZ 解压缩 archiver - 多格式支持的解压缩包 compress - Optimized compression packages Brotli xz - xz 压缩格式读写包 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:18","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.19 RPC gRPC-Go - gRPC 官方包 Go gRPC Middleware - gRPC 常用中间件 gorpc gorilla/rpc - 构建基于 HTTP 的 RPC 服务，比如 JSON-RPC Lile - gRPC 服务构建包 rpcx Twirp - 基于 Protobuf 的 RPC 框架，与 gRPC 类似 dubbo-go - Dubbo Go 版本 Kitex gRPCurl - 像 cURL 一样通过命令行访问 gRPC 服务 protoc-gen-doc - 文档生成插件 gRPC-Gateway - 读取 gRPC 服务定义并生成一个反向代理服务器，同时提供 gRPC 和 RESTful 风格的 API ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:19","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.20 邮件 gomail - 邮件发送包 scorredoira/email Hermes - Go 版本的 mailgen 引擎，根据配置生成 HTML 格式的邮件 Go-Guerrilla - SMTP 邮件服务器 MailHog - 基于Web和API的SMTP测试工具 Maddy - 邮件服务器 jordan-wright/email Mox - 邮件服务器 Pop - 邮件发送工具，支持交互式和参数式 email-verifier - 邮箱校验，无需发送邮件 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:20","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.21 消息队列 NSQ - 实时分布式消息平台 NATS - 云原生消息中间件 amqp - AMQP 0.9.1 客户端 sarama - Kafka 客户端 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:21","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.22 文件/存储 MinIO - 对象存储服务器 rclone - 不同云存储之间同步文件 Syncthing - 文件同步 fsnotify - 文件系统监控工具 reflex - 监听文件变更并执行命令 gohttpserver - HTTP 静态文件服务器 XLSX - Excel 读写包 Excelize - 360 开源的 Excel 工具包 gopdf - PDF 生成 rsc/pdf - PDF reader SeaweedFS - 分布式文件系统 go-fastdfs - 分布式文件存储服务 Dragonfly - 基于 P2P 的分布式文件系统 filetype - 检测文件类型 Afero - 文件操作包 fsync - 文件/目录同步 filebrowser - Web File Browser Bigfile - 文件传输管理系统 filetype - 文件类型与 MIME 检测 go-app-paths - 跨平台检索目录文件 copy - 拷贝文件夹 lakeFS - 类 Git 文件对象存储 Duplicacy - 无锁云备份工具，支持几乎所有存储方式 CasaOS - 家庭云系统 AList - 支持多存储的文件列表程序 UniPDF - PDF 读写处理 mimetype - MIME 类型与文件扩展检测 gocryptfs - 加密 overlay 文件系统 restic - 备份工具，使用现代的加密方法对数据进行安全的备份，支持 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:22","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.23 模板引擎 goTemplateBenchmark - 给各 Go 模板引擎做性能测试，当然也就包含了最全的模板引擎包 Jet - 速度很快 amber - HTML 模板引擎 fasttemplate - Simple and fast template engine for Go quicktemplate mustache Ace Sprig - 常用模板方法 pongo2 - Django 语法风格的模板引擎 plush ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:23","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.24 代码生成 esc ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:24","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.25 文本处理 10.25.1 Markdown Blackfriday - Markdown 解析器 Lute - 结构化的 Markdown 引擎 goldmark - Markdown 解析器 docx2md - 转换 Word 为 Markdown glamour - 命令行下渲染 Markdown go-md2man - 转换 Markdown 为 man 手册内容 gomarkdown/markdown html-to-markdown - 转换 HTML 为 Markdown 10.25.2 HTML/CSS DOM - HTML DOM 节点操作 obelisk - 保存 Web 网页为 HTML 单页面 html2text - HTML 转 text go-readability - 让 HTML 可读性更高 gomponents - 声明式视图组件，可以渲染成 HTML5 daz - HTML 组件组合，渲染 HTML html-strip-tags-go - 去除 HTML 标签 bluemonday - XSS 探测 cascadia - CSS 选择器 htmlquery - XPath 语法查询 HTML xmlquery - XPath 语法查询 XML xpath - XPath 语法 goquery - jQuery 语法查询 HTML css - CSS 选择器 10.25.3 其他 go-runewidth - 字符长度计算 gpy - Go 语言汉字转拼音工具 go-hashids - hashids 的 Go 版本 go-pinyin - 汉语拼音转换工具 Go 版 mahonia - 字符集编码转换 pangu.go - Go 版本的 pangu，给中英文之间加空格 goorgeous - A Go ORG syntax parser to HTML sergi/go-diff - Go 版本的 diff 工具包 sourcegraph/go-diff - Go 版本的 diff 工具包 Chroma - 代码语法高亮 syntaxhighlight - 代码高亮 kyokomi/emoji enescakir/emoji golang/freetype - Freetype font rasterizer prose - natural language processing library minify - Web 静态资源压缩(HTML/JS/CSS/JSON/XML/SVG) Inflection - Pluralizes and singularizes English nouns autocorrect - 自动给中英文之间加入合理的空格并纠正专用名词大小写 bleve - modern text indexing etree - XML 解析\u0026生成 go-xml feeds - RSS 内容生成 gofeed - RSS \u0026 Atom feeds 内容解析 sitemap - sitemap.xml 生成 yarr - RSS 阅读软件 gogrep - 通过语法树搜索 Go 源码 PipeIt - 文本转换，清理和提取工具 regexp2 - 全功能正则表达式引擎。如果标准库的 regexp 满足不了你，可以尝试使用 regexp2 html2article - 基于文本密度的 html2article 实现 hostctl - hosts 命令行管理工具 go-shellwords - 解析命令行中字段 woke - 检查文本文件中是否存在歧视词汇 go-password-validator - 密码强度校验器 xurls - 从文本中提取 URL whatlanggo - 自然语言探测 go-enry - 检测编程语言 fuzzy - 字符串模糊匹配 godlp - 数据脱敏 Zoekt - 文本搜索引擎 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:25","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.26 文档 swag - Swagger for Go gin-swagger - Swagger for Gin go-swagger - Swagger 2.0 implementation for go ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:26","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.27 数学计算 decimal - 解决浮点数计算精度问题 fixed apd - decimal 包 mathfmt - 将 LaTeX 语法的注释转换为数学公式格式 q - 量子计算模拟器 accounting - 货币格式化 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:27","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.28 日期时间 now when - 自然日期时间解析 Carbon - Carbon 时间处理库的 Go 语言实现 strftime - 时间格式化 dateparse - 解析任意未知格式的时间字符串 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:28","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.29 配置 GoDotEnv - .env 配置文件解析 go-yaml/yaml ghodss/yaml toml - TOML 解析\u0026编码包 INI - INI 配置文件解析 Viper - 支持 JSON, TOML, YAML, HCL, Java 等配置文件 fig Multiconfig configor envconfig confd - 配置管理工具 HCL - configuration language env - 解析 ENV 环境变量到结构体中 configor koanf go-toml - TOML butler - Adobe 开源的配置管理系统 envsubst - 环境变量替换 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:29","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.30 爬虫 Crawlab - 基于Golang的分布式爬虫管理平台，支持Python、NodeJS、Go、Java、PHP等多种编程语言以及多种爬虫框架 Colly - 网络爬虫框架 Pholcus - 支持分布式的高并发、重量级爬虫软件 go_spider Muffet - 网站链接检查器 Creeper Geziyor - 支持 JS 渲染的快速爬虫框架 Apollo - 一个爬虫工具 ferret - 声明式 Web 数据抓取 gocrawl Antch katana - 爬虫\u0026蜘蛛框架 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:30","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.31 数据库 10.31.1 SQL解析 pingcap/parser - 兼容 MySQL 的 SQL 解析 xsqlparser - SQL 解析 sqlparser - SQL 解析 vitess-sqlparser - SQL 解析 dbml-go - DBML 解析 10.31.2 分布式事务 go-saga - Saga 分布式事务实现 DTM - 跨语言的分布式事务管理服务，支持TCC、Saga、XA等 10.31.3 数据库相关 usql - 几乎支持全部 SQL 与 NoSQL 数据库的命令行工具 GORM - GORM V2 GORM V1 gorm2sql - 根据 Model Struct 生成建表语句 gorm-sharding - 基于 Conn 层做 SQL 拦截、AST 解析、分表路由、自增主键填充，对使用者透明 Xorm XormPlus - Xorm 的定制增强版本 GoRose sqlx - database/sql 扩展包 dbq - 数据库操作 gendry - 滴滴开源的SQL Builder ozzo-dbx Squirrel - Fluent SQL Builder qb - the database toolkit for go mgo globalsign/mgo - The MongoDB driver for Go mgo使用指南 kingshard - MySQL Proxy SOAR - 对SQL进行优化和改写的自动化工具 SQLE - SQL 审核工具 Vitess - 用于部署、扩展和管理大型MySQL实例集群的数据库解决方案 gh-ost - GitHub 开源的在线更改 MySQL 表结构的工具 SQLer - write APIs using direct SQL queries with no hassle, let’s rethink about SQL gocraft/dbr Gaea - 小米开源的基于 MySQL 协议的数据库中间件 OctoSQL - 支持多数据库的 SQL 查询工具 goose - 数据库迁移工具 migrate - 数据库迁移工具 dbmate - 数据库迁移工具 ent - An Entity Framework For Go godb - a Go query builder and struct mapper go-nulltype go-mysql - MySQL 工具集 SQLittle - 纯读取 SQLite 文件 Bifrost - MySQL 同步到 Redis、ClickHouse 等服务的异构中间件 elasticsql - 转换 SQL 成 Elasticsearch DSL POP - 基于 sqlx 封装的数据库 ORM 工具 REL - Modern Database Access Layer for Go RDB - Redis RDB 文件解析和生成工具，支持转 JSON、转 AOF、寻找 Big Key、生成 RDB 文件及绘制内存火焰图等功能 Bytebase - 基于网络、零配置、无依赖的数据库 Schema 变更和版本控制管理工具 Bun - SQL 优先的 ORM，写 SQL 的方式写 Go 代码，支持 PostgreSQL、MySQL、MSSQL、SQLite 10.31.4 数据库客户端 Go-MySQL-Driver - MySQL 驱动 go-mssqldb - MSSQL 驱动 pq - PostgreSQL 驱动 mongo-go-driver - MongoDB 官方出品的 Go 语言驱动 qmgo - MongoDB 客户端 clickhouse-go - ClickHouse 官方 Go 语言客户端 go-clickhouse - ClickHouse 客户端 go-sqlite3 - SQLite3 驱动 gohbase - HBase 客户端 redigo - Redis 客户端 go-redis - Redis 客户端 rueidis - Redis 客户端 redsync - 基于 Redis 的分布式锁 redislock - 基于 Redis 的分布式锁 Tiny RDM - Redis 桌面客户端 10.31.5 数据库引擎 etcd - KV 分布式存储 InfluxDB - 时间序列数据库 Prometheus - 服务监控系统 \u0026 时间序列数据库 tstorage - 时间序列数据库 Thanos - 支持 Prometheus 简化部署、高可用、分布式存储 CockroachDB - 分布式 SQL 数据库 Cayley - 图数据库 RadonDB - 基于 MySQL 研发的新一代分布式关系型数据库 TiDB - 分布式关系型数据库，兼容 MySQL 协议 AresDB - Uber 开源的 GPU 驱动的实时分析存储\u0026查询引擎 leveldb - LevelDB 的 Go 实现 Dgraph - 分布式图数据库 rqlite - 基于 SQLite 的轻量级分布式关系数据库 gaeadb BadgerDB - KV 数据库，支持 ACID 事务 LBADD - 用 Go 实现的分布式 SQL 数据库 go-memdb - 建立在不可变 Radix 树上的内存数据库 VectorSQL - 应用于 IoT 和大数据的 DBMS 数据库，类似于 ClickHouse BuntDB - 基于内存的KV数据库，支持磁盘持久化、ACID事务 TinySQL - 迷你分布式关系型数据库 Tile38 - GEO 数据库 Redcon - 兼容 Redis 协议的自定义 Redis 服务，采用 BuntDB 和 Tile38 实现存储 genji - 文档内嵌型数据库 Dolt - 像 Git 一样操作数据库 rosedb - 简洁、高效的 KV 数据库，支持多种数据结构 LinDB - 分布式时序数据库 mandodb - 一个示例项目，作者介绍如何从零开始实现一个小型的时序数据库 go-mysql-server - 解析 MySQL 协议并优化 SQL 的数据库引擎 Milvus - 向量数据库 FerretDB - MangoDB 替代品 LotusDB - 快速 KV 存储引擎，兼容 LSM 和 B+ 树 NutsDB - 可持久化、事务的内嵌 KV 数据库 Olric ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:31","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.32 缓存 GCache bbolt - key/value store BigCache go-cache - KV 内存缓存 gomemcache - Memcache 客户端 cache2go ristretto fastcache FreeCache godis - Go 语言实现的 Redis 服务器和分布式集群 groupcache - 分布式缓存 cachego - 支持 Redis、Bolt 等缓存接口 diskv - 基于硬盘的 KV 存储 Pebble - 被 CockroachDB 使用的 KV 存储 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:32","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.33 搜索推荐 wukong - 全文搜索引擎 go-elasticsearch - 官方 ES 客户端 elastic - Elasticsearch 客户端 go-mysql-elasticsearch - Sync MySQL data into elasticsearch gse - Go 语言分词 sego - Go 中文分词 gojieba - “结巴\"中文分词的 Go 语言版本 Riot - 全文搜索引擎 simplefts - 超简单的全文搜索引擎实现 Blast - 全文搜索(Archived) Fuzzy Search - 文本模糊搜索 gorse - 单节点训练和分布式预测推荐系统引擎 gofound - 全文搜索引擎 ZincSearch - 全文搜索引擎 Bluge - 文本分词 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:33","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.34 表单 validator ozzo-validation - 使用代码指定规则，而非Tag go-tagexpr - 字节跳动开源的结构体标签表达式解释器 govalidator ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:34","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.35 Auth Casbin - 权限控制管理 pam-ussh - Uber’s SSH certificate pam module jwt-go - JWT for Go kataras/jwt - JWT 轻量级实现 cristalhq/jwt sessions - 后端 SESSION 服务 securecookie - cookie 加密/解密 Goth - Multi-Provider Authentication for Go branca - 号称比 JWT 更安全的 token 解决方案 gin-jwt - Gin 框架的 JWT 中间件 Authboss - Web Auth 系统 ZITADEL - 身份认证系统，支持各种认证模式 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:35","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.36 加密/解密 2fa - Two-factor authentication on the command line age - 文件加密工具（库） CIRCL - Cloudflare Interoperable, Reusable Cryptographic Library ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:36","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.37 视频 goav - FFmpeg 视频处理 lal - 直播流媒体网络传输服务器 bililive-go - 直播录制工具 screego - 通过浏览器共享开发者屏幕 livego - 直播服务器 Monibuca - 流媒体服务器开发框架 olive - 支持虎牙等平台的直播录制 lux - 各大视频网站的视频下载工具 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:37","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.38 图形处理 barcode - 条形码/二维码生成器 picfit - 图片操作、裁剪、管理服务器 gmfs - 图片操作、裁剪、管理服务器 besticon - favicon 服务 Caire - 图片操作库 Imaging - 图片操作库 gocaptcha - 验证码生成 base64Captcha - 验证码 go-is-svg - 校验是否为 SVG 图片 identicon - 根据用户的 IP 、邮箱名等任意数据为用户产生漂亮的随机头像 prominentcolor - 识别图片的主要颜色 dchest/captcha - 生成和验证图片或音频验证码 bimg - 图片处理 imaginary - 图片处理服务 primitive - 用原始几何图形绘制图形 orly - 生成你自己的O’RLY动物书封面 smartcrop - 智能裁剪图片 gift - 图片滤镜 Germanium - 给代码生成图片 Go Graphics - 2D 图片渲染 canvas - 矢量图绘制 formulae - 数学公式解析、计算、图表绘制 imagor - 图像处理服务器 Triangula - 给图片增加三角形纹样风格的滤镜 D2 - 一种将文本转换成图形的图表脚本语言 ImGo - 简洁、链式调用的图像处理库 Invoice - 发票生成工具，可通过参数和配置文件进行创建和管理各种类型的发票 10.38.1 图片识别 go-face - 面部识别 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:38","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.39 图表 go-echarts - Echarts 图表库 gonum/plot - 图形绘制 pinhole - 3D 线框图绘制 globe - 地球线框图绘制 ink - Go 中的 2D 图形框架 go-plantuml - 基于 Go 源码生成 plantuml 图 go-diagrams - 通过代码生成图表 GoCity - 3D 展示城市 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:39","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.40 构建编译 Mage - 类似于 Makefile 的命令行工具，用于构建和运行 Go 项目 GoReleaser - Go 多平台二进制文件打包、并支持发布到 Homebrew 的工具 goxc - 跨平台编译工具（因 1.5 版本开始已自带交叉编译，故已不再维护） Task - 类似于 Make 的构建工具 codegangsta/gin - 热编译工具 Air - 热编译工具 gowatch - 热编译工具 Fresh - 热编译工具 dh-make-golang - 自动构建 Debian 包 gobinaries - 不用安装Go就能编译安装Go编写的程序 nFPM - deb、rpm、apk 等打包工具 Gox - Go 跨端编译工具 garble - 混淆代码 gobfuscate - 混淆代码 go-appimage - Go 语言实现 AppImage 打包工具 10.40.1 静态资源内嵌 pkger - 将静态文件打包成 Go 二进制文件 mewn - 静态文件嵌入打包到二进制文件 statik - 静态文件嵌入 go.rice go-bindata - 将静态文件转换成 Go 代码文件 vfsgen - 将静态文件打包成 http.FileSystem 类型进行访问 packr ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:40","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.41 优雅升级 tableflip - Web 服务升级 selfupdate - 二进制文件自动升级 overseer go-github-selfupdate - 依托 GitHub 自动升级 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:41","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.42 代码分析 reviewdog - Code Review 机器人 revive - 代码检查分析 GolangCI-Lint - 代码质量检查分析工具 errcheck - 检测未处理的错误(errors) Staticcheck - 一系列的 Go 代码静态分析工具 Golint - Google 官方出品的代码质量检测工具 GoReporter go-critic gocloc - 分语言代码行数统计 coca - 代码统计分析 Go Report Card - Go 项目质量分析报告工具 ddsv-go - 死锁检测工具 golang/perf - 官方性能量化分析工具 GoPlantUML - 为 Go 项目生成 PlantUML 类图 gosize - 分析Go二进制文件大小 shotizam - 分析 Go 二进制文件的大小并输出到 SQLite3 goconst - 查找可以被常量替换的重复字符串 sploit - 帮助二进制分析和开发的库 perf - Perf Utilities for Go fgprof - Go 性能分析工具 conprof - 协程分析 statsview - 实时 Go 运行时统计数据可视化分析器 codesearch - 代码搜索工具 Pyroscope - 可视化程序性能监控工具，支持多种语言 gosec - 代码安全性检查工具 gokart - 代码静态分析工具 gofumpt - gofmt 增强版代码格式化工具 NoVerify - PHP 代码分析工具 fieldalignment - 结构体字段内存对齐分析和自动修复工具 Bearer - 代码安全扫描工具 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:42","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.43 调试 go-spew - 变量打印工具 Delve - Debug 工具 gdlv - Delve 界面版本 Weaver - 跟踪 Go 程序执行链路 repr - 变量打印工具 pp - 彩色变量打印工具 ffmt - 变量打印工具 gops - 谷歌官方出品的 Go 程序监控调试工具 pprof go-callvis - 可视化Go程序的调用图 q - 自动打印变量类型并且格式化输出 Litter RDebug - 滴滴开源的一款用于 RD 研发、自测、调试的实用工具 debugcharts - Go 内存占用可视化调试工具 gcvis - 实时可视化 gctrace pkg/profile statsviz - 在浏览器中实时查看 Go 应用程序运行时统计信息（GC，MemStats 等） autopprof - 自动分析 pprof stack - 捕获、操作、格式化调用栈信息 pretty - 打印变量 go-deadlock - 对 (RW)Mutex 进行注入，并提供死锁检测 mmcloughlin/profile gcnotifier - 当发生 GC 时通知 grmon - 命令行监控显示 goroutines valast - 打印输出变量的 go/ast 结构，类似于 PHP 的 var_export 函数 lensm - Go 汇编与源码对照查看工具 holmes - 基于规则的自动 Go Profile Dumper ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:43","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.44 测试 GoConvey - 含Web界面的单元测试框架 GoMock - 谷歌出品的Mock测试框架 GoStub Monkey - (Archived) Monkey patching in Go gomonkey - 猴子补丁，对函数、变量等进行打桩，方便单元测试，Fork 自 Monkey SuperMonkey - 让私有方法可测 mockery - 自动为接口生成 mock 代码 Ginkgo - BBD 测试框架 fperf - 压测工具 gocheck Testify gotests - 根据源码自动生成测试文件 TestSQL - 根据 SQL 创建语句生成测试数据 httpmock - HTTP Mock Goblin - BDD 测试框架 go-faker/faker - Struct Data Fake Generator gofakeit - 随机数据生成器 dmgk/faker go-tprof - 包测试报告生成工具 go-fuzz - randomized testing for Go gofight - Testing API Handler sqlmock - SQL 测试 sqlbench - SQL silk - 基于 Markdown 的接口测试 gock - HTTP mock 测试 godog - BDD 测试框架 Cucumber 的 Go 版本 endly - E2E（端到端）测试 is - 迷你测试框架 Terratest - 基础设施测试，比如 Docker agouti - Web 驱动的验收测试框架 httpexpect - 端到端 HTTP \u0026 REST 测试框架 gocov - 测试覆盖率 miniredis - Redis 数据测试 htmltest - HTML 测试 gnomock - 无需 mock 的 Go 代码测试框架 gunit - xUnit 风格测试框架 quicktest k6 - 负载测试工具 go-cover-treemap - 将覆盖率测试结果转换成 TreeMap 图 ZTF - 禅道开源的自动化测试框架 Moq - 为接口生成 Mock 代码 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:44","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.45 错误处理 errors errorx errwrap - Go tool to wrap and fix errors with the new %w verb directive erris - Linter for errors.Is and errors.As eris - 旨在通过错误包装，堆栈跟踪和输出格式为你提供对错误处理的更多控制 errlog - 使用静态和堆栈跟踪分析来快速确定哪个函数调用导致的错误 juju/errors go-fault - GitHub 官方出品，基于标准库 http 中间件的故障注入库 merry - 支持堆栈、状态码的错误处理 cockroachdb/errors - 功能强大、可替代 errors 和 github.com/pkg/errors 的错误处理包 go-multierror - 支持错误列表 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:45","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.46 安全 Kunpeng - 开源POC检测框架 nmap - 安全审计工具 nmap 开发包 Hetty - 用于安全研究的 HTTP 工具包，具有 Web 接口和代理日志查看器的拦截 HTTP 代理 Fibratus - Windows 内核漏洞利用和跟踪工具 Secure - HTTP 安全中间件 nuclei - 基于YAML语法模板的定制化快速漏洞扫描器 Gitleaks - 用于在 Git 存储库中查找敏感信息和密钥的开源工具 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:46","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.47 系统信息 go-hardware - 收集了一堆关于硬件信息的包 cpuid - CPU 信息 gopsutil - ps 功能包 go-sysinfo - 系统信息 go-locale - 跨平台语言检测库 go-ps - 系统进程信息 psgo - ps 命令实现 ghw - 硬件信息 machineid - 获取机器ID ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:47","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.48 UUID go.uuid - UUID 库 SEQSVR - Go + MySQL 实现的分布式 ID 生成服务 google/uuid - Google 开源的 uuid 包 gofrs/uuid snowflake - Twitter snowflake IDs sonyflake - Sony 版本的 Twitter’s Snowflake ulid - ULID Go 语言实现 ksuid - K-Sortable Globally Unique IDs go-nanoid - NanoID 实现 xid - 全局唯一 ID 生成器 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:48","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.49 日志 logr - 日志包标准接口 Logrus - 日志记录包 zerolog zap - Uber 开发的日志记录包 Seelog logkit - 七牛开源的日志收集工具 gogstash - 类似于 Logstash 的日志收集器 lumberjack - 日志文件切割 file-rotatelogs - 日志文件切割 go-syslog - 极速 Syslog 解析器 glog ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:49","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.50 监控告警 OpenFalcon - 小米开源的监控系统 Prometheus - 服务监控系统 \u0026 时间序列数据库 Grafana - 分析监视平台, 支持 Graphite, Elasticsearch, OpenTSDB, Prometheus, InfluxDB 等数据源 grabana - 用 Go 代码快速创建 grafana dashboards Jaeger - 分布式追踪系统 go-osstat - 系统指标统计 grafterm - Metrics dashboards on terminal mymon - MySQL 运行监控 PingMe - 支持多消息平台的服务可用性报警命令工具 supervisord - Go 语言实现 Supervisor Grafana Tempo - 分布式追踪系统 EaseProbe - 服务探活工具并通知 Uptrace - APM 工具，支持 OpenTelemetry 追踪、指标和日志 Nightingale - 滴滴基于 OpenFalcon 开源的监控系统 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:50","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.51 统计分析 Fathom - Web 站点统计 Veneur - 分布式实时数据处理管道 gonum - 科学计算相关 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:51","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.52 容器技术 moby - Docker docker-ce Rancher - 全栈化企业级容器管理平台 Gorsair docui - TUI Client for Docker Podman - 管理和运行任何符合 OCI 规范的容器和容器镜像 Skopeo - 镜像管理工具 Buildah - 构建 OCI 容器镜像的工具 go-docker - 用 Go 实现 Docker 核心功能 Packer - 轻量级的镜像定义工具 cosign - 容器签名和验证 SlimToolkit - 检查、缩小和调试容器 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:52","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.53 集群管理 Nomad - 集群管理器和调度器 OpenShift Origin - Red Hat 开发的容器化软件解决方案 10.53.1 Kubernetes kubernetes - 容器调度管理平台 k0s - 最小体积的 k8s 发行版 sealos - 一条命令部署 Kubernetes 高可用集群 KubeEye - 通过配置规则发现 Kubernetes 上的各种问题 endpoints-operator - K8S内部服务访问外部服务的具备探活功能的4层LB ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:53","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.54 机器学习 goml - 机器学习库 GoLearn - 一个 “开箱即用” 的机器学习库 glow - 易用的分布式计算系统 Gobot - 机器人和物理计算语言库 Olivia - 神经网络 Pico - 基于像素强度比较的物体检测纸张的纯 Go 脸部检测库 tfgo - Tensorflow in Go Prophecis - 微众银行自研的一站式云原生机器学习平台 AID - 机器学习ops平台，发现、部署、优化 SQLFlow - SQL引擎+AI引擎 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:54","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.55 人工智能 go-openai - OpenAI API Go 客户端 SDK LocalAI - 低成本的硬件上运行模型计算的本地计算框架，支持多种模型，提供兼容 OpenAI 接口协议的 REST API ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:55","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.56 算法 GoDS - Go 实现了多种数据结构 Dragonboat - 多组 Raft 共识算法库 eliben/raft - Raft 算法 hashicorp/raft - Raft 算法 Graft - Raft 算法 golang-lru - LRU 算法实现 tinylru finn - Fast Raft framework using the Redis protocol for Go xorfilter priyankchheda/algorithms - 各种算法的 Go 语言实现 meow - Meow hash basalt - 高性能的分布式的专门空间优化的 Bitmap 服务, 杜绝 Bloomfilter 和 CuckooFilter 的误判 go-blurhash - BlurHash，是模糊图片的一种哈希算法 xxhash - xxHash 哈希算法实现 go-multihash - 各种 Hash 算法实现 memberlist - 基于 gossip 协议实现的管理集群成员和成员失败检测的开发包 backoff - 指数退避算法(Exponential Backoff) FSM - 有限状态机 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:56","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.57 数据结构 go-datastructures Play-with-Data-Structures - 「玩转数据结构」课程的 Go 语言实现版本 HashMap SipHash - SipHash-2-4 Bigslice golang-set - The missing set collection rbang - R!tree 实现 rtreego - R-tree google/btree - B-Tree tinybtree - B-tree dataframe-go - 用于数据统计和操作的包 go-set - 集合工具包 orderedmap - 有序字典 trie Slim - 空间高利用率的数据结构 bitset - 位集合及其操作 bloom - Bloom filters roaring - 压缩位图 go-immutable-radix - Radix 树 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:57","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.58 依赖注入 go-autowire - 使用注解自动生成 wire - 依赖注入 dig Fx ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:58","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.59 JSON GJSON - JSON 解释器 SJSON - JSON 修改工具 fastjson - fast JSON parser and validator for Go jsonparser ffjson json-iterator - 滴滴开源的 JSON 解析器 gojsonq - JSON/YAML/XML/CSV 等数据查询 easyjson go-jsonc - 将带注释的 JSON 转为无注释的 jin - JSON 操作工具包，同时具有标准库和类似 tidwall/gjson 和 tidwall/sjson 的功能 hujson - 支持注释的 JSON 解码 pkg/json - JSON Decoder ColorJSON - 终端中打印彩色 JSON jid - JSON 数据解析读取工具 jsonc - 支持注释与逗号 sonic - 字节跳动开源的 JSON 解析器\u0026修改器 go-json jsonquery - XPath 语法查询 JSON fx - 命令行 JSON 显示 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:59","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.60 依赖管理 goproxy.io - GOPROXY 代理服务 goproxy.cn - 更适合国内用户的代理服务 Gopm - Go 包管理工具 govendor - Vendor 包管理工具 gom - 包版本管理工具 rvflash/goup - 检查包版本是否有更新 owenthereal/goup - Go 多版本管理 Athens - GOPROXY 代理服务 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:60","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.61 微服务 Istio [中文文档] - 大型微服务系统管理工具 goa Micro - 微服务工具 Go Micro - 微服务框架 Go kit - Go 微服务工具集 GoKit CLI - Go kit 脚手架 gogo go-chassis Kite Kratos - B站开源的微服务框架 Temporal - 微服务编排平台 Serf - 服务编排管理平台 Open Policy Agent - 通用策略引擎，CNCF 孵化项目 gizmo - 微服务工具集 MOSN - 用于边缘和服务网格的云原生网络数据平面 Erda - 为企业提供 DevOps、微服务治理、多云管理的 PaaS Service Weaver Consul - 服务发现、配置管理中心服务 Traefik Mesh - 简单的服务网格 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:61","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.62 Serverless OpenFaaS - Serverless Functions Made Simple(功能服务化的 FaaS 框架) faasd - 轻量级 FaaS 引擎 fn - 事件驱动的 FaaS riff - 基于 Kubernetes 的 FaaS Nuclio - 实时事件与数据的 Serverless 框架 Flogo - 事件驱动的 Serverless 框架 Dapr - 微软开源的云和边缘计算的微服务构件 kubeless Fission - 基于 Kubernetes 的 Serverless pulumi Knative fx IronFunctions schollz/faas - 让任何包的函数变成一个 HTTP 接口 Vanus - 无服务事件流处理系统 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:62","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.63 devops act - 本地运行 GitHub Actions ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:63","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.64 持续集成/部署 CDS - 持续集成服务 gopub CodePub syncd - 代码部署工具 Drone - 基于 Docker 的持续发布平台 Cyclone - 持续集成\u0026发布平台 tbls - 用于记录数据库文档的 CI 友好工具 Woodpecker - Fork 自 Drone Dagger - 基于容器的 CI/CD 工具 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:64","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.65 Git gogs - 类似于 GitLab 的 Git 服务器 Gitea - 由 gogs 分叉出的 Git 服务器 go-git - Go 实现的 Git 操作 gitin - commit/branch/status explorer for git hub - GitHub 命令行工具 git-o-matic - 一个监控 Git 仓库变化和自动 pull/push 的工具 gitbase - SQL 的方式查询 Git 日志 git-chglog - CHANGELOG 管理工具 chglog - CHANGELOG 管理工具 lazyhub - GitHub 的终端 UI 客户端 goaction - 在 Go 中编写 GitHub Action bit - Git 命令增强版，支持文件和分支名称自动完成、命令和标志建议 go-github - GitHub API 操作库 askgit - 通过 SQL 访问 Git 仓库信息 git2graph - 根据 Git 仓库提交记录生成结构图 lazygit - Git 终端 UI gh-dash - GitHub CLI（gh）漂亮终端面板 Soft Serve - 命令行式自托管 Git 服务器 Git LFS - 处理大文件的 Git 扩展 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:65","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.66 限流器 Tollbooth - Simple middleware to rate-limit HTTP requests ratelimit RateLimit go-rate Circuit - 熔断器 uber-go/ratelimit Sentinel - 阿里巴巴开源的面向分布式服务架构的流量控制组件 Go 语言版本 gohalt - 限流 gobreaker - 熔断器 ulule/limiter ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:66","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.67 编译器 TinyGo - 一个适用于微控制器、WebAssembly 和命令行工具的 Go 编译器 minigo - A Go compiler from scratch llir/llvm - LLVM 编译器 jit-compiler - JIT 编译器 Go+ - 七牛云开源面向数据科学的语言，完全兼容Go语言 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:67","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.68 解释器 10.68.1 语言解释器 participle - 通用的自定义语法解析包 GopherLua - VM and compiler for Lua in Go go-lua - A Lua VM in pure Go DCLua - Go Lua Compiler and VM otto - JavaScript 解释器 goja - ECMAScript 5.1(+) 实现 v8go - Execute JavaScript from Go gpython - Python Interpreter on Go Grumpy - 转换 Python 为 Go 代码，谷歌开源 starlark-go - Starlark in Go avo - x86 汇编程序构建器 wagon - WebAssembly 解释器 GopherJS - 把 Go 代码编译成 JavaScript 代码 Yaegi - Go 语言解释器 properties - Java properties scanner for Go jvm.go - JVM gobasic - A BASIC interpreter written in golang golisp - Lisp 解释器 dst - Go Decorated Syntax Tree mvdan/sh - Shell 解析、格式化、接口 tdewolff/parse - 通用词法分析器 Lexer，并内置支持解析 HTML/CSS/JSON/XML/JS/SVG 语法 Joker - Clojure 10.68.2 PHP z7zmey/php-parser - PHP AST 语法解析 deuill/go-php - PHP bindings for Go goridge - High-performance PHP-to-Golang IPC bridge RoadRunner - 高性能PHP应用服务器，支持负载均衡及进程管理 VKCOM/php-parse - PHP AST 语法解析 10.68.3 自定义解释器 CUE - Configure Unify Execute(Validate and define text-based and dynamic configuration) cel-go - Common Expression Language(CEL 的 Go 实现) Math-Engine - 使用 Go 实现的数学表达式解析计算引擎库，学习语法解析很适用 Gval - 表达式计算 expression-parsing goexp - Recursive descent expression parser in Go goastch - Go AST 语法解析 tdop swallow Anko Expr - 编译\u0026执行字符串中的表达式 Tengo - 用 Go 编写的脚本语言 V - Go 编写的语言 kumarUjjawal/bison Monkey govaluate Compiler - 将自定义语法代码编译成 X86-64 Assembly elvish - 交互式 Shell 语言 QLBridge - Go SQL Runtime Engine YQL - SQL WHERE 风格的规则引擎 Flux - InfluxDB 数据语言 Spiker - Go 编写的简单规则表达式执行器，支持自定义函数和流程控制，适用于业务规则复杂的场景 gocc - 解析器生成器，可以将指定的文法转换为 Go 语言的解析器程序代码，用于编译和解析特定类型的源代码 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:68","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.69 代码生成 jennifer - Go 代码生成 ifacemaker - 根据结构体方法生成接口 gg - Go 代码生成 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:69","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.70 编辑器 micro - 基于终端的编辑器 sourcegraph - 代码搜索\u0026导航 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:70","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.71 运行器 gore - 在线运行 Go 代码 nodebook - 在线运行多种语言 go-pry - 像 Python、R、PHP 等在终端交互式输入与运行 Go 代码 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:71","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.72 查询语言 graphql - Go 实现的 GraphQL graphql-go GQLEngine - 基于 graphql-go 实现 RQL - REST 资源查询语言 Thunder - GraphQL 服务构建框架 gqlgen - 构建 GraphQL 服务器的包 super-graph - 无需编写代码即可在 Go 项目中构建复杂的 GraphQL API ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:72","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.73 游戏相关 Nano - 游戏开发框架 Leaf einx CloudRetro - 游戏云服务框架 G3N - Go 3D Game Engine Ebiten - 2D 游戏库 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:73","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.74 桌面开发 10.74.1 GUI Lorca - 用 Go 编写 HTML5 桌面程序，依赖 Chrome 进行 UI 渲染，但却不把 Chrome 打包到应用中 webview - 用 Go/C/C++ 构建跨平台的桌面软件 walk - Windows GUI toolkit go-gtk - Go bindings for GTK andlabs/ui - Platform-native GUI library for Go fyne - Material Design 风格的 GUI go-gl - Go bindings for OpenGL (generated via glow) therecipe/qt - 基于 Qt 的跨全平台 UI 包 giu - 基于 Dear ImGui 的跨平台 GUI 框架 go-app - 一个 WebAssembly 框架，用于使用 Go，HTML 和 CSS 构建 GUI 应用 wails - 使用 Go 和 Web 技术创建桌面应用程序 chromedp - 纯 Go 语言实现的驱动浏览器的 Chrome DevTools Protocol，可用于爬虫、反爬虫、测试等场景 Rod - 一个为简化自动化和爬虫设计的 devtools driver，利用浏览器的 devtools 可编程接口来操控浏览器 go-astilectron - 基于 Electron 的跨平台开发 Gio - 跨平台 UI 框架，支持移动应用 nucular - 基于 Gio 的实现 GoVCL - 跨平台的 GUI 包 vugu - WebAssembly UI 框架 GoGi - 2D/3D GUI 框架 systray - 跨平台支持菜单栏管理 go-flutter - 绑定 Flutter 到桌面应用 NuxUI 10.74.2 桌面辅助包 pkg/browser - 在浏览器中打开文件、URL MacDriver - macOS 原生 API gon - 为 macOS 签名和公证 10.74.3 桌面应用 xbar - 基于 Wails.app 开发的 macOS 菜单栏管理 阿里云盘小白羊版 - UI由Flutter构建 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:74","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.75 移动端 golang/mobile - Go support for Mobile devices ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:75","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.76 协程/线程 ants - 协程池 tunny go-workers - 安全地并发运行一组 worker，通过 channel 进行输入输出 Machine - 受 errgroup.Group 启发的协程管理 thread conc - 更好用的结构化并发控制 zeropool - 零回收、类型安全的协程池 workerpool - 无阻塞队列任务池 pond - 协程池 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:76","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.77 任务/定时器 RxGo - Go 版 ReactiveX，简单方便的处理异步数据流 Grift - Go based task runner cron - a cron library for go gocron - 任务定时调度器 jobrunner CurlyQ - 后台任务处理库 overtalk/task - 任务的管理\u0026执行，支持自定义次数的重发 PPGo_Job - 定时任务管理系统 gocelery - Celery 的 Go 语言实现 Machinery - 通过分布式消息实现异步任务调度 dkron - 分布式任务调度系统 Grit - 基于 MultiTree 实现的任务管理 Asynq - 异步分布式任务队列 cronsun - 分布式任务系统 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:77","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.78 流处理 benthos gostream watermill go-streams goflow Cadence (Cadence Web UI) - Uber开源的分布式工作流引擎，主要用于微服务编排和分布式事务等场景 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:78","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.79 微信 weapp - 微信小程序 SDK wechat - WeChat SDK for Go wechat-go - 微信 Web 版 API 的 Go 实现 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:79","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.80 SDK gopay - QQ、微信（WeChat）、支付宝（AliPay）的Go版本SDK alipay - 支付宝SDK ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:80","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.81 区块链 Hyperledger Fabric - 基于区块链的超级账本 go-ethereum - 以太坊协议的官方 Go 语言实现 bbgo - 用 Go 编写的加密货币交易框架 btcd - 比特币实现 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:81","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.82 开发辅助包 cvt - 任意数据类型转换，支持自定义类型、提取结构体字段和值 copier - struct 之间拷贝值 cast - 数据类型转换 diff - 结构体\u0026值比较 go-extend com - 工具包 php2go - Go 实现的 140+ 个 PHP 函数功能包 gommon - Common packages for Go reflect2 - reflect api without runtime reflect.Value cost mapstructure - 将 map 值转换到结构体中 naza - Go语言基础库 automaxprocs - 自动设置 GOMAXPROCS c2go - 将 C 代码转换为 Go 代码的工具 rnm - 代码重构辅助工具 memviz - 图形化数据结构 underscore.go go-testdeep - 非常灵活的深度比较包，扩展了 Go 测试包 go-model - struct 操作包 concurrent-map - 并发安全 map goleak - 检测 goroutine 泄漏 guregu/null - SQL/JSON的null处理包，提供替代类型 stats - 标准数字统计 Chronos - 静态竞争检测器 collection - 替代原生的 Slice rf - 代码重构工具 bytebufferpool - byte buffers pool bpool - byte buffers pool，支持 bytes.Buffers mergo - 合并结构体和字典数据 go-funk - 基于反射实现的常用函数 lo - 基于 1.18+ 泛型的常用函数 juniper - 基于泛型实现常用的容器、迭代器、数据流等功能 mergo - 合并结构体和字典 xstrings - 字符串相关函数 pie - slice/map 链式处理 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:82","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.83 代码生成 ChimeraCoder/gojson - 根据 JSON 生成结构体 db2struct - 根据表结构生成结构体 smallnest/gen - 根据表结构生成结构体 sqlc - 根据 SQL 语句生成 Go 代码 xo - 根据表结构或查询语句自动生成 Go 代码 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:83","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.84 系统开发 LinuxKit - 为容器构建安全、便携、可移植操作系统的工具包 go-systemd - 绑定 systemd Lima - Linux-on-Mac (“macOS subsystem for Linux”, “containerd for Mac”) gopher-os - 一个兼容 Linux 的 64 位 POSIX 风格系统 gouring - 不依赖 CGO 实现系统调用 ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:84","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"10.85 未归类 go-playground - 比官方更好用的 Go Playground Robotgo - Golang 跨平台自动化系统，控制键盘鼠标位图和读取屏幕，窗口句柄以及全局事件监听 go-homedir i18n - i18n 多语言工具包 go-i18n - 多语言工具包 Paginater - 分页工具 gls - Goroutine local storage mcuadros/go-version - 版本号比较 go-semver - 语义版本 semver - 另一个语义版本 hashicorp/go-version Metabolize - Decodes HTML meta tags into a Golang struct otp - 一次性密码工具包(One Time Password utilities) misspell - 常拼写错误的英语单词 CRDT - CRDT(Convergent and Commutative Replicated Data Types)最终一致性算法的实现 script - Making it easy to write shell-like scripts in Go sysadmin-utils licenseclassifier - 识别文件中的 LICENSE 类型 go-license-detector rose - 在 HTML 中嵌入和运行 Go 代码 esbuild - JavaScript 构建打包工具 clipboard - 剪切板 clipboard - 剪切板 clipboard - 剪切板 Timeliner - 搜集整理个人在社交网站上的数据并索引成时间线 hc - HomeKit 平台开发框架 address - 地址处理库，支持多国语言 webhook - 可执行 Shell 命令的 Web Hook 服务 webhookd - 为 Shell 脚本提供 Web Hook 服务 go-cid - CID spec Go 语言实现 gorush - APP 消息通知服务 EventBus - 事件总线 go-winio - 为 Win32 IO 操作提供接口支持 fq - 以 jq 语法读取二进制数据/文件 lego - Let’s Encrypt client and ACME library ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:10:85","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"11 logo Gophers ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:11:0","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"12 工具 syndbg/goenv - Go 版本管理 wfarr/goenv - Go 版本管理 gvm - Go 版本管理 GoLand - IDE 软件 Visual Studio Code ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:12:0","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏"],"content":"13 资源站点 Go 101 Go 语言中文网 Golang 中国 go-zh Golang sizeof tips - 输入结构体定义，会显示内存布局 Golang Programs Golang bot ","date":"2023-12-15","objectID":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/:13:0","tags":["Go"],"title":"Go 语言优秀资源整理，为项目落地加速🏃","uri":"/posts/03.go%E4%BC%98%E7%A7%80%E8%B5%84%E6%BA%90/"},{"categories":["资源收藏","设计模式"],"content":"23种设计模式分类如下： 模式类型 描述 包括的模式 创建型模式 这些设计模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new 运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活。 工厂模式（Factory Pattern） 抽象工厂模式（Abstract Factory Pattern） 单例模式（Singleton Pattern） 建造者模式（Builder Pattern） 原型模式（Prototype Pattern） 结构型模式 这些设计模式关注类和对象的组合。继承的概念被用来组合接口和定义组合对象获得新功能的方式。 适配器模式（Adapter Pattern） 桥接模式（Bridge Pattern） 过滤器模式（Filter、Criteria Pattern） 组合模式（Composite Pattern） 装饰器模式（Decorator Pattern） 外观模式（Facade Pattern） 享元模式（Flyweight Pattern） 代理模式（Proxy Pattern） 行为型模式 这些设计模式特别关注对象之间的通信，即对象之间的行为。 责任链模式（Chain of Responsibility Pattern） 命令模式（Command Pattern） 解释器模式（Interpreter Pattern） 迭代器模式（Iterator Pattern） 中介者模式（Mediator Pattern） 备忘录模式（Memento Pattern） 观察者模式（Observer Pattern） 状态模式（State Pattern） 空对象模式（Null Object Pattern） 策略模式（Strategy Pattern） 模板模式（Template Pattern） 访问者模式（Visitor Pattern） 设计模式的六大原则是软件设计中的基石，它们为构建灵活、易于维护和升级的软件系统提供了指导。以下是对这六大原则的简要说明： 开闭原则（Open Close Principle）： 意义：对扩展开放，对修改关闭。即在需要进行拓展时，不修改原有代码，实现热插拔的效果。 实现方式：使用接口和抽象类，通过抽象化来保持程序的扩展性，易于维护和升级。 里氏代换原则（Liskov Substitution Principle）： 意义：任何基类可以出现的地方，子类一定可以出现。基类能够被派生类替换，且不影响软件单位的功能，实现真正的复用。 补充关系：是对开闭原则的补充，通过继承关系实现对抽象化的具体步骤规范。 依赖倒转原则（Dependence Inversion Principle）： 基础：是开闭原则的基础。具体内容为针对接口编程，依赖于抽象而不依赖于具体。 接口隔离原则（Interface Segregation Principle）： 意义：使用多个隔离的接口比使用单个接口更好，降低类之间的耦合度。 设计思想：从大型软件架构出发，强调降低依赖，降低耦合。 迪米特法则，又称最少知道原则（Demeter Principle）： 定义：一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。 合成复用原则（Composite Reuse Principle）： 意义：尽量使用合成/聚合的方式，而不是使用继承。通过组合而非继承实现代码复用，增强系统的灵活性。 这些原则提供了一种指导思想，帮助开发人员设计出具有弹性、可维护性和可扩展性的软件系统。通过遵循这些原则，可以有效应对软件变化，提高代码质量和可维护性。 以下是部分语言实现设计模式的仓库，以供学习。 Go Java C++ Python JavaScript ","date":"2023-12-14","objectID":"/posts/02.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%AE%9E%E7%8E%B0%E6%A8%A1%E7%89%88/:0:0","tags":["设计模式"],"title":"遵循最佳实践，各种语言实现设计模式的模版","uri":"/posts/02.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%AE%9E%E7%8E%B0%E6%A8%A1%E7%89%88/"},{"categories":["资源收藏"],"content":" The Algorithms提供 GitHub 最大的开源算法库。 The Algorithms 官方网站 The Algorithms Github仓库 以下是部分语言实现数据和算法的仓库，以供学习。 Go Java C++ C Python JavaScript ","date":"2023-12-14","objectID":"/posts/01.%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E6%A8%A1%E7%89%88/:0:0","tags":["算法"],"title":"遵循最佳实践，各种语言实现数据结构和算法的模版","uri":"/posts/01.%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E6%A8%A1%E7%89%88/"},{"categories":["课程笔记"],"content":"1 定义 数域定义 数域$F$，是至少包含$0$和$1$的数集，并满足以下性质： $\\forall a\\in F, -a\\in F$ $\\forall b\\in F(b\\neq 0), b^{-1}\\in F$ $\\forall a, b\\in F, a+b\\in F$ $\\forall a,b\\in F, a\\cdot b\\in F$ 矩阵论中最常用到的两个数域是$R$（实数域）和$C$（复数域） 代数系统定义 代数系统通常是定义了一些运算和运算规则的集合。描述一个代数系统需要： 一组元素 运算 运算规则 几何向量定义 有大小有方向的量，可以用有向线段表示，如$\\vec{\\alpha}$。有加法和数乘运算。 向量空间定义 一个域 $F$（底域）上的向量空间（线性空间或线性向量空间）$V$ 是一组元素（称为向量）以及加法和标量乘法这两种运算，并满足以下条件： 闭包性 $\\forall x,y\\in V, x+y\\in V$，且$x+y$运算结果唯一 $\\forall a\\in F,x\\in V, a\\cdot x\\in V$，且$a\\cdot x$运算结果唯一 加法公理 交换律：$\\forall x,y\\in V, x+y=y+x$ 结合律：$\\forall x,y,z\\in V, x+(y+z)=(x+y)+z$ 存在零向量：$\\forall x\\in V,x+0=0+x=x$ 存在相反向量：$\\forall x\\in V,\\exist (-x)\\in V,x+(-x)=0$ 标量乘法公理 结合律：$\\forall a,b\\in F, x\\in V,a\\cdot (b\\cdot x)=(ab)\\cdot x$ 分配律$1$：$\\forall a\\in F, x,y\\in V,a\\cdot(x+y)=a\\cdot x+a\\cdot y$ 分配律$2$：$\\forall a,b\\in F, x\\in V,(a+b)\\cdot x=a\\cdot x + b\\cdot x$ 存在单位元素：$\\forall x\\in V,1\\cdot x=x$ 向量空间重点 定义一个向量空间需要：一个集合$V$，一个数域$F$，两种运算，八种运算规则。 常见向量空间 $R^{m\\times n},(R^{m\\times 1}=R^m)$：$m\\times n$的实数矩阵集合，在$R$上的向量空间 $C^{m\\times n},(C^{m\\times 1}=R^m)$：$m\\times n$的复数矩阵集合，在$C$上的向量空间 $C_{[a,b]}$：闭区间上的连续函数集合，在$R$上的向量空间 $P_n$：次数小于 $n$ 的实多项式的集合，在$R$上的向量空间 ","date":"2023-12-01","objectID":"/posts/01.%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4/:1:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 1—向量空间知识点总结复习","uri":"/posts/01.%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4/"},{"categories":["课程笔记"],"content":"2 子空间 子空间定义 如果$S$是向量空间$V$在数域$F$上的一个非空子集，且满足闭包性，则$S$就是$V$的一个子空间。 由$V$的零向量所组成的自己${0}$是$V$的一个子空间，称为零子空间，向量空间$V$本身也是$V$的一个子空间，它们都称为$V$的平凡子空间，$V$的其他子空间称为非平凡子空间。 子空间重点 $V$ 的子空间 $S$ 以及 $V$ 的加法和标量乘法运算满足向量空间定义中的所有条件。因此，向量空间的每个子空间本身就是一个向量空间。$S$ 的底层域与 $V$ 的底层域相同。 零空间定义 设$A\\in F^{m\\times n},N(A)={x\\in F^n|Ax=0}$，则$N(A)$为$F^n$的子空间，$N(A)$称为$A$的零空间。 向量的线性相关性 设$V$是数域$F$上的线性空间，$a_1,\\cdots,a_n\\in F,v_1,\\cdots,v_n\\in V$，则$a_1v_1+\\cdots+a_nv_n$就是$v_1,\\cdots,v_n$的线性组合。 若存在$n$个不全为零的数$a_1,\\cdots,a_n\\in F$，使得$a_1v_1+\\cdots+a_nv_n=0$，则称$v_1,\\cdots,v_n$线性相关，否则就称为线性无关。 线性相关的充要条件是其中有一个向量是其余向量的线性组合 生成集定义 $span(K)={v|v\\texttt{是向量}K\\texttt{的一个线性组合}}$，即为向量$K$的线性组合生成的集合。如果$K$是向量空间$V$中的有限集，那么$span(K)$也就是$V$的子空间。 如果$v_1,\\cdots,v_n$是向量空间$V$的向量，且$V=span{v_1,\\cdots,v_n}$，则集合${v_1,\\cdots,v_n}$称为$V$的生成集。 子空间的交集、和 设$U_1,U_2$为向量空间$V$的子空间，则$U_1\\cap U_2={v|v\\in U_1, v\\in U_2}$，$U_1\\cap U_2$也是$V$的子空间。 设$U_1,U_2$为向量空间$V$的子空间，则$U_1+U_2={v_1+v_2|v_1\\in U_1,v_2\\in U_2}$，$U_1+ U_2$也是$V$的子空间。 如果$U_1=span(u_1,\\cdots_,u_k),U_2=span(w_1,\\cdots,w_s)$，则$U_1+U_2=span(u_1,\\cdots,u_k,w_1,\\cdots,w_s)$。 子空间的直和 设$V_1,V_2$是向量空间$V$的两个子空间，如果和$V_1+V_2$中每一个向量$\\alpha$可唯一表示成$\\alpha=\\alpha_1+\\alpha_2,\\alpha_1\\in V_1,\\alpha_2\\in V_2$，则称和$V_1+V_2$为直和，记为$V_1+V_2$。 和$V_1+V_2$是直和$\\Longleftrightarrow$和$V_1+V_2$中零向量的表示法唯一，即若$\\alpha_1+\\alpha_2=0(\\alpha_1\\in V_1,\\alpha_2\\in V_2)$，则$\\alpha_1=0,\\alpha_2=0\\Longleftrightarrow V_1\\cap V_2={0}\\Longleftrightarrow\\dim(V_1+V_2)=\\dim(V_1)+\\dim(V_2)$ 补空间定义 如果$V=V_1\\oplus V_2 $，我们则称$V_1$和$V_2$互为补空间，即$V_1$是$V_2$的补。 补空间定理 如果$U$是$V$的子空间，则存在$V$的子空间$W$，使得$V=U\\oplus W$ ","date":"2023-12-01","objectID":"/posts/01.%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4/:2:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 1—向量空间知识点总结复习","uri":"/posts/01.%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4/"},{"categories":["课程笔记"],"content":"3 基、坐标和维数 基、坐标定义 $n$个向量$v_1,\\cdots,v_n$是向量空间$V$的一组基，当且仅当： $v_1,\\cdots,v_n$线性无关 $V=span(v_1,\\cdots,v_n)$ 基不是唯一的，但$V$的所有基中的向量个数是相同的 设$a$是$V$中的任一向量，则$a$可以唯一的表示为基$v_1,\\cdots,v_n$的线性组合$a=k_1v_1+\\cdots+k_nv_n$，其中系数$k_1,\\cdots,k_n$称为$a$在基$v_1,\\cdots,v_n$下的坐标，记为$(k_1,\\cdots,k_n)^T$。 维数定义 如果向量空间$V$的基由$n$个向量组成，则我们称$V$的维数是$n$。 定理 在$n$维线性空间$V$中，任意一个线性无关的向量组$a_1,\\cdots,a_r$都可以扩充为$V$的一组基。 维数公式 设$U_1,U_2$为向量空间$V$的两个子空间，则 $\\dim(U_1+U_2)=\\dim(U_1)+\\dim(U_2)-\\dim(U_1\\cap U_2)$ ","date":"2023-12-01","objectID":"/posts/01.%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4/:3:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 1—向量空间知识点总结复习","uri":"/posts/01.%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4/"},{"categories":["课程笔记"],"content":"4 基变换 过渡矩阵 设$u_1,\\cdots,u_n$与$v_1,\\cdots,v_n$是$n$维线性空间$V$的两组基，则有如下关系 关系式用矩阵表示为 $n$阶矩阵 称为由基$u_1,\\cdots,u_n$到基$v_1,\\cdots,v_n$的过渡矩阵。 ","date":"2023-12-01","objectID":"/posts/01.%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4/:4:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 1—向量空间知识点总结复习","uri":"/posts/01.%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4/"},{"categories":["课程笔记"],"content":"5 行空间和列空间 矩阵的秩 如果矩阵$A$的秩为$r$，则说明： 存在一个$r×r$子矩阵，其行列式不为零；和 所有的 $(r+1)\\times (r+1)$ 的子矩阵的行列式为零。 行空间和列空间 设$A\\in F^{m\\times n}$ 行空间：由$A$的行向量生成的$F^{1\\times n}$的子空间。（也为$A^T$的列空间） 列空间：由$A$的列向量生成的$F^{m\\times 1}$的子空间。（也为$A^T$的行空间） 行等价条件 矩阵$A$和$B$被称为是行等价$\\Longleftrightarrow$$B$可以由$A$进行初等行变换得到。 特别地，对于非奇异矩阵，有充要条件是存在一个非奇异矩阵$M$使得，$MA=B$。 行等价性质 设矩阵$A,B$是两个行等价的矩阵，则： 它们有相同的行空间。 如果$A$中的列向量$a_{i_1},\\cdots,a_{i_k}$是线性无关的，则$B$中的列向量$b_{i_1},\\cdots,b_{i_k}$也是线性无关的 列空间性质 线性系统$Ax=b$相容（有解）$\\Longleftrightarrow$$b$在$A$的列空间里 $Ax=b$相容当且仅当$rank(A)=rank(A,b)$，即等价于$A$的列空间等于$(A,b)$的列空间 如果$\\forall b\\in F^m$，$Ax=b$相容，说明$A$的列空间是$F^m$。 如果$\\forall b,Ax=b$至多只有一个解，说明$A$的列向量是线性无关的，则$A$的列向量是$A$的列空间的基，等价于$A$是非奇异矩阵。 秩——零度定理 设$A$为$m\\times n$矩阵，则$rank(A)+rank(N(A))=0$ 秩和维数 设$A$是$m\\times n$矩阵，$A$的行空间维数等于$A$的列空间维数，即$\\dim(R(A^T))=\\dim(R(A))$，其中$R(A^T)$表示$A^T$的列空间，即$A$的行空间。 虽然矩阵$A$的行空间和列空间不相同，但是它们有相同的维数，都为$A$的秩，矩阵$A$在初等变换下秩是不变的。 ","date":"2023-12-01","objectID":"/posts/01.%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4/:5:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 1—向量空间知识点总结复习","uri":"/posts/01.%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4/"},{"categories":["课程笔记"],"content":"1 内积空间 内积空间定义 设$V$是在数域$F$上的向量空间，则$V$到$F$的一个代数运算记为$(\\alpha,\\beta)$。如果$(\\alpha,\\beta)$满足以下条件： $(\\alpha,\\beta)=\\overline{(\\beta,\\alpha)}$（$\\overline{}$表示共轭符，针对复数域，为了保证复数运算的正确性） $(\\alpha+\\beta,\\gamma)=(\\alpha,\\gamma)+(\\beta,\\gamma)$ $(k\\alpha,\\beta)=k(\\alpha,\\beta)$ $(\\alpha,\\alpha)\\geq 0$，当且仅当$\\alpha=0$时，$(\\alpha,\\alpha)=0$。 其中$k\\in F,\\alpha,\\beta,\\gamma\\in V$。则称$(\\alpha,\\beta)$为$\\alpha$和$\\beta$的内积。定义了内积的向量空间$V$称为内积空间。特别地，称实数域$R$上的内积空间$V$为Euclid空间（欧式空间）；称复数域$C$上的内积空间$V$为酉空间。 标准内积 在实数域$R$上的$n$维向量空间$R^n$中，对向量$x=(x_1,\\cdots,x_n)^T,y=(y_1,\\cdots,y_n)^T$，定义内积 在复数域$C$上的$n$维向量空间$C^n$，对向量$x=(x_1,\\cdots,x_n)^T,y=(y_1,\\cdots,y_n)^T$，定义内积 其中$y^H$表示$y$的共轭转置。 以上两个内积我们称为$R^n$或$C^n$的标准内积，一般我们探讨的也就是标准内积。 重要定义 设$u,v$是内积空间$V$的向量 则$v$的长度或范数为：$||v||=\\sqrt{(v,v)}$，长度为$1$的称为单位向量。如果$v\\neq 0$，则$\\frac{v}{||v||}$是一个单位向量 如果$v\\neq 0$，则$u$在$v$上的数量投影被定义为：$\\alpha=\\frac{(u,v)}{||v||}$，$u$在$v$上的向量投影被定义为：$p=\\alpha\\frac{v}{||v||}=\\frac{(u,v)}{(v,v)}v$ 如果$(u,v)=0$，则称$u$和$v$正交 内积的基本性质 设$u,v\\in V$，其中$V$是内积空间，则 勾股定理：如果$u\\perp v$，则$||u-v||^2=||u||^2+||v||^2$ 证明： 柯西不等式：$|(u,v)|\\leq ||u||\\space ||v||$。等式成立当且仅当$u$和$v$线性相关。 证明： 如果$u,v$线性相关，则设$u=kv,k\\in F$，则$(u,v)=(kv,v)=k||v||^2$ 如果$u,v$线性无关，设$z=u-\\frac{(u,v)}{(v,v)}v$，则$(z,v)=(u-\\frac{(u,v)}{(v,v)}v,v)=(u,v)-\\frac{(u,v)}{(v,v)}(v,v)=0$，则$z$和$v$正交。转换得到$u=z+\\frac{(u,v)}{(v,v)}v$，根据正交性，结合勾股定理则$||u||^2=||z||^2+|\\frac{(u,v)}{(v,v)}|^2||v||^2=||z||^2+\\frac{|(u,v)|^2}{(||v||^2)^2}||v||^2=||z||^2+\\frac{|(u,v)|^2}{||v||^2}$ 又因为$||z||^2\u003e 0$（线性无关，$||z||^2$必大于$0$），则$|(u,v|\u003c||u||\\space ||v||$ 三角不等式：$||u+v||^2\\leq ||u||^2+||v||^2$ 证明： 平行四边形准则：$||u+v||^2+||u-v||^2=2(||u||^2+||v||^2)$ 证明： ","date":"2023-12-01","objectID":"/posts/02.%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4/:1:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 2—内积空间知识点总结复习","uri":"/posts/02.%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4/"},{"categories":["课程笔记"],"content":"2 标准正交向量集 正交向量集定义 设$v_1,\\cdots,v_n$是内积空间$V$中的非零向量，如果$V$中的任意两个向量$(v_i,v_j)=0(i\\neq j)$，则$V$是一个正交向量集。 标准正交向量集定义 如果$V$是一个正交向量集，且$V$中的所有向量都是单位向量，即$(v_i,v_i)=1$，则$V$是一个标准正交向量集。 正交向量集性质 如果$v_1,\\cdots,v_n$是内积空间$V$的一个正交向量集，则$v_1,\\cdots,v_n$都是线性无关的。 正交基和标准正交基 在$n$维内积空间中，由$n$个正交向量组成的基称为正交基，由$n$个标准正交向量组成的基称为标准正交基。 标准正交基表示向量坐标 设$u_1,\\cdots,u_n$是内积空间$V$的一个标准正交基，如果$v=\\sum_{i=1}^nc_iu_i$，则$c_i=(v,u_i)$其中$c_i$为向量$v$在向量$u_i$的标量投影。 Parseval公式 设$u_1,\\cdots,u_n$是内积空间$V$的一个标准正交基，如果$u=\\sum_{i=1}^na_iu_i,v=\\sum_{i=1}^nb_iu_i$，则$(u,v)=\\sum_{i=1}^na_i\\bar{b_i}$。并且，$||v||^2=\\sum_{i=1}^n b_i\\bar{b_i}=\\sum_{i=1}^n|b_i|^2$。 正交投影向量定义 如果$S$是内积空间$V$的子空间，令$b\\in V$，如果存在向量$p\\in S,q$，使得$q\\perp S,b=p+q$，则称$p$是$b$在子空间$S$上的正交投影向量。 设$u_1,\\cdots ,u_n$为$S$的标准正交基，如果$p=\\sum_{i=1}^n(b,u_i)u_i$，则 $b-p$与$s$的任意一个向量正交 $p$是$S$中唯一一个最接近$b$的向量。也就是说$\\forall y\\in S,y \\neq p$，有$||y-b||\u003e||p-b||$。向量$p$是$b$在子空间$S$上的正交投影向量。 投影矩阵 设$S$是内积空间$F^n$的非零子空间，$b\\in F^n$，$u_1,\\cdots,u_n$为$S$的标准正交基，$U={u_1,\\cdots,u_n}$，则$b$在子空间$S$的正交投影$p=UU^Hb$，其中$U$则是投影矩阵。 ","date":"2023-12-01","objectID":"/posts/02.%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4/:2:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 2—内积空间知识点总结复习","uri":"/posts/02.%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4/"},{"categories":["课程笔记"],"content":"3 Gram-Schmidt正交化方法 设$\\alpha_1,\\cdots,\\alpha_n$是向量空间$V$的线性无关向量组。我们按照以下步骤标准正交化得到标准正交向量组$\\beta_1,\\cdots,\\beta_n$ 单位化向量$\\alpha_1$，得到$\\beta_1=\\frac{\\alpha_1}{||\\alpha_1||}$。易知$span(\\alpha_1)=span(\\beta_1)$。 找到$\\alpha_2$在$span(\\beta_1)$上的向量投影$p_1=(\\alpha_2,\\beta_1)\\beta_1$，根据推导可知$\\alpha_2-p_1$和$span(\\beta_1)$正交。我们对其单位化得到$\\beta_2=\\frac{\\alpha_2-p_1}{||\\alpha_2-p_1||}$。易得$span(\\alpha_1,\\alpha_2)=span(\\beta_1,\\beta_2)$。 找到$\\alpha_3$在$span(\\beta_1,\\beta_2)$上的向量投影$p_2=(\\alpha_3,\\beta_1)\\beta_1+(\\alpha_3,\\beta_2)\\beta_2$，根据推导可知$\\alpha_3-p_2$和$span(\\beta_1,\\beta_2)$正交。我们对其单位化得到$\\beta_3=\\frac{\\alpha_3-p_2}{||\\alpha_3-p_2||}$。易得$span(\\alpha_1,\\alpha_2,\\alpha_3)=span(\\beta_1,\\beta_2,\\beta_3)$。 如上进行操作，$\\alpha_i$在$S_{i-1}=span(\\alpha_1,\\cdots,\\alpha_i)=span(\\beta_1,\\cdots,\\beta_i)$的向量投影$p_{i-1}=(\\alpha_i,\\beta_1)\\beta_1+\\cdots+(\\alpha_i,\\beta_{i-1})\\beta_{i-1}$，则$\\alpha_i-p_{i-1}$和$S_{i-1}$正交。所以对其单位化得到$\\beta_i=\\frac{\\alpha_i-p_{i-1}}{||\\alpha_i-p_{i-1}||}$。易得$span(\\alpha_1,\\cdots,\\alpha_{i})=span(\\beta_1,\\cdots,\\beta_{i})$。 直到求得$\\beta_n$，得到标准正交向量组$\\beta_1,\\cdots,\\beta_n$ ","date":"2023-12-01","objectID":"/posts/02.%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4/:3:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 2—内积空间知识点总结复习","uri":"/posts/02.%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4/"},{"categories":["课程笔记"],"content":"4 正交子空间 正交子空间定义 $X,Y$是内积空间$V$的子空间，如果$\\forall x\\in X,y\\in Y$，$(x,y)=0$，则$X$和$Y$正交，我们记作$X\\perp Y$。 正交补定义 设$Y$是内积空间$V$的子空间，则$V$中与$Y$的每个向量正交的所有向量称为$Y^{\\perp}$，$Y^\\perp ={x\\in V|\\forall y\\in Y,(x,y)=0 }$。 正交子空间定理 如果$V_1$和$V_2$正交，则$V_1+V_2$的和为直和。 正交补性质 设$S$为有限维内积空间$V$的子空间，则： $V=S\\oplus S^\\perp$。并且如果$V=S\\oplus W,W\\perp S$，则$W=S^\\perp$。 $(S^{\\perp})^{\\perp}=S$ 向量到子空间的最小距离 设$S$为有限维内积空间$V$的子空间，$\\forall b\\in V$，则$S$ 中的给定向量 $p$ 与给定向量$b$ 最接近，当且仅当$b-p\\perp S^{\\perp}$。即$p$是$b$在$S$上的向量投影。 矩阵的基本子空间 设$A$为$m\\times n$矩阵，则 $N(A)={x\\in F^n|Ax=0}$：$A$的零空间，$F^n$的子空间。 $R(A)={Ax|x\\in F^n}$：$A$的列空间，$F^m$的子空间。 $N(A^H)$：$A^H$的零空间，$F^m$的子空间。 $R(A^H)$：$A^H$的列空间，$F^n$的子空间。 $N(A)=R(A^H)^\\perp,N(A^h)=R(A)^\\perp$ $F^n=N(A)\\oplus N(A)^\\perp=N(A)\\oplus R(A^H)$ $\\dim(F^n)=\\dim(N(A))+\\dim(R(A^H))$ ","date":"2023-12-01","objectID":"/posts/02.%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4/:4:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 2—内积空间知识点总结复习","uri":"/posts/02.%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4/"},{"categories":["课程笔记"],"content":"5 最小二乘问题 问题定义 设线性系统$Ax=b$，其中$A\\in F^{m\\times n}$，可能不相容（无解）。我们能否找到一个最佳解，即向量$\\hat{x}$使得$A\\hat{x}-b=\\min_{x\\in F^n}||Ax-b||$ 问题核心 找到向量$\\hat{x}$即是使得$A\\hat{x}$等于$b$在$R(A)$上的向量投影。 最小二乘解等价条件 $\\hat{x}$是$Ax=b$的最小二乘解 $A\\hat{x}-b=\\min_{x\\in F^n}||Ax-b||$ $A\\hat{x}$等于$b$在$R(A)$上的正交向量投影 $A\\hat{x}-b\\in R(A)^\\perp =N(A^H)$ $A^H(A\\hat{x}-b)=0$ $A^HA\\hat{x}=A^Hb$（正规方程） 正规方程的相容性 设$A\\in F^{m\\times n}$，则正规方程$A^HAx=A^Hb$有解，其为$Ax=b$的最小二乘解。 最小二乘解不唯一，但是对于任意解$x,y$，$Ax=Ay$，且$Ax$和$Ay$都是$b$在$R(A)$上的向量投影。 最小二乘解唯一解 设$A\\in F^{m\\times n}$，且$rank(A)=n$（列满秩），$b\\in F^n$，则正规方程$A^HAx=A^Hb$有唯一解$\\hat{x}=(A^HA)^{-1}A^Hb$。$\\hat{x}$为$Ax-b$的唯一最小二乘解。 ","date":"2023-12-01","objectID":"/posts/02.%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4/:5:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 2—内积空间知识点总结复习","uri":"/posts/02.%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4/"},{"categories":["课程笔记"],"content":"6 正交矩阵和酉矩阵 正交矩阵定义 设$A\\in R^{n\\times n}$，$A$的所有列向量构成$R^n$的标准正交集，具有$R^n$上的标准内积。 酉矩阵定义 设$A\\in C^{n\\times n}$，$A$的所有列向量构成$C^n$的标准正交集，具有$C^n$上的标准内积。 易知，正交矩阵也是酉矩阵。 正交矩阵和酉矩阵的充要条件 $A$是正交矩阵当且仅当$A^TA=I$ $A$是酉矩阵当且仅当$A^HA=I$ 若$A\\in C^{n\\times n}$，则以下条件等价 $A$是酉矩阵 $A$的列向量构成$C^n$的标准正交集 $A^HA=I$ $A^{-1}=A^H$ $\\forall x,y \\in C^n,(Ax,Ay)=(x,y)$ $\\forall x\\in C^n,(Ax,Ax)=(x,x)$ ","date":"2023-12-01","objectID":"/posts/02.%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4/:6:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 2—内积空间知识点总结复习","uri":"/posts/02.%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4/"},{"categories":["课程笔记"],"content":"1 线性映射及其矩阵表示 映射定义 设$A,B$是两个集合，如果存在一个规则$f$，使得对于$A$中的元素$x$都有$B$中唯一的元素$y$与之对应，则称$f$是从$A$到$B$的映射，记作：$f:A\\rightarrow B$。在映射$f:A\\rightarrow B$中，$A$的元素$x$被映射到$B$的元素$y$，我们通常写作$f(x)=y$， 如果$\\forall x_1,x_2\\in A,x_1\\neq x_2,f(x_1)\\neq f(x_2)$，则称映射$f:A\\rightarrow B$是单射的； 如果$\\forall y\\in B,\\exist x\\in A,f(x)=y$，则称映射$f:A\\rightarrow B$是满射的； 如果映射$f:A\\rightarrow B$既满足单射又满足满射，则称映射$f:A\\rightarrow B$是双射的。 线性映射定义 设$V,W$是在数域$F$上的向量空间，如果$\\forall v_1,v_2\\in V,\\forall \\alpha_1,\\alpha_2\\in F$有$\\sigma(\\alpha_1v_1+\\alpha_2v_2)=\\alpha_1\\sigma(v_1)+\\alpha_2\\sigma(v_2)$，则从$V$到$W$的映射$\\sigma$称为线性映射。 线性映射定理 设$\\sigma,\\gamma$是线性空间$V$到$W$的线性映射，则： $\\sigma(0)=0$ $\\forall x\\in V_1,\\sigma(-x)=-\\sigma(x)$ 如果$x_1,\\cdots,x_n$是$V_1$的一组向量，$k_1,\\cdots,k_n\\in F$，则有 $\\sigma(k_1x_1+\\cdots+k_nx_n)=k_1\\sigma(x_1)+\\cdots+k_n\\sigma(x_n)$ 如果$x_1,\\cdots,x_n$是$V_1$的一组线性相关向量，则$\\sigma(x_1),\\cdots,\\sigma(x_n)$是$V_2$中的一组线性相关向量；并且当且仅当$\\sigma$是一一映射时，$V_1$中的线性无关向量组的像（像即是线性映射的值域）是$V_2$中的线性无关向量组。 如果$v_1,\\cdots,v_n$是$V$的一组基，且$\\sigma(v_i)=\\gamma(v_i)(1\\leq i\\leq n)$，则$\\sigma=\\gamma$。说明线性映射由基像组唯一确定。 线性映射运算 设$V_1$到$V_2$的所有线性映射组成的集合记为$\\varphi(V_1,V_2)$，类似地，$\\varphi(V_1,V_3),\\varphi(V_2,V_3)$分别表示$V_1$到$V_3$的所有线性映射组成的集合和$V_2$到$V_3$的所有线性映射组成的集合 设$\\sigma,\\gamma \\in \\varphi(V_1,V_2)$，定义它们的和$\\sigma+\\gamma$为$(\\sigma+\\gamma)(x)=\\sigma(x)+\\gamma(x),\\forall x\\in V_1$。 $\\sigma,\\gamma \\in \\varphi(V_1,V_2)$，则$\\sigma+\\gamma \\in \\varphi(V_1,V_2)$ $\\sigma\\in \\varphi(V_1,V_2),\\gamma \\in \\varphi(V_2,V_3)$，则$\\sigma \\gamma \\in \\varphi(V_1,V_2)$ 线性映射的加法适合交换律和结合律，乘法适合结合律，标量乘法适合结合律，分配律。 重要定理 设$\\sigma \\in \\varphi(V_1,V_2)$，如果$\\sigma$是可逆映射，则$\\sigma^{-1}\\in \\varphi(V_2,V_1)$。 线性映射的矩阵表示 设$\\sigma:U\\rightarrow V$是一个线性映射，$[u_1,\\cdots,u_n]$是$U$的一组基，$\\sigma$完全由$\\sigma(u_1),\\cdots,\\sigma(u_n)$确定，如果$u=x_1u_1+\\cdots,x_nu_n$，则$\\sigma(u)=x_1\\sigma(u_1)+\\cdots+x_n\\sigma(u_n)$。 设$v_1,\\cdots,v_m$是$V$的一组基，则 故$[\\sigma(u_1),\\cdots,\\sigma(u_n)]=[v_1,\\cdots,v_m]A$，其中。 矩阵$A$称为线性映射$\\sigma$在$U$的基$[u_1,\\cdots,u_n]$和$V$的基$[v_1,\\cdots,v_n]$下的表示矩阵。 重要定理 设设$\\sigma$为数域$F$上线性空间$U$到$V$的线性映射，其中$u_1,\\cdots,u_n$是$U$的一组基，$v_1,\\cdots,v_m$是$V$的一组基，$\\sigma$在这对基下的矩阵是$A$，$\\forall \\alpha =\\sum_{i=1}^nx_iu_i$，有$\\sigma(\\alpha)=\\sum_{i=1}^my_iv_i$，则$[y_i,\\cdots,y_m]^T=A[x_1,\\cdots,x_n]$。 线性映射在不同基下的矩阵之间的关系 同一个线性映射在不同基下的矩阵一般是不同的 设$\\sigma$为数域$F$上$n$维线性空间$U$到$n$维线性空间$V$的线性映射，其中$u_1,\\cdots,u_n$和$u_1’,\\cdots,u’_n$是$U$的两组基，由$u_1,\\cdots,u_n$到$u_1’,\\cdots,u’_n$的过渡矩阵是$Q$，$v_1,\\cdots,v_m$和$v_1’,\\cdots,v_m’$是$V$的两组基，由$v_1,\\cdots,v_m$到$v_1’,\\cdots,v_m’$的过渡矩阵是$P$，$\\sigma$在基$u_1,\\cdots,u_n$与基$v_1,\\cdots,v_m$下的矩阵是$A$，而在基$u_1’,\\cdots,u’_n$与基$v_1’,\\cdots,v_m’$的矩阵为$B$，则$B=P^{-1}AQ$。 推导： 因为： 则把式子代入得到： 因为线性映射$\\sigma$的矩阵由基唯一确定，所以$B=P^{-1}AQ$。 相抵 设$A,B\\in F^{m\\times n}$，如果存在数域$F$上的$m$阶非奇异矩阵$P$和$n$阶非奇异矩阵$Q$使得$B=PAQ$，则称$A$与$B$相抵（等价）。 如果$A$与$B$相抵，则它们可作为$n$维线性空间$U$到$m$维线性空间$V$的同一线性映射在两对基所对应的矩阵。 相抵的充分必要条件是它们有相同的秩。 ","date":"2023-12-01","objectID":"/posts/03.%E7%BA%BF%E6%80%A7%E6%98%A0%E5%B0%84%E5%92%8C%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2/:1:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 3—线性映射和线性变换知识点总结复习","uri":"/posts/03.%E7%BA%BF%E6%80%A7%E6%98%A0%E5%B0%84%E5%92%8C%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2/"},{"categories":["课程笔记"],"content":"2 线性映射的值域（像）和核 值域（像）和核的定义 设$\\sigma$为数域$F$上线性空间$U$到$V$的线性映射，令$R(\\sigma)=I_m(\\sigma)={\\sigma(x)| x\\in U}$，$Ker(\\sigma)=N(\\sigma)={x\\in U|\\sigma(x)=0}$。 称$R(\\sigma)$是线性映射$\\sigma$的值域（也称像），$Ker(\\sigma)$是线性映射$\\sigma$的核。 易知$R(\\sigma)$是$V$的一个子空间，$Ker(\\sigma)$是$U$的一个子空间。 值域（像）和核理解 值域（像）是映射所能到的空间，它包含了所有在映射过程中真实映射到的点，描述了映射的覆盖范围。值域（像）是目标空间 $W$的一个子空间。 核是映射的零空间，它包含了所有被映射到零的输入向量，描述了映射的非单射性，即存在映射到同一个元素的不同输入。核是定义在$V$上的一个子空间。 定理 设$\\sigma$为数域$F$上$n$维线性空间$U$到$n$维线性空间$V$的线性映射，其中$u_1,\\cdots,u_n$是$U$的一组基，$v_1,\\cdots,v_m$是$V$的一组基，$\\sigma$在这对基下的矩阵是$A$，则 $R(\\sigma)=span(\\sigma(u_1),\\cdots,\\sigma(u_n))$ $rank(\\sigma)=rank(A)$ $dim(R(\\sigma))+dim(Ker(\\sigma))=n$ 一般求法 $R(\\sigma)=R[x])_3$ $Ker(\\sigma)={0}$ ","date":"2023-12-01","objectID":"/posts/03.%E7%BA%BF%E6%80%A7%E6%98%A0%E5%B0%84%E5%92%8C%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2/:2:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 3—线性映射和线性变换知识点总结复习","uri":"/posts/03.%E7%BA%BF%E6%80%A7%E6%98%A0%E5%B0%84%E5%92%8C%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2/"},{"categories":["课程笔记"],"content":"3 线性变换 定义 设$V$是数域$F$上的线性空间，$V$到自身的线性映射称为$V$上的线性变换。 $n$维线性空间$V$上的线性变换与矩阵之间的关系 设$\\sigma$是在$V$上的线性变换，$v_1,\\cdots,v_n$是一组基，则 故$[\\sigma(v_1),\\cdots,\\sigma(v_n)]=[v_1,\\cdots,v_m]A$，其中。矩阵$A$称为线性变换$\\sigma$在$U$的基$[v_1,\\cdots,v_n]$下的表示矩阵。 重要定理 设$n$维线性空间$V$上线性变换$\\sigma$在基$v_1,\\cdots,v_n$和$v_1’,\\cdots,v_n’$下的矩阵分别为$A$和$B$，由基$v_1,\\cdots,v_n$到基$v_1’,\\cdots,v_n’$的过渡矩阵为$P$，则$B=P^{-1}AP$ 推导： 因为 则代入得到 所以$AP=PB$，左乘$P^{-1}$，得$B=P^{-1}AP$。 相似 设$A,B\\in F^{m\\times n}$，如果存在可逆矩阵$P\\in F^{n\\times n}$使得$B=P^{-1}AB$，则称$A$与$B$相似。 ","date":"2023-12-01","objectID":"/posts/03.%E7%BA%BF%E6%80%A7%E6%98%A0%E5%B0%84%E5%92%8C%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2/:3:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 3—线性映射和线性变换知识点总结复习","uri":"/posts/03.%E7%BA%BF%E6%80%A7%E6%98%A0%E5%B0%84%E5%92%8C%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2/"},{"categories":["课程笔记"],"content":"4 酉变换和正交变换 定义 设$V$是$n$维酉（欧式）空间（一个在复数（实数）域上的内积空间），$\\sigma:V\\rightarrow V$是线性变换，如果 $$ \\forall x\\in V,||\\sigma(x)||=||x|| $$ $\\sigma$就称为酉（正交）变换 定理 设$V$是$n$维酉（欧式）空间（一个在复数（实数）域上的内积空间），如果$\\sigma:V\\rightarrow V$是酉（正交）变换，则 $$ \\forall x,y\\in V,(\\sigma(x),\\sigma(y))\u003e=(x,y) $$ 即酉（正交变换）保持向量的内积。 如果$v_1,\\cdots,v_n$是$V$的一组标准正交基，则$\\sigma(v_1),\\cdots,\\sigma(v_n)$也是$V$的一组标准正交基。 $\\sigma$在$V$的任意一组标准正交基下的矩阵是酉（正交）矩阵。 设$v=[v_1,\\cdots,v_n]$是酉（欧式）空间$V$的一组标准正交基，$A$维$\\sigma: V\\rightarrow V$在基$v$的表示矩阵为$A$，则$\\sigma$是一个酉（正交）变换当且仅当$A^HA=I(A^T=I)$。 即，$A$的列向量组成了$C^{n}(R^n)$的标准正交基。 ","date":"2023-12-01","objectID":"/posts/03.%E7%BA%BF%E6%80%A7%E6%98%A0%E5%B0%84%E5%92%8C%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2/:4:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 3—线性映射和线性变换知识点总结复习","uri":"/posts/03.%E7%BA%BF%E6%80%A7%E6%98%A0%E5%B0%84%E5%92%8C%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2/"},{"categories":["课程笔记"],"content":"5 同态和同构 定义 设$V$和$W$是在相同数域$F$上的两个向量空间，$\\sigma:V\\rightarrow W$是线性变换（也称为同态）。如果$\\sigma$是一一对应的，则称为同构。 如果存在从$V$到$W$的同构，则称$V$与$W$同构。 对于同构$\\sigma: V\\rightarrow W,ker(\\sigma)={0} \\space and \\space \\sigma(V)=W$。 定理 设$V$和$W$是在相同数域$F$上的两个向量空间，$\\sigma$是从$V$到$W$的同构，$S$为$V$的子空间，则$\\dim(S)=\\dim(\\sigma(S))$。即，两个同构空间有相同的维数（充要条件）。 设$\\sigma$是从$V$到$W$的同构，则$\\sigma^{-1}$是从$W$到$V$的同构 数域 $F$ 上任意一个 $n$维 向量空间$V$同构于向量空间 $F^n$。 性质 同构具有如下性质： 自反性 对称性 传递性 ","date":"2023-12-01","objectID":"/posts/03.%E7%BA%BF%E6%80%A7%E6%98%A0%E5%B0%84%E5%92%8C%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2/:5:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 3—线性映射和线性变换知识点总结复习","uri":"/posts/03.%E7%BA%BF%E6%80%A7%E6%98%A0%E5%B0%84%E5%92%8C%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2/"},{"categories":["课程笔记"],"content":"6 不变子空间 定义 设$\\sigma:V\\rightarrow V$是线性变换，如果$V$的子空间$S$满足$\\forall x\\in S, \\sigma(x)\\in S$，即$\\sigma(x)\\subset S$，则称$S$是一个不变子空间。 当说到不变子空间时，要指明是在什么映射下是不变的。利用$\\sigma$-不变子空间，我们可以简化$\\sigma$的表示矩阵。 矩阵的不变子空间 设$A\\in F^{n\\times n}$，$\\sigma_A:F^n\\rightarrow F^n$被定义为：$\\sigma_A(x)=Ax$，$F^n$的子空间$S$如果满足$\\forall x\\in S, Ax\\in S$，则称$S$是$\\sigma $-不变子空间。 定理 设$\\sigma:V\\rightarrow V$是线性变换，则两个$\\sigma$-不变子空间的交、和、直和也是$\\sigma$-不变子空间。 设$\\sigma$是在向量空间$V$上的线性变换，$W=span{x_1,\\cdots,x_k}$是$V$的$\\sigma$-不变子空间当且仅当$\\sigma(x_i)\\in W(i=1,2,\\cdots,k)$。 设$\\sigma$是数域$F$上$n$维向量空间$V$上的线性变换，则$\\sigma$可以对角化的充要条件是$V$可以分解成$\\sigma$的一维不变子空间的直和。 设$\\sigma$是数域$F$上$n$维向量空间$V$上的线性变换，则$\\sigma$在$V$的一组基下的矩阵为形如 的块上三角矩阵的充要条件是$\\sigma$的非平凡的不变子空间。 设$\\sigma$是数域$F$上$n$维向量空间$V$上的线性变换，则$\\sigma$在$V$的一组基下的矩阵为块对角巨好着呢的充要条件是$V$可以分解成$\\sigma$的若干个非平凡不变子空间的直和。 ","date":"2023-12-01","objectID":"/posts/03.%E7%BA%BF%E6%80%A7%E6%98%A0%E5%B0%84%E5%92%8C%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2/:6:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 3—线性映射和线性变换知识点总结复习","uri":"/posts/03.%E7%BA%BF%E6%80%A7%E6%98%A0%E5%B0%84%E5%92%8C%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2/"},{"categories":["课程笔记"],"content":"1 特征值和特征向量 定义 设$\\sigma$为数域$F$上线性空间$V$上的一个线性变换，一个非零向量$v\\in V$，如果存在一个$\\lambda \\in F$使得$\\sigma(v)=\\lambda v$，则$\\lambda$称为$\\sigma$的特征值。$\\sigma$的特征值的集合称为$\\sigma$的谱。并称$v$为$\\sigma$的属于（或对应于）特征值$\\lambda $的特征向量。 特征值和特征向量的求法 设$V$是数域$F$上的$n$维线性空间，$v_1,\\cdots,v_n$是$V$的一组基，线性变换$\\sigma$在这组基下的矩阵为$A$，如果$\\lambda$是$\\sigma$的特征值，$\\alpha$是相应的特征向量。则 将上式代入$\\sigma(v)=\\lambda v$得到 由于$v_1,\\cdots,v_n$线性无关，所以 则说明特征向量$\\alpha$的坐标满足齐次线性方程组$(\\lambda I-A)x=0$。 因为$\\alpha\\neq 0$，则$x\\neq 0$，即齐次线性方程组$(\\lambda I-A)x=0$有非零解。有非零解的充要条件是它的系数矩阵它的系数矩阵行列式$|\\lambda I-A|=0$。 相关定义 设$A$是数域$F$上的$n$阶矩阵，$\\lambda$是一个符号，也是未知的特征值，矩阵$\\lambda I-A$称为$A$的特征矩阵，其行列式$|\\lambda I-A|$称为$A$的特征多项式。方程$|\\lambda I-A|=0$称为$A$的特征方程，它的根（即$\\lambda$的值）称为$A$的特征根（或特征值）。以$A$的特征值$\\lambda$代入$Ax=\\lambda x$中所得到的非零解$x$称为$A$对应于$\\lambda$的特征向量。 定理 设$A$为$n\\times n$矩阵，$\\lambda$是一个数值，以下命题等价： $\\lambda$是$A$的特征值 $(\\lambda I-A)x=0$有一个非平凡的解（即有非零向量的解） $N(\\lambda I-A)\\neq{0}$ $\\lambda I-A$矩阵是奇异矩阵 $\\det(\\lambda I-A)=0$ 特征多项式的系数 如果 则$c_k(1\\leq k\\leq n)$是所有$k$阶主子式（选择$k$行$k$列形成的行列式）的和，特别的，$c_1=\\text{tr}(A),c_n=\\text{det}(A)$。 定理 设$A\\in C^{n\\times n}$，如果$A$有特征值$\\lambda_1,\\cdots,\\lambda_n$，则 如果$A$相似$B$，则两个矩阵有相同的特征值和特征多项式。 设$A\\in C^{m\\times n}$，则$A^HA$和$AA^H$特征值都是非负实数，且它们都有相同的非零特征值和相同的重数，并且非零特征值（包含重数）的数量等于$\\text{rank}(A)$。 ","date":"2023-12-01","objectID":"/posts/04.%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F/:1:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 4—特征值和特征向量知识点总结复习","uri":"/posts/04.%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F/"},{"categories":["课程笔记"],"content":"2 对角化 定义 设矩阵$A\\in F^{n\\times n}$，如果存在一个非奇异矩阵$P\\in F^{n\\times n}$和一个对角矩阵$D\\in F^{n\\times n}$，使得$P^{-1}AP=D$，则称$A$可被对角化。 定理 $A$可以被对角化当且仅当$A$有$n$个线性无关的特征向量 $\\lambda_1,\\cdots,\\lambda_k$是$A$的不同的特征值，则对应的特征向量$x_1,\\cdots,x_k$它们是线性无关的 由以上两条定理即可推出如果$A$有$n$个不同的特征值，则$A$可被对角化 不同特征值对应的特征向量的集合的并集是线性无关的。即取每个特征值的所有特征向量，无论这些向量属于哪个特征值，它们的并集都是线性无关的。 代数重数 设$A\\in F^{n\\times n}$，如果$\\det(\\lambda I-A)=(\\lambda -\\lambda_i)^{r_1}\\cdots(\\lambda-\\lambda_k)^{r_k}$，其中$\\lambda_1,\\cdots,\\lambda_k$是$A$的特征值，它们是不同的。则特征值$\\lambda_i$的代数重数是$r_i$，即特征值$\\lambda_i$出现的次数。 几何重数 与特征值$\\lambda_i$对应的特征子空间是$N(\\lambda_i I-A)$，则特征值$\\lambda_i$的几何重数为$\\dim(N(\\lambda_i I-A))$。 几何重数$\\leq $代数重数 几何重数看可对角化 矩阵$A\\in F^{n\\times n}$可对角化当且仅当$A$中不同特征值的几何重数和等于$n$（即每个特征值的代数重数都要等于几何重数） ","date":"2023-12-01","objectID":"/posts/04.%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F/:2:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 4—特征值和特征向量知识点总结复习","uri":"/posts/04.%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F/"},{"categories":["课程笔记"],"content":"3 Schur定理和正规矩阵 酉（正交）相似定义 设$A\\in C^{n\\times n}(R^{n\\times n})$，如果存在一个酉（正交）矩阵$U$使得$U^HAU=B\\space\\space\\space(U^H=U^{-1})$，则可称$A$酉（正交）相似$B$ Schur定理 $\\forall A\\in C^{n\\times n}$，$A$都与上三角矩阵相似，且存在酉矩阵$U$和上三角矩阵$T$使得$U^HAU=U^{-1}AU=T$。 仅适用于复数域，实数域上不一定适用 正规矩阵定义 设$A\\in C^{n\\times n}$，如果$A$满足$A^HA=AA^H$，则称$A$是正规矩阵。 Hermite矩阵，酉（正交）矩阵都是正规矩阵 谱定理 设$A\\in C^{n\\times n}$，如果$A$是Hermite矩阵，则$A$酉相似于一个实对角矩阵，换句话说，Hermite矩阵的特征值都是实数。 引理 设$A\\in C^{n\\times n}$，$A$是正规矩阵当且仅当$\\forall \\lambda,x$使得$||Ax-\\lambda x||=||A^Hx-\\bar{\\lambda}x||$。 同时对角化 设$A,B$都是相同阶数的正规矩阵，则存在一个酉矩阵可以同时酉对角化$A,B$当且仅当$AB=BA$ ","date":"2023-12-01","objectID":"/posts/04.%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F/:3:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 4—特征值和特征向量知识点总结复习","uri":"/posts/04.%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F/"},{"categories":["课程笔记"],"content":"4 Python求解 import numpy as np from sympy import symbols, Matrix import pprint # 定义符号变量 lambda_ = symbols('lambda') A = np.array([[0, 2, 1], [-2, 0, 3], [-1, -3, 0]]) A = Matrix(A) # 求特征矩阵 characteristic_matrix = A - lambda_ * np.eye(3) pprint.pprint(\"关于 lambda 的特征矩阵:\") pprint.pprint(characteristic_matrix) # 计算特征多项式 characteristic_polynomial = A.charpoly(lambda_) pprint.pprint(\"关于 lambda 的特征多项式:\") pprint.pprint(characteristic_polynomial) # 求特征值 eigenvalues = A.eigenvals() # 打印特征值、其代数重数、特征向量和几何重数 for k, v in eigenvalues.items(): pprint.pprint(\"特征值 %s 的代数重数为 %s\" % (k, v)) pprint.pprint(\"特征值 %s 的几何重数为 %s\" % (k, A.eigenvects()[list(eigenvalues.keys()).index(k)][1])) pprint.pprint(\"特征值 %s 的特征向量为 %s\" % (k, A.eigenvects()[list(eigenvalues.keys()).index(k)][2])) # 判断A是否可对角化，如果可以，打印出对角化矩阵 if A.is_diagonalizable(): pprint.pprint(\"A可对角化\") pprint.pprint(\"对角化矩阵为:\") pprint.pprint(A.diagonalize()[0]) # 求A的行空间、列空间、零空间 pprint.pprint(\"A的行空间为:\") pprint.pprint(A.rowspace()) pprint.pprint(\"A的列空间为:\") pprint.pprint(A.columnspace()) pprint.pprint(\"A的零空间为:\") pprint.pprint(A.nullspace()) ","date":"2023-12-01","objectID":"/posts/04.%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F/:4:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 4—特征值和特征向量知识点总结复习","uri":"/posts/04.%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F/"},{"categories":["课程笔记"],"content":"$\\lambda$矩阵与Jordan 标准型 ","date":"2023-12-01","objectID":"/posts/05.lambda%E7%9F%A9%E9%98%B5%E4%B8%8Ejordan%E6%A0%87%E5%87%86%E5%9E%8B/:0:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 5—lambda矩阵与Jordan 标准型","uri":"/posts/05.lambda%E7%9F%A9%E9%98%B5%E4%B8%8Ejordan%E6%A0%87%E5%87%86%E5%9E%8B/"},{"categories":["课程笔记"],"content":"1 $\\lambda $矩阵关键概念 $\\lambda$矩阵定义 设$a_{ij}(\\lambda)(1\\leq i \\leq m,1\\leq j \\leq n)$是数域$P$上的多项式，以$a_{ij}(\\lambda)$为元素的$m\\times n$矩阵 成为多项式矩阵或$\\lambda$矩阵，多项式$a_{ij}(\\lambda)(1\\leq i \\leq m,1\\leq j \\leq n)$中的最高次数成为$A(\\lambda)$的次数，则数字矩阵显然是$\\lambda$矩阵，为$0$次；数字矩阵$A$的特征矩阵$\\lambda I-A$就是$1$次$\\lambda$矩阵。 设$A(\\lambda)$矩阵的次数为$k$，则$A(\\lambda)$可表示为 其中$A_i(0\\leq i \\leq k)$是数字矩阵，并且$A_k\\neq 0$。 $\\lambda$矩阵性质 $\\lambda$矩阵也可以进行初等变换 若$A(\\lambda)$可以经过有限次初等变换化为$B(\\lambda)$，则称$\\lambda$矩阵$A(\\lambda)$和$B(\\lambda)$相抵，记为$A(\\lambda)\\cong B(\\lambda)$ $\\lambda$矩阵定理 设$A(\\lambda)=(a_{ij}(\\lambda))\\in P[\\lambda]^{m\\times n}$，且$rank(A(\\lambda))=r$，则$A(\\lambda)$相似于如下的对角矩阵 其中$d_i(\\lambda)(1\\leq i \\leq r)$是首项系数为$1$的多项式，并且$d_i(\\lambda)|d_{i+1}(\\lambda)(1\\leq i \\leq r-1)$ $Smith$标准型 $\\lambda$矩阵定理中的对角矩阵就称为$\\lambda $矩阵$A(\\lambda)$在相抵下的标准型或者$Smith$标准型。 $Smith$标准型是唯一的 不变因子、行列式因子、初等因子 重要性质：相抵的$\\lambda$矩阵具有相同的秩、相同的各阶行列式因子、相同的不变因子 $Smith$标准型“主对角线”上非零元$d_1(\\lambda),d_2(\\lambda),\\dots,d_r(\\lambda)$称为$A(\\lambda)$的不变因子； $A(\\lambda)$的全部$k$阶子式的最大公因式称为$A(\\lambda)$的$k$阶行列式因子，记为$D_k(\\lambda)$； 其中$d_k(\\lambda)=\\frac{D_{k+1}(\\lambda)}{D_k(\\lambda)}$ 初等因子是从不变因子分解得来的，具体如下： 假设不变因子为 则所有指数大于$0$的因子$(\\lambda -\\lambda _ {j})^ {e_ {ij}}(1\\leq i \\leq r,1\\leq j\\leq k)$称为$\\lambda $矩阵$A(\\lambda)$的初等因子 ","date":"2023-12-01","objectID":"/posts/05.lambda%E7%9F%A9%E9%98%B5%E4%B8%8Ejordan%E6%A0%87%E5%87%86%E5%9E%8B/:1:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 5—lambda矩阵与Jordan 标准型","uri":"/posts/05.lambda%E7%9F%A9%E9%98%B5%E4%B8%8Ejordan%E6%A0%87%E5%87%86%E5%9E%8B/"},{"categories":["课程笔记"],"content":"2 矩阵相似的条件 定义 设$A$为$n$阶数字矩阵，其特征矩阵$\\lambda I-A$的行列式因子，不变因子和初等因子分别称为矩阵$A$的行列式因子，不变因子和初等因子。 相似的充分必要条件 $n$阶矩阵$A$和$B$相似$\\Longleftrightarrow $存在一个可逆矩阵 $P$，使得$B = P^{-1} A P $$\\Longleftrightarrow $它们的特征矩阵$\\lambda I-A$和$\\lambda I-B$相抵$\\Longleftrightarrow $它们具有相同的行列式因子或者它们有相同的不变因子$\\Longleftrightarrow $它们具有相同的初等因子 ","date":"2023-12-01","objectID":"/posts/05.lambda%E7%9F%A9%E9%98%B5%E4%B8%8Ejordan%E6%A0%87%E5%87%86%E5%9E%8B/:2:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 5—lambda矩阵与Jordan 标准型","uri":"/posts/05.lambda%E7%9F%A9%E9%98%B5%E4%B8%8Ejordan%E6%A0%87%E5%87%86%E5%9E%8B/"},{"categories":["课程笔记"],"content":"3 矩阵的Jordan标准型 Jordan块和Jordan标准型 Jordan块分上Jordan块和下Jordan块，我们一般用上Jordan块。 如果$(\\lambda -a)^d$是$A$的初等因子，我们则可以构建一个$d\\times d$的矩阵形式 这个矩阵我们称为上Jordan块。下Jordan块则为 那由若干个Jordan块为对角块组成的块对角矩阵称为Jordan标准型 性质 Jordan块被它的初等因子唯一确定 Jordan标准型的全部初等因子由它的全部Jordan块的初等因子组成 每个$n$阶矩阵都相似于它的Jordan标准型 Jordan标准型不唯一，其内部Jordan块的顺序可以随意，但每个Jordan块唯一，如果除去其中Jordan块排列的次序外是被矩阵$A$唯一确定的 求$n$阶方阵$A$的Jordan标准型 得到$(\\lambda I-A)$矩阵，求它的各阶行列式因子$D_k(\\lambda)$ 根据公式$d_1(\\lambda)=D_1(\\lambda)$，$d_k(\\lambda)=\\frac{D_{k+1}(\\lambda)}{D_k(\\lambda)}(2\\leq k\\leq n)$得到不变因子 从不变因子分解得到初等因子 根据初等因子构成Jordan块$J_i$，再组成Jordan标准型$J$ 求可逆矩阵$P$，使得$P^{-1}AP=J$ 根据上一个方法求出矩阵$A$的Jordan标准型$J$ 左右两边左乘$P^{-1}$变换公式得到$AP=PJ$ 设$P=(P_1,..,P_n)$，根据公式构造 其中$J_{(i,i+1)}$的取值只能为$0\\space or\\space 1$，$J_{ii}$的取值即为对角线元素。根据方程从而解得$P$。 注意：$P$不唯一，但是我们在设$P$元素的时候一定要保证$P$可逆，即$rank(P)=n$。可以自己进行初等变换验证一下是否正确！ Python求解$J$和可逆矩阵$P$ import numpy as np from sympy import Matrix import pprint A = np.array([[2, 2, 1], [-2, 6, 1], [0, 0, 4]]) A = Matrix(A) P, J = A.jordan_form() # 验证P^-1 * A * P = J assert P ** -1 * A * P == J, \"P^-1 * A * P != J\" pprint.pprint(\"P:\", P) pprint.pprint(\"J:\", J) ","date":"2023-12-01","objectID":"/posts/05.lambda%E7%9F%A9%E9%98%B5%E4%B8%8Ejordan%E6%A0%87%E5%87%86%E5%9E%8B/:3:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 5—lambda矩阵与Jordan 标准型","uri":"/posts/05.lambda%E7%9F%A9%E9%98%B5%E4%B8%8Ejordan%E6%A0%87%E5%87%86%E5%9E%8B/"},{"categories":["课程笔记"],"content":"4 Cayley-Hamilton 定理与最小多项式 Cayley-Hamilton 定理 设$A$是$n$阶矩阵，$f(\\lambda)$是$A$的特征多项式，则$f(A)=0$ 相关定义 设$A$为$n$阶矩阵，如果存在多项式$\\varphi(\\lambda)$使得$\\varphi(A)=0$，则称$\\varphi(\\lambda)$为$A$的化零多项式。易知$f(\\lambda)$为$A$的化零多项式，且$g(\\lambda)f(\\lambda)$也为$A$的化零多项式，故$A$的化零多项式有无穷多个 $A$的所有化零多项式中，次数最低，且首项系数为$1$的多项式称为$A$的最小多项式。$A$的最小多项式是唯一的 结论 $A$的最小多项式就是$d_n(\\lambda)$，即$A$的第$n$个不变因子 ","date":"2023-12-01","objectID":"/posts/05.lambda%E7%9F%A9%E9%98%B5%E4%B8%8Ejordan%E6%A0%87%E5%87%86%E5%9E%8B/:4:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 5—lambda矩阵与Jordan 标准型","uri":"/posts/05.lambda%E7%9F%A9%E9%98%B5%E4%B8%8Ejordan%E6%A0%87%E5%87%86%E5%9E%8B/"},{"categories":["课程笔记"],"content":"矩阵分解 ","date":"2023-12-01","objectID":"/posts/06.%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/:0:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 6—矩阵分解知识点总结复习（附Python实现）","uri":"/posts/06.%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/"},{"categories":["课程笔记"],"content":"1 满秩分解（Full-Rank Factorization） 满秩分解定理 设$m\\times n$矩阵$A$的秩为$r\u003e0$，则存在$m\\times r$矩阵$B$（列满秩矩阵）和$r\\times n$矩阵$C$（行满秩矩阵）使得 并且$rank(B)=rank(C)=r$ 满秩分解不唯一 定理：设$A$为$m\\times n$矩阵，且$rank(A)=r$，存在$m$阶可逆矩阵$P$和$n$阶可逆矩阵$Q$，使得。 证明满秩分解定理： 则令，可得到$A=BC$ $\\because$ $P,C$是可逆矩阵，$B$的$r$个列是$P$的前$r$列；$C$的$r$个行是$Q$的前$r$行 $\\therefore$ $rank(B)=rank(C)=r$ 满秩分解步骤 设$A$为$m\\times n$矩阵，首先求$rank(A)$ 取$A$的$j_1,j_2,…j_r$列构成$B_{m\\times r}$ 取$A$的Hermite标准型（即行最简行矩阵）$H$的前$r$行构成矩阵$C_{r\\times n}$ 则$A=BC$就是矩阵$A$的一个满秩分解 Python求解满秩分解 import numpy as np from sympy import Matrix ''' Full-Rank Factorization @params: A Matrix @return: F, G Matrix ''' def full_rank(A): r = A.rank() A_arr1 = np.array(A.tolist()) # 求解A的最简行阶梯矩阵，要转换成list，再转换成array A_rref = np.array(A.rref()[0].tolist()) k = [] # 存储被选中的列向量的下标 # 遍历A_rref的行 for i in range(A_rref.shape[0]): # 遍历A_rref的列 for j in range(A_rref.shape[1]): # 遇到1就说明找到了A矩阵的列向量的下标 # 这些下标的列向量组成F矩阵，然后再找下一行 if A_rref[i][j] == 1: k.append(j) break # 通过选中的列下标，构建F矩阵 B = Matrix(A_arr1[:,k]) # G就是取行最简行矩阵A的前r行构成的矩阵 C = Matrix(A_rref[:r]) return B, C if __name__ == \"__main__\": # 表示矩阵A A = np.array([[1, 1, 0], [0, 1, 1], [-1, 0, 0], [1, 1, 1]]) A = Matrix(A) B, C = full_rank(A) print(\"B:\", B) print(\"C:\", C) ","date":"2023-12-01","objectID":"/posts/06.%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/:1:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 6—矩阵分解知识点总结复习（附Python实现）","uri":"/posts/06.%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/"},{"categories":["课程笔记"],"content":"2 三角分解（Triangular Factorization） $LU$分解定义 如果有一个矩阵$A$，我们能表示下三角矩阵$L$和上三角矩阵$U$的乘积，称为$A$的三角分解或$LU$分解。 更进一步，我们希望下三角矩阵的对角元素都为$1$ $LU$分解定理 若$A$是$n$阶非奇异矩阵，则存在唯一的单位下三角矩阵$L$和上三角矩阵$U$使得$A=LU$的充分必要条件是$A$的所有顺序主子式均非零（这一条件保证了对角线元素非零），即$\\Delta_k\\neq 0(k=1,…,n-1)$ $LU$分解步骤 设$A$为$n\\times n$矩阵 进行初等行变换（注意：不涉及行交换的初等变换），从第$1$行开始，到第$n$行结束。将第$i$行第$i$列以下的元素全部消为$0$ 这样操作后得到的矩阵即为$U$ 构造对角线元素全为$1$的单位下三角矩阵$L$，$L$的剩余元素通过构建方程组的形式来求解。 Python求解$LU$分解 $LU$分解的实际意义 解线性方程组 假设我们有一个线性方程组$Ax=b$，其中$A$是一个非奇异矩阵，而$b$是一个列向量。通过$LU$分解，我们可以将方程组转化为两个简化的方程组$Ly=b$和$Ux=y$，其中$L$是下三角矩阵，$U$是上三角矩阵。这两个方程组分别易于求解。 具体： 首先，通过前代法（forward substitution）解$Ly=b$，然后通过回代法（backward substitution）解$Ux=y$。这样，我们就得到了方程组的解。 $LDU$分解定理 设$A$是$n$阶非奇异矩阵，则存在唯一的单位下三角矩阵$L$，对角矩阵$D=diag(d_1,d_2,…,d_n)$和上三角矩阵$U$使得$A=LDU$的充分必要条件是$A$的所有顺序主子式均非零（这一条件保证了对角线元素非零），即$\\Delta_k\\neq 0(k=1,…,n-1)$并且$d_1=a_{11},d_k=\\frac{\\Delta_k}{\\Delta_{k+1}},k=2,…,n$ $LDU$分解步骤 设$A$为$n\\times n$矩阵 先求$LU$分解 将$U$的对角线元素提出来构成对角矩阵$D$ $U$中的元素$u_{ij}$除以$d_i$，其中$d_i$表示第$i$个对角元素。这样操作得到变换后的$U$ Python求解$LDU$分解 import numpy as np from sympy import Matrix import pprint EPSILON = 1e-8 def is_zero(x): return abs(x) \u003c EPSILON def LU(A): # 断言A必须是非奇异方阵A assert A.rows == A.cols, \"Matrix A must be a square matrix\" assert A.det() != 0, \"Matrix A must be a nonsingular matrix\" n = A.rows U = A # 构建出U矩阵 # 将U转换成list，再转换成array U = np.array(U.tolist()) # 遍历U的每一行利用高斯消元法 for i in range(n): # 判断U[i][i]是否为0 assert not is_zero(U[i][i]), \"主元为0，无法进行LU分解\" # 对i+1行到n行进行消元 for j in range(i + 1, n): # 计算消元因子 factor = U[j][i] / U[i][i] # 对第j行进行消元 for k in range(i, n): U[j][k] -= factor * U[i][k] # 消元后的矩阵U则是最终U矩阵 U = Matrix(U) # 根据LU = A，得到L矩阵 L = A * U.inv() return L, U def LDU(A): L, U = LU(A) D = Matrix(np.diag(np.diag(U))) U = D.inv() * U return L, D, U if __name__ == '__main__': A = np.array([[2, 3, 4], [1, 1, 9], [1, 2, -6]]) A = Matrix(A) ''' # test LU分解 L, U = LU(A) pprint.pprint(\"L:\") pprint.pprint(L) pprint.pprint(\"U:\") pprint.pprint(U) ''' # test LDU分解 L, D, U = LDU(A) pprint.pprint(\"L:\") pprint.pprint(L) pprint.pprint(\"D:\") pprint.pprint(D) pprint.pprint(\"U:\") pprint.pprint(U) $PLU$分解 PLU 分解是将矩阵$A$分解成一个置换矩阵$P$、单位下三角矩阵$L$和上三角矩阵$U$的乘积，即 之前$LU$分解中限制了行交换，如果不可避免的必须进行行互换，我们就需要进行$PLU$分解。 实际上只需要把$A = LU$变成$P^{-1}A = P^{-1}PLU$就可以了，实际上所有的$A = LU$都可以写成$P^{-1}A = LU$的形式，由于左乘置换矩阵$P^{-1}$是在交换行的顺序，所以由$P^{-1}A = P^{-1}PLU$推得适当的交换$A$的行的顺序，即可将$A$ 做 $LU$ 分解。当$A$没有行互换时，$P$就是单位矩阵。 事实上，所有的方阵都可以写成 $PLU$ 分解的形式，事实上，$PLU$ 分解有很高的数值稳定性，因此实用上是很好用的工具。 有时为了计算上的方便，会同时间换行与列的顺序，此时会将 $A$ 分解成 其中 $P$、$L$、$U$ 同上，$Q$ 是一个置换矩阵。 ","date":"2023-12-01","objectID":"/posts/06.%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/:2:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 6—矩阵分解知识点总结复习（附Python实现）","uri":"/posts/06.%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/"},{"categories":["课程笔记"],"content":"3 正交三角分解（QR Factorization） $QR$分解定理 设$A$是$m\\times n$实（复）矩阵，$m\\ge n$且其$n$个列向量线性无关，则存在$m$阶正交（酉）矩阵$Q$和$n阶$非奇异实（复）上三角矩阵$R$使得 $QR$分解步骤 设$A$为$3\\times 3$矩阵，即$A=(\\alpha_1, \\alpha_2,\\alpha_3)$。则： 正交化：$\\beta_1=\\alpha_1$，$\\beta_2=\\alpha_2-k_{21}\\beta_1$，$\\beta_3=\\alpha_3-k_{31}\\beta_1-k_{32}\\beta_2$，其中$k_{21}=\\frac{\u003c\\alpha_2,\\beta_1\u003e}{\u003c\\beta_1,\\beta_1\u003e}$，$k_{31}=\\frac{\u003c\\alpha_3,\\beta_1\u003e}{\u003c\\beta_1,\\beta_1\u003e}$，$k_{31}=\\frac{\u003c\\alpha_3,\\beta_2\u003e}{\u003c\\beta_2,\\beta_2\u003e}$。 单位化得到矩阵$Q$：$Q=(\\frac{\\beta_1}{||\\beta_1||},\\frac{\\beta_2}{||\\beta_2||},\\frac{\\beta_3}{||\\beta_3||})$ 计算得到矩阵$R$： 这样，$A=QR$ Python求解$QR$分解 常规计算： import numpy as np import sympy from sympy import Matrix from sympy import * import pprint #正交三角分解（QR） a = [[1, 1, -1], [-1, 1, 1], [1, 1, -1], [1, 1, 1]] # a = [[1,1,-1], # [1,0,0], # [0,1,0], # [0,0,1]] A_mat = Matrix(a)#α向量组成的矩阵A # A_gs= GramSchmidt(A_mat) A_arr = np.array(A_mat) L = [] for i in range(A_mat.shape[1]): L.append(A_mat[:,i]) #求Q A_gs = GramSchmidt(L)#α的施密特正交化得到β A_gs_norm = GramSchmidt(L,True)#β的单位化得到v A = [] for i in range(A_mat.shape[1]): for j in range(A_mat.shape[0]): A.append(A_gs_norm[i][j])#把数排成一行 A_arr = np.array(A) A_arr = A_arr.reshape((A_mat.shape[0],A_mat.shape[1]),order = 'F')#用reshape重新排列（‘F’为竖着写） #得到最后的Q Q = Matrix(A_arr) #求R C = [] for i in range(A_mat.shape[1]): for j in range(A_mat.shape[1]): if i \u003e j: C.append(0) elif i == j: t = np.array(A_gs[i]) m = np.dot(t.T,t) C.append(sympy.sqrt(m[0][0])) else: t = np.array(A_mat[:,j]) x = np.array(A_gs_norm[i]) n = np.dot(t.T,x) # print(n) C.append(n[0][0]) # C_final为R C_arr = np.array(C) # print(C_arr) C_arr = C_arr.reshape((A_mat.shape[1],A_mat.shape[1])) R = Matrix(C_arr) pprint.pprint(\"Q:\") pprint.pprint(Q) pprint.pprint(\"R:\") pprint.pprint(R) 调用库函数 # 求矩阵A的QR分解，保留根号 Q_, R_ = A_mat.QRdecomposition() pprint.pprint(\"Q_:\") pprint.pprint(Q_) pprint.pprint(\"R_:\") pprint.pprint(R_) assert Q_ == Q, \"Q_ != Q\" assert R_ == R, \"R_ != R\" ","date":"2023-12-01","objectID":"/posts/06.%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/:3:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 6—矩阵分解知识点总结复习（附Python实现）","uri":"/posts/06.%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/"},{"categories":["课程笔记"],"content":"4 奇异值分解（SVD） $SVD$定理 设$A$是$m\\times n$矩阵，且$rank(A)=r$，则存在$m$阶酉矩阵$U$和$n$阶酉矩阵$V$使得 其中$\\Sigma=diag(\\sigma_1,…,\\sigma_r)$，且$\\sigma_1\\geq …\\geq \\sigma_r\u003e0$。 $\\sigma$为$A$的奇异值，具体含义这里不在叙述，但需要记住的是$\\sigma^2$是$A^HA$的特征值，也是$AA^H$的特征值，且： $A^HA$与$AA^H$的特征值均为非负数 $A^HA$与$AA^H$的非零特征值相同，并且非零特征值的个数（重特征值按重数计算）等于$rank(A)$ 所以我们求$\\Sigma$就转换成求这两个矩阵其中一个的特征值。 $SVD$分解步骤 求$A^HA$的$n$个特征值，即计算$|\\lambda I-A^HA|=0$。得到特征值：$\\lambda_1,…,\\lambda_r,\\lambda_{r+1}=0,…,\\lambda_n=0$，其中$r=rank(A)$。 将$r$个奇异值（即非零特征值开根号）从大到小排列组成对角矩阵，再添加额外的$0$构成$\\Sigma_{m\\times n}$矩阵。 求特征值：$\\lambda_1,…,\\lambda_r,\\lambda_{r+1}=0,…,\\lambda_n=0$对应的特征向量$\\xi_1,…,\\xi_n$：当$\\lambda=\\lambda_1$时，$(\\lambda I-A^HA)\\times \\xi_1=0$，解得$\\xi_1$，同理，计算其余特征向量。 因为$\\xi_1,…,\\xi_n$相互正交，我们还需要进行单位化，得到$v_1,…,v_n$，即$v_1=\\frac{\\xi_1}{||\\xi_1||},…,v_n=\\frac{\\xi_n}{||\\xi_n||}$。则$V=(v_1,…,v_n)$。 根据$A=U_{m\\times m}\\Sigma_{m\\times n}V_{n\\times n}^H$，可得$U_1=AV_{n\\times n}\\Sigma_{r\\times n}^{-1}$（注意，$\\sigma$此时为$\\Sigma_{m\\times n}$的前$r$行），易知$U_1$为$m\\times r$的矩阵，我们还需要扩充$U_2$，其为$m\\times (m-r)$矩阵。 取$U_1^HU_2=0$，取$U_2$，必须要单位化$U_2$，这样$U=[U_1:U_2]$ 则 Python求解奇异值分解 import numpy as np from sympy import Matrix import pprint A = np.array([[1,0],[0,1],[1,1]]) # 求A的奇异值分解 U, sigma, VT = np.linalg.svd(A) print (\"U:\", U) print (\"sigma:\", sigma) print (\"VT:\", VT) ","date":"2023-12-01","objectID":"/posts/06.%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/:4:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 6—矩阵分解知识点总结复习（附Python实现）","uri":"/posts/06.%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/"},{"categories":["课程笔记"],"content":"1 Hermite矩阵 定义 设$A$为$n$阶方阵，如果称$A$为Hermite矩阵，则需满足$A^H=A$，其中$A^H$表示$A$的共轭转置，也称Hermite转置，具体操作如下： 将矩阵的每个元素取共轭。对于复数$a+bi$，它的共轭是$a-bi$，其中$a$和$b$ 是实部和虚部 将矩阵的行和列互换 Hermite矩阵与实对称矩阵的性质和证明方法都十分相似 Hermite矩阵性质 若$A,B$为$n$阶Hermite矩阵，则 $A$的所有特征值全是实数 $A$的不同特征值所对应的特征向量是相互正交的 对正整数$k$，$A^k$也是Hermite矩阵 若$A$可逆，则$A^{-1}$也是Hermite矩阵 对实数$k,p,kA+pB$也是Hermite矩阵 Hermite矩阵充分必要条件 设$A\\in C^{n\\times n},B\\in C^{n\\times n}$ $A$是Hermite矩阵的充要条件是存在酉矩阵$U$使得 其中$\\lambda_1,…,\\lambda_n$均为实数。实对称矩阵则是存在正交矩阵$U…$ A是Hermite矩阵的充要条件是对任意方阵$S$，$S^HAS$是Hermite矩阵 如果$A,B$是Hermite阵，则$AB$是Hermite矩阵的充要条件是$AB=BA$ 相合标准形 设$A$为$n$阶Hermite矩阵，则$A$相合矩阵 其中$r=rank(A)$，$s$是$A$的正特征值（重特征值按重数计算）的个数。矩阵$D_0$则称为$n$阶Hermite矩阵$A$的相合标准形。 Sylvester惯性定律 设$A,B$为$n$阶Hermite矩阵，则$A$与$B$相合的充要条件是 其中$In(A)$称为$A$的惯性，$In(A)={\\pi(A),v(A),\\delta(A)}$。其中$\\pi(A)$,$v(A)$,$\\delta(A)$分别表示$A$的正、负和零特征值的个数（重特征值按重数计算）。则$A$非奇异的充要条件为$\\delta(A)=0$且$\\pi(A)+v(A)=rank(A)$。 ","date":"2023-12-01","objectID":"/posts/07.hermite%E7%9F%A9%E9%98%B5%E4%B8%8E%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5/:1:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 7—Hermite矩阵与正定矩阵知识点总结复习","uri":"/posts/07.hermite%E7%9F%A9%E9%98%B5%E4%B8%8E%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5/"},{"categories":["课程笔记"],"content":"2 Hermite二次型 Hermite二次型定义 由$n$个复变量$x_1,…,x_n$，系数为负数的二次齐式 其中$a_{ij}=a_{ji}$，称为Hermite二次型。Hermite二次型可写为$f(x)=x^HAx$，我们称$A$的秩就为Hermite二次型的秩。 Hermite二次型的标准形定理 对Hermite二次型$f(x)=x^HAx$，存在酉线性变换$x=Uy$（其中$U$是酉矩阵）使得Hermite二次型$f(x)$变成标准形（只包含平方项的二次型） 其中$\\lambda_1,…,\\lambda_n$为$A$的特征值。 Hermite二次型化标准形（酉线性变换） 设$f(x)=x^HAx$，其中$A$为$n$阶Hermite矩阵 求出二次型矩阵$A$的特征值$\\lambda_1,…\\lambda_n$和特征向量$v_1,…,v_n$，并将特征向量$v_1,…,v_n$规范正交 令$U=(v_1,…,v_n),x=Uy$，则 Hermite二次型规范形定理 对二次型$f(x)=x^HAx$，存在可逆线性变换$x=Py$使得Hermite二次型$f(x)$化为 其中$r=rank(A),s=\\pi(A)$。上式则为Hermite二次型$f(x)$的规范形，其中$s$和$(r-s)$分别称为Hermite二次型的正惯性指数和负惯性指数。 二次型化规范形 设$f(x)=x^HAx$，其中$A$为$n$阶Hermite矩阵 将二次型化为标准形，得到标准形$f(x)=y^H\\Lambda y$和酉矩阵$U$ 将对角线元素提取出来，即只保留$\\lambda_i$的正负性，则 其中$\\Lambda_1$为对角矩阵，对角线元素为$\\sqrt {|\\lambda_i}|(1\\leq i \\leq n)$。 令$y=\\Lambda_1^{-1} z$，则 故$x=U\\Lambda^{-1}z$，可逆矩阵$P=U\\Lambda^{-1}$ 正定相关概念 设$f(x)=x^HAx$为Hermite二次型 如果$f(x)\u003e0$（等价$s=r=n$），则称$f(x)$为正定的； 如果$f(x)\\geq0$（等价$s=r\u003cn$），则称$f(x)$为半正定（非负定的）的； 如果$f(x)\u003c0$（等价$s=0,r=n$），则称$f(x)$为负定的； 如果$f(x)\\leq0$（等价$s=0,r\u003cn$），则称$f(x)$为半负定的； 如果$f(x)$有时为正有时为负（等价$0\u003cs\u003cr\\leq n$），则称$f(x)$为不定的； ","date":"2023-12-01","objectID":"/posts/07.hermite%E7%9F%A9%E9%98%B5%E4%B8%8E%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5/:2:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 7—Hermite矩阵与正定矩阵知识点总结复习","uri":"/posts/07.hermite%E7%9F%A9%E9%98%B5%E4%B8%8E%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5/"},{"categories":["课程笔记"],"content":"3 Hermite正定（非负定矩阵） 定义 根据Hermite二次型的正定（非负定）可以定义Hermite矩阵的正定（非负定）。 设$A$为$n$阶Hermite矩阵，$f(x)=x^HAx$ 如果$f(x)\u003e0$，则称$A$为正定的，记作$A\u003e0$； 如果$f(x)\\geq0$，则称$A$为半正定（非负定的）的，记作$A\\geq 0$； 如果$f(x)\u003c0$，则称$A$为负定的，记作$A\u003c0$； 如果$f(x)\\leq0$，则称$A$为半负定的，记作$A\\leq 0$； 如果$f(x)$有时为正有时为负，则称$A$为不定的； 判断$n$阶Hermite矩阵$A$正定 通过正定矩阵的定义 $A$的$n$个特征值均为正数 $A$的顺序主子式均为正数 $A$的所有主子式全大于$0$ 存在$n$阶非奇异下三角矩阵$L$，使得$A=LL^H$（该分解称为Cholesky分解） 存在$n$阶非奇异矩阵，使得$A=B^HB$ 存在$n$阶非奇异Hermite矩阵$A=S^2$ 判断$n$阶Hermite矩阵$A$半正定 通过半正定矩阵的定义 $A$的$n$个特征值均为非负数 $A$的所有主子式均非负 定理证明 设$A,B$均为$n$阶Hermite矩阵，且$B\u003e0$，则存在非奇异矩阵$P$使得 其中$\\lambda_1,…,\\lambda_n$是广义特征值问题的特征值 证明： $\\because B \u003e0$ $\\therefore $存在非奇异矩阵$P_1$使得$P_1^HBP_1=I$ 又$\\because P_1^HAP_1$仍为Hermite矩阵 $\\therefore$酉矩阵$U$使得 令$P=P_1U$ $\\because P$非奇异，根据定理$P^HBP=I$ $\\therefore P^HBP=(P_1U)^HB(P_1U)=U^HP_1^HBP_1U=I$ 又$\\because P_1$非奇异，使得$P_1^HBP_1=I$ $\\therefore$ $\\therefore$ $\\therefore$我们可以对$(12)$右乘$P^{-1}$和$B^{-1}$，得到 $\\therefore $将$(14)$代入$(13)$中得到 即$B^{-1}A$相似于对角矩阵，故$\\lambda_1,…,\\lambda_n$是矩阵$B^{-1}A$的特征值，即$\\lambda_1,…,\\lambda_n)$是广义特征值问题的特征值。 广义特征值问题$Ax=\\lambda Bx$，左乘$B^{-1}$，即为$B^{-1}Ax=\\lambda x$ ","date":"2023-12-01","objectID":"/posts/07.hermite%E7%9F%A9%E9%98%B5%E4%B8%8E%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5/:3:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 7—Hermite矩阵与正定矩阵知识点总结复习","uri":"/posts/07.hermite%E7%9F%A9%E9%98%B5%E4%B8%8E%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5/"},{"categories":["课程笔记"],"content":"4 矩阵不等式 定义 设$A,B$都是$n$阶Hermite矩阵，如果$A-B\\geq 0$则称$A$大于或等于$B$（或称$B$小于等于$A$），记作$A\\geq B$（或$B\\leq A$），即$A-B$半正定；如果$A-B\u003e0$，则称$A$大于$B$（或称$B$小于$A$），记作$A\u003eB$（或$B\u003cA$），即$A-B$正定。 性质 设$A,B,C$均为$n$阶Hermite矩阵，则 $A\\geq B(A\u003eB) \\Longleftrightarrow-A\\leq -B(-A\u003c-B)\\Longleftrightarrow$对任意$n$阶可逆矩阵$P$都有$P^HAP\\geq P^HBP(P^HAP\u003eP^HBP)$ 若$A\u003e0(A\\geq 0),C\u003e0(C\\geq 0)$，且$AC=CA$，则$AC\u003e0(AC\\geq 0)$ 若$A\u003eB$，$P$为$n\\times m$列满秩矩阵，则$P^HAP\u003eP^HBP$ 若$A\\geq B$，$P$为$n\\times m$矩阵，则$P^HAP\\geq P^HBP$ 定理 设$A,B$都是$n$阶Hermite矩阵，且$A\\geq 0,B\u003e0$，则 $B\\geq A$的充要条件是$\\rho(AB^{-1})\\leq 1$ $B\u003eA$的充要条件是$\\rho(AB^{-1})\u003c1$ 设$A$是$n$阶Hermite矩阵，则$\\lambda_{min}(A)I\\leq A\\leq\\lambda_{max}I$，这时$\\lambda_{min}$和$\\lambda_{max}$分别表示$A$的最大和最小特征值。 设$A,B$均为$n$阶Hermite正定矩阵，则 若$A\\geq B\u003e0$，则$B^{-1}\\geq A^{-1}\u003e0$ 若$A\u003eB\u003e0$，则$B^{-1}\u003eA^{-1}\u003e0$ 设$A,B$均为$n$阶Hermite正定矩阵，且$AB=BA$，则 若$A\\geq B$，则$A^2\\geq B^2$ 证明：$A^2-B^2=(A-B)(A+B)=(A+B)(A-B)$，易知$(A-B)\\geq0,A+B\u003e0$，则克制 若$A\\geq B$，则$A^2\u003e B^2$ 同理得证 设$A$是$m\\times n$行满秩矩阵，$B$是$n\\times k$矩阵，则 $$ B^HB\\geq (AB)^H(AA^H)^{-1}(AB) $$ 等号成立当且仅当存在一个$m\\times k$矩阵$C$使得$B=A^HC$ ","date":"2023-12-01","objectID":"/posts/07.hermite%E7%9F%A9%E9%98%B5%E4%B8%8E%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5/:4:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 7—Hermite矩阵与正定矩阵知识点总结复习","uri":"/posts/07.hermite%E7%9F%A9%E9%98%B5%E4%B8%8E%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5/"},{"categories":["课程笔记"],"content":"1 向量范数 向量范数定义 设$V$是数域$P$上的线性空间，$||x||$是以$V$中的向量$x$为自变量的非负实值函数，如果满足以下三个条件： 非负性：$||x||\\geq 0$，且$||x||=0$当且仅当$x=0$ 齐次性：$\\forall \\alpha \\in P,x\\in V$，有$||\\alpha x||=|\\alpha|||x||$ 三角不等式：$\\forall x,y \\in V$，有$||x+y||\\leq ||x||+||y||$ 则称$||x||$为向量$x$的范数，并称定义了范数的线性空间为赋范线性空间。 $1$范数，$2$范数、$\\infty$范数和$p$范数 在$n$维向量空间$C^n$中，对任意向量$x=(x_1,…,x_n)^T\\in C^n$ $1$范数： $2$范数： $\\infty$范数： $p$范数： 利用已知范数构造新范数 设是$C^m$上的向量范数，$A\\in C^{m\\times n}$且$rank(A)=n$，则由所定义的$||\\cdot||$是$C^n$上的向量范数 性质 向量范数的等价具有自反性、对称性和传递性 有限维线性空间$V$上的任意两个向量范数都是等价的 ","date":"2023-12-01","objectID":"/posts/08.%E8%8C%83%E6%95%B0%E4%B8%8E%E6%9E%81%E9%99%90/:1:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 8—范数与极限知识点总结复习","uri":"/posts/08.%E8%8C%83%E6%95%B0%E4%B8%8E%E6%9E%81%E9%99%90/"},{"categories":["课程笔记"],"content":"2 矩阵范数 矩阵范数定义 设$||A||$是以$C^{m\\times n}$中的矩阵$A$为自变量的非负实值函数，如果满足以下四个条件： 非负性：$||A||\\geq 0$，且$||A||=0$当且仅当$A=0$ 齐次性：$\\forall \\alpha \\in C,A\\in C^{m\\times n}$，有$||\\alpha A||=|\\alpha|||A||$ 三角不等式：$\\forall A,B \\in C^{m\\times n}$，有$||A+B||\\leq ||A||+||B||$ 相容性：$\\forall A,B \\in C^{m\\times n}$，有$||AB||\\leq ||A||\\space ||B||$ 则称$||A||$为$m\\times n$矩阵$A$的范数 定理 设$A=(a_{ij})\\in C^{n\\times n}$，则由$l_1,l_2,l_{\\infty}$向量范数各自推导得到的矩阵范数 行和范数： 列和范数： 谱范数： $F$范数： Python求解矩阵范数 import numpy as np A = np.matrix([[-1, -1, 4], [1, 1, 2], [1, -2, 2]]) # 表示复数矩阵[[1, -1, 1], [-i, 0, 2i], [1, 1, 1]] B = np.matrix([[1, -1, 1], [-1j, 0, 2j], [1, 1, 1]]) # 求A的矩阵范数，ord分别为1，2，np.inf，F print(\"A范数\") print(\"A的1范数（列和范数）：\", np.linalg.norm(A, ord=1)) print(\"A的2范数（谱范数）：\", np.linalg.norm(A, ord=2)) print(\"A的无穷范数（行和范数）：\", np.linalg.norm(A, ord=np.inf)) print(\"A的F范数：\", np.linalg.norm(A, ord='fro')) print(\"B范数\") print(\"B的1范数（列和范数）：\", np.linalg.norm(B, ord=1)) print(\"B的2范数（谱范数）：\", np.linalg.norm(B, ord=2)) print(\"B的无穷范数（行和范数）：\", np.linalg.norm(B, ord=np.inf)) print(\"B的F范数：\", np.linalg.norm(B, ord='fro')) ","date":"2023-12-01","objectID":"/posts/08.%E8%8C%83%E6%95%B0%E4%B8%8E%E6%9E%81%E9%99%90/:2:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 8—范数与极限知识点总结复习","uri":"/posts/08.%E8%8C%83%E6%95%B0%E4%B8%8E%E6%9E%81%E9%99%90/"},{"categories":["课程笔记"],"content":"3 矩阵序列 矩阵序列的收敛 设有矩阵序列${A^{(k)}}$，其中$A^{(k)}=(a_{ij}^{(k)})\\in C^{m\\times n}$，如果当$k\\rightarrow \\infty$时，矩阵$A^{(k)}$的每一个元素$a_{ij}^{(k)}$都有极限$a_{ij}$，即 $$ \\lim_{k\\rightarrow \\infty}a_{ij}^{(k)}=a_{ij},1\\leq i\\leq m;1\\leq j\\leq n $$ 则称矩阵序列${A^{(k)}}$是收敛的，并把矩阵$A=(a_{ij})\\in C^{m\\times n}$称为${A^{(k)}}$的极限。 定理 设$A\\in C^{n\\times n}$，$\\lim_{k\\rightarrow \\infty}A^k=0$的充要条件是$\\rho(A)\u003c1$。其中$\\rho(A)$为$A$的谱半径，即所有特征值的绝对值的最大值。 ","date":"2023-12-01","objectID":"/posts/08.%E8%8C%83%E6%95%B0%E4%B8%8E%E6%9E%81%E9%99%90/:3:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 8—范数与极限知识点总结复习","uri":"/posts/08.%E8%8C%83%E6%95%B0%E4%B8%8E%E6%9E%81%E9%99%90/"},{"categories":["课程笔记"],"content":"4 矩阵级数 矩阵级数定义 设有矩阵序列${A^{(k)}}\\in C^{m\\times n}$，则无穷和$A^{(1)}+A^{(2)}+…+A^{(k)}+…$称为矩阵级数，记为$\\sum_{k=1}^{\\infty}A^{(k)}$。由定义可知，矩阵级数收敛的充要条件是$mn$个数项级数$\\sum_{k=1}^\\infty a_{ij}^{(k)}(1\\leq i\\leq m, 1\\leq j \\leq n)$都收敛，如果它们都绝对收敛，则称矩阵级数绝对收敛。 定理 矩阵级数$\\sum_{k=1}^{\\infty}A^{(k)}$绝对收敛的充要条件是数项级数$\\sum_{k=1}^{\\infty}||A^{(k)}||$，其中$||\\cdot ||$是$C^{m\\times n}$上的任一矩阵范数。 矩阵幂级数定义 设$A\\in C^{n\\times n}$，形如 $$ \\sum_{k=0}^{\\infty}c_kA^{k}=c_0I+c_1A+c_2A^2+\\cdots+c_kA^k+\\cdots $$ 的矩阵级数称为矩阵幂级数。 定理 设$A\\in C^{n\\times n}$，并且幂级数$\\sum_{k=0}^{\\infty}c_kx^k$的收敛半径为$R$，如果$\\rho(A)\u003cR$，则矩阵幂级数$\\sum_{k=0}^{\\infty}c_kA^k$绝对收敛；如果$\\rho(A)\u003eR$，则矩阵幂级数$\\sum_{k=0}^{\\infty}c_kA^k$发散。 求收敛半径 设幂级数$\\sum_{k=0}^{\\infty}c_kx^k$ 比值法 $R=\\lim_{n\\rightarrow \\infty}|\\frac{a_n}{a_{n+1}}|$ 根式法 $R=\\lim_{n\\rightarrow \\infty}|\\frac{1}{\\sqrt[n]{a_n}}|$ 例题 Given For $T\u003e0$, find the radius of covergence for $$ s(z)=\\sum_{k=0}^{\\infty}\\frac{1}{(T^3+\\frac{3}{k^2+3})^{\\frac{k}{3}}}z^k $$ Let $h(z)=s(2z-T)$. Decide when the matrix power series $h(A)$ converges absolutely. Solution: For $s(z)$: $R=\\lim_{k\\rightarrow \\infty}\\frac{(T^3+\\frac{3}{(k+1)^2+3})^{\\frac{k+1}{3}}}{(T^3+\\frac{3}{k^2+3})^{\\frac{k}{3}}}=\\lim_{k\\rightarrow \\infty}\\frac{(T^3)^{\\frac{k+1}{3}}}{(T^3)^\\frac{k}{3}}=T$ So for matrix $2A-TI$, we can determine $|\\lambda I-2A+TI|=(\\lambda -2+T)^2(\\lambda -6 + T)=0$, The eigenvalues are solved as: $2-T,2-T,6-T$. From , so when $T\u003e3$, $h(A)$ converges absolutly. ","date":"2023-12-01","objectID":"/posts/08.%E8%8C%83%E6%95%B0%E4%B8%8E%E6%9E%81%E9%99%90/:4:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 8—范数与极限知识点总结复习","uri":"/posts/08.%E8%8C%83%E6%95%B0%E4%B8%8E%E6%9E%81%E9%99%90/"},{"categories":["课程笔记"],"content":"5 矩阵函数 矩阵函数定义 设$A\\in C^{n\\times n}$，一元函数$f(z)$能够展开为$z$的幂级数$f(z)=\\sum_{k=0}^\\infty c_kz^k$，并且该幂级数的收敛半径为$R$。当矩阵$A$的谱半径$\\rho(A)\u003cR$时，则将收敛矩阵幂级数$\\sum_{k=0}^{\\infty}c_kA^k$的和定义为矩阵函数，记为$f(A)$，即$f(A)=\\sum_{k=0}^{\\infty}c_kA^k$。 常见矩阵函数 矩阵指数函数：$e^A=\\sum_{k=0}^\\infty \\frac{1}{k!}A^k=I+A+\\frac{1}{2!}+\\cdots+\\frac{1}{n!}A^n+\\cdots$ 矩阵正弦函数：$sinA=\\sum_{k=0}^\\infty \\frac{(-1)^k}{(2k+1)!}A^{2k+1}=A-\\frac{1}{3!}A^3+\\frac{1}{5!}A^5-\\cdots+(-1)^n\\frac{1}{(2n+1)!}A^{2n+1}$ 矩阵余弦函数：$cosA=\\sum_{k=0}^\\infty \\frac{(-1)^k}{(2k)!}A^{2k}=A-\\frac{1}{2!}A^2+\\frac{1}{4!}A^4-\\cdots+(-1)^n\\frac{1}{(2n)!}A^{2n}$ 定理 设$A,B\\in C^{n\\times n}$，如果$AB=BA$，则$e^Ae^B=e^Be^A=e^{A+B}$。 利用Jordan标准型求矩阵函数$f(A)$ 求出矩阵$A$的若当标准型$J$和可逆矩阵$P,P^{-1}$，其中$J=diag(J_1,J_2,\\cdots,J_s)$ 计算 则 ","date":"2023-12-01","objectID":"/posts/08.%E8%8C%83%E6%95%B0%E4%B8%8E%E6%9E%81%E9%99%90/:5:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 8—范数与极限知识点总结复习","uri":"/posts/08.%E8%8C%83%E6%95%B0%E4%B8%8E%E6%9E%81%E9%99%90/"},{"categories":["课程笔记"],"content":"Hermite标准型实际上就是行最简行 ","date":"2023-12-01","objectID":"/posts/09.%E5%B9%BF%E4%B9%89%E9%80%86%E7%9F%A9%E9%98%B5/:0:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 9—广义逆矩阵知识点总结复习","uri":"/posts/09.%E5%B9%BF%E4%B9%89%E9%80%86%E7%9F%A9%E9%98%B5/"},{"categories":["课程笔记"],"content":"1 广义逆矩阵定义 广义逆矩阵$G$的定义：对任意$m\\times n$矩阵的$A$，如果存在某个$n\\times m$的矩阵$G$，满足Penrose方程的一部分或全部，则称$G$为$A$的广义逆矩阵 Penrose方程的四个条件： $AGA=A$; $GAG=G$; $(AG)^T=AG$; $(GA)^T=GA$ 满足第$i$个条件，则把$G$记为$A^{(i)}$，这类矩阵的全体记为$A{i}$，所以$A^{i}\\in A{i}$ 类似，满足第$i,j$个条件：$A^{i,j}\\in A{i,j}$ 根据以上，满足$1$个，$2$个，$3$个，$4$个Penrose方程的广义逆矩阵有$C_4^1+C_4^2+C_4^3+C_4^4=4+6+4+1=15$，但应用最多的，也就是我们所学的以下四种： 减号逆或者$g$逆：$A^-=A^{(1)}$ 最小二乘广义逆：$A_l^-=A^{(1,3)}$ 极小范数广义逆：$A_m^-=A^{(1,4)}$ 加号逆或Moore-Penrose广义逆：$A^+=A^{(1,2,3,4)}$ ","date":"2023-12-01","objectID":"/posts/09.%E5%B9%BF%E4%B9%89%E9%80%86%E7%9F%A9%E9%98%B5/:1:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 9—广义逆矩阵知识点总结复习","uri":"/posts/09.%E5%B9%BF%E4%B9%89%E9%80%86%E7%9F%A9%E9%98%B5/"},{"categories":["课程笔记"],"content":"2 减号逆 $A^-$的性质 设$A$为$m\\times n$矩阵，$P$和$Q$分别是$m$阶和$n$阶非奇异方阵，且$B=PAQ$，$A^-$为A的减号逆，则： $rank(A)\\leq rank(A^-)$ $AA^-$和$A^-A$是幂等矩阵，并且$rank(AA^-)=rank(A^-A)=rank(A)$ $Q^{-1}A^-P^{-1}\\in B{1}$ $A^T{1}={G^T|G\\in A{1}}$ （Penrose定理） 设$A,B,C$分别为$m\\times n,p\\times q,m\\times q$矩阵，则矩阵方程： $$ AXB=C $$ 有解的充分必要条件是： $$ AA^-CB^-B=C $$ 并且在有解的情况下，其通解为： $$ X=A^-CB^-+Y-A^-AYBB^- $$ 其中$Y\\in R^{n\\times p}$是任意的矩阵。 求解$A^-$ $A$为$m\\times n$矩阵 ，其中$P,Q,E_r$通过对$A$进行如下操作得到，$G_{12},G_{21},G_{22}$均为常数矩阵，每一项均用$g_{ij}$表示常数，且$Q,P$维度均为$m\\times n$，$E_r$是一个$r \\times r$ 的对角矩阵，其中$r$是矩阵$A$的秩，$G_{12}$维度为$m \\times (n-r)$ ，$G_{21}$维度为$(m-r) \\times n$，$G_{22}$是一个$ (m-r) \\times (n-r)$的矩阵。 例子 初等行变换化为行最简阶梯形矩阵，则 再进行列变换化为$E_r$得到 则 令$g_{ij}=0$，则 利用$A^-$求解线性方程组$Ax=b$ $Ax=b$有解的充分必要条件是$AA^-b=b$，这时特解$x_0=A^-b$，通解$x=A^-b+(I-A^-A)y,\\forall y\\in C^n$ 这里不给出$A^-$，感兴趣的读者可以自己去实现，具体的算法如下： 构造水平增广矩阵： 将原矩阵和单位矩阵水平拼接，形成增广矩阵。 初等行变换： 利用初等行变换将增广矩阵转化为最简行阶梯形式。 提取$P$：变换后的单位矩阵就是$P$ 构造垂直增广矩阵：再将最简行阶梯形与单位矩阵垂直拼接，形成增广矩阵。 初等列变换，提取$G$：变换后的单位矩阵就是$G$ ","date":"2023-12-01","objectID":"/posts/09.%E5%B9%BF%E4%B9%89%E9%80%86%E7%9F%A9%E9%98%B5/:2:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 9—广义逆矩阵知识点总结复习","uri":"/posts/09.%E5%B9%BF%E4%B9%89%E9%80%86%E7%9F%A9%E9%98%B5/"},{"categories":["课程笔记"],"content":"3 最小二乘广义逆 定理1 设$A\\in C^{m\\times n}$，$G\\in A{1,3}$的充分必要条件是$G$满足 $$ A^HAG=A^H $$ 这即为$A{1,3}$（最小二乘广义逆）的通式 定理2 设$A\\in C^{m\\times n}$，$A_l^-$是$A$的任一最小二乘广义逆，则 $$ A{1,3}={G\\in C^{n\\times m}|AG=AA_l^-} $$ 定理3 设$A$是$m\\times n$矩阵，则$G\\in A{1,3}$（即G为最小二乘广义逆）的充分必要条件为$x=Gb$是不相容线性方程组$Ax=b$的最小二乘解。 利用$A_l^-$求解线性方程组$Ax=b$ $x$是不相容线性方程组$Ax=b$的最小二乘解当且仅当$x$是相容线性方程组 $$ Ax=AA_l^-b $$ 的解，并且$Ax=b$的最小二乘解的通式为$x=A_l^-b+(I-A^-A)y,\\forall y\\in C^n$ ","date":"2023-12-01","objectID":"/posts/09.%E5%B9%BF%E4%B9%89%E9%80%86%E7%9F%A9%E9%98%B5/:3:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 9—广义逆矩阵知识点总结复习","uri":"/posts/09.%E5%B9%BF%E4%B9%89%E9%80%86%E7%9F%A9%E9%98%B5/"},{"categories":["课程笔记"],"content":"4 极小范数广义逆 定理1 设$A\\in C^{m\\times n}$，$G\\in A{1,4}$的充分必要条件是$G$满足 $$ GAA^H=A^H $$ 这即为$A{1,4}$（极小范数广义逆）的通式 定理2 设$A\\in C^{m\\times n}$，$A_m^-$是$A$的任一极小范数广义逆，则 $$ A{1,4}={G\\in C^{n\\times m}|GA=A_m^-A} $$ 定理$3$ 设$A$是$m\\times n$矩阵，则$G\\in A{1,4}$（即G为极小范数广义逆）的充分必要条件为$x=Gb$是相容线性方程组$Ax=b$的极小范数解。 利用$A_m^-$求解线性方程组$Ax=b$ 设$A$是$m\\times n$矩阵，则$G\\in A{1,4}$的充分必要条件为$x=Gb$是相容线性方程组$Ax=b$的极小范数解，即$x=A_m^-b$为相容线性方程组$Ax=b$的极小范数解 注意：极小范数解是唯一的，而最小二乘解不唯一 ","date":"2023-12-01","objectID":"/posts/09.%E5%B9%BF%E4%B9%89%E9%80%86%E7%9F%A9%E9%98%B5/:4:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 9—广义逆矩阵知识点总结复习","uri":"/posts/09.%E5%B9%BF%E4%B9%89%E9%80%86%E7%9F%A9%E9%98%B5/"},{"categories":["课程笔记"],"content":"5 Moore-Penrose（加号逆） $A^+$的性质 $A^+$存在且唯一 $A^+=A_m^-AA_l^-$ 定理1 设$A$是$m\\times n$矩阵，则$G$是加号逆$A^+$的充分必要条件为$x=Gb$是不相容线性方程组$Ax=b$的极小最小二乘解。 重点 因为加号逆满足四个条件，所以它也是减号逆、最小二乘广义逆、极小范数广义逆。所以： 当$b\\in R(A)$时，$Ax=b$的通解为： $$ x=A^+b+(I-A^+A)y,\\forall y\\in R^n $$ 当$b\\in R(A)$时，$Ax=b$的极小范数解为： $$ x=A^+b $$ 极小范数解是唯一的 对于$\\forall b$，$Ax=b$的最小二乘解为： $$ x=A^+b+(I-A^+A)y,\\forall y\\in R^n $$ 对于$\\forall b$，$Ax=b$的具有极小范数的最小二乘解为： $$ x=A^+b $$ 求解$A^+$ 若$A$为行满秩矩阵，则：$A^+=A^H(AA^H)^{-1}$ 若$A$为列满秩矩阵：则：$A^+=(A^HA)^{-1}A^H$ 否则利用满秩分解求解：$A^+=G^+F^+=G^H(GG^H)^{-1}(F^HF)^{-1}F^H$ Python代码如下： import numpy as np from sympy import Matrix, Symbol def get_A_plus(A): A_plus = None # 判断A是行满秩还是列满秩，如果都不是则利用满秩分解求解A_plus if A.rank() == A.rows: print(\"A为行满秩矩阵\") A_plus = A.H * (A * A.H).inv() elif A.rank() == A.cols: print(\"A为列满秩矩阵\") A_plus = (A.H * A).inv() * A.H else: print(\"A为非满秩矩阵\") # 利用满秩分解求解A_plus，full_rank在另一篇矩阵论复习博客中 F, G = full_rank(A) A_plus = G.H * ((G * G.H).inv()) * ((F.H * F).inv()) * F.H return A_plus 利用$A^+$求解线性方程组$Ax=b$ $Ax=b$有解（相容）的充要条件是$AA^+b=b$ $x=A^+b+(I-A^+A)y,\\forall y\\in C^n$是相容方程组$Ax=b$的通解，或是不相容方程组$Ax=b$的全部最小二乘解 $x_0=A^+b$是相容方程组$Ax=b$的唯一极小范数解，或是不相容方程组$Ax=b$的唯一极小范数最小二乘解 Python代码如下： import numpy as np from sympy import Matrix, Symbol def get_solution(A, b): A_plus = get_A_plus(A) # 单位矩阵 I = Matrix(np.eye(A_plus.rows)) print(\"I:\", I) # 生成符号列表 symbols_list = [Symbol(f'y{i+1}') for i in range(A_plus.rows)] # 生成符号矩阵 symbols_matrix = Matrix(symbols_list) print(\"symbols_matrix:\", symbols_matrix) if A * A_plus * b == b: print(\"Ax = b有解\") print(\"通解为：\") print(A_plus.rows) print(A_plus * b + (I - A_plus * A) * symbols_matrix) print(\"唯一极小范数解为：\") print(A_plus * b) else: print(\"Ax = b无解\") print(\"全部最小二乘解为：\") print(A_plus.rows) print(A_plus * b + (I - A_plus * A) * symbols_matrix) print(\"唯一极小范数最小二乘解：\") print(A_plus * b) get_solution(A, b) ","date":"2023-12-01","objectID":"/posts/09.%E5%B9%BF%E4%B9%89%E9%80%86%E7%9F%A9%E9%98%B5/:5:0","tags":["矩阵论"],"title":"【矩阵论】Chapter 9—广义逆矩阵知识点总结复习","uri":"/posts/09.%E5%B9%BF%E4%B9%89%E9%80%86%E7%9F%A9%E9%98%B5/"},{"categories":["技巧"],"content":"1 普通搜索 我们一般在github搜索项目，都是直接在根据仓库关键字搜索项目，可能还会用到图中的匹配条件进行筛选。 这样虽然能实现我们的大部分需求，但还不足实现精确查找。而github有自己的一套搜索语法，能帮助我们实现精确查找。 ","date":"2023-11-21","objectID":"/posts/05.github%E6%90%9C%E7%B4%A2%E6%8A%80%E5%B7%A7/:1:0","tags":["Github"],"title":"Github搜索技巧","uri":"/posts/05.github%E6%90%9C%E7%B4%A2%E6%8A%80%E5%B7%A7/"},{"categories":["技巧"],"content":"2 高级搜索技巧 in:name \u003c关键字\u003e 根据仓库名称搜索仓库。 in:description \u003c关键字\u003e：根据仓库描述搜索仓库。 in:readme \u003c关键字\u003e：根据 README 文件内容搜索仓库。 stars(fork): \u003e(=) \u003c数字\u003e \u003c关键字\u003e：搜索 star 或 fork 数大于（或等于）指定数字的仓库，并包含关键字。 stars(fork): 10..20 \u003c关键词\u003e：搜索 star 或 fork 数在 10 到 20 之间的仓库，并包含关键字。 size:\u003e=5000 \u003c关键词\u003e：搜索仓库大小$\\geq$ 5000KB，并包含关键字。 pushed(created):\u003e2023-7-1 \u003c关键字\u003e：搜索更新或创建日期在 2023 年 7 月 1 日之后的仓库，并包含关键字。 license:mit \u003c关键字\u003e：搜索 LICENSE 为 MIT 的仓库，并包含关键字。 language:Go \u003c关键字\u003e：搜索仓库语言为 Go 的仓库，并包含关键字。 user:\u003c用户名\u003e \u003c关键字\u003e：查询某个用户的项目，并包含关键字。 org:\u003c组织名\u003e \u003c关键字\u003e：查询某个组织的项目，并包含关键字。 repo:owner/name： 匹配特定仓库名称，例如repo:unique-pure/unique-pure.github.io is:public/private \u003c关键字\u003e：根据公有或私有仓库搜索，并包含关键字。当然，只有你具有访问权限的私有仓库才可以搜索到。 topic:\u003c关键字\u003e：根据主题搜索仓库。 topics:\u003e5：搜索具有3个以上主题的仓库。 followers:n：根据仓库关注者数量搜索仓库。 ","date":"2023-11-21","objectID":"/posts/05.github%E6%90%9C%E7%B4%A2%E6%8A%80%E5%B7%A7/:2:0","tags":["Github"],"title":"Github搜索技巧","uri":"/posts/05.github%E6%90%9C%E7%B4%A2%E6%8A%80%E5%B7%A7/"},{"categories":["技巧"],"content":"3 github advance查找工具 github开发了一套查找工具，非常全面，也可以使用这个工具进行精确查找。 https://github.com/search/advanced ","date":"2023-11-21","objectID":"/posts/05.github%E6%90%9C%E7%B4%A2%E6%8A%80%E5%B7%A7/:3:0","tags":["Github"],"title":"Github搜索技巧","uri":"/posts/05.github%E6%90%9C%E7%B4%A2%E6%8A%80%E5%B7%A7/"},{"categories":["工具"],"content":"1 引言 ","date":"2023-11-16","objectID":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/:1:0","tags":["VPN"],"title":"WireGuard组网教程","uri":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1.1 什么是WireGuard 官方介绍如下： WireGuard ® 是一款极其简单但快速且现代的 VPN，采用最先进的加密技术。它的目标是比 IPsec 更快、更简单、更精简、更有用，同时避免令人头疼的问题。它的性能远高于 OpenVPN。 WireGuard 被设计为通用 VPN，可在嵌入式接口和超级计算机上运行，适合许多不同的情况。它最初针对 Linux 内核发布，现在已跨平台（Windows、macOS、BSD、iOS、Android）且可广泛部署。它目前正在大力开发中，但它可能已被视为业内最安全、最易于使用且最简单的 VPN 解决方案。 我们可以用一句话概括它： WGuard是一款可以组建虚拟私人局域网（VPN）的软件，允许用户通过公共网络（如互联网）安全地传输数据，同时保持数据的机密性和完整性。 WireGuard有如下优势： 更轻便：以Linux内核模块的形式运行，资源占用小。 更高效：相比目前主流的IPSec、OpenVPN等协议，WireGuard的效率要更高。 更快速：比目前主流的VPN协议，连接速度要更快。 更安全：使用了更先进的加密技术。 更易搭建：部署难度相对更低。 更隐蔽：以UDP协议进行数据传输，比TCP协议更低调。 不易被封锁：TCP阻断对WireGuard无效，IP被墙的情况下仍然可用。 更省电：不使用时不进行数据传输，移动端更省电。 ","date":"2023-11-16","objectID":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/:1:1","tags":["VPN"],"title":"WireGuard组网教程","uri":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1.2 WireGuard可以用来做什么 建立VPN（不限设备类型） WireGuard支持多种平台，包括电脑、智能手机和路由器。这一特性使其成为构建虚拟私有网络（VPN）的理想选择，能在这些设备上实现安全连接。无论是用于远程工作、保护数据隐私，还是绕过地理限制，WireGuard都能提供稳定且安全的网络连接。 实现内网穿透 内网穿透，即NAT（Network Address Translator）穿透，是指计算机在内网（局域网）内使用私有IP地址，在连接外网（互联网）时使用全局IP地址的技术。该技术被普遍使用在有多台主机但只通过一个公有IP地址访问的私有网络中。 举个例子：比如我在实验室配置了一个服务器 Server A，当我在实验室的时候，就可以通过自己的笔记本使用SSH连接【因为我和服务器处于一个局域网】，当我回宿舍以后，就没有办法直接使用SSH连接了【因为我和服务器不在一个局域网】，这个时候就需要进行NAT穿透，让我在宿舍也可以使用SSH连接Server A。 通过Wireguard可以将广域网上的主机连接起来，形成一个局域网。只需要有一台具有固定公网IP的服务器，就可以将其作为我们搭建的局域网的中心节点，让其他的主机（不论是否有公网IP，不论是否在NAT内），都通过这个中心节点和彼此相连。由此就构建了一个中心辐射型的局域网，实现了内网穿透等功能。 Docker容器通信 WireGuard还可用于Docker容器之间的通信。在Docker环境中，容器之间的网络通信是一个重要的问题。WireGuard通过提供一种安全的通信方式，能够在不同容器之间建立一个加密的网络连接，从而保障数据的安全传输。这对于需要在不同容器间安全共享数据的应用尤为重要。 ","date":"2023-11-16","objectID":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/:1:2","tags":["VPN"],"title":"WireGuard组网教程","uri":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1.3 WireGuard原理 WireGuard源码地址 WireGuard 是一种在第 3 层（网络层）运行的安全网络隧道，与传统的 VPN 解决方案（如 IPsec 和 OpenVPN）相比，它的设计更安全、性能更高且更易于使用。它是作为 Linux 内核虚拟网络接口实现的，基于安全隧道的基本原理：将peer的公钥与隧道源 IP 地址关联。 相关术语： Peer/Node/Device 连接到VPN 并为自己注册一个VPN子网地址（如 192.0.2.3）的主机。还可以通过使用逗号分隔的 CIDR 指定子网范围，为其自身地址以外的 IP 地址选择路由。 中继服务器（Bounce Server） 一个公网可达的peer，可以将流量中继到 NAT 后面的其他peer。Bounce Server 并不是特殊的节点，它和其他peer一样，唯一的区别是它有公网 IP，并且开启了内核级别的 IP 转发，可以将 威屁恩 的流量转发到其他客户端。 子网（Subnet） 一组私有 IP，例如 192.0.2.1-255 或 192.168.1.1/24，一般在 NAT 后面，例如办公室局域网或家庭网络。 CIDR 表示法 CIDR，即无类域间路由（Classless Inter-Domain Routing），是一种用于对IP地址进行灵活表示和分配的标准。 NAT 子网的私有 IP 地址由路由器提供，通过公网无法直接访问私有子网设备，需要通过 NAT 做网络地址转换。路由器会跟踪发出的连接，并将响应转发到正确的内部 IP。 公开端点（Public Endpoint） 节点的公网 IP 地址:端口，例如 123.124.125.126:1234，或者直接使用域名 some.domain.tld:1234。如果peer节点不在同一子网中，那么节点的公开端点必须使用公网 IP 地址。 私钥（Private key） 单个节点的 WireGuard 私钥，生成方法是：wg genkey \u003e example.key。 公钥（Public key） 单个节点的 WireGuard 公钥，生成方式为：wg pubkey \u003c example.key \u003e example.key.pub。 DNS 域名服务器，用于将域名解析为 VPN 客户端的 IP，不让 DNS请求泄漏到 VPN 之外。 主要功能和原理如下 WireGuard 通过添加一个（或多个）网络接口来工作，例如 eth0 或 wlan0 ，称为 wg0 （或 wg1 、 wg2 、 wg3 等）。然后可以使用 ifconfig(8) 或 ip-address(8) 正常配置该网络接口，并使用 route(8) 或 ip-route(8) 添加和删除其路由，以及所有普通网络实用程序都是如此。接口的特定 WireGuard 方面使用 wg(8) 工具进行配置。该接口充当隧道接口。 WireGuard 将隧道 IP 地址与公钥和远程端点相关联。当接口向peer发送数据包时，它会执行以下操作： 该数据包适用于 192.168.30.8。那是哪位peer啊？让我看看…好吧，这是给peer ABCDEFGH 的。 （或者，如果它不适合任何已配置的peer，则丢弃该数据包。） 使用peer ABCDEFGH 的公钥加密整个 IP 数据包。 Peer ABCDEFGH 的远程端点是什么？让我看看…好的，端点是主机 216.58.211.110 上的 UDP 端口 53133。 使用 UDP 通过 Internet 将步骤 2 中的加密字节发送到 216.58.211.110:53133。 当接口收到数据包时，会发生以下情况： 我刚刚从主机 98.139.183.24 上的 UDP 端口 7361 收到一个数据包。让我们来解密吧！ 它为peer LMNOPQRS 正确解密和验证。好的，让我们记住，peer LMNOPQRS 的最新 Internet 端点是使用 UDP 的 98.139.183.24:7361。 解密后，明文数据包来自 192.168.43.89。是否允许peer LMNOPQRS 以 192.168.43.89 向我们发送数据包？ 如果是，则在接口上接受数据包。如果没有，就放弃它。 WireGuard 的核心是一个称为加密密钥路由的概念，它的工作原理是将公钥与隧道内允许的隧道 IP 地址列表相关联。每个网络接口都有一个私钥和一个peer点列表。每个peer都有一个公钥。公钥短小且简单，由peer用来相互验证。它们可以通过任何带外方法传递以在配置文件中使用，类似于将 SSH 公钥发送给朋友以访问 shell 服务器的方式。 ","date":"2023-11-16","objectID":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/:1:3","tags":["VPN"],"title":"WireGuard组网教程","uri":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1.4 WireGuard安装 wireGuard官方安装教程 ","date":"2023-11-16","objectID":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/:1:4","tags":["VPN"],"title":"WireGuard组网教程","uri":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"2 WireGuard组网实现内网穿透 ","date":"2023-11-16","objectID":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/:2:0","tags":["VPN"],"title":"WireGuard组网教程","uri":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"2.1 前提条件 公网服务器： 必须拥有一台具有公网IP地址的服务器，这是内网穿透的关键。该服务器充当中转站，负责将外部请求传递到内部网络。 网络设备配置权限： 需要对内部网络的路由器或防火墙有一定的配置权限，以便进行端口映射或其他必要的网络设置。这确保了从公网服务器到内网的连接是有效的。 安装WireGuard： 在公网服务器和内网设备上都需要安装和配置WireGuard软件。确保两端的WireGuard配置一致，包括公私钥的生成和网络接口的配置。 开启相应端口： 在公网服务器的防火墙配置中，需要打开WireGuard所使用的端口（默认是51820/UDP），以确保能够接收来自内网设备的连接请求。 合适的网络拓扑： 确保了解内部网络的拓扑结构，以便正确设置WireGuard配置，包括允许流量通过的子网、路由等。 ","date":"2023-11-16","objectID":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/:2:1","tags":["VPN"],"title":"WireGuard组网教程","uri":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"2.2 网络拓扑结构 ","date":"2023-11-16","objectID":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/:2:2","tags":["VPN"],"title":"WireGuard组网教程","uri":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"2.3 具体步骤 2.3.1 中继服务器配置 创建密钥对 wg genkey | tee server_privatekey | wg pubkey \u003e server_publickey 执行以上两条命令后，会在执行命令的当前文件夹自动生成2个文件： 开启IP地址转发 sudo sysctl net.ipv4.ip_forward 如果显示1则说明已开启，否则则未开启。 echo \"net.ipv4.ip_forward = 1\" \u003e\u003e /etc/sysctl.conf echo \"net.ipv4.conf.all.proxy_arp = 1\" \u003e\u003e /etc/sysctl.conf sysctl -p /etc/sysctl.conf 设置IP地址伪装 # 允许防火墙伪装IP firewall-cmd --add-masquerade # 检查是否允许伪装IP firewall-cmd --query-masquerade # 禁止防火墙伪装IP firewall-cmd --remove-masquerade 配置wireguard虚拟网卡（不推荐，只是让读者直观了解过程） sudo ip link add wg0 type wireguard # 添加一块叫 wg0 的虚拟 wireguard 网卡 sudo ip addr add 192.168.71.1/24 dev wg0 # 给 wg0 网卡添加 ip 地址 192.168.71.1，子网掩码 255.255.255.0 sudo wg set wg0 private-key ./server-privatekey # wireguard 设置密钥 sudo ip link set wg0 up # 启用刚刚添加的网卡 我们可以通过ip addr命令查看到wg0网卡的状态 可以看到网卡wg0 接口是已启用的，具有 IPv4 地址 192.168.71.1 输入wg命令则可以看到配置信息，配置文件通常在 有想继续尝试这种方式的可以看一下官方教程 编写配置文件配置网卡（推荐，应该wg set命令需要提供很多参数，很容易出错） 我们在/etc/wireguard目录中创建wg0.conf并编写配置，配置项请看2.4 配置项说明 [Interface] # 本机密钥 PrivateKey = KIDTljv66CgVYBNlrSD13Au6qfUdIcFJkTBkuErhTEk= # 本机地址 Address = 192.168.71.1/24 # 监听端口 ListenPort = 51820 [Peer] # 对端的publickey PublicKey = iWy57DmR6wVXcVzMDOa2WyywO0WT5JRAGYIlh0v/nW8= # 对端地址 AllowedIPs = 192.168.71.2/24 重新启动网卡 sudo wg-quick down wg0 sudo wg-quick up wg0 2.3.2 其他peer 我这里只列举MacOS的操作方式（其他都同理，就是要配置私钥和公钥） 操作完之后，它会给出密钥对，我们只需要添加好其他信息即可。 配置文件如下： [Interface] # 本机密钥 PrivateKey = kDUqWzkbaB1EU5C2ADoId1TXtZF89xxn0VV45EcjFHs= # 本机地址 Address = 192.168.71.2/24 [Peer] # 对端公钥，即公网服务器公钥 PublicKey = bEm1p736FQySfKlTTUCeHmiwTmna5umZWOWLGWqioSk= # 允许此对等方的传入流量并指定传出流量的目标。 AllowedIPs = 192.168.71.0/24 # 公网IP+监听端口号 Endpoint = 1.1.1.1:51820 PersistentKeepalive = 25 2.3.3 测试 MacOS端： 服务器Ping 主机： ","date":"2023-11-16","objectID":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/:2:3","tags":["VPN"],"title":"WireGuard组网教程","uri":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"2.4 WireGuard配置文件说明 interface部分： PrivateKey: 由 wg genkey 生成的 Base64 编码的私钥。必须配置。 ListenPort: 用于监听的 16 位端口。可选，如果未指定，则随机选择端口。 DNS: 指定 DNS 服务器的 IP 地址。 FwMark: 用于传出数据包的 32 位 fwmark。如果设置为 0 或 “off”，则禁用此选项。可选。可以以十六进制形式指定，例如，以 “0x” 开头。可选。 Peer 部分： PublicKey: 由 wg pubkey 根据私钥计算的 Base64 编码的公钥。必须配置。 PresharedKey: 由 wg genpsk 生成的 Base64 编码的预共享密钥。可选，可以省略。此选项为现有的公钥加密提供了额外的对称密钥加密层，以增强对抗后量子计算的能力。 AllowedIPs: 逗号分隔的 IP 地址（IPv4 或 IPv6）列表，带有 CIDR 掩码，用于允许此对等方的传入流量并指定传出流量的目标。可以多次指定。可用 0.0.0.0/0 匹配所有 IPv4 地址，使用 ::/0 匹配所有 IPv6 地址。 Endpoint: 一个 IP 地址或主机名，后跟冒号，然后是一个端口号。此端点将自动更新为来自对等方的正确经过身份验证的数据包的最新源 IP 地址和端口。可选。 PersistentKeepalive: 保持活跃的时间间隔，介于 1 和 65535 之间，表示多久发送一次对等方的身份验证空数据包，以保持有状态的防火墙或 NAT 映射的有效性。如果设置为 0 或 “off”，则禁用此选项。可选，默认情况下此选项被禁用。 下面是一个简单的配置文件示例： [Interface] PrivateKey = yAnz5TF+lXXJte14tji3zlMNq+hd2rYUIgJBgB3fBmk= ListenPort = 51820 [Peer] PublicKey = xTIBA5rboUvnH4htodjb6e697QjLERt1NAB4mZqp8Dg= Endpoint = 192.95.5.67:1234 AllowedIPs = 10.192.122.3/32, 10.192.124.1/24 [Peer] PublicKey = TrMvSoP4jYQlY6RIzBgbssQqY3vxI2Pi+y71lOWWXX0= Endpoint = [2607:5300:60:6b0::c05f:543]:2468 AllowedIPs = 10.192.122.4/32, 192.168.0.0/16 [Peer] PublicKey = gN65BkIKy1eCE9pP1wdc8ROUtkHLF2PfAqYdyYBz6EA= Endpoint = test.wireguard.com:18981 AllowedIPs = 10.10.10.230/32 ","date":"2023-11-16","objectID":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/:2:4","tags":["VPN"],"title":"WireGuard组网教程","uri":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"3 WireGuard工具 ","date":"2023-11-16","objectID":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/:3:0","tags":["VPN"],"title":"WireGuard组网教程","uri":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"3.1 wg-easy github地址 这是一个用于管理 WireGuard 设置的 Web 用户界面。使用它之前我们得先安装docker和docker-compose。这里我给出docker-compose.yml配置文件示例。还有很多配置项可在仓库中找到，灵活配置VPN version: '3' services: wg-easy: image: weejewel/wg-easy container_name: wg-easy environment: - WG_HOST=YOUR_SERVER_IP # 公网IP - PASSWORD=YOUR_ADMIN_PASSWORD # Web UI登录密码 - WG_PORT=51820 # 监听端口 - WG_PERSISTENT_KEEPALIVE=25 # 保持“连接”打开的值（以秒为单位） - WG_DEFAULT_ADDRESS=192.168.71.0 # 客户端 IP 地址范围 - WG_ALLOWED_IPS=192.168.71.0/24 # 客户端将使用的允许 IP volumes: - ~/.wg-easy:/etc/wireguard ports: - 51820:51820/udp - 51821:51821/tcp cap_add: - NET_ADMIN - SYS_MODULE sysctls: - net.ipv4.conf.all.src_valid_mark=1 - net.ipv4.ip_forward=1 restart: unless-stopped 通过docker compose up -d部署好后，我们进入Web界面即可添加Client。 这里，我们只需要将这三个配置文件分给对应的Client的即可完成网络搭建，特别方便！ ","date":"2023-11-16","objectID":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/:3:1","tags":["VPN"],"title":"WireGuard组网教程","uri":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"3.2 wg-gen-web wg-gen-web 跟wg-easy类似，不过功能更强大。 ","date":"2023-11-16","objectID":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/:3:2","tags":["VPN"],"title":"WireGuard组网教程","uri":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"3.3 dsnet github地址 一款用于管理集中式wireguard VPN 的FAST 命令。 ","date":"2023-11-16","objectID":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/:3:3","tags":["VPN"],"title":"WireGuard组网教程","uri":"/posts/01.wireguard%E7%BB%84%E7%BD%91%E6%95%99%E7%A8%8B/"},{"categories":["前端"],"content":"1 构建工具 ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:1:0","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"1.1 什么是构建工具 浏览器它只认识html，css，js 企业级项目里都可能具备哪些功能？ typescript：使用tsc工具将ts代码转换为js代码； React/Vue：安装react-compiler/vue-compiler，将我们写的jsx文件或者.vue文件转换为render函数； less/sass/postcss/component-style：我们有需要安装less-loader,sass-loader等一系列编译工具转换为css代码； 语法降级：babel可以将es的新语法转换旧版浏览器可以接受的语法； 体积优化：uglifyjs可以将我们的代码进行压缩变成体积更小性能更高的文件。 以上稍微改一点，就会很麻烦，所以我们希望有一个构建工具可以将以上工具全部集成到一起，实现上述功能，我们只需要关注我们写的代码即可。即构建工具可以帮我们自动去tsc，react-comiler，less，babel，uglifyjs全部走一遍，让我们不用每次关心我们的代码在浏览器运行。 打包：将我们写的浏览器不认识的代码，交给构建工具进行编译处理的过程就叫做打包，打包完成以后会给我们一个浏览器可以认识的文件。 构建工具承担了以下脏活累活： 模块化开发支持：支持直接从node_modules里引入代码 + 多种模块化支持 处理代码兼容性：比如babel语法降级，less，ts语法转换（不是构建工具做的，构建工具将这些语法对应的处理工具集成进来自动化处理） 提高项目性能：压缩文件，代码分割 优化开发体验： 构建工具会帮你自动监听文件的变化，当文件变化以后自动帮你调用对应的集成工具进行重新打包，然后再浏览器重新运行（整个过程叫做热更新，hot replacement） 开发服务器：跨域的问题，用react-cli create-react-element vue-cli解决跨域的问题 我们只需要首次给构建工具提供一个配置文件（这个配置文件也不是必须的，没有它也会默认处理），有了集成的配置文件以后，我们就可以在下次需要更新的时候调用一次对应的命令即可，如果再结合热更新，我们就更加不需要管任何东西，这就是构建工具去做的事情，它让我们不用关心生产的带啊吗也不用关心代码如何在浏览器运行，只需要关心我们的开发怎么写的爽怎么写就好了。 ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:1:1","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"1.2 主流构建工具 webpack vite parcel esbuild rollup grunt gulp 国内主流还是webpack，vite和esbuild。 ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:1:2","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"1.3 vite相较于webpack的优势 然而，当我们开始构建越来越大型的应用时，需要处理的 JavaScript 代码量也呈指数级增长。包含数千个模块的大型项目相当普遍。基于 JavaScript 开发的工具就会开始遇到性能瓶颈：通常需要很长时间（甚至是几分钟！）才能启动开发服务器，即使使用模块热替换（HMR），文件修改后的效果也需要几秒钟才能在浏览器中反映出来。如此循环往复，迟钝的反馈会极大地影响开发者的开发效率和幸福感。 起因：我们的项目越大，构建工具（webpack）所要处理的js代码就越多【跟webpack的一个构建过程（工作流程有关）】 造成的结果：构建工具需要很长时间才能启动开发服务器（把项目跑起来） yarn start yarn dev npm run dev npm run start webpack不能改，如果要改，则会动到webpack的大动脉。 // 这段代码最终回到浏览器里去运行 const lodash = require(\"lodash\"); // commonjs 规范 import Vue from \"vue\"; // es6 module // webpack是允许我们这么写的，webpack会这样转换 const lodash = webpack_require(\"loadsh\"); const Vue = webpack_require(\"vue\"); webpack的编译原理，AST抽象语法分析的工具，分析出js文件有哪些导入导出操作 构建工具是运行在服务端的 (function(modules) { function webpack_require() {} // 入口是index.js // 通过webpack的配置文件得来的：webpack.config.js ./src/index.js modules[entry](webpack_require); }, ({ \"index.js\": (webpack_require) =\u003e { const lodash = webpack_require(\"lodash\"); const Vue = webpack_require(\"vue\"); } })) 因为webpack支持模块化，它一开始就必须要统一模块化代码，所以意味着它需要将所有的依赖读一遍。 vite会不会直接把webpack干翻？vite是基于es modules的，侧重点不一样，webpack更多的关注兼容性，而vite关注浏览器端的开发体验。 ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:1:3","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"2 vite启动项目初体验 ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:2:0","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"2.1 你必须要理解的vite脚手架和vite vite官网搭建vite项目文档教程：https://cn.vitejs.dev/guide/#scaffolding-your-first-vite-project 比如我们敲了yarn create vite 帮我们全局安装了一个东西：create-vite（vite的脚手架） 直接运行这个create-vite bin目录下的一个执行配置 误区：认为官网中使用对应的yarn create构建项目的过程也是vite在做的事情 我们之前接触过vue-cli，create-vite和vite的关系是：create-vite内置了vite。使用vue-cli会内置webpack 先学习的就是vite，暂时不会使用yarn create vite my-vue-app --template vue。vue-cli可以和webpack分的很清楚。 vue-cli给我们提供已经精装修的模板。 我们自己搭建一个项目：下载vite，vue，post-css，less，label vue-cli/create-vite给了一套精装修的模板：什么都下好了，并且给你做了最佳实践的配置 ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:2:1","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"2.2 vite开箱即用 开箱即用（out of box）：不需要做任何额外的配置就可以使用vite来帮你处理构建工作 在默认情况下，我们的esmodule去导入资源的时候，要么是绝对路径，要么是相对路径，既然我们现在的最佳实践是node_modules，那么为什么es官方在我们导入非绝对路径和非相对路径的资源的时候不默认帮我们搜寻node_modules？ 浏览器环境中的安全性原因是一个主要考虑因素。如果浏览器默认搜索node_modules目录，那么恶意的代码可能会利用这个功能访问和执行不受信任的模块代码，从而导致安全风险。通过限制导入路径，浏览器可以更好地控制模块的来源和访问权限。 另外，性能也是一个重要的考虑因素。浏览器默认只支持绝对路径和相对路径的导入，可以在编译时静态解析模块依赖关系，从而提高加载和执行模块的效率。如果浏览器要搜索node_modules目录，可能需要进行额外的文件系统操作和路径解析，增加了加载模块的时间和资源消耗。 ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:2:2","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"2.3 vite的预加载 import _ from \"lodash\"; // lodash可能也import了其他的东西 import _vite_cjsImport0_lodash from \"/node_modules/.vite/deps/loadsh.js?v=ebe57916\"; 在处理的过程中如果说看到了有非绝对路径或者相对路径的引用，则会尝试开启路径补全 找寻依赖的过程是自当前目录依次向上查找的过程，直到搜寻到根目录或者搜寻到对应依赖为止 /user/node_modules/lodash, ../ 区分生产环境和开发环境： yarn dev —-\u003e 开发（每次依赖预构建所重新构建的相对路径都是正确的） vite会全权交给一个叫做rollup的库去完成生产环境的打包 缓存 —-\u003e 实际上vite在考虑另外一个问题的时候就顺便把这个问题解决了 commonjs 规范的导出 module.exports 有的包是以commonjs规范的格式导出 axios 依赖预构建：首先vite会找到对应的依赖，然后调用esbuild（对js语法进行处理的一个库），将其他规范的代码转换成esmodule规范，然后放到当前目录下的node_modules/.vite/deps，同时对esmodule规范的各个模块进行统一集成 所以它解决了3个问题： 不同的第三方包会有不同的导出格式（这个是vite没法约束人家的事情） 对路径的处理上可以直接使用.vite/deps，方便路径重写 叫做网络多包传输的性能问题（也是原生esmodule规范不敢支持node_modules的原因之一），有了依赖预构建以后无论它有多少的额外的export和import，vite都会尽可能的将他们集成最后只生成一个或者几个模块 vite.config.js === webpack.config.js ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:2:3","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"2.4 vite配置文件处理细节 vite配置文件的语法提示 如果你使用的是webstorm，那你可以得到很好的语法补全 如果你使用的是vscode或者其他编辑器，则需要做一些特殊处理 关于环境的处理 过去我们使用webpack的时候，我们需要区分配置文件的一个环境： webpack.dev.config webpack.prod.config webpack.base.config webpackmerge ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:2:4","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"2.5 vue环境变量配置 环境变量：会根据当前的代码环境产生值的变化的变量就叫做环境变量 代码环境： 开发环境：开发环境是开发人员进行软件开发和调试的地方。在开发环境中，开发人员可以进行代码编写、调试、测试和验证。这个环境通常是本地的开发机器，开发人员可以通过使用 Vite 的开发服务器（dev server）来提供实时的重新加载（live reloading）和模块热替换（hot module replacement）功能，以便更快地进行开发和调试。 测试环境：测试环境是用于进行软件测试的环境。在测试环境中，开发人员和测试人员可以对软件进行不同类型的测试，例如单元测试、集成测试和端到端测试。在测试环境中，可以使用 Vite 构建工具生成测试所需的构建文件，并在模拟的环境中进行测试。 预发布环境：预发布环境是在软件发布之前进行最后测试和验证的环境。在预发布环境中，可以对软件进行更全面的测试，以确保它符合发布的质量标准。这个环境通常是一个类似于生产环境的环境，但在实际发布之前，可能会使用一些模拟数据和模拟系统进行测试。 灰度环境：灰度环境是在软件发布后逐步向用户群体推出新功能或更新的环境。在灰度环境中，新的软件版本或功能将部署到一小部分用户中，以便测试其稳定性和兼容性。这个环境类似于生产环境，但只有一部分用户能够访问新的功能或更新。 生产环境：生产环境是最终向用户提供服务的环境。在生产环境中，已经通过了开发、测试、预发布和灰度环境的验证，并且已准备好为最终用户提供稳定、可靠的服务。在生产环境中，通常会使用 Vite 构建工具生成用于部署的生产级别的构建文件，并进行必要的优化和压缩，以提供最佳的性能和用户体验。 我们在和后端同学对接的时候，前端在开发环境中请求的后端API地址和生产环境请求的后端API地址是一个吗？肯定不是一个 开发和测试：http://test.api/ 生产：https://api/ 在vite中的环境变量处理： vite内置了dotenv这个第三方库，会自动读取.env文件，并解析这个文件中的对应的环境变量，并将其注入到process对象下（但是vite考虑到和其他配置的一些冲突问题，它不会直接注入到process对象下） 涉及到vite.config.js中的一些配置： root envDir：用来配置当前环境变量的文件地址 vite给我们提供了一些补偿措施：我们可以调用vite的loadEnv来手动确认env文件 porcess.cwd方法：返回node进程的工作目录 小知识：为什么vite.config.js可以书写成esmodule的形式，这是因为vite他在读取这个vite.config.js的时候会率先node去解析文件语法，如果发现你是esmodule规范则会直接将你的esmodule规范替换成common js规范 .env：所有环境都需要用到的环境变量 .env.development：开发环境需要用到的环境变量（默认情况下vite将我们的开发环境取名为development） .env.production：生产环境需要用到的环境变量（默认情况下vite将我们的生产环境取名为production） yarn dev –mode development 会将mode设置为development传递进来 当我们调用loadenv的时候，它会做如下几件事情： 直接找到.env文件不解释，并解析其中的环境变量，放到一个对象里 会将传进来的mode这个变量的值进行拼接：env.development，并根据我们提供的目录去取对应配置文件并进行解析，并放进一个对象 我们可以理解为 const baseEnvConfig = 读取.env配置 const modeEnvConfig = 读取env相关配置 const lastEnvConfig = {...baseEnvConfig, ...modeEnvConfig} 如果是客户端，vite会将对应的环境变量注入到import.meta.env里去 vite做了一个拦截，为了防止我们将隐私性的变量直接送到import.meta.env中，所以做了一层拦截，如果你的环境变量不是以VITE开头的，他就不会帮你注入到客户端中去，如果我们想要更改这个前缀，可以去使用envPrefix配置。 ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:2:5","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"3 vite 原理篇 ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:3:0","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"3.1 vite是怎么让浏览器可以识别.vue文件呢 Vite 是一个现代化的前端构建工具，它使用了一种名为单文件组件（Single File Components）的技术来让浏览器能够识别和加载 .vue 文件。 在传统的前端开发中，浏览器无法直接识别和加载 .vue 文件，因为 .vue 文件包含了 HTML、CSS 和 JavaScript 代码，而浏览器只能识别和执行 JavaScript 文件。 Vite 利用了构建工具和打包器的能力，在开发阶段将 .vue 文件转换为浏览器可以识别的形式。它借助特定的编译器（如 Vue 编译器）将 .vue 文件的模板、样式和脚本部分分别提取出来，并将它们转换为浏览器可以理解的代码。 具体地说，Vite 使用了名为 “vue-loader” 的工具来解析和转换 .vue 文件。这个工具会解析 .vue 文件的内容，提取出其中的模板、样式和脚本，并将它们转化为独立的代码块。然后，Vite 使用浏览器原生的 ES 模块导入机制，通过 \u003cscript type=\"module\"\u003e 标签将这些代码块加载到浏览器中。 当浏览器遇到 \u003cscript type=\"module\"\u003e 标签时，它会将标签中的 JavaScript 代码作为一个独立的模块加载和执行。Vite 利用这个特性，将 .vue 文件中的模板、样式和脚本部分分别作为独立的模块加载到浏览器中，并在浏览器中动态组合它们，构建出最终的组件。 ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:3:1","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"3.2 使用path.resolve的原因 在使用路径时，尽量使用 path.resolve 方法可以确保路径的可靠性和跨平台性。以下是几个使用 path.resolve 方法的好处： 处理相对路径和绝对路径：path.resolve 方法可以接受多个参数，将它们解析为一个绝对路径。这意味着你可以使用相对路径作为参数，并将其解析为相对于当前工作目录的绝对路径。这对于确定准确的文件路径非常有用。 解决跨平台路径问题：在不同的操作系统中，对于路径分隔符和路径表示法有所差异。使用 path.resolve 方法可以确保生成的路径在不同的操作系统下都是有效的，因为它会自动根据当前操作系统调整路径分隔符和表示法。 处理路径拼接和规范化：path.resolve 方法会将传入的路径片段进行拼接，并返回一个规范化的路径。这意味着它会解析和处理路径中的 ..、. 等相对路径符号，确保生成的路径是规范化的、干净的路径。 确保路径的存在性：使用 path.resolve 方法生成的路径是确保存在的，它不会检查路径是否有效或文件是否存在，但会确保路径的格式正确。这可以帮助你在操作文件系统时提供正确的路径，避免出现错误或异常。 ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:3:2","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"4 vite与css ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:4:0","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"4.1 在vite中处理css vite天生就支持对css文件的直接处理 vite在读取到main.js文件中引用到了index.css 直接使用fs模块去读取index.css中文件内容 直接创建一个style标签，将index.css中文件内容直接copy到style标签里 将style标签插入到index.html的head中 将css文件中的内容直接替换为js脚本（方便热更新或者css模块化），同时设置Content-Type为js，从而让浏览器以JS脚本的形式来执行该css后缀的文件 场景： 一个组件最外层的元素类名一般取名： wrapper 一个组件最底层的元素类名一般取名：footer 但你取了footer这个名字，别人因为没有看过你这个组件的源代码，也可能去取名footer这个类名，最后可能会导致样式被覆盖（因为类名重复），这就是我们在协同开发很容易出现的问题 cssmodule就是来解决这个问题的： module.css（module是一种约定，表示需要开启css模块化） 他会将你的所有类名进行一定规则的替换（将footer替换为_footer_i22st_1） 同时创建一个映射对象{ footer: \"_footer_i22st_1\"} 将替换过后的内容塞进style标签里然后放入到head标签中（能够读到index.html的文件内容） 将componentA.module.css内容全部抹除，替换为JS脚本 将创建的映射对象在脚本中默认导出 ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:4:1","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"4.2 css文件类型 CSS（.css）：CSS 是层叠样式表的标准文件格式，它使用类似于选择器和属性的语法来描述网页的样式。CSS 是前端开发中最常见的样式表语言，浏览器原生支持。 LESS（.less）：LESS 是 CSS 的拓展，它引入了变量、嵌套规则、Mixin（混入）等功能，以简化 CSS 的编写和维护。LESS 文件需要在开发阶段通过 LESS 编译器转换为标准的 CSS 文件，然后在浏览器中加载。 SCSS/SASS（.scss/.sass）：SCSS（Sassy CSS）和 SASS（Syntactically Awesome Style Sheets）也是 CSS 的拓展，提供了类似 LESS 的功能，如变量、嵌套规则和 Mixin。SCSS 与 SASS 的语法略有不同，但都需要通过编译器将其转换为标准的 CSS 文件。 /* SCSS */ .container { width: 100%; .header { background-color: #333; color: #fff; padding: 10px; } .content { padding: 20px; p { margin-bottom: 10px; } a { color: #f00; text-decoration: none; \u0026:hover { text-decoration: underline; } } } .footer { background-color: #333; color: #fff; padding: 10px; } } 在这个示例中，.container 是最外层的容器选择器，它包含了 .header、.content 和 .footer 子选择器。通过嵌套定义，我们可以更直观地表示这些选择器之间的层次结构。 此外，嵌套定义还可以减少重复代码的编写。在上述示例中，.header 和 .footer 具有相同的背景颜色、文字颜色和内边距，通过嵌套定义，我们只需在父选择器中指定一次即可，避免了重复的样式声明。 另外，嵌套定义还可以方便地应用伪类和伪元素样式。在示例中，嵌套定义了 a 元素的样式，并使用 \u0026:hover 表示其悬停状态下的样式，这样可以更直观地表示选择器之间的关系。 通过使用嵌套定义，我们可以更清晰地组织和维护样式代码，减少了冗余和重复的工作，提高了代码的可读性和可维护性。 ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:4:2","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"4.3 vite.config.js中css配置 在vite.config.js中我们通过css属性去控制整个vite对于css的处理行为 4.3.1 module篇 css: { modules: { } } css: { // 对css的行为进行配置 // modules配置最终会丢给postcss modules modules: { // 是对css模块化的默认行为进行覆盖 localsConvention: 'camelCase', // 修改生成的配置对象的 key 的展示形式为驼峰命名 scopeBehaviour: 'global', // 配置当前的模块化行为为全局化 generateScopedName: '[name]__[local]___[hash:base64:5]', // 指定生成的类名的命名规则 hashPrefix: 'my-app', // 生成的 hash 的前缀 globalModulePaths: ['path/to/global/styles'] // 不参与 CSS 模块化的路径 } } localsConvention：修改生成的配置对象的key的展示形式（驼峰还是中划线形式） scopeBehaviour：配置当前的模块化行为是模块化还是全局化（有hash就是开启了模块化的一个标志，因为它可以保证产生不同的hash值来控制我们的样式类名不被覆盖） generateScopedName：[name_[local]_[hash:5]]，指定生成的类名的命名规则（可以配置为函数，也可以配置成字符串规则） hashPrefix：生成的hash会根据你的类名进行生成，如果想要你生成的hash更加的独特一点，你可以配置hashPrefix，你配置的这个字符串会参与到最终的hash生成 globalModulePaths：代表你不想参与到css模块化的路径 4.3.2 preprocessorOption篇 主要是用来配置css预处理的一些全局参数 css: { preprocessorOptions: { // 配置 CSS 预处理器的全局参数 } } 在 preprocessorOptions 中，你可以配置 CSS 预处理器的一些全局参数，具体参数的配置取决于你使用的预处理器（如 Sass、Less 等）。这里可以配置一些通用的选项，比如： additionalData：额外的全局样式数据，可以在每个 CSS 文件的顶部注入，例如共享的变量、混合器等。 sass：用于配置 Sass 预处理器的选项，如 sass 选项中的 indentedSyntax 表示是否使用缩进语法。 less：用于配置 Less 预处理器的选项，如 less 选项中的 javascriptEnabled 表示是否启用 Less 中的 JavaScript 表达式。 4.3.3 postcss篇 import autoprefixer from 'autoprefixer'; export default { // ... css: { postcss: { plugins: [ autoprefixer(), // 配置 PostCSS 插件，例如 Autoprefixer // 其他的 PostCSS 插件... ] } } } 在 postcss 配置项中，你可以指定要使用的 PostCSS 插件。在示例中，我们使用了一个常见的插件 Autoprefixer，它用于自动添加 CSS 浏览器前缀，以提供跨浏览器兼容性。 你可以根据需要，将其他的 PostCSS 插件添加到 plugins 数组中。这些插件可以用于执行各种 CSS 处理任务，例如压缩、优化、转换等。 需要注意的是，为了使用特定的 PostCSS 插件，你需要在项目中安装这些插件的相应依赖，并在 vite.config.js 文件中进行正确的导入和配置。 此外，你还可以在 postcss 配置项中设置其他选项，例如 config、sourceMap 等，以满足特定的需求。具体的配置选项和语法规则可以参考 PostCSS 插件的文档或相关资源。 ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:4:3","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"5 vite相关知识 ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:5:0","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"5.1 vite加载静态资源 什么是静态资源？ 静态资源是指不需要经过构建处理的文件，例如图片、视频、字体等，除了动态API以外，百分之九十九的资源都被视作静态资源 vite对静态资源基本上是开箱即用的，除了一些特殊情况（svg） 要加载静态资源，你可以将它们放置在你的项目目录中的任何位置。通常，你可以将这些静态资源放置在你的项目根目录下的 public 文件夹中，这是一个预定义的静态资源文件夹。当你在代码中引用这些静态资源时，Vite 会自动将它们提供给你的应用程序。 例如，如果在你的项目中有一个名为 public 的文件夹，并且在其中有一个图片文件 logo.png，你可以在代码中像下面这样引用它： \u003cimg src=\"/logo.png\" alt=\"Logo\" /\u003e Vite 会自动将此路径解析为相应的静态资源，并将其提供给你的应用程序。 需要注意的是，在 Vite 中，你可以使用相对于根目录的绝对路径来引用静态资源，而无需考虑模块化的路径解析。这是因为 Vite 使用自己的开发服务器，能够在运行时动态处理这些静态资源的请求。 对于某些特殊的静态资源，如 SVG 文件，你可能需要额外的配置来确保正确加载。对于 SVG 文件，你可以使用 @vitejs/plugin-svg 插件来处理。你可以按照 Vite 官方文档中的说明，添加该插件并进行相应的配置。 ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:5:1","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"5.2 vite在生产环境中对静态资源的处理 静态资源的导入和处理： 在你的代码中，如果有静态资源的导入语句（如图片、字体、CSS 文件等），Vite 会根据这些导入语句自动处理这些资源。 资源优化和压缩： Vite 会对导入的静态资源进行优化和压缩，以减小文件大小并提升加载性能。这包括但不限于压缩图片、压缩和合并 CSS 文件等操作。 指纹化文件名： 为了更好的缓存管理和更新机制，Vite 会为处理后的静态资源生成带有指纹的文件名。这意味着每个文件都会有一个唯一的哈希值作为文件名的一部分，例如 logo.8e4c5f7b.png。当文件内容发生变化时，哈希值也会发生变化，从而确保客户端能够正确地缓存和更新静态资源。 输出静态资源： 处理后的静态资源会被输出到构建目录（默认为 dist）中。Vite 会根据资源类型生成相应的文件，如图片会生成 .png、.jpg 等文件，CSS 文件会生成 .css 文件等。 引用静态资源： 在你的 HTML 文件或生成的代码中，Vite 会自动更新静态资源的引用路径，以指向构建目录中的正确文件。这样，在生产环境中，你可以直接使用相对于构建目录的路径来引用静态资源，而无需关心开发环境中的模块解析和路径处理。 ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:5:2","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["前端"],"content":"5.3 vite常用插件 插件是什么？ vite会在生命周期的不同阶段中调用不同的插件以达到不同的目的 生命周期：vite从开始执行到执行结束 5.3.1 vite-aliases 作用：别名自动生成 安装：yarn add vite-aliases -D 将其添加到vite.config.js中 // vite.config.js import { ViteAliases } from 'vite-aliases' export default { plugins: [ ViteAliases() ] }; vite-aliases的可选配置项如下： ViteAliases({ /** * Relative path to the project directory */ dir: 'src', /** * Prefix symbol for the aliases */ prefix: '~', /** * Allow searching for subdirectories */ deep: true, /** * Search depthlevel for subdirectories */ depth: 1, /** * Creates a Logfile * use `logPath` to change the location */ createLog: false, /** * Path for Logfile */ logPath: 'src/logs', /** * Create global project directory alias */ createGlobalAlias: true, /** * Turns duplicates into camelCased path aliases */ adjustDuplicates: false, /** * Used paths in JS/TS configs will now be relative to baseUrl */ useAbsolute: false, /** * Adds seperate index paths * approach created by @davidohlin */ useIndexes: false, /** * Generates paths in IDE config file * works with JS or TS */ useConfig: true, /** * Override config paths */ ovrConfig: false, /** * Will generate Paths in tsconfig * used in combination with `useConfig` * Typescript will be auto detected */ dts: false, /** * Disables any terminal output */ silent: true, /** * Root path of Vite project */ root: process.cwd() }); 5.3.2 vite-plugin-html 功能： HTML 压缩能力 EJS 模版能力 多页应用支持 支持自定义entry 支持自定义template 安装：yarn add vite-plugin-html -D 将其添加到vite.config.js中 用法： 将EJS标签添加到index.html中 \u003chead\u003e \u003cmeta charset=\"UTF-8\" /\u003e \u003clink rel=\"icon\" href=\"/favicon.ico\" /\u003e \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /\u003e \u003ctitle\u003e\u003c%- title %\u003e\u003c/title\u003e \u003c%- injectScript %\u003e \u003c/head\u003e 在vite.config.js中配置，该方法可以根据需要引入需要的功能 import { defineConfig, Plugin } from 'vite' import vue from '@vitejs/plugin-vue' import { createHtmlPlugin } from 'vite-plugin-html' export default defineConfig({ plugins: [ vue(), createHtmlPlugin({ minify: true, /** * After writing entry here, you will not need to add script tags in `index.html`, the original tags need to be deleted * @default src/main.ts */ entry: 'src/main.ts', /** * If you want to store `index.html` in the specified folder, you can modify it, otherwise no configuration is required * @default index.html */ template: 'public/index.html', /** * Data that needs to be injected into the index.html ejs template */ inject: { data: { title: 'index', injectScript: `\u003cscript src=\"./inject.js\"\u003e\u003c/script\u003e`, }, tags: [ { injectTo: 'body-prepend', tag: 'div', attrs: { id: 'tag', }, }, ], }, }), ], }) 5.3.3 vite-plugin-mock mock数据：模拟数据 前后端一般是并行开发，用户列表（接口文档） mock数据，去做你前端的工作 简单方式：直接去写死一两个数据，方便调试。 缺陷：没法做海量数据测试 没法获得一些标准数据 没法去感知http的异常 mockjs：模拟海量数据的，vite-plugin-mock的依赖项是mockjs 安装： yarn add mockjs -D yarn add vite-plugin-mock -D 使用方法：https://github.com/vbenjs/vite-plugin-mock 5.3.4 其他插件 插件地址 ","date":"2023-11-12","objectID":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/:5:3","tags":["Vite"],"title":"vite构建工具介绍","uri":"/posts/01.vite%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/"},{"categories":["工具"],"content":"1 commit message 规范 commit message格式都包括三部分：Header，Body和Footer \u003ctype\u003e(\u003cscope\u003e): \u003csubject\u003e \u003cbody\u003e \u003cfooter\u003e Header是必需的，Body和Footer则可以省略 ","date":"2023-11-12","objectID":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/:1:0","tags":["Git"],"title":"Git Commit 之道：规范化 Commit Message 写作指南","uri":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/"},{"categories":["工具"],"content":"1.1 Header Type（必需） type用于说明git commit的类别，允许使用下面几个标识。 feat：新功能（Feature） “feat\"用于表示引入新功能或特性的变动。这种变动通常是在代码库中新增的功能，而不仅仅是修复错误或进行代码重构。 fix/to：修复bug。这些bug可能由QA团队发现，或由开发人员在开发过程中识别。 fix关键字用于那些直接解决问题的提交。当创建一个包含必要更改的提交，并且这些更改能够直接修复已识别的bug时，应使用fix。这表明提交的代码引入了解决方案，并且问题已被立即解决。 to关键字则用于那些部分处理问题的提交。在一些复杂的修复过程中，可能需要多个步骤或多次提交来完全解决问题。在这种情况下，初始和中间的提交应使用to标记，表示它们为最终解决方案做出了贡献，但并未完全解决问题。最终解决问题的提交应使用fix标记，以表明问题已被彻底修复。 docs：文档（Documentation） “docs” 表示对文档的变动，这包括对代码库中的注释、README 文件或其他文档的修改。这个前缀的提交通常用于更新文档以反映代码的变更，或者提供更好的代码理解和使用说明。 style: 格式（Format） “style” 用于表示对代码格式的变动，这些变动不影响代码的运行。通常包括空格、缩进、换行等风格调整。 refactor：重构（即不是新增功能，也不是修改bug的代码变动） “refactor” 表示对代码的重构，即修改代码的结构和实现方式，但不影响其外部行为。重构的目的是改进代码的可读性、可维护性和性能，而不是引入新功能或修复错误。 perf: 优化相关，比如提升性能、体验 “perf” 表示与性能优化相关的变动。这可能包括对算法、数据结构或代码实现的修改，以提高代码的执行效率和用户体验。 test：增加测试 “test” 表示增加测试，包括单元测试、集成测试或其他类型的测试。 chore：构建过程或辅助工具的变动 “chore” 表示对构建过程或辅助工具的变动。这可能包括更新构建脚本、配置文件或其他与构建和工具相关的内容。 revert：回滚到上一个版本 “revert” 用于回滚到以前的版本，撤销之前的提交。 merge：代码合并 “merge” 表示进行代码合并，通常是在分支开发完成后将代码合并回主线。 sync：同步主线或分支的Bug “sync” 表示同步主线或分支的 Bug，通常用于解决因为合并而引入的问题。 Scope（可选） scope用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。 例如修改了Dao或者Controller，则可以添加表示这些范围受到影响，这有助于更清晰地理解提交的变更影响范围。例如： feat(Controller): 添加用户登录功能 这个提交消息中，Controller 是 scope，表示这次提交影响了控制层。 fix(DataAccess): 修复数据查询逻辑 这个提交消息中，DataAccess 是 scope，表示这次提交影响了数据访问层。 如果你的修改影响了不止一个scope，你可以使用*代替。 Subject（必需） subject是 commit 目的的简短描述，不超过50个字符。规范如下： 以动词开头，使用第一人称现在时，比如change，而不是changed或changes 第一个字母小写 结尾不加句号（.） 例如： feat(UserAuth): implement user authentication 这个提交消息中，implement user authentication 是 subject，简洁明了地描述了引入用户认证功能的目的。 fix(Validation): correct input validation logic 这个提交消息中，correct input validation logic 是 subject，清晰地说明了修复输入验证逻辑的目的。 ","date":"2023-11-12","objectID":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/:1:1","tags":["Git"],"title":"Git Commit 之道：规范化 Commit Message 写作指南","uri":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/"},{"categories":["工具"],"content":"1.2 Body Body 部分是对本次 commit 的详细描述，可以分成多行。Body编写有两个注意点。 使用第一人称现在时，比如使用change而不是changed或changes。这有助于使描述更加直观和连贯，增强可读性。 应该说明代码变动的动机，以及与以前行为的对比。 Body 部分不仅仅是描述代码的变动，还应该解释为什么进行这个变动，以及与之前的代码行为相比有哪些改进。这有助于其他开发者更好地理解代码变更的背后动机和意图。 ","date":"2023-11-12","objectID":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/:1:2","tags":["Git"],"title":"Git Commit 之道：规范化 Commit Message 写作指南","uri":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/"},{"categories":["工具"],"content":"1.3 Footer Footer 部分只用于两种情况。 不兼容变动 如果当前代码与上一个版本不兼容，则 Footer 部分以BREAKING CHANGE开头，后面是对变动的描述、以及变动理由和迁移方法。 关闭 Issue 如果当前 commit 针对某个issue，那么可以在 Footer 部分关闭这个 issue 。 Closes #234 也可以一次关闭多个 issue 。 Closes #123, #245, #992 ","date":"2023-11-12","objectID":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/:1:3","tags":["Git"],"title":"Git Commit 之道：规范化 Commit Message 写作指南","uri":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/"},{"categories":["工具"],"content":"1.4 示例 添加用户配置文件编辑功能 feat(UserProfile): add user profile editing feature This commit introduces a new feature that allows users to edit their profiles directly from the user interface. The motivation behind this change is to enhance user interaction and provide a more seamless experience. Previously, users had to navigate to a separate editing page to update their profile information. With this new feature, users can now make changes efficiently from their profile page, eliminating unnecessary steps in the workflow. Changes included in this commit: - Added a new 'Edit Profile' button on the user profile page. - Implemented frontend components for profile editing. - Updated backend API to handle profile updates securely. By streamlining the profile editing process, we aim to improve overall user satisfaction and make our application more user-friendly. This enhancement is in response to user feedback, addressing the need for a more intuitive and accessible way to modify profile details. Closes #234 纠正输入验证逻辑 fix(Validation): correct input validation logic This commit addresses an issue related to input validation logic in the application. Previously, the validation process was not handling certain edge cases correctly, leading to unexpected behavior in specific scenarios. To resolve this issue, the validation logic has been revised to properly handle various input scenarios. This ensures that user input is thoroughly validated, reducing the likelihood of errors in the application. The changes made in this commit include: - Correcting boundary checks for user input. - Improving error messages for better user guidance. These adjustments align with our commitment to delivering a robust and reliable application experience. Closes #123 优化数据库查询 refactor(DataAccess): optimize database queries In this commit, we have refactored the data access layer to optimize database queries and improve overall system performance. The existing query structure was identified as a bottleneck during performance testing, leading to longer response times. Changes made in this commit: - Reorganized database queries to reduce redundant operations. - Utilized database indexing for faster data retrieval. By optimizing database queries, we expect to see a significant improvement in system responsiveness and user experience. Closes #456 ","date":"2023-11-12","objectID":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/:1:4","tags":["Git"],"title":"Git Commit 之道：规范化 Commit Message 写作指南","uri":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/"},{"categories":["工具"],"content":"2 git commit 工具 ","date":"2023-11-12","objectID":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/:2:0","tags":["Git"],"title":"Git Commit 之道：规范化 Commit Message 写作指南","uri":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/"},{"categories":["工具"],"content":"2.1 commitizen Commitizen是一个强大的工具，用于撰写合格的 Git 提交消息。使用 Commitizen 可以帮助团队遵循统一的提交消息规范，使提交历史更加清晰和易读。 首先，通过以下命令全局安装 Commitizen： npm install -g commitizen 然后，在项目目录里，运行下面的命令，使其支持 Angular 的 Commit message 格式。 commitizen init cz-conventional-changelog --save --save-exact 这个命令会配置项目，使其支持 Angular 规范的 Commit Message。在执行命令时，你可以选择其他预定义的规范或者创建自定义规范。 之后，当你执行 git commit 命令时，将其替换为 git cz。此时，Commitizen 将引导你通过一个交互式的界面，以生成符合规范的 Commit Message。 在这个交互式界面中，你可以选择提交的类型（feat、fix、docs 等）、影响的范围（scope）、简短的描述（subject）以及其他相关信息。通过这种方式，可以确保提交消息符合规范，并提供了更多的上下文信息，便于他人理解变更的目的。 使用 Commitizen 和规范化的提交消息格式，有助于提高代码库的可读性，方便生成自动化的变更日志，并促使开发者更注重写出清晰、明确的提交消息。 ","date":"2023-11-12","objectID":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/:2:1","tags":["Git"],"title":"Git Commit 之道：规范化 Commit Message 写作指南","uri":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/"},{"categories":["工具"],"content":"2.2 commitlint commitlint是一个用于检查提交消息是否符合指定规范的工具。它可以帮助团队确保 Git 提交消息的一致性和规范性，尤其是当项目采用类似 Angular Commit Message Conventions 的规范时。 安装 Commitlint 首先，你需要安装 commitlint 及其相关的配置和规则。通常，@commitlint/config-conventional 是与 Angular 规范兼容的配置。 npm install --save-dev @commitlint/config-conventional @commitlint/cli 配置 Commitlint 在项目根目录下创建 commitlint.config.js 文件，并添加如下内容： module.exports = { extends: ['@commitlint/config-conventional'], }; 这个配置文件使用了 @commitlint/config-conventional 中预定义的规则，确保符合常见的提交规范。 配置Git钩子 你可以使用 Husky 钩子工具来在提交前运行 commitlint。首先，安装 Husky： bashCopy code npm install --save-dev husky 然后，在 package.json 中添加以下配置： jsonCopy code \"husky\": { \"hooks\": { \"commit-msg\": \"commitlint -E HUSKY_GIT_PARAMS\" } } 这样配置后，每次提交前都会自动运行 commitlint 检查提交消息是否符合规范。 ","date":"2023-11-12","objectID":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/:2:2","tags":["Git"],"title":"Git Commit 之道：规范化 Commit Message 写作指南","uri":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/"},{"categories":["工具"],"content":"3 生成Change log 如果你的所有 Commit 都符合 Angular 格式，那么发布新版本时， Change log 就可以用脚本自动生成（例1，例2）。 ![image-20231112222340929](/Users/zfhe/Library/Application Support/typora-user-images/image-20231112222340929.png) 生成的文档包括以下三个部分。 New features（新特性） Bug fixes（bug修复） Breaking changes（重大变更） 每个部分都会罗列相关的 commit ，并且有指向这些 commit 的链接。当然，生成的文档允许手动修改，所以发布前，你还可以添加其他内容。 conventional-changelog 就是生成 Change log 的工具，运行下面的命令即可。 npm install -g conventional-changelog cd my-project conventional-changelog -p angular -i CHANGELOG.md -w 上面命令不会覆盖以前的 Change log，只会在CHANGELOG.md的头部加上自从上次发布以来的变动。 如果你想生成所有发布的 Change log，要改为运行下面的命令。 $ conventional-changelog -p angular -i CHANGELOG.md -w -r 0 为了方便使用，可以将其写入package.json的scripts字段。 { \"scripts\": { \"changelog\": \"conventional-changelog -p angular -i CHANGELOG.md -w -r 0\" } } 以后，直接运行下面的命令即可。 $ npm run changelog 这个自动化流程不仅简化了 Change log 的生成过程，还确保了记录项目变更的一致性和准确性。生成的文档会按照新特性、bug 修复和重大变更等分类，方便用户快速了解每个版本的变更情况。 ","date":"2023-11-12","objectID":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/:3:0","tags":["Git"],"title":"Git Commit 之道：规范化 Commit Message 写作指南","uri":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/"},{"categories":["工具"],"content":"4 参考资料 如何规范你的Git commit？—阿里云开发者 Commit message 和 Change log 编写指南—阮一峰的网络日志 ","date":"2023-11-12","objectID":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/:4:0","tags":["Git"],"title":"Git Commit 之道：规范化 Commit Message 写作指南","uri":"/posts/01.git-commit-%E4%B9%8B%E9%81%93%E8%A7%84%E8%8C%83%E5%8C%96-commit-message-%E5%86%99%E4%BD%9C%E6%8C%87%E5%8D%97/"},{"categories":["技巧"],"content":"1 下载网页中的内嵌 PDF 在一些网页中，PDF文件是以内嵌形式呈现的，直接下载链接可能隐藏在网络请求中。以下是找到并下载这些内嵌PDF文件的方法： 打开开发者工具（Fn+F12） 选中Network栏目后再选择XHR，这会筛选出所有XMLHttpRequest，通常内嵌PDF的请求会出现在这里。 Ctrl+R（刷新）重新加载所有网络请求 在 Network 面板中，找到PDF文件的请求。通常，这些请求会有一个文件名以 .pdf 结尾。 右键点击该请求，然后选择 Open in new tab。这样会在新的标签页中打开PDF文件，您可以直接获取下载链接并保存文件。 ","date":"2023-07-08","objectID":"/posts/01.%E6%B5%8F%E8%A7%88%E5%99%A8%E5%AE%9E%E7%94%A8%E5%B0%8F%E6%8A%80%E5%B7%A7/:1:0","tags":["browser"],"title":"浏览器实用小技巧","uri":"/posts/01.%E6%B5%8F%E8%A7%88%E5%99%A8%E5%AE%9E%E7%94%A8%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"categories":["技巧"],"content":"2 解决网站复制问题 不能复制的根本原因是网站使用了JavaScript代码来阻止用户选择和复制内容。我们只需要禁用JavaScript就可以。 打开开发者工具（Fn+F12） Settings-\u003ePreferences 划到最后有个Disable JavaScript选项 ","date":"2023-07-08","objectID":"/posts/01.%E6%B5%8F%E8%A7%88%E5%99%A8%E5%AE%9E%E7%94%A8%E5%B0%8F%E6%8A%80%E5%B7%A7/:2:0","tags":["browser"],"title":"浏览器实用小技巧","uri":"/posts/01.%E6%B5%8F%E8%A7%88%E5%99%A8%E5%AE%9E%E7%94%A8%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"categories":["系统架构"],"content":"1 用户和用户组介绍 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:1:0","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"1.1 用户 任何操作系统都存在“用户”的概念，Linux也不例外。Linux系统是一个多用户多任务的分时操作系统，即Linux系统支持多个用户在同一时间内登录，不同用户可以执行不同的任务，并且互不影响。每个用户账号都拥有一个用户名和各自的口令（即密码）。在登录系统时，只有正确输入用户名和密码，才能进入系统和自己的主目录。 在Linux中，用户分为两大类、三小类：分别为系统管理员（一般为root）和普通用户 。普通用户中，又划分为两类，分别为系统用户和登录用户。 系统管理员：即超级管理员，可以操作系统中任意文件和命令，拥有最高的管理权限。 普通用户 登录用户：为管理员手动添加的用户，默认仅拥有操作自身家目录中文件及目录的权限，以及进入与浏览相关目录文件的权限（如/etc、/var/log等），但没有创建、修改、删除等权限。 系统用户：一般为系统安装后默认存在的，且默认情况下不能登录系统，它们的存在主要是为了满足系统进程对文件属主的需求。 Tips：在部署某些服务是，也可以手动添加某些系统用户。 Linux系统使用UID（User ID）来标识不同用户，说白了，其实Linux并不认识你的用户名称，它只认识用户名对应的UID。其中UID是16bit的二进制数字，所以换算成十进制，UID的范围是0~65535，Linux根据用户类别，对UID划分做了规定： 0（系统管理员）：，当UID是0时，代表这个用户为超级管理员，所以当你想要其他的用户也有root权限时，将该用户的UID改为0即可。但一般来说，用户的UID应当是独一无二的，其他用户不应当有相同的UID数值，只有UID等于0时可以例外。 1499（系统账号）：该范围内的UID是保留给系统使用的 ID，其实 165534 之间的账号并没有不同， 也就是除了 0 之外，其它的 UID 并没有不一样，预设 500 以下给系统作为保留账号只是一个习惯。这样的好处是，以有名的 DNS 服务器的启动服务『 named 』为例，这个程序的预设所有人 named 的账号 UID 是 25 ，当你自定义的账号也是 25 时，会造成系统冲突！为了杜绝这样的问题，养成好习惯，保留 500 以前的 UID 给系统使用！ 一般来说， 1到99 会保留给系统预设的账号，另外 100~499 则保留给一些服务来使用。 500~65535（登录用户）：给一般使用者用的。事实上，目前的 linux 核心 (2.6.x 版)已经可以支持到 4294967295 (2^32-1) 这么大的 UID 号码。 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:1:1","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"1.2 用户组 用户组是具有相同特征用户的逻辑集合。简单的理解，有时我们需要让多个用户具有相同的权限，比如查看、修改某一个文件的权限，一种方法是分别对多个用户进行文件访问授权，如果有 10 个用户的话，就需要授权 10 次，那如果有 100、1000 甚至更多的用户呢？ 显然，这种方法不太合理。最好的方式是建立一个组，让这个组具有查看、修改此文件的权限，然后将所有需要访问此文件的用户放入这个组中。那么，所有用户就具有了和组一样的权限，这就是用户组。将用户分组是 Linux 系统中对用户进行管理及控制访问权限的一种手段，通过定义用户组，很多程序上简化了对用户的管理工作。 Linux对用户组也有三种划分方式： 第一种组类别 管理员组 普通用户组（包括系统用户组和登录用户组） 第二种组类别 用户的基本组（主组）：用户必须有且只能有一个基本组。 用户的附加组 （附属组）：用户可以有0个、1个或多个附加组。 基本组和附加组就比如，每个人有一个用来安家的房子（基本组），还可以有N个用于投资的房子（附属组）。 第三种组类别 私有组：每新建一个用户，如果不指定-g参数，都会自动创建一个和用户名同名的组，且组内只包含用户本身。 公共组：组内可包含多个用户。 Linux系统也是使用GID（Group ID）来标识不同组。用户和用户组的对应关系有以下 4 种： 一对一：一个用户可以存在一个组中，是组中的唯一成员； 一对多：一个用户可以存在多个用户组中，此用户具有这多个组的共同权限； 多对一：多个用户可以存在一个组中，这些用户具有和组相同的权限； 多对多：多个用户可以存在多个组中，也就是以上 3 种关系的扩展。 下图形象的表示了用户和用户组的4种对应关系。 注意：每一个用户组也有一个口令，当我们将用户添加到指定组时需要该用户组的密码。 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:1:2","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"1.3 文件权限 在Linux操作系统中，任何文件都归属于某一特定的用户，其作为多用户系统，如何区分不同用户对文件的权限成了不可避免的问题。例如，小 A 希望个人文件不被其他用户读取，而如果不对文件进行权限设置，共享了主机资源的小 B 也可以读取小 A 的个人文件，这是不合理的，不同用户对不同文件所拥有的权限应该不尽相同。 因此，Linux 以 “用户与用户组” 的概念，建立用户与文件权限之间的联系，保证系统能够充分考虑每个用户的隐私保护，很大程度上保障了 Linux 作为多用户系统的可行性。从文件权限的角度出发，“用户与用户组” 引申为三个具体的对象——文件所有者、用户组成员、其他人。每一个对象对某一个文件的持有权限是不同的。 1.3.1 文件所有者（User） 当一个用户创建了一个文件，这个用户就是这个文件的文件所有者。文件所有者对文件拥有最高权限，除非文件所有者开放权限，否则其他人无法对文件执行查看、修改等操作。**这也是 Linux 系统能够保护用户隐私的最关键的原因。**在文件所有者占有文件之后，需要文件所有者对其他用户开放权限，其他用户才能查看、修改文件。 如果仅区分 “文件所有者” 和 “其他用户”，那么文件所有者对其他用户开放权限后，所有其他用户均能查看、修改文件。但是，若文件所有者希望仅对部分用户开放，那么仅仅区分 “用户所有者” 和 “其他用户” 显然不满足需求。这就引入了 “用户组的概念”。 1.3.2 用户组成员（Group） 将 “其他用户” 区分为用户组成员和其他人后，若文件所有者希望对部分用户开放权限，而对其他人继续保持私有，则只需要将这部分用户与文件所有者划入一个用户组。这样，这部分用户就成了与文件所有者同组的用户组成员。用户可以对用户组成员开放文件权限，用户组成员则具备了查看、修改文件的权限，而对其他无关用户保持私有。 用户组成员在团队开发中非常有帮助。例如，团队成员之间保持文件资源共享，但对非团队成员保持私有，这就需要将文件所有者与团队成员用户划分为同一个用户组，再对用户组成员开放权限即可。 需要注意的是，一个用户可在多个用户组中。 1.3.3 其他人（Others） 顾名思义，就是与文件所有者没有任何联系的用户，即不是文件所有者也不是所在文件所属用户组。 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:1:3","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"1.4 超级管理员（root） 由于Linux系统中，root具有最高权限，可以执行任何想要执行的操作，也正因为如此，处于安全考虑，一般情况下不推荐使用 root 用户进行日常使用。root 用户所在的用户组称为 “root组”，处于 root 组的普通用户，能够通过 sudo 命令获取 root 权限，即我们是可以通过sudo权限来操作文件的。 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:1:4","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"1.5 AAA基础 AAA指的是Authentication、Authorization、Accounting，即认证、授权和审计。 认证：验证用户是否可以获得权限，是AAA的第一步，即验证身份； 授权：授权用户可以使用那些服务或资源，即身份验证成功后，赋予这个身份相应的权限； 审计：记录用户的操作情况，在Linux中，日志就是审计的一种手段。 Linux的用户和组管理可以说是基于AAA进行的，首先用户登录输入用户名密码，就是认证的过程；其次，在用户登录成功后，所拥有的权限各不相同，这就是 授权；最后，用户的操作历史会记录在日志中，这是审计。 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:1:5","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2 用户和用户组文件 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:2:0","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.1 用户账号文件— /etc/passwd /etc/passwd文件是Linux系统安全的关键文件之一，只有系统管理员才可以修改此文件。该文件用于用户登录等操作时校验用户的登录名、加密的口令数据项、用户ID（UID）、默认的用户组ID（GID）、用户信息、用户主目录及登录后使用的shell。该文件种每一行保存一个用户的资料，而用户数据按域以冒号’:‘分割。格式如下。 username:password:uid:gid:userinfo:home:shell 具体含义如表所示。 域 含义 username 登录名 password 加密的用户口令 uid 用户ID gid 用户组ID userinfo 用户信息 home 分配给用户的主目录 shell 用户登录后将执行的shell（若为空格泽默认为“/bin/sh”） 其中关于用户主目录，每个用户都需要保存专属于自己的配置文件及其他文档，这是以免用户间相互干扰。除root账户外（root账户的主目录为\"/root\"），大多数Linux默认将用户主目录安置在\"/home\"目录下，并把每个用户的主目录命名为其上机使用的登录名。 如图，acs的登录主目录为\"/home/acs\"。通常，“~”被指向当前用户的登录子目录。 注意：用户主目录被安排在“/home”下完全是认为决定的。系统并不关心我们到底把用户主目录安排在什么地方，因为每个用户的位置是在账号文件中定义说明的。所以，用户可以自行调整，灵活使用 关于shell，Shell是用户与Linux系统之间的接口。Linux的Shell有许多种，每种都有不同的特点。当用户登录进入系统时，会启动一个Shell程序，默认是bash。系统管理员可以根据系统情况和用户习惯为用户指定某个Shell。如果不指定Shell，那么系统使用bash为默认的登录Shell，即这个字段的值为/bin/bash。用户的登录Shell也可以指定为某个特定的程序（此程序不是一个命令解释器）。 我们通过查看/etc/passwd文件，可以得到如下完整的系统账号文件。 我们发现，第二列都为x。我们可以继续往下看。 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:2:1","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.2 用户影子文件—/etc/shadow 实际上，Linxu使用不可逆的加密算法（如MD5）来加密口令，由于加密算法是不可逆的，所以黑客从密文是得不到明文的。但/etc/passwd文件时全局可读的，且加密的算法是公开的，如果在passwd中显示密文，黑客据此可以破解口令。Linux系统目前广泛采用了“shadow（影子）文件”机制。将加密的口令转移到“/etc/shadow”文件中。/etc/shadow文件只为root超级用户可读，而相应的etc/passwd文件的密文域泽显示为一个x，从而最大限度地减少了密文泄露的机会。x表示该账户需要密码才能登录，为空时，账户无须密码即可登录。 和/etc/passwd类似，/etc/shadow文件中每条记录用冒号“：”分隔，形成9个域，格式如下。 username:password:lastchg:min:max:warn:inactive:expire:flag 域 含义 username 用户登陆名 password 加密的用户口令 lastchg 表示从1970年1月1日起到上次修改口令所经过的天数 min 表示两次修改口令之间至少经过的天数 max 表示口令还会有效的最大天数，如果是99999则表示永不过期 warn 表示口令失效前多少天内系统向用户发出警告 inactive 表示禁止登录前用户名还有效的天数 expire 表示用户被禁止登录的时间 flag 保留域，暂未使用 下图为系统中实际影子文件的例子。 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:2:2","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.3 创建用户的默认设置文件—/etc/login.defs /etc/login.defs 文件用于在创建用户时，对用户的一些基本属性做默认设置，例如指定用户 UID 和 GID 的范围，用户的过期时间，密码的最大长度，等等。 需要注意的是，该文件的用户默认配置对 root 用户无效。并且，当此文件中的配置与 /etc/passwd 和 /etc/shadow 文件中的用户信息有冲突时，系统会以/etc/passwd 和 /etc/shadow 为准。 其中设置项含义如下表所示。 设置项 含义 MAIL_DIR /var/spool/mail 创建用户时，系统会在目录 /var/spool/mail 中创建一个用户邮箱，比如 lamp 用户的邮箱是 /var/spool/mail/lamp。 PASS_MAX_DAYS 99999 密码有效期，99999 是自 1970 年 1 月 1 日起密码有效的天数，相当于 273 年，可理解为密码始终有效。 PASS_MIN_DAYS 0 表示自上次修改密码以来，最少隔多少天后用户才能再次修改密码，默认值是 0。 PASS_MIN_LEN 5 指定密码的最小长度，默认不小于 5 位，但是现在用户登录时验证已经被 PAM 模块取代，所以这个选项并不生效。 PASS_WARN_AGE 7 指定在密码到期前多少天，系统就开始通过用户密码即将到期，默认为 7 天。 UID_MIN 500 指定最小 UID 为 500，也就是说，添加用户时，默认 UID 从 500 开始。注意，如果手工指定了一个用户的 UID 是 550，那么下一个创建的用户的 UID 就会从 551 开始，哪怕 500~549 之间的 UID 没有使用。 UID_MAX 60000 指定用户最大的 UID 为 60000。 GID_MIN 500 指定最小 GID 为 500，也就是在添加组时，组的 GID 从 500 开始。 GID_MAX 60000 用户 GID 最大为 60000。 CREATE_HOME yes 指定在创建用户时，是否同时创建用户主目录，yes 表示创建，no 则不创建，默认是 yes。 UMASK 077 用户主目录的权限默认设置为 077。 USERGROUPS_ENAB yes 指定删除用户的时候是否同时删除用户组，准备地说，这里指的是删除用户的初始组，此项的默认值为 yes。 ENCRYPT_METHOD SHA512 指定用户密码采用的加密规则，默认采用 SHA512，这是新的密码加密模式，原先的 Linux 只能用 DES 或 MD5 加密。 如果我们想修改默认配置即可修改配置项的值即可。 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:2:3","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.4 用户组账号文件—/etc/group 我们知道，/etc/passwd文件中包含着每个用户的用户组ID（GID），但如果我们需要找一个用户组中的所有用户，通过/etc/passwd难免有些复杂，需要从头到尾寻找同组用户。而/etc/group文件包含关于用户组信息，GID被映射到用户分组的名称及同一分组中的其他成员，这样找同组用户以及配置用户组就方便了许多。/etc/group文件对用户组的许可权限的控制并不是必要的，这是因为Linux系统用来自于/etc/passwd文件的UID、GID来决定文件存取权限。即使/etc/group文件不存在于系统中，具有相同的GID用户也能以用户组的许可权限共享文件。 /etc/group文件记录格式如下。 group_name:group_password:group_id:group_members 其中，各个域的含义如下表。 域 含义 group_name 用户组名 group_password 加密后的用户组口令 group_id 用户组ID（GID） group_members 以逗号分隔的成员用户清单 以下是一个/etc/group文件的实例。 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:2:4","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.5 用户组影子文件—/etc/gshadow 和用户账号文件passwd一样，为了应对黑客对其进行的暴力攻击，用户组文件也采用一种将组口令与组的其他信息相分离的安全机制——gshadow。/etc/shadow文件记录格式如下。 group_name:group_password:group_members 其中，各个域的含义如下表。 域 含义 group_name 用户组名 group_password 加密后的用户组口令 group_members 以逗号分隔的成员用户清单 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:2:5","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"3 用户和用户组管理 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:3:0","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"3.1 用户管理 3.1.1 使用useradd命令添加用户 Linux使用useradd命令添加用户或更新新创建用户的默认信息。其命令格式如下。 useradd [option] username 可使用的选项如下： -c comment：描述新用户账号，通常为用户全名。 -d home_dir：设置用户主目录。默认值为用户的登录名，并放在\"/home\"目录下。 -g group：指定用户所属的基本组。 -G group：指定用户所属的附加组。 -u uid：设置用户的ID。 -s shell类型：设定用户使用的登录shell类型。 -k dir：设置框架目录，创建用户时该目录下的文件都被复制到主目录。 -e expire_date：设置账号过期时间。 -f inactivity：设置口令失效时间。 -n：不为用户创建私有用户组。 -p password：为新建用户指定登录密码。此处的 password 是对应登录密码经 MD5 加密后所得到的密码值，不是真实密码原文，因此在实际应用中，该参数选项使用较少，通常单独使用 passwd 命令来为用户设置登录密码。 -r：创建一个用户 ID 小于 500 的系统账户，默认不创建对应的主目录。 -m：若主目录不存在，则创建它。通常与-r结合，可为系统用户主目录。 -M：不创建主目录。 实例1：创建一个普通用户，名为hzf，其中uid为6666，用户主目录指定在/hzf/。 useradd -u 6666 -d /hzf/ hzf 实例2：创建一个系统账户，名为mysystem，其中为系统用户创建主目录，指定密码为12345678 首先需要加密密码串，这里使用md5sum工具。 利用md5sum加密字符串的方法 # md5sum //然后回车 12345678 //输入12345678，然后按两次ctrl+d。 这个时候就会得到一串密文。 使用以下命令即可创建该系统用户 useradd -r -m -p 1234567825d55ad283aa400af464c76d713c07ad mysystem 查看/etc/passwd即可看到我们创建得用户信息。 3.1.2 使用usermod命令修改用户信息 对于已创建好的用户，可使用 usermod 命令来修改和设置账户的各项属性，包括登录名，主目录，用户组，登录 shell 等，该命令格式如下。 usermod [option] username 常用的选项包括-c, -d, -m, -g, -G, -s, -u以及-o等，这些选项的意义与useradd命令中的选项一样，可以为用户指定新的资源值。 另外，有些系统还可以使用-l修改用户名。用法为：usermod -l newusername 使用-L可以锁定用户账号，临时禁止用户登录。用法为：usermod -L username，Linux锁定用户，是通过在密码文件 shadow 的密码字段前加 “！” 来标识该用户被锁定。 但如果我们是用root用户登录，再用su命令切换到被锁定的账号是可以进去的。 使用-U可以解锁用户账号。用法为：usermod -U username。 3.1.3 使用userdel命令删除用户 要删除用户，可以使用userdel命令删除，命令格式如下。 userdel [-r] username 其中-r参数可选，若带上参数，表示在删除账户的同时，一并删除用户的主目录。 3.1.4 使用passwd命令管理用户口令 用户管理的一项重要内容是用户口令的管理。用户账号刚创建时没有口令，但是被系统锁定，无法使用，必须为其指定口令后才可以使用，即使是指定空口令。 指定和修改用户口令的Shell命令是passwd。超级用户可以为自己和其他用户指定口令，普通用户只能用它修改自己的口令。命令的格式如下。 passwd [option] username 可使用的选项如下： -l：锁定口令，即禁用账号。 -u：口令解锁。 -d：使账号无口令。这样，下次登录的时候，系统就不再允许该用户登录了。 -f：强迫用户下次登陆时修改口令。 如果不指定用户名，则表示修改自己的口令。 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:3:1","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"3.2 用户组管理 3.2.1 使用groupadd命令创建用户组 增加一个新的用户组使用groupadd命令。命令格式如下。 groupadd [option] groupname 可使用的选项如下： -r：表示创建系统用户组，该类用户组的 GID 值小于 500；若没有 - r 参数，则创建普通用户组，其 GID 值大于或等于 500。 -g gid：指定新用户组的标识号GID。 -o：一般与-g选项同时使用，表示新用户组的GID可以与系统已有用户组的GID相同。 如果没有指定选择参数，新组的组标识号是在当前已有的最大组标识号的基础上加1。 3.2.2 使用groupmod修改 修改用户组的属性使用groupmod命令。命令格式如下。 groupmod [option] groupname 可使用的选项如下： -g gid：为用户组指定新的组标识号。 -o：与-g选项同时使用，用户组的新GID可以与系统已有用户组的GID相同。 -n newgroupname： 将用户组的名字改为新名字 3.2.3 使用groupdel命令删除用户组 使用groupdel命令可以删除用户组。命令格式如下。 groupdel groupname 在删除用户组时，被删除的用户组不能是某个账户的私有用户组，否则将无法删除，若要删除，则应先删除引用该私有用户组的账户，然后再删除用户组。 3.2.4 使用gpasswd命令管理用户组 为了避免系统管理员（root）太忙碌，无法及时管理群组，我们可以使用 gpasswd 命令给群组设置一个群组管理员，代替 root 完成将用户加入或移出群组的操作。gpasswd命令格式如下。 gpasswd [option] groupname 可选择的选项如下： 选项 功能 选项为空时，表示给群组设置密码，仅 root 用户可用。 -A user1,… 将群组的控制权交给 user1,… 等用户管理，也就是说，设置 user1,… 等用户为群组的管理员，仅 root 用户可用。 -M user1,… 将 user1,… 加入到此群组中，仅 root 用户可用。 -r 移除群组的密码，仅 root 用户可用。 -R 让群组的密码失效，仅 root 用户可用。 -a user 将 user 用户加入到群组中。 -d user 将 user 用户从群组中移除。 实例如下。 3.2.5 使用newgrp命令切换用户的有效组 我们知道，每个用户可以属于一个初始组（用户是这个组的初始用户），也可以属于多个附加组（用户是这个组的附加用户）。既然用户可以属于这么多用户组，那么用户在创建文件后，默认生效的组身份是哪个呢？ 当然是初始用户组的组身份生效，因为初始组是用户一旦登陆就获得的组身份。也就是说，用户的有效组默认是初始组，因此所创建文件的属组是用户的初始组。那么，既然用户属于多个用户组，能不能改变用户的初始组呢？使用命令 newgrp 就可以。此命令基本格式如下。 newgrp groupname newgrp 命令可以从用户的附加组中选择一个群组，作为用户新的初始组。 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:3:2","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"4 其他相关命令 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:4:0","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"4.1 id命令查看用户的UID和GID id 命令可以查询用户的UID、GID 和附加组的信息。命令比较简单，格式如下。 id username 实例如下： ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:4:1","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"4.2 su命令临时切换用户身份 su 是最简单的用户切换命令，通过该命令可以实现任何身份的切换，包括从普通用户切换为 root 用户、从 root 用户切换为普通用户以及普通用户之间的切换。 普通用户之间切换以及普通用户切换至 root 用户，都需要知晓对方的密码，只有正确输入密码，才能实现切换；从 root 用户切换至其他用户，无需知晓对方密码，直接可切换成功。 su命令格式如下。 su [option] username 可使用的选项如下： -l或-：带这个参数就好像是重新 login 为该使用者一样，大部份环境参数都是以该使用者为主，并且工作目录也会改变，如果没有指定 USER ，内定是 root。 -c \u003ccommand\u003e ：仅切换用户执行一次命令，执行后自动切换回来，该选项后通常会带有要执行的命令。 -s \u003cshell\u003e： 指定要执行的 shell （bash csh tcsh 等），预设值为 /etc/passwd 内的该使用者shell -h：显示说明文件。 -V：显示版本资讯。 -m或-p：执行su时不改变工作环境。 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:4:2","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"4.3 whoami和who am i命令 whoami 命令和 who am i 命令是不同的 2 个命令，前者用来打印当前执行操作的用户名，后者则用来打印登陆当前 Linux 系统的用户名。 我们可以看一下操作实例来感受区别： 在未切换用户身份之前，whoami 和 who am i 命令的输出是一样的，但使用 su 命令切换用户身份后，使用 whoami 命令打印的是切换后的用户名，而 who am i 命令打印的仍旧是登陆系统时所用的用户名。 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:4:3","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"4.4 users和groups命令 users命令格式如下。 users [option] 如果没有参数，则显示当前登录系统的所有用户的用户列表。每个显示的用户名对应一个登录会话。如果一个用户有不止一个登录会话，那他的用户名将显示相同的次数。 --help：显示命令的帮助信息。 --version：显示命令的版本信息。 groups命令格式如下。 groups [option] [groupname] 如果没有参数，查看当前登录用户的组内成员。如果指定了groupname，则显示该group的成员。 --help：显示命令的帮助信息。 --version：显示命令的版本信息。 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:4:4","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"5 高级操作示例 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:5:0","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"5.1 通过更改用户和组的配置文件，直接添加或修改用户和组 为了更深入了解用户和组的相关配置文件，可以手动更改配置文件以达到命令的执行效果。 首先我们需要了解Linux中的/etc/skel目录。skel是skeleton的缩写，意为骨骼、框架。故此目录的作用是在建立新用户时，用于初始化用户根目录。系统会将此目录下的所有文件、目录都复制到新建用户的主目录，并且将用户属主与用户组调整为与此主目录相同。所以可将用户配置文件预置到/etc/skel目录下，比如说.bashrc、.profile与.vimrc等。 注意： 如果在新建用户时，没有自动建立用户根目录，则无法调用到此框架目录。 如果不想以默认的/etc/skel目录作为框架目录，可以在运行useradd命令时使用-k指定新的框架目录。 如果不想在每次新建用户时，都重新指定新的框架目录，可以通过修改/etc/default/useradd配置文件来改变默认的框架目录。修改SKEL变量的值即可。原来为SKEL=/etc/skel。 实际操作步骤如下： 编辑/etc/group文件，添加组test，其中GID为1500。 echo 'test:x:1500' \u003e\u003e /etc/group 创建用户的主目录。 我们需要将框架目录中的文件放到主目录中。同时还需要修改好主目录对其他用户都没有任何访问权限。 编辑/etc/passwd文件，添加用户test，UID为1500，其中基本组ID为test组的GID，其家目录为/home/test。 echo 'test:x:1500:1500::/home/test:/bin/bash' \u003e\u003e /etc/passwd 修改/home/test目录及其内部所有文件的属主为test，属组为test。 修改test用户的密码并尝试登录。 ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:5:1","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"5.2 Linux批量添加用户 我们可以使用useradd+passwd命令配合shell脚本来实现该功能。 首先我们将需要创建的用户名写入一个文本文件，其中每行代表一个用户名： 然后实际上我们的思路就是提取出文件中的用户名然后自动执行useradd命令，再执行passwd自动填入初始密码。编写的shell脚本文件如下： #! /bin/bash for username in $(more username.txt) do if [ -n $username ] then useradd -m $username # 执行useradd命令 echo $username\"123456\" | passwd --stdin $username echo \"User $username's password is changed!\" else echo \"The username is null!\" fi done 测试登录，登录成功！ ","date":"2022-05-24","objectID":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/:5:2","tags":["Linux"],"title":"Linux用户和用户组教程","uri":"/posts/03.linux%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%E6%95%99%E7%A8%8B/"},{"categories":["设计模式"],"content":"1 策略模式介绍 在很多情况下，实现某个目标的途径不止一条，例如在外出旅游时游客可以选择多种不同的出行方式，可根据实际情况来确定最适合的出行方式。 在软件开发中，也常常会遇到类似的情况，实现某个功能有多种算法，一种常用的方法是通过硬编码将所有的算法集中在一个类中，在该类中提供多个方法，每个方法对应一个算法；当然也可以将这些算法封装在一个统一的方法中，通过if…else…等条件判断选择。这两种实现方法都可以称为硬编码。但这样的方式封装了大量的算法，代码非常复杂，维护也很困难。 策略模式（Strategy Pattern）定义一些独立的类来封装不同的算法，每一个类封装一种具体的算法，在这里每一个封装算法的类都可以称为一种策略（Strategy），为了保证这些策略在使用时具有一致性，一般会提供一个抽象的策略类来做算法的声明，而每种算法对应于一个具体策略类。 策略模式定义一系列算法，将每一个算法封装起来，并让它们可以相互替换。策略模式让算法可以独立于使用它们的客户而变化。它又称为政策（Policy）模式，是一种对象行为型模式。 ","date":"2022-05-01","objectID":"/posts/13.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:1:0","tags":["策略模式"],"title":"设计模式之策略模式详解（Java实现）","uri":"/posts/13.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2 策略模式详解 ","date":"2022-05-01","objectID":"/posts/13.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:0","tags":["策略模式"],"title":"设计模式之策略模式详解（Java实现）","uri":"/posts/13.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.1 策略模式结构 其结构图如下： 由图可知，策略模式包含以下3个角色。 Context（环境类）：环境类是使用算法的角色，它在解决某个问题时可以采用多种策略。在环境类中维持一个对抽象策略类的引用实例，用于定义所采用的策略。 Strategy（抽象策略类）：抽象策略类为所支持的算法声明了抽象方法，是所有策略类的父类，它可以是抽象类或具体类，也可以是接口。环境类通过抽象策略类中声明的方法在运行时调用具体策略类中实现的算法。 ConcreteStrategy（具体策略类）：具体策略类实现了在抽象策略类中声明的算法，在运行时具体策略类将覆盖在环境类中定义的抽象策略类对象，使用一种具体的算法实现某个业务功能。 ","date":"2022-05-01","objectID":"/posts/13.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:1","tags":["策略模式"],"title":"设计模式之策略模式详解（Java实现）","uri":"/posts/13.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.2 策略模式实现 抽象策略类典型代码如下： public abstract class AbstractStrategy { // 声明抽象算法 public abstract void algorithm(); } 具体策略类典型代码如下： public class ConcreteStrategyA extends AbstractStrategy { // 算法的具体实现 public void algorithm() { // 算法A } } 环境类典型代码如下： public class Context { private AbstractStrategy strategy; // 维持一个对抽象策略类的引用 public void setStrategy(AbstractStrategy strategy) { this.strategy = strategy; } // 调用策略类中的算法 public void algorithm() { strategy.algorithm(); } } ","date":"2022-05-01","objectID":"/posts/13.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:2","tags":["策略模式"],"title":"设计模式之策略模式详解（Java实现）","uri":"/posts/13.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.3 策略模式应用举例 题目描述 某软件公司为某电影院开发了一套影院售票系统，在该系统中需要为不同类型的用户提供不同的电影票打折方式，具体打折方案如下：* (1) 学生凭学生证可享受票价8折优惠。 (2) 年龄在10周岁及以下的儿童可享受每张票减免10元的优惠（原始票价需大于等于20元）。 (3) 影院VIP用户除享受票价半价优惠外还可进行积分，积分累计到一定额度可换取电影院赠送的奖品。 该系统在将来可能还要根据需要引入新的打折方式。现使用策略模式设计该影院售票系统的打折方案。 UML类图 其中，MovieTicket充当环境类角色，Discount充当抽象策略角色，StudentDiscount、ChildrenDiscount和VIPDiscount充当具体策略角色。 代码 代码地址 ","date":"2022-05-01","objectID":"/posts/13.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:3","tags":["策略模式"],"title":"设计模式之策略模式详解（Java实现）","uri":"/posts/13.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"1 模板方法模式介绍 在软件开发中，某个方法的实现需要多个步骤，其中有些步骤是固定的，而有些步骤并不固定，存在可变性。为了提高代码的复用性和系统的灵活性，可以使用一种称为模板方法模式（Template Method Pattern）的设计模式来对这类情况进行设计。在模板方法模式中将实现功能的每一个步骤所对应的方法称为基本方法，而将调用这些基本方法同时定义基本方法的执行次序的方法称为模板方法。 模板方法模式定义一个操作中算法的框架，而将一些步骤延迟到子类中。模板方法模式使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。它是结构最简单的行为型设计模式，在其结构中只存在父类与子类的继承关系。 模板方法模式将一些复杂流程的实现步骤封装在一系列基本方法中，在抽象父类中提供一个称之为模板方法的方法来定义这些基本方法的执行次序，而通过其子类来覆盖某些步骤，从而使得相同的算法框架可以有不同的执行结果。 主要解决： 一些方法通用，却在每一个子类都重新写了这一方法。 何时使用： 有一些通用的方法。 如何解决： 将这些通用算法抽象出来。 关键代码： 在抽象类实现，其他步骤在子类实现。 应用实例： 1、在造房子的时候，地基、走线、水管都一样，只有在建筑的后期才有加壁橱加栅栏等差异。 2、西游记里面菩萨定好的 81 难，这就是一个顶层的逻辑骨架。 3、spring 中对 Hibernate 的支持，将一些已经定好的方法封装起来，比如开启事务、获取 Session、关闭 Session 等，程序员不重复写那些已经规范好的代码，直接丢一个实体就可以保存。 优点： 1、封装不变部分，扩展可变部分。 2、提取公共代码，便于维护。 3、行为由父类控制，子类实现。 缺点： 每一个不同的实现都需要一个子类来实现，导致类的个数增加，使得系统更加庞大。 使用场景： 1、有多个子类共有的方法，且逻辑相同。 2、重要的、复杂的方法，可以考虑作为模板方法。 注意事项： 为防止恶意操作，一般模板方法都加上 final 关键词。 ","date":"2022-05-01","objectID":"/posts/14.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:1:0","tags":["模板方法模式"],"title":"设计模式之模板方法模式详解（Java实现）","uri":"/posts/14.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2 模板方法模式详解 ","date":"2022-05-01","objectID":"/posts/14.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:0","tags":["模板方法模式"],"title":"设计模式之模板方法模式详解（Java实现）","uri":"/posts/14.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.1 模板方法模式结构 模板方法模式的结构比较简单，其核心是抽象类和其中的模板方法设计，其结构图如下： 由上图可知，模板方法模式包含以下两个角色。 AbstractClass（抽象类）：在抽象类中定义了一系列基本操作（Primitive Operations），这些基本操作可以是具体的，也可以是抽象的，每一个基本操作对应算法的一个步骤，在其子类中可以重定义或实现这些步骤。同时在抽象类中实现了一个模板方法（Template Method），用于定义一个算法的框架，模板方法不仅可以调用在抽象类中实现的基本方法，也可以调用在抽象类的子类中实现的基本方法，还可以调用其他对象中的方法。 ConcreteClass（具体子类）：它是抽象类的子类，用于实现在父类中声明的抽象基本操作以及完成子类特定算法的步骤，也可以覆盖在父类中已经实现的具体基本操作。 ","date":"2022-05-01","objectID":"/posts/14.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:1","tags":["模板方法模式"],"title":"设计模式之模板方法模式详解（Java实现）","uri":"/posts/14.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.2 模板方法模式实现 在实现模板方法模式时，开发抽象类的软件设计师和开发具体子类的软件设计师之间可以进行协作。 模板方法 一个模板方法就是将定义在抽象类中的把基本操作方法组合在一起形成一个总算法或一个总行为的方法。这个模板方法定义在抽象类中，并由子类不加修改地完全继承下来。由于模板方法是具体方法，因此模板方法模式中的抽象层只能是抽象类，而不是接口。 基本方法 基本方法是实现算法各个步骤的方法，是模板方法的组成部分。基本方法又可以分为3种，即抽象方法（Abstract Method）、具体方法（Concrete Method）和钩子方法（Hook Method）。 抽象方法：一个抽象方法由抽象类声明、由其具体子类实现。 具体方法：一个具体方法由一个抽象类或具体类声明并实现，其子类可以进行覆盖也可以直接继承。 钩子方法：一个钩子方法由一个抽象类或具体类声明并实现，而其子类可能会加以扩展。通常在父类中给出的实现是一个空实现，并以该空实现作为方法的默认实现。当然，钩子方法也可以提供一个非空的默认实现。 抽象类的典型代码如下： public abstract class AbstractClass { //模板方法 public void templateMethod() { primitiveOperation1(); primitiveOperation2(); primitiveOperation3(); } //基本方法—具体方法 public void primitiveOperation1() { //实现代码 } //基本方法—抽象方法 public abstract void primitiveOperation2(); //基本方法—钩子方法 public void primitiveOperation3() { } } 具体子类的典型代码如下： public class ConcreteClass extends AbstractClass { public void primitiveOperation2() { //实现代码 } public void primitiveOperation3() { //实现代码 } } ","date":"2022-05-01","objectID":"/posts/14.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:2","tags":["模板方法模式"],"title":"设计模式之模板方法模式详解（Java实现）","uri":"/posts/14.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.3 模板方法模式应用举例 题目描述 某软件公司要为某银行的业务支撑系统开发一个利息计算模块，利息的计算流程如下： (1) 系统根据账号和密码验证用户信息，如果用户信息错误，则系统显示出错提示。 (2) 如果用户信息正确，则根据用户类型的不同使用不同的利息计算公式计算利息（如活期账户和定期账户具有不同的利息计算公式）。 (3) 系统显示利息。 现使用模板方法模式设计该利息计算模块。 UML类图 其中，Account充当抽象类角色，CurrentAccount和SavingAccount充当具体子类角色。 代码 代码地址 ","date":"2022-05-01","objectID":"/posts/14.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:3","tags":["模板方法模式"],"title":"设计模式之模板方法模式详解（Java实现）","uri":"/posts/14.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"1 观察者模式介绍 “红灯停，绿灯行”。在这个过程中，交通信号灯是汽车的观察目标，而汽车则是观察者。随着交通信号灯的变化，汽车的行为也随之变化，一盏交通信号灯可以指挥多辆汽车。 在软件系统中有些对象之间也存在类似交通信号灯和汽车之间的关系，一个对象的状态或行为的变化将导致其他对象的状态或行为也发生改变。观察者模式（Observer Pattern）则是用于建立一种对象与对象之间的依赖关系，使得每当一个对象状态发生改变时其相关依赖对象皆得到通知并被自动更新。发生改变的对象称为观察目标，被通知的对象称为观察者，一个观察目标可以对应多个观察者。它有如下别名： 发布-订阅(Publish/Subscribe)模式 模型-视图(Model/View)模式 源-监听器(Source/Listener)模式 从属者(Dependents)模式 主要解决： 一个对象状态改变给其他对象通知的问题，而且要考虑到易用和低耦合，保证高度的协作。 何时使用： 一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知，进行广播通知。 如何解决： 使用面向对象技术，可以将这种依赖关系弱化。 关键代码： 在抽象类里有一个 ArrayList 存放观察者们。 应用实例： 1、拍卖的时候，拍卖师观察最高标价，然后通知给其他竞价者竞价。 2、西游记里面悟空请求菩萨降服红孩儿，菩萨洒了一地水招来一个老乌龟，这个乌龟就是观察者，他观察菩萨洒水这个动作。 优点： 1、观察者和被观察者是抽象耦合的。 2、建立一套触发机制。 缺点： 1、如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间。 2、如果在观察者和观察目标之间有循环依赖的话，观察目标会触发它们之间进行循环调用，可能导致系统崩溃。 3、观察者模式没有相应的机制让观察者知道所观察的目标对象是怎么发生变化的，而仅仅只是知道观察目标发生了变化。 使用场景： 一个抽象模型有两个方面，其中一个方面依赖于另一个方面。将这些方面封装在独立的对象中使它们可以各自独立地改变和复用。 一个对象的改变将导致其他一个或多个对象也发生改变，而不知道具体有多少对象将发生改变，可以降低对象之间的耦合度。 一个对象必须通知其他对象，而并不知道这些对象是谁。 需要在系统中创建一个触发链，A对象的行为将影响B对象，B对象的行为将影响C对象……，可以使用观察者模式创建一种链式触发机制。 注意事项： 1、JAVA 中已经有了对观察者模式的支持类。 2、避免循环引用。 3、如果顺序执行，某一观察者错误会导致系统卡壳，一般采用异步方式。 ","date":"2022-05-01","objectID":"/posts/12.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:1:0","tags":["观察者模式"],"title":"设计模式之观察者模式详解（Java实现）","uri":"/posts/12.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2 观察者模式详解 ","date":"2022-05-01","objectID":"/posts/12.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:0","tags":["观察者模式"],"title":"设计模式之观察者模式详解（Java实现）","uri":"/posts/12.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.1 观察者模式结构 观察者模式结构中通常包括观察目标和观察者两个继承层次结构，其结构图如下： 由图可知，观察者模式包含以下4个角色。 Subject（目标）：目标又称为主题，它是指被观察的对象。在目标中定义了一个观察者集合，一个观察目标可以接受任意数量的观察者来观察，它提供了一系列方法来增加和删除观察者对象，同时它定义了通知方法notify()。目标类可以是接口，也可以是抽象类或具体类。 ConcreteSubject（具体目标）：具体目标是目标类的子类，它通常包含有经常发生改变的数据，当它的状态发生改变时它向各个观察者发出通知；同时它还实现了在目标类中定义的抽象业务逻辑方法。如果无须扩展目标类，具体目标类可以省略。 Observer（观察者）：观察者将对观察目标的改变做出反映，观察者一般定义为接口，该接口声明了更新数据的方法update()，因此又称为抽象观察者。 ConcreteObserver（具体观察者）：在具体观察者中维护一个指向具体目标对象的引用，它存储具体观察者的有关状态，这些状态需要和具体目标的状态保持一致；它实现了在抽象观察者Observer中定义的update()方法。通常在实现时可以调用具体目标类的attach()方法将自己添加到目标类的集合中或者通过detach()方法将自己从目标类的集合中删除。 ","date":"2022-05-01","objectID":"/posts/12.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:1","tags":["观察者模式"],"title":"设计模式之观察者模式详解（Java实现）","uri":"/posts/12.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.2 观察者模式实现 抽象目标类典型代码如下： import java.util.List; import java.util.ArrayList; public abstract class Subject { //定义一个观察者集合用于存储所有观察者对象 protected List\u003cObserver\u003e observers = new ArrayList(); //注册方法，用于向观察者集合中增加一个观察者 public void attach(Observer observer) { observers.add(observer); } //注销方法，用于在观察者集合中删除一个观察者 public void detach(Observer observer) { observers.remove(observer); } //声明抽象通知方法 public abstract void notify(); } 具体目标类典型代码如下： public class ConcreteSubject extends Subject { //实现通知方法 public void notify() { //遍历观察者集合，调用每一个观察者的响应方法 for(Observer obs:observers) { obs.update(); } } } 抽象观察者典型代码如下： public interface Observer { //声明响应方法 public void update(); } 具体观察者典型代码如下： public class ConcreteObserver implements Observer { //实现响应方法 public void update() { //具体响应代码 } } 有时候在具体观察者类ConcreteObserver中需要使用到具体目标类ConcreteSubject中的状态（属性），会存在关联或依赖关系。 如果在具体层之间具有关联关系，系统的扩展性将受到一定的影响，增加新的具体目标类有时候需要修改原有观察者的代码，在一定程度上违背了开闭原则，但是如果原有观察者类无须关联新增的具体目标，则系统扩展性不受影响。 ","date":"2022-05-01","objectID":"/posts/12.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:2","tags":["观察者模式"],"title":"设计模式之观察者模式详解（Java实现）","uri":"/posts/12.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.3 观察者模式应用举例 题目描述 在某多人联机对战游戏中，多个玩家可以加入同一战队组成联盟，当战队中的某一成员受到敌人攻击时将给所有其他盟友发送通知，盟友收到通知后将做出响应。现使用观察者模式设计并实现该过程，以实现战队成员之间的联动。 题目分析 战队成员之间的联动过程：联盟成员受到攻击——\u003e发送通知给盟友——\u003e盟友做出响应。 UML类图 其中，AllyControlCenter充当抽象目标类，ConcreteAllyControlCenter充当具体目标类，Observer充当抽象观察者，Player充当具体观察者。 代码 代码地址 ","date":"2022-05-01","objectID":"/posts/12.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:3","tags":["观察者模式"],"title":"设计模式之观察者模式详解（Java实现）","uri":"/posts/12.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"3 观察者模式与MVC 在当前流行的MVC（Model-View-Controller）架构中也应用了观察者模式，MVC是一种架构模式，它包含了3个角色，即模型(Model)，视图(View)和控制器(Controller)。其中，模型可对应于观察者模式中的观察目标，而视图对应于观察者，控制器可充当两者之间的中介者。当模型层的数据发生改变时，视图层将自动改变其显示内容。MVC的结构图如下： ","date":"2022-05-01","objectID":"/posts/12.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:3:0","tags":["观察者模式"],"title":"设计模式之观察者模式详解（Java实现）","uri":"/posts/12.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"1 命令模式介绍 在现实生活中人们通过使用开关来控制一些电器的打开和关闭，例如电灯或者排气扇，如下图。 我们可以将开关看成一个请求发送者，电灯或者排气扇则是请求的最终接收者和处理者。开关和电灯之间并不存在直接耦合关系，它们通过电线连接在一起，使用不同的电线可以连接不同的请求接收者，只需要更换一根电线，相同的发送者（开关）即可对应不同的接收者（电器）。 在软件开发中也存在很多与开关和电器类似的请求发送者和接收者对象，例如按钮和事件处理类。为了降低系统的耦合度，将请求的发送者和接收者解耦，我们可以使用命令模式（Command Pattern）来设计系统。 在命令模式中发送者与接收者之间引入了新的命令对象（类似电线），将发送者的请求封装在命令对象中，再通过命令对象来调用接收者的方法。它可以使请求发送者和接收者完全解耦，发送者和接收者之间没有直接引用的关系，发送请求的对象只需要知道如何发送请求，而不必知道如何完成请求。 定义： 将一个请求封装为一个对象，从而可用不同的请求对客户进行参数化，对请求排队或者记录请求日志，以及支持可撤销的操作。 主要解决： 在软件系统中，行为请求者与行为实现者通常是一种紧耦合的关系，但某些场合，比如需要对行为进行记录、撤销或重做、事务等处理时，这种无法抵御变化的紧耦合的设计就不太合适。 何时使用： 在某些场合，比如要对行为进行\"记录、撤销/重做、事务\"等处理，这种无法抵御变化的紧耦合是不合适的。在这种情况下，如何将\"行为请求者\"与\"行为实现者\"解耦？将一组行为抽象为对象，可以实现二者之间的松耦合。 如何解决： 通过调用者调用接受者执行命令，顺序：调用者→命令→接受者。 关键代码： 定义三个角色：1、received 真正的命令执行对象 2、Command 3、invoker 使用命令对象的入口 应用实例： struts 1 中的 action 核心控制器 ActionServlet 只有一个，相当于 Invoker，而模型层的类会随着不同的应用有不同的模型类，相当于具体的 Command。 优点： 1、降低了系统耦合度。 2、新的命令可以很容易添加到系统中去。 缺点： 使用命令模式可能会导致某些系统有过多的具体命令类。 使用场景： 认为是命令的地方都可以使用命令模式，比如： 1、GUI 中每一个按钮都是一条命令。 2、模拟 CMD。 注意事项： 系统需要支持命令的撤销(Undo)操作和恢复(Redo)操作，也可以考虑使用命令模式，见命令模式的扩展。 ","date":"2022-04-30","objectID":"/posts/11.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:1:0","tags":["命令模式"],"title":"设计模式之命令模式详解（Java实现）","uri":"/posts/11.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2 命令模式详解 ","date":"2022-04-30","objectID":"/posts/11.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:0","tags":["命令模式"],"title":"设计模式之命令模式详解（Java实现）","uri":"/posts/11.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.1 命令模式结构 命令模式的核心在于引入了抽象命令类和具体命令类，通过命令类来降低发送者和接收者的耦合度，请求发送者只需指定一个命令对象，再通过命令对象来调用请求接收者的处理方法，结构图如下： 由图可知，命令模式包含以下4个角色。 Command（抽象命令类）：抽象命令类一般是一个抽象类或接口，在其中声明了用于执行请求的execute()等方法，通过这些方法可以调用请求接收者的相关操作。 ConcreteCommand（具体命令类）：具体命令类是抽象命令类的子类，实现了在抽象命令类中声明的方法，它对应具体的接收者对象，将接收者对象的动作绑定其中。具体命令类在实现execute()方法时将调用接收者对象的相关操作(Action)。 Invoker（调用者）：调用者即请求发送者，它通过命令对象来执行请求。一个调用者并不需要在设计时确定其接收者，因此它只与抽象命令类之间存在关联关系。在程序运行时可以将一个具体命令对象注入其中，再调用具体命令对象的execute()方法，从而实现间接调用请求接收者的相关操作。 Receiver（接收者）：接收者执行与请求相关的操作，具体实现对请求的业务处理。 ","date":"2022-04-30","objectID":"/posts/11.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:1","tags":["命令模式"],"title":"设计模式之命令模式详解（Java实现）","uri":"/posts/11.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.2 命令模式实现 典型的抽象命令类代码如下： public abstract class Command { public abstract void execute(); } 对于请求发送者（即调用者）而言，将针对抽象命令类进行编程，可以通过构造函数或者Setter方法在运行时注入具体命令类对象，并在业务方法中调用命令对象的execute()方法，其典型代码如下： public class Invoker { private Command command; // 构造注入 public Invoker(Command command) { this.command = command; } // 设值注入 public setCommand(Command command) { this.command = command; } // 业务方法，用于调用命令类中的execute()方法 public void call() { command.execute(); } } 具体命令类继承了抽象命令类，它与请求接收者关联，实现了在抽象命令类中声明的execute()方法，并在实现时调用接收者的请求响应方法。其典型代码如下： public class ConcreteCommand extends Command { private Receiver receiver; //维持一个对请求接收者对象的引用 public void execute() { receiver.action(); //调用请求接收者的业务处理方法action() } } 请求接收者Receiver具体实现对请求的业务处理，它拥有action()方法，用于执行与请求相关操作，其典型代码如下： public class Receiver { public void action() { //具体操作 } } ","date":"2022-04-30","objectID":"/posts/11.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:2","tags":["命令模式"],"title":"设计模式之命令模式详解（Java实现）","uri":"/posts/11.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.3 命令模式应用举例 题目描述 为了用户使用方便，某系统提供了一系列功能键，用户可以自定义功能键的功能，例如功能键FunctionButton可以用于退出系统（由SystemExitClass类来实现），也可以用于显示帮助文档（由DisplayHelpClass类来实现）。 用户可以通过修改配置文件来改变功能键的用途，现使用命令模式来设计该系统，使得功能键类与功能类之间解耦，可为同一个功能键设置不同的功能。 UML类图 其中，FunctionButton充当请求调用者，SystemExitClass和DisplayHelpClass充当请求接收者，Command是抽象命令类，ExitCommand和HelpCommand充当具体命令类。 代码 代码地址 ","date":"2022-04-30","objectID":"/posts/11.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:3","tags":["命令模式"],"title":"设计模式之命令模式详解（Java实现）","uri":"/posts/11.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"3 实现命令队列 有时候，当一个请求发送者发送一个请求时有不止一个请求接收者产生响应，这些请求接收者将逐个执行业务方法，完成对请求的处理，此时可以通过命令队列来实现。 命令队列的实现方法有多种形式，其中最常用、灵活性最好的一种方式就是增加一个CommandQueue类，由该类负责存储多个命令对象，而不同的命令对象可以对应不同的请求接收者。CommandQueue类的典型代码如下： package homework; import java.util.ArrayList; import java.util.List; public class CommandQueue { private List\u003cCommand\u003e commandList = new ArrayList(); public void addCommand(Command command) { commandList.add(command); } public void removeCommand(Command command) { commandList.remove(command); } /** * 循环调用每一个命令对象的execute()方法 */ public void execute() { for (Command command : commandList) { command.execute(); } } } 在增加命令队列类CommandQueue以后，请求发送者Invoker将针对CommandQueue编程。即将Command修改为CommandQueue即可。 ","date":"2022-04-30","objectID":"/posts/11.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:3:0","tags":["命令模式"],"title":"设计模式之命令模式详解（Java实现）","uri":"/posts/11.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"1 代理模式介绍 代理模式（Proxy Pattern）是常用的结构型设计模式之一，当无法直接访问某个对象或访问某个对象存在困难时可以通过一个代理对象来间接访问，代理对象在客户端对象和目标对象之间起到中介的作用，它去掉客户不能看到的内容和服务或者增添客户需要的额外的新服务。 代理模式的变化形式非常多，常见的代理形式有远程代理、保护代理、虚拟代理、缓冲代理、智能引用代理等。 主要解决： 在直接访问对象时带来的问题，比如说：要访问的对象在远程的机器上。在面向对象系统中，有些对象由于某些原因（比如对象创建开销很大，或者某些操作需要安全控制，或者需要进程外的访问），直接访问会给使用者或者系统结构带来很多麻烦，我们可以在访问此对象时加上一个对此对象的访问层。 何时使用： 想在访问一个类时做一些控制。 如何解决： 增加中间层。 关键代码： 实现与被代理类组合。 应用实例： 1、Windows 里面的快捷方式。 2、猪八戒去找高翠兰结果是孙悟空变的，可以这样理解：把高翠兰的外貌抽象出来，高翠兰本人和孙悟空都实现了这个接口，猪八戒访问高翠兰的时候看不出来这个是孙悟空，所以说孙悟空是高翠兰代理类。 3、买火车票不一定在火车站买，也可以去代售点。 4、一张支票或银行存单是账户中资金的代理。支票在市场交易中用来代替现金，并提供对签发人账号上资金的控制。 5、spring aop。 优点： 1、职责清晰。 2、高扩展性。 3、智能化。 缺点： 1、由于在客户端和真实主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢。 2、实现代理模式需要额外的工作，有些代理模式的实现非常复杂。 使用场景： 按职责来划分，通常有以下使用场景： 1、远程代理。 2、虚拟代理。 3、Copy-on-Write 代理。 4、保护（Protect or Access）代理。 5、Cache代理。 6、防火墙（Firewall）代理。 7、同步化（Synchronization）代理。 8、智能引用（Smart Reference）代理。 注意事项： 1、和适配器模式的区别：适配器模式主要改变所考虑对象的接口，而代理模式不能改变所代理类的接口。 2、和装饰器模式的区别：装饰器模式为了增强功能，而代理模式是为了加以控制。 ","date":"2022-04-30","objectID":"/posts/10.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:1:0","tags":["代理模式"],"title":"设计模式之代理模式详解（Java实现）","uri":"/posts/10.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2 代理模式详解 ","date":"2022-04-30","objectID":"/posts/10.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:0","tags":["代理模式"],"title":"设计模式之代理模式详解（Java实现）","uri":"/posts/10.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.1 代理模式结构 代理模式的结构比较简单，其核心是代理类，为了让客户端能够一致地对待真实对象和代理对象，在代理模式中引入了抽象层，其结构图如下： 由图可知，代理模式包含以下3个角色。 Subject（抽象主题角色）：它声明了真实主题和代理主题的共同接口，这样一来在任何使用真实主题的地方都可以使用代理主题，客户端通常需要针对抽象主题角色进行编程。 Proxy（代理主题角色）：它包含了对真实主题的引用，从而可以在任何时候操作真实主题对象；在代理主题角色中提供了一个与真实主题角色相同的接口，以便任何时候都可以代替真实主题；代理主题角色还可以控制真实主题的使用，负责在需要的时候创建和删除真实主题对象，并对真实主题对象的使用加以约束。 通常，在代理主题角色中客户端在调用所引用的真实主题操作之前或之后还需要执行其他操作，而不仅仅单纯调用真实主题对象中的操作。 RealSubject（真实主题角色）：它定义了代理角色所代表的真实对象，在真实主题角色中实现了真实的业务操作，客户端可以通过代理主题角色间接使用真实主题角色中定义的操作。 ","date":"2022-04-30","objectID":"/posts/10.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:1","tags":["代理模式"],"title":"设计模式之代理模式详解（Java实现）","uri":"/posts/10.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.2 代理模式实现 典型的抽象主题类代码如下： public abstract class Subject { public abstract void request(); } 真实主题类继承了抽象主题类，提供了业务方法的具体实现，其典型代码如下： public class RealSubject extends Subject { public void request() { // 业务方法的具体实现代码 } } 代理类也是抽象主题类的子类，它维持一个对真实主题对象的引用，调用在真实主题中实现的业务方法，在调用时可以在原有业务方法的基础上附加一些新的方法对功能进行扩充或约束。最简单的代理类实现代码如下： public class Proxy extends Subject { // 维持一个对真实主题对象的引用 private RealSubject realSubject = new RealSubject(); public void preRequest() { ... } public void request() { preRequest(); // 调用真实主题对象的方法 realSubject.request(); postRequest(); } public void postRequest() { ... } } ","date":"2022-04-30","objectID":"/posts/10.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:2","tags":["代理模式"],"title":"设计模式之代理模式详解（Java实现）","uri":"/posts/10.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.3 代理模式应用举例 题目描述 在一个论坛中已注册用户和游客的权限不同，已注册的用户拥有发帖、修改自己的注册信息、修改自己的帖子等功能；而游客只能看到别人发的帖子，没有其他权限。使用保护代理来设计该权限管理模块。 UML类图 其中，AbstractPermission 为抽象主题角色，PermissionProxy 为代理主题角色， RealPermission 为真实主题角色。 代码 代码地址 ","date":"2022-04-30","objectID":"/posts/10.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:3","tags":["代理模式"],"title":"设计模式之代理模式详解（Java实现）","uri":"/posts/10.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"1 外观模式概述 在软件开发中，有时候为了完成一项较为复杂的功能，一个客户类需要和多个业务类交互，而这些需要交互的业务类经常会作为一个整体出现，由于设计的类比较多，导致使用代码较为复杂，此时特别需要一个类似服务员的角色，由它来负责和多个业务类进行交互，而客户类只需要与该类进行交互。外观模式（Facade Pattern）通过引入一个新的外观类(Facade)来负责和多个业务类【子系统(Subsystem)，所指的子系统是一个广义的概念，它可以是一个类、一个功能模块、系统的一个组成部分或者一个完整的系统】进行交互，而客户类只需与外观类交互。 它为子系统中的一组接口提供了一个统一的入口。外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。 主要解决： 降低访问复杂系统的内部子系统时的复杂度，简化客户端之间的接口。 何时使用： 1、客户端不需要知道系统内部的复杂联系，整个系统只需提供一个\"接待员\"即可。 2、定义系统的入口。 如何解决： 客户端不与系统耦合，外观类与系统耦合。 关键代码： 在客户端和复杂系统之间再加一层，这一层将调用顺序、依赖关系等处理好。 应用实例： 1、去医院看病，可能要去挂号、门诊、划价、取药，让患者或患者家属觉得很复杂，如果有提供接待人员，只让接待人员来处理，就很方便。 2、JAVA 的三层开发模式。 优点： 1、减少系统相互依赖。 2、提高灵活性。 3、提高了安全性。 **缺点：**不符合开闭原则，如果要改东西很麻烦，继承重写都不合适。 使用场景： 1、为复杂的模块或子系统提供外界访问的模块。 2、子系统相对独立。 3、预防低水平人员带来的风险。 注意事项： 在层次化结构中，可以使用外观模式定义系统中每一层的入口。 ","date":"2022-04-30","objectID":"/posts/09.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:1:0","tags":["外观模式"],"title":"设计模式之外观模式详解（Java实现）","uri":"/posts/09.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2 外观模式详解 ","date":"2022-04-30","objectID":"/posts/09.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:0","tags":["外观模式"],"title":"设计模式之外观模式详解（Java实现）","uri":"/posts/09.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.1 外观模式结构 外观模式没有一个一般化的类图描述，下图可以用来描述外观模式的结构图。 由上图可知，外观模式包含以下两个角色。 Facade（外观角色）：在客户端可以调用它的方法，在外观角色中可以知道相关的（一个或者多个）子系统的功能和责任；在正常情况下，它将所有从客户端发来的请求委派到相应的子系统，传递给相应的子系统对象处理。 SubSystem（子系统角色）：在软件系统中可以有一个或者多个子系统角色，每一个子系统可以不是一个单独的类，而是一个类的集合，它实现子系统的功能；每一个子系统都可以被客户端直接调用，或者被外观角色调用，它处理由外观类传过来的请求；子系统并不知道外观的存在，对于子系统而言，外观角色仅仅是另外一个客户端而已。 ","date":"2022-04-30","objectID":"/posts/09.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:1","tags":["外观模式"],"title":"设计模式之外观模式详解（Java实现）","uri":"/posts/09.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.2 外观模式实现 子系统类通常是一些业务类，实现了一些具体的、独立的业务功能，其典型代码如下： public class SubSystemA { public void methodA() { //业务实现代码 } } public class SubSystemB { public void methodB() { //业务实现代码 } } public class SubSystemC { public void methodC() { //业务实现代码 } } 外观类的典型代码如下： public class Facade { private SubSystemA obj1 = new SubSystemA(); private SubSystemB obj2 = new SubSystemB(); private SubSystemC obj3 = new SubSystemC(); public void method() { obj1.method(); obj2.method(); obj3.method(); } } 由于在外观类中维持了对子系统对象的引用，客户端可以通过外观类来间接调用子系统对象的业务方法，而无须与子系统对象直接交互。在引入外观类后，客户端代码变得非常简单，其典型代码如下： public class Client { public static void main(String args[]) { Facade facade = new Facade(); facade.method(); } } ","date":"2022-04-30","objectID":"/posts/09.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:2","tags":["外观模式"],"title":"设计模式之外观模式详解（Java实现）","uri":"/posts/09.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.3 外观模式应用举例 题目描述 某软件公司要开发一个可应用于多个软件的文件加密模块，该模块可以对文件中的数据进行加密并将加密之后的数据存储在一个新文件中，具体的流程包括3个部分，分别是读取源文件、加密、保存加密之后的文件，其中，读取文件和保存文件使用流来实现，加密操作通过求模运算实现。这3个操作相对独立，为了实现代码的独立重用，让设计更符合单一职责原则，这3个操作的业务代码封装在3个不同的类中。 现使用外观模式设计该文件加密模块。 UML类图 其中，EncryptFacade充当外观类，FileReader、CipherMachine和FileWriter充当子系统类。 代码 代码地址 ","date":"2022-04-30","objectID":"/posts/09.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:3","tags":["外观模式"],"title":"设计模式之外观模式详解（Java实现）","uri":"/posts/09.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"3 抽象外观类 在标准的外观模式的结构图中，如果需要增加、删除或更换与外观类交互的子系统类，必须修改外观类或客户端的源代码，这将违背开闭原则，因此可以通过引入抽象外观类对系统进行改进，在一定程度上解决该问题。 如2.3中的题目我们需要更换一个加密类，如果我们需要增加一个新的外观类NewEncryptFacade与FileReader类、FileWriter类以及新增加的NewClipherMachine类交互，虽然原有系统类库无须作修改，但是因为客户端代码中原来针对EncryptFacade类进行编程，现在需要修改为NewEncryptFacade类，所以需要修改客户端源代码。如何在不修改客户端代码的前提下使用新的外观类呢？那么我们可以引入一个抽象外观类，客户端针对抽象外观类编程即可。结构图如下： 修改后的代码如下： 代码地址 ","date":"2022-04-30","objectID":"/posts/09.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:3:0","tags":["外观模式"],"title":"设计模式之外观模式详解（Java实现）","uri":"/posts/09.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"1 装饰模式介绍 在生活中，我们往往会给图片增加一些边框等来装饰图片，可以让图片变得更漂亮，如下图，就是对小狗图片的装饰。 在软件设计中，我们也有一种类似图片的技术可以对已有对象（图片）的功能进行扩展（装修），以获得更加符合用户需求的对象，使得对象具有更加强大的功能。这种技术对应于一种被称之为装饰模式（Decorator Pattern）的设计模式。装饰模式能动态地给一个对象增加一些额外的职责。就扩展功能而言，装饰模式提供了一种比使用子类更加灵活的替代方案。引入了装饰类，在装饰类中既可以调用待装饰的原有类的方法，还可以增加新的方法，以扩展原有类的功能 主要解决： 一般的，我们为了扩展一个类经常使用继承方式实现，由于继承为类引入静态特征，并且随着扩展功能的增多，子类会很膨胀。 何时使用： 在不想增加很多子类的情况下扩展类。 如何解决： 将具体功能职责划分，同时继承装饰者模式。 关键代码： 1、Component 类充当抽象角色，不应该具体实现。 2、修饰类引用和继承 Component 类，具体扩展类重写父类方法。 应用实例： 1、孙悟空有 72 变，当他变成\"庙宇\"后，他的根本还是一只猴子，但是他又有了庙宇的功能。 2、不论一幅画有没有画框都可以挂在墙上，但是通常都是有画框的，并且实际上是画框被挂在墙上。在挂在墙上之前，画可以被蒙上玻璃，装到框子里；这时画、玻璃和画框形成了一个物体。 优点： 装饰类和被装饰类可以独立发展，不会相互耦合，装饰模式是继承的一个替代模式，装饰模式可以动态扩展一个实现类的功能。 缺点： 多层装饰比较复杂。 使用场景： 1、扩展一个类的功能。 2、动态增加功能，动态撤销。 注意事项： 可代替继承。 ","date":"2022-04-28","objectID":"/posts/08.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:1:0","tags":["装饰模式"],"title":"设计模式之装饰模式详解（Java实现）","uri":"/posts/08.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2 装饰模式详解 ","date":"2022-04-28","objectID":"/posts/08.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:0","tags":["装饰模式"],"title":"设计模式之装饰模式详解（Java实现）","uri":"/posts/08.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.1 装饰模式结构 装饰模式的结构如图所示： 由结构图可知，装饰模式包含以下4个角色。 Component（抽象构件）：它是具体构件和抽象装饰类的共同父类，声明了在具体构件中的业务方法，它的引入可以使客户端以一致的方式处理未被装饰的对象以及装饰之后的对象，实现客户端的透明操作。 ConcreteComponent（具体构件）：它是抽象构件的子类，用于定义具体的构件对象，实现了在抽象构件中声明的方法，装饰类可以给它增加额外的职责（方法）。 Decorator（抽象装饰类）：它也是抽象构件类的子类，用于给具体构件增加职责，但是具体职责在其子类中实现。它维护一个指向抽象构件对象的引用，通过该引用可以调用装饰之前构件对象的方法，并通过其子类扩展该方法，以达到装饰的目的。 ConcreteDecorator（具体装饰类）：它是抽象装饰类的子类，负责向构件添加新的职责。每一个具体装饰类都定义了一些新的行为，它可以调用在抽象装饰类中定义的方法，并可以增加新的方法用于扩充该对象的行为。 ","date":"2022-04-28","objectID":"/posts/08.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:1","tags":["装饰模式"],"title":"设计模式之装饰模式详解（Java实现）","uri":"/posts/08.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.2 装饰模式实现 抽象构件类典型代码： public abstract class Component { public abstract void operation(); } 具体构件类典型代码： public class ConcreteComponent extends Component { public void operation() { //实现基本功能 } } 抽象装饰类典型代码： public class Decorator extends Component { private Component component; //维持一个对抽象构件对象的引用 //注入一个抽象构件类型的对象 public Decorator(Component component) { this.component=component; } public void operation() { component.operation(); //调用原有业务方法 } } 具体装饰类典型代码： public class ConcreteDecorator extends Decorator { public ConcreteDecorator(Component component) { super(component); } public void operation() { super.operation(); //调用原有业务方法 addedBehavior(); //调用新增业务方法 } //新增业务方法 public void addedBehavior() { …… } } ","date":"2022-04-28","objectID":"/posts/08.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:2","tags":["装饰模式"],"title":"设计模式之装饰模式详解（Java实现）","uri":"/posts/08.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.3 装饰模式应用举例 题目描述 简单的手机（SimplePhone）再接收到来电的时候，会发出声音提醒主人；而现在我们需要为该手机添加一项功能，在接收来电的时候，除了声音还能产生振动（JarPhone）；还可以得到更高级的手机（ComplexPhone），来电的时候，它不仅能够发声，产生振动，而且还有灯光在闪烁提示。现在用装饰模式来模拟一下手机的升级过程，要求绘制类图并编程实现。 UML类图 其中，Cellphone 为抽象类，声明了来电方法 receiveCall()，SimplePhone 为简单手机类， 提供了声音提示，JarPhone 和 ComplexPhone 分别提供了振动提示和灯光闪烁提示。 PhoneDecorator 是抽象装饰者，它维持一个对父类对象的引用。 代码 代码地址 ","date":"2022-04-28","objectID":"/posts/08.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:3","tags":["装饰模式"],"title":"设计模式之装饰模式详解（Java实现）","uri":"/posts/08.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"3 透明装饰模式和半透明装饰模式 透明装饰模式 要求客户端完全针对抽象编程，装饰模式的透明性要求客户端程序不应该将对象声明为具体构件类型或具体装饰类型，而应该全部声明为抽象构件类型。对于客户端而言，具体构件对象和具体装饰对象没有任何区别。可以让客户端透明地使用装饰之前的对象和装饰之后的对象，无须关心它们的区别。可以对一个已装饰过的对象进行多次装实例： …… Component component_o,component_d1,component_d2; //全部使用抽象构件定义 component_o = new ConcreteComponent(); component_d1 = new ConcreteDecorator1(component_o); component_d2 = new ConcreteDecorator2(component_d1); component_d2.operation(); //无法单独调用component_d2的addedBehavior()方法 …… 半透明装饰模式 用具体装饰类型来定义装饰之后的对象，而具体构件使用抽象构件类型来定义。对于客户端而言，具体构件类型无须关心，是透明的；但是具体装饰类型必须指定，这是不透明的。可以给系统带来更多的灵活性，设计相对简单，使用起来也非常方便，客户端使用具体装饰类型来定义装饰后的对象，因此可以单独调用addedBehavior()方法。最大的缺点在于不能实现对同一个对象的多次装饰，而且客户端需要有区别地对待装饰之前的对象和装饰之后的对象。实例： …… Component component_o; //使用抽象构件类型定义 component_o = new ConcreteComponent(); component_o.operation(); ConcreteDecorator component_d; //使用具体装饰类型定义 component_d = new ConcreteDecorator(component_o); component_d.operation(); component_d.addedBehavior(); //单独调用新增业务方法 …… ","date":"2022-04-28","objectID":"/posts/08.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:3:0","tags":["装饰模式"],"title":"设计模式之装饰模式详解（Java实现）","uri":"/posts/08.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["问题记录"],"content":"开机后报错如下： 报这个错误多数情况下是因为/etc/fstab文件的错误。注意一下是不是加载了外部硬盘、存储器或者是网络共享空间，在重启时没有加载上导致的。 我就是因为在上次编辑了/etc/fstab文件想实现自动挂载，但重启并没有挂载成功导致的。 所以我们需要恢复/etc/fstab文件，处理方法如下： 先输入密码登录root账户； 输入vim /etc/fstab编辑，注释或者修改自己增加的内容； 这里我挂载defaults写成default了，所以会出错，所以我这里直接更改后就没有问题了。 保存并退出； 输入reboot重启即可恢复正常。 ","date":"2022-04-26","objectID":"/posts/03.%E8%A7%A3%E5%86%B3linux%E7%B3%BB%E7%BB%9Fcentos7%E7%9A%84%E5%BC%80%E6%9C%BA%E6%8A%A5%E9%94%99welcome-to-emergency-mode/:0:0","tags":["Linux"],"title":"解决Linux系统centos7的开机报错：Welcome to emergency mode","uri":"/posts/03.%E8%A7%A3%E5%86%B3linux%E7%B3%BB%E7%BB%9Fcentos7%E7%9A%84%E5%BC%80%E6%9C%BA%E6%8A%A5%E9%94%99welcome-to-emergency-mode/"},{"categories":["设计模式"],"content":"1 组合模式介绍 在我们的树形目录结构中，包含文件和文件夹两类不同的元素，如下图。 其中文件夹中可以包含文件，也可以继续包含文件夹；而在文件中不能再包含子文件或者子文件夹。 那么我们可以将文件夹看作是容器（Container），将文件看作是叶子（Leaf）。那如何一致的对待容器对象和叶子对象呢？ 组合模式（Composite Pattern）让客户端可以统一对待单个对象和组合对象。这种模式创建了一个包含自己对象组的类。该类提供了修改相同对象组的方式。 主要解决： 它在我们树型结构的问题中，模糊了简单元素和复杂元素的概念，客户程序可以像处理简单元素一样来处理复杂元素，从而使得客户程序与复杂元素的内部结构解耦。 何时使用： 1、您想表示对象的部分-整体层次结构（树形结构）。 2、您希望用户忽略组合对象与单个对象的不同，用户将统一地使用组合结构中的所有对象。 如何解决： 树枝和叶子实现统一接口，树枝内部组合该接口。 关键代码： 树枝内部组合该接口，并且含有内部属性 List，里面放 Component。 应用实例： 1、算术表达式包括操作数、操作符和另一个操作数，其中，另一个操作数也可以是操作数、操作符和另一个操作数。 2、在 JAVA AWT 和 SWING 中，对于 Button 和 Checkbox 是树叶，Container 是树枝。 优点： 1、高层模块调用简单。 2、节点自由增加。 缺点： 在使用组合模式时，其叶子和树枝的声明都是实现类，而不是接口，违反了依赖倒置原则。 使用场景： 部分、整体场景，如树形菜单，文件、文件夹的管理。 注意事项： 定义时为具体类。 ","date":"2022-04-25","objectID":"/posts/07.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:1:0","tags":["组合模式"],"title":"设计模式之组合模式详解（Java实现）","uri":"/posts/07.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2 组合模式详解 ","date":"2022-04-25","objectID":"/posts/07.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:0","tags":["组合模式"],"title":"设计模式之组合模式详解（Java实现）","uri":"/posts/07.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.1 组合模式结构 组合模式的结构如图所示： 由图可知，组合模式包含以下3个角色。 Component（抽象构件）：它可以是接口或抽象类，为叶子构件和容器构件对象声明接口，在该角色中可以包含所有子类共有行为的声明和实现。在抽象构件中定义了访问及管理它的子构件的方法，如增加子构件、删除子构件、获取子构件等。 Leaf（叶子构件）：它在组合结构中表示叶子结点对象，叶子结点没有子结点，它实现了在抽象构件中定义的行为。对于那些访问及管理子构件的方法，可以通过抛出异常、提示错误等方式进行处理。 Composite（容器构件）：它在组合结构中表示容器结点对象，容器结点包含子结点，其子结点可以是叶子结点，也可以是容器结点，它提供一个集合用于存储子结点，实现类在抽象构件中定义的行为，包括那些访问及管理子构件的方法，在其业务方法中可以递归调用其子结点的业务方法。 ","date":"2022-04-25","objectID":"/posts/07.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:1","tags":["组合模式"],"title":"设计模式之组合模式详解（Java实现）","uri":"/posts/07.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.2 组合模式实现 对于组合模式中的抽象构件角色，其典型代码如下： public abstract class Component { public abstract void addComponent(Component c); // 增加成员 public abstract void remove(Component c); // 删除成员 public abstract Component getChild(int i); // 获取成员 public abstract void operation(); // 业务方法 } 对于组合模式中的叶子构件角色，其典型代码如下： public class Leaf extends Component { public void add(Component c) { // 异常处理或错误提示 } public void remove(Component c) { // 异常处理或错误提示 } public void getChild(int i) { // 异常处理或错误提示 } public void operation() { // 叶子构件具体业务方法的实现 } } 对于组合模式中的容器构件角色，其典型代码如下： import java.util.*; public class Composite extends Component { private ArrayList\u003cComponent\u003e list = new ArrayList\u003cComponent\u003e(); public void add(Component c) { list.add(c); } public void remove(Component c) { list.remove(c); } public void getChild(int i) { return (Componnent) list.get(i); } public void operation() { // 容器构件具体业务方法的实现，将递归调用成员构件的业务方法 for (Object object : list) { ((Component)obj).operation(); } } } ","date":"2022-04-25","objectID":"/posts/07.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:2","tags":["组合模式"],"title":"设计模式之组合模式详解（Java实现）","uri":"/posts/07.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.3 组合模式应用举例 题目描述 某软件公司欲开发一个杀毒(Antivirus)软件，该软件既可以对某个文件夹(Folder)杀毒，也可以对某个指定的文件(File)进行杀毒。该杀毒软件还可以根据各类文件的特点，为不同类型的文件提供不同的杀毒方式，例如图像文件(ImageFile)和文本文件(TextFile)的杀毒方式就有所差异。现使用组合模式来设计该杀毒软件的整体框架。 UML类图 其中，AbstractFile充当抽象构件类，Folder充当容器构件类，ImageFile、TextFile和VideoFile充当叶子构件类。 代码 代码地址 ","date":"2022-04-25","objectID":"/posts/07.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:3","tags":["组合模式"],"title":"设计模式之组合模式详解（Java实现）","uri":"/posts/07.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"3 透明组合模式和安全组合模式 组合模式根据抽象构件的定义形式又可以分为透明组合模式和安全组合模式。 透明组合模式 根据结构图我们可以看出抽象构件Component中声明了所有用于管理成员对象的方法，包括add()、remove()，以及getChild()等方法，在客户端看来，叶子对象与容器对象所提供的方法是一致的，客户端可以一致地对待所有的对象，缺点是不够安全，因为叶子对象和容器对象在本质上是有区别的。 安全组合模式 根据结构图可以看出抽象构件Component中没有声明任何用于管理成员对象的方法，而是在Composite类中声明并实现这些方法，对于叶子对象，客户端不可能调用到这些方法。缺点是不够透明，客户端不能完全针对抽象编程，必须有区别地对待叶子构件和容器构件。但在实际应用中，安全组合模式的使用频率也非常高。 ","date":"2022-04-25","objectID":"/posts/07.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:3:0","tags":["组合模式"],"title":"设计模式之组合模式详解（Java实现）","uri":"/posts/07.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"1 桥接模式介绍 毛笔和蜡笔是两种很常见的文具，它们都归属于画笔。假设我们需要大、中、小3种型号的画笔，能够绘制12种不同的颜色。那么我们的解决方案如下： 显然，在毛笔中，我们将颜色和型号进行了分离，增加新的颜色或者型号对另一方没有影响，即用软件工程中的术语，可以认为在蜡笔中颜色和型号之间存在较强的耦合性，而毛笔很好地将二者解耦，使用起来非常灵活，扩展也较为方便。 在软件开发中也有一种设计模式可以用来处理上述类似的具有多变化维度的情况，它就是桥接模式（Bridge Pattern）。它将抽象部分与它的实现部分解耦，使得两者都能独立变化。 桥接模式又被称为柄体(Handle and Body)模式或接口(Interface)模式，用抽象关联取代了传统的多层继承，将类之间的静态继承关系转换为动态的对象组合关系。 主要解决： 在有多种可能会变化的情况下，用继承会造成类爆炸问题，扩展起来不灵活。 何时使用： 实现系统可能有多个角度分类，每一种角度都可能变化。 **如何解决：**把这种多角度分类分离出来，让它们独立变化，减少它们之间耦合。 关键代码： 抽象类依赖实现类。 应用实例： 1、猪八戒从天蓬元帅转世投胎到猪，转世投胎的机制将尘世划分为两个等级，即：灵魂和肉体，前者相当于抽象化，后者相当于实现化。生灵通过功能的委派，调用肉体对象的功能，使得生灵可以动态地选择。 2、墙上的开关，可以看到的开关是抽象的，不用管里面具体怎么实现的。 优点： 1、抽象和实现的分离。 2、优秀的扩展能力。 3、实现细节对客户透明。 **缺点：**桥接模式的引入会增加系统的理解与设计难度，由于聚合关联关系建立在抽象层，要求开发者针对抽象进行设计与编程。 使用场景： 1、如果一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性，避免在两个层次之间建立静态的继承联系，通过桥接模式可以使它们在抽象层建立一个关联关系。 2、对于那些不希望使用继承或因为多层次继承导致系统类的个数急剧增加的系统，桥接模式尤为适用。 3、一个类存在两个独立变化的维度，且这两个维度都需要进行扩展。 注意事项： 对于两个独立变化的维度，使用桥接模式再适合不过了。 ","date":"2022-04-24","objectID":"/posts/06.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:1:0","tags":["桥接模式"],"title":"设计模式之桥接模式详解（Java实现）","uri":"/posts/06.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2 桥接模式详解 ","date":"2022-04-24","objectID":"/posts/06.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:0","tags":["桥接模式"],"title":"设计模式之桥接模式详解（Java实现）","uri":"/posts/06.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.1 桥接模式结构 桥接模式的结构图如下： 由上图可知，桥接模式包括以下4个角色。 Abstraction（抽象类）：它是用于定义抽象类的接口，通常是抽象类而不是接口，其中定义了一个Implementor（实现类接口）类型的对象并可以维护该对象，它与Implementor之间具有关联关系，它既可以包含抽象业务方法，也可以包含具体业务方法。 RefinedAbstraction（扩充抽象类）：它扩充由Abstraction定义的接口，通常情况下它不再是抽象类而是具体类，实现了在Abstraction中声明的抽象业务方法，在RefinedAbstraction中可以调用在Implementor中定义的业务方法。 Implementor（实现类接口）：它是定义实现类的接口，这个接口不一定要与Abstraction的接口完全一致，事实上这两个接口可以完全不同。一般而言，Implementor接口仅提供基本操作，而Abstraction定义的接口可能会做更多更复杂的操作。Implementor接口对这些基本操作进行了声明，而具体实现交给其子类。通过关联关系，在Abstraction中不仅拥有自己的方法，还可以调用到Implementor中定义的方法，使用关联关系代替继承关系。 ConcreteImplementor（具体实现类）：它具体实现了Implementor接口，在不同的ConcreteImplementor中提供基本操作的不同实现，在程序运行时ConcreteImplementor对象将替换其父类对象，提供给抽象类具体的业务操作方法。 ","date":"2022-04-24","objectID":"/posts/06.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:1","tags":["桥接模式"],"title":"设计模式之桥接模式详解（Java实现）","uri":"/posts/06.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.2 桥接模式实现 在具体编码实现时，由于在桥接模式中存在两个独立变化的维度，为了降低两者之间的耦合度，首先需要针对两个不同的维度提取抽象类和实现类接口，并建立一个抽象关联关系。对于“实现部分维度”，典型的接口代码如下： public interface Implementor { public void operationImpl(); } 在实现Implementor接口的子类ConcreteImplementor中实现了在该接口中声明的方法，用于定义与该维度相对应的一些具体方法，代码如下： public class ConcreteImplementor implements Implementor { public void operationImpl() { //具体业务方法的实现 } } 对于另一“抽象部分”维度而言，其典型的抽象类代码如下： public abstract class Abstraction { protected Implementor impl; //定义实现类接口对象 public void setImpl(Implementor impl) { this.impl = impl; } public abstract void operation(); //声明抽象业务方法 } 在抽象类Abstraction中定义了一个实现类接口类型的成员对象impl，再通过Setter方法或者构造方法以注入的方式给该对象赋值。一般将该对象的可见性定义为protected，以便在其子类中访问Implementor的方法，其子类一般称为扩充对象类或细化抽象类（RefinedAbstraction），典型的RefinedAbstraction类代码如下： public class RefinedAbstraction extends Abstraction { public void operation() { //业务代码 impl.operationImpl(); //调用实现类的方法 //业务代码 } } 对于客户端而言，可以针对两个维度的抽象层编程，在程序运行时再动态确定两个维度的子类，动态组合对象，将两个独立变化的维度完全解耦，以便能够灵活地扩充任一维度而对另一维度不造成任何影响。 ","date":"2022-04-24","objectID":"/posts/06.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:2","tags":["桥接模式"],"title":"设计模式之桥接模式详解（Java实现）","uri":"/posts/06.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.3 桥接模式应用实例 题目描述 某软件公司欲开发一个数据转换工具，可以将数据库中的数据转换成多种文件格式，例如TXT、XML、PDF等格式，同时该工具需要支持多种不同的数据库。试用桥接模式对其进行设计。 UML类图 其中，FileConvertor 充当抽象类角色，TXTConvertor、XMLConvertor 和 PDFConvertor 充当扩充抽象类角色，DataHandler 充当实现类接口角色，OracleHandler 和SQLServerHandler充当具体实现类角色。 代码 代码地址 ","date":"2022-04-24","objectID":"/posts/06.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:3","tags":["桥接模式"],"title":"设计模式之桥接模式详解（Java实现）","uri":"/posts/06.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"1 适配器模式介绍 在现实生活中生活用电220V和笔记电脑20V不兼容，我们需要引入 AC Adapter（交流电适配器），在软件开发中我们也会存在不兼容的结构，这个时候就需要引入适配器模式。 适配器模式（Adapter Pattern）可以将一个类的接口和另一个类的接口匹配起来，而无需修改原来的适配者接口和抽象目标接口。 它将一个类的接口转换称客户希望的另一个接口，让那些接口不兼容的类可以一起工作。 适配器模式的别名为包装器模式（Wrapper Pattern），它既可以作为类结构模式，也可以作为对象结构型模式。在适配器模式的定义中所提及的接口是指广义的接口，它可以表示为方法或者方法的集合。 主要解决： 主要解决在软件系统中，常常要将一些\"现存的对象\"放到新的环境中，而新环境要求的接口是现对象不能满足的。 何时使用： 1、系统需要使用现有的类，而此类的接口不符合系统的需要。 2、想要建立一个可以重复使用的类，用于与一些彼此之间没有太大关联的一些类，包括一些可能在将来引进的类一起工作，这些源类不一定有一致的接口。 3、通过接口转换，将一个类插入另一个类系中。（比如老虎和飞禽，现在多了一个飞虎，在不增加实体的需求下，增加一个适配器，在里面包容一个虎对象，实现飞的接口。） 如何解决： 继承或依赖（推荐）。 关键代码： 适配器继承或依赖已有的对象，实现想要的目标接口。 应用实例： 1、美国电器 110V，中国 220V，就要有一个适配器将 110V 转化为 220V。 2、JAVA JDK 1.1 提供了 Enumeration 接口，而在 1.2 中提供了 Iterator 接口，想要使用 1.2 的 JDK，则要将以前系统的 Enumeration 接口转化为 Iterator 接口，这时就需要适配器模式。 3、在 LINUX 上运行 WINDOWS 程序。 4、JAVA 中的 jdbc。 优点： 1、可以让任何两个没有关联的类一起运行。 2、提高了类的复用。 3、增加了类的透明度。 4、灵活性好。 缺点： 1、过多地使用适配器，会让系统非常零乱，不易整体进行把握。比如，明明看到调用的是 A 接口，其实内部被适配成了 B 接口的实现，一个系统如果太多出现这种情况，无异于一场灾难。因此如果不是很有必要，可以不使用适配器，而是直接对系统进行重构。 2.由于 JAVA 至多继承一个类，所以至多只能适配一个适配者类，而且目标类必须是抽象类。 使用场景： 有动机地修改一个正常运行的系统的接口，这时应该考虑使用适配器模式。 注意事项： 适配器不是在详细设计时添加的，而是解决正在服役的项目的问题。 ","date":"2022-04-24","objectID":"/posts/05.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:1:0","tags":["适配器模式"],"title":"设计模式之适配器模式详解（Java实现）","uri":"/posts/05.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2 适配器模式详解 ","date":"2022-04-24","objectID":"/posts/05.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:0","tags":["适配器模式"],"title":"设计模式之适配器模式详解（Java实现）","uri":"/posts/05.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.1 适配器模式结构 类适配器模式的结构图如下： 对象适配器模式的结构图如下： 由上图可知，适配器模式包含以下3个角色。 Target（目标抽象类）：目标抽象类定义客户所需的接口，可以是一个抽象类或者接口，也可以是具体类。在类适配器中，由于Java语言不支持多重继承，它只能是接口。 Adapter（适配器类）：它可以调用另一个接口 ，作为一个转换器，对Adaptee和Target进行适配。适配器Adapter是适配器模式的核心，在类适配器中，它通过实现Target接口并继承Adaptee类来使二者产生联系，在对象适配器中，它通过继承Target并关联一个Adaptee对象来使二者产生联系。 Adaptee（适配者类）：适配者即被适配的角色，它定义了一个已经存在的接口，这个接口需要适配，适配者类一般是一个具体的类，包含了客户希望使用的业务方法，在某些情况下甚至没有适配者类的代码。 ","date":"2022-04-24","objectID":"/posts/05.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:1","tags":["适配器模式"],"title":"设计模式之适配器模式详解（Java实现）","uri":"/posts/05.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.2 适配器模式实现 2.2.1 类适配器 根据上图，在类适配器中适配者类Adaptee没有request方法，而客户端期待这个方法，但在适配者类中实现了specificRequest()方法，该方法提供的实现正式客户端所需要的。为了使客户端能够使用适配者类，提供了一个中间类，即适配器类Adapter，适配器类实现了抽象目标类接口Target，并继承了适配者类，在适配器类的request()方法中调用所继承的适配者类的specificRequest()方法，达到了适配的目的。 因为适配器类与适配者类使继承关系，所以这种适配器模式称为类适配器模式。典型的类适配器代码如下： public class Adapter extends Adaptee implements Target { public void request() { super.specificRequest(); } } 2.2.2 对象适配器 根据上图，在对象适配器中适配者类Adaptee没有request方法，而客户端期待这个方法，但在适配者类中实现了specificRequest()方法，该方法提供的实现正式客户端所需要的。为了使客户端能够使用适配者类，需要提供一个包装类Adapter，即适配器类。 这个包装类包装了一个适配者的实例，从而将客户端与适配者衔接起来，在适配器的request()方法中调用适配者的specificRequest()方法。 因为适配器类与适配者类是关联关系，所以这种适配器模式称为对象适配器模式。典型的对象适配器代码如下： public class Adapter extends Target { // 维持一个对适配者对象的引用 private Adaptee adaptee; public Adapter(Adaptee adaptee) { this.adaptee = adaptee; } public void request() { // 转发调用 adaptee.specificRequest(); } } ","date":"2022-04-24","objectID":"/posts/05.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:2","tags":["适配器模式"],"title":"设计模式之适配器模式详解（Java实现）","uri":"/posts/05.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.3 适配器模式应用举例 题目描述 某公司欲开发一款儿童玩具汽车，为了更好地吸引小朋友的注意力，该玩具汽车在移动过程中伴随着灯光闪烁和声音提示。在该公司以往的产品中已经实现了控制灯光闪烁（例如警灯闪烁）和声音提示（例如警笛音效）的程序，为了重用先前的代码并且使得汽车控制软件具有更好的灵活性和扩展性，现使用适配器模式设计该玩具汽车控制软件。 UML类图 使用对象适配器模式来实现，其UML类图如下： 其中，CarController类充当抽象目标，PoliceSound和PoliceLamp类充当适配者，PoliceCarAdapter充当适配器。 代码 代码地址 ","date":"2022-04-24","objectID":"/posts/05.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:3","tags":["适配器模式"],"title":"设计模式之适配器模式详解（Java实现）","uri":"/posts/05.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"3 缺省适配器模式 缺省适配器模式(Default Adapter Pattern)：当不需要实现一个接口所提供的所有方法时，可先设计一个抽象类实现该接口，并为接口中每个方法提供一个默认实现（空方法），那么该抽象类的子类可以选择性地覆盖父类的某些方法来实现需求，它适用于不想使用一个接口中的所有方法的情况，又称为单接口适配器模式。其结构图如下： 由上图可知，在缺省适配器模式中包含以下3个角色： ServiceInterface（适配者接口）：它是一个接口，通常在接口中声明了大量的方法。 AbstractServiceClass（缺省适配器类）：它是缺省适配器模式的核心类，使用空方法的形式实现了在ServiceInterface接口中声明的方法。通常将它定义为抽象类，因为对它进行实例化没有任何意义。 ConcreteServiceClass（具体业务类）：它是缺省适配器类的子类，在没有引入适配器之前它需要实现适配者接口，因此需要实现在适配者接口中定义的所有方法，而对于一些无须使用的方法不得不提供空实现。在有了缺省适配器之后可以直接继承该适配者类，根据需要有选择性地覆盖在适配器类中定义的方法。 缺省适配器类的典型代码如下： public abstract class AbstractServiceClass implements ServiceInterface { public void serviceMethod1() { } //空方法 public void serviceMethod2() { } //空方法 public void serviceMethod3() { } //空方法 } ","date":"2022-04-24","objectID":"/posts/05.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:3:0","tags":["适配器模式"],"title":"设计模式之适配器模式详解（Java实现）","uri":"/posts/05.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"4 双向适配器 在对象适配器的使用过程中，如果在适配器中同时包含对目标类和适配者类的引用，适配者可以通过它调用目标类中的方法，目标类也可以通过它调用适配者类的方法，那么该适配器就是一个双向适配器。其结构图如下： 其典型代码如下： public class Adapter implements Target,Adaptee { // 同时维持对抽象目标类和适配者类的引用 private Target target; private Adaptee adaptee; public Adapter(Target target) { this.target = target; } public Adapter(Adaptee adaptee) { this.adaptee = adaptee; } public void request() { adaptee.specificRequest(); } public void specificRequest() { target.request(); } } ","date":"2022-04-24","objectID":"/posts/05.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:4:0","tags":["适配器模式"],"title":"设计模式之适配器模式详解（Java实现）","uri":"/posts/05.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"1 建造者模式介绍 建造者模式（Builder Pattern）使用多个简单的对象一步一步构建成一个复杂的对象。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 一个 Builder 类会一步一步构造最终的对象。该 Builder 类是独立于其他对象的。 意图： 将一个复杂的构建与其表示相分离，使得同样的构建过程可以创建不同的表示。 主要解决： 主要解决在软件系统中，有时候面临着\"一个复杂对象\"的创建工作，其通常由各个部分的子对象用一定的算法构成；由于需求的变化，这个复杂对象的各个部分经常面临着剧烈的变化，但是将它们组合在一起的算法却相对稳定。 何时使用： 一些基本部件不会变，而其组合经常变化的时候。 如何解决： 将变与不变分离开。 关键代码： 建造者：创建和提供实例，导演：管理建造出来的实例的依赖关系。 应用实例： 1、去肯德基，汉堡、可乐、薯条、炸鸡翅等是不变的，而其组合是经常变化的，生成出所谓的\"套餐\"。 2、JAVA 中的 StringBuilder。 优点： 1、建造者独立，易扩展。 2、便于控制细节风险。 缺点： 1、产品必须有共同点，范围有限制。 2、如内部变化复杂，会有很多的建造类。 使用场景： 1、需要生成的对象具有复杂的内部结构。 2、需要生成的对象内部属性本身相互依赖。 注意事项： 与工厂模式的区别是：建造者模式更加关注与零件装配的顺序。 ","date":"2022-04-24","objectID":"/posts/02.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:1:0","tags":["建造者模式"],"title":"设计模式之建造者模式详解（Java实现）","uri":"/posts/02.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2 建造者模式详解 ","date":"2022-04-24","objectID":"/posts/02.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:0","tags":["建造者模式"],"title":"设计模式之建造者模式详解（Java实现）","uri":"/posts/02.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.1 建造者模式结构 建造者模式的UML类图如下： 由上图可知，建造者模式包含以下4个角色。 Builder（抽象建造者）：它为创建一个产品对象的各个部件指定抽象接口，在该接口中一般声明两类方法，一类方法是buildPartX()（如图中的buildPartA()、buildPathB()等），它们用于创建复杂对象的各个部件；另一类方法是getResult（），它们用于返回复杂对象。Builder既可以是抽象类，也可以是接口。 ConcreteBuilder（具体建造者）：它实现了Builder接口，实现各个部件的具体构造和装配方法，定义并明确所创建的复杂对象，还可以提供一个方法返回创建好的复杂产品对象（该方法也可以由抽象建造者实现）。 Product（产品）：它是被构建的复杂对象，包含多个组成部件，具体建造者创建该产品的内部表示并定义它的装配过程。 Director（指挥者）：指挥者又称为导演类，它负责安排复杂对象的建造次序，指挥者与抽象建造者之间存在关联关系，可以在其construct()建造方法中调用建造者对象的部件构造与装配方法，完成复杂对象的建造。 ","date":"2022-04-24","objectID":"/posts/02.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:1","tags":["建造者模式"],"title":"设计模式之建造者模式详解（Java实现）","uri":"/posts/02.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.2 建造者模式实现 典型的复杂对象类的代码如下： public class Product { private String partA; // 定义部件，部件可以是任意类型，包括值类型和引用类型 private String partB; private String partC; // 属性的Getter和Setter方法省略 } 典型的抽象建造者类的代码如下： public abstract class Builder { // 创建产品对象 protected Product product = new Product(); public abstract void buildPartA(); public abstract void buildPartB(); public abstract void buildPartC(); // 返回产品对象 public Product getResult() { return product; } } 典型的具体建造者类的代码如下： public class ConcreteBuilder1 extends Builder { public void buildPartA() { product.setPartA(\"A1\"); } public void buildPartB() { product.setPartA(\"B1\"); } public void buildPartC() { product.setPartA(\"C1\"); } } 典型的指挥者类的代码如下： public class Director { private Builder builder; public Director(Builder builder) { this.builder = builder; } public void setBuilder(Builder builder) { this.builder = builder; } // 产品的构建与组装方法 public Product construct() { builder.buildPartA(); builder.buildPartB(); builder.buildPartC(); return builder.getResult(); } } ","date":"2022-04-24","objectID":"/posts/02.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:2","tags":["建造者模式"],"title":"设计模式之建造者模式详解（Java实现）","uri":"/posts/02.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.3 建造者模式应用举例 题目描述 计算机组装工厂可以将CPU、内存、硬盘、主机、显示器等硬件设备组装在一起构成一台完整的计算机，且构成的计算机可以是笔记本，也可以是台式机，还可以是不提供显示器的服务器主机。对于用户而言，无须关心计算机的组成设备和组装过程，工厂返回给用户的。是完整的计算机对象，使用建造者模式实现计算机组装过程。 UML类图 其中，Computer充当符合产品，ComputerBuilder充当抽象建造者，Notebook、Desktop和Server充当具体建造者，ComputerAssembleDirector充当指挥者，其assemble()方法用于定义产品的构造过程。 代码 代码地址 ","date":"2022-04-24","objectID":"/posts/02.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:3","tags":["建造者模式"],"title":"设计模式之建造者模式详解（Java实现）","uri":"/posts/02.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"1 原型模式介绍 原型模式（Prototype Pattern）是一种对象创建型模式，它是使用原型实例指定待创建对象的类型，并且通过复制这个原型来创建新的对象。 它的工作原理很简单：将一个原型对象传给要发动创建的对象（即客户端对象），这个要发动创建的对象通过请求原型对象复制自己来实现创建过程。 意图： 用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。 主要解决： 在运行期建立和删除原型。 何时使用： 1、当一个系统应该独立于它的产品创建，构成和表示时。 2、当要实例化的类是在运行时刻指定时，例如，通过动态装载。 3、为了避免创建一个与产品类层次平行的工厂类层次时。 4、当一个类的实例只能有几个不同状态组合中的一种时。建立相应数目的原型并克隆它们可能比每次用合适的状态手工实例化该类更方便一些。 如何解决： 利用已有的一个原型对象，快速地生成和原型对象一样的实例。 关键代码： 1、实现克隆操作，在 JAVA 继承 Cloneable，重写 clone()，在 .NET 中可以使用 Object 类的 MemberwiseClone() 方法来实现对象的浅拷贝或通过序列化的方式来实现深拷贝。 2、原型模式同样用于隔离类对象的使用者和具体类型（易变类）之间的耦合关系，它同样要求这些\"易变类\"拥有稳定的接口。 应用实例： 1、细胞分裂。 2、JAVA 中的 Object clone() 方法。 优点： 1、性能提高。 2、逃避构造函数的约束。 缺点： 1、配备克隆方法需要对类的功能进行通盘考虑，这对于全新的类不是很难，但对于已有的类不一定很容易，特别当一个类引用不支持串行化的间接对象，或者引用含有循环结构的时候。 2、必须实现 Cloneable 接口。 使用场景： 1、资源优化场景。 2、类初始化需要消化非常多的资源，这个资源包括数据、硬件资源等。 3、性能和安全要求的场景。 4、通过 new 产生一个对象需要非常繁琐的数据准备或访问权限，则可以使用原型模式。 5、一个对象多个修改者的场景。 6、一个对象需要提供给其他对象访问，而且各个调用者可能都需要修改其值时，可以考虑使用原型模式拷贝多个对象供调用者使用。 7、在实际项目中，原型模式很少单独出现，一般是和工厂方法模式一起出现，通过 clone 的方法创建一个对象，然后由工厂方法提供给调用者。原型模式已经与 Java 融为浑然一体，大家可以随手拿来使用。 注意事项： 与通过对一个类进行实例化来构造新对象不同的是，原型模式是通过拷贝一个现有对象生成新对象的。浅拷贝实现 Cloneable，重写，深拷贝是通过实现 Serializable 读取二进制流。 ","date":"2022-04-24","objectID":"/posts/03.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:1:0","tags":["原型模式"],"title":"设计模式之原型模式详解（Java实现）","uri":"/posts/03.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2 原型模式详解 ","date":"2022-04-24","objectID":"/posts/03.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:0","tags":["原型模式"],"title":"设计模式之原型模式详解（Java实现）","uri":"/posts/03.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.1 原型模式结构 原型模式包含以下3个角色。 Prototype（抽象原型类）：它是声明克隆方法的接口，是所有具体原型类的公共父类，它可以是抽象类也可以是接口，甚至还可以是具体实现类。 ConcretePrototype（具体原型类）：它实现在抽象原型类中声明的克隆方法，在克隆方法中返回自己的一个克隆对象。 Client（客户类）：在客户类中，让一个原型对象克隆自身从而创建一个新的对象，只需要直接实例化或通过工厂方法等方式创建一个原型对象，再通过调用该对象的克隆方法即可得到多个相同的对象。 ","date":"2022-04-24","objectID":"/posts/03.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:1","tags":["原型模式"],"title":"设计模式之原型模式详解（Java实现）","uri":"/posts/03.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.2 深克隆与浅克隆 根据在复制原型对象的同时是否复制包含在原型对象中引用类型的成员变量，原型模式的克隆机制可分为两种，即浅克隆（Shallow Clone）和深克隆（Deep Clone）。 2.2.1 浅克隆 在浅克隆中，如果原型对象的成员变量是值类型，将复制一份给克隆对象；如果原型对象的成员变量是引用类型，则将引用对象的地址复制一份给克隆对象，也就是说原型对象和克隆对象的成员变量指向相同的内存地址。简单来说，在浅克隆中，当对象被复制时只复制它本身和其中包含的值类型的成员变量，而引用类型的成员对象并没有复制。 2.2.2 深克隆 在深克隆中，无论原型对象的成员变量是值类型还是引用类型，都将复制一份给克隆对象，深克隆将原型对象的所有引用对象也复制一份给克隆对象。简单来说，在深克隆中，除了对象本身被复制外，对象所包含的所有成员变量也将复制。 ","date":"2022-04-24","objectID":"/posts/03.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:2","tags":["原型模式"],"title":"设计模式之原型模式详解（Java实现）","uri":"/posts/03.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.3 原型模式实现 实现原型模式的关键在于如何实现克隆方法。这里介绍两种在Java语言中最常用的克隆实现方法。 2.3.1 通用实现方法 通用的克隆实现方法是在具体原型类的克隆方法中实例化一个与自身类型相同的对象并将其返回，同时将相关的参数传入新创建的对象中，保证它们的成员变量相同。 典型的抽象原型类代码如下： public abstract class Prototype { public abstract Prototype clone(); } 典型的具体原型类代码如下： public class ConcretePrototype extends Prototype { private String name; // 成员变量 public void setName(String name) { this.name = name; } public void getName() { return this.name; } // 克隆方法实现 public Prototype clone() { Prototype prototype = new ConcretePrototype(); // 创建新对象 prototype.setName(this.name); return prototype; } } 这样我们就只需要在客户类中创建一个ConcretePrototype对象作为原型对象，然后调用其clone()方法即可得到对应的克隆对象。 此方法是原型模式的通用实现，它与编程语言本身的特性无关，其他面向对象编程语言也可以使用这种形式来实现对原型对象的克隆。 在这种通用实现方法中，可通过手工编写clone()方法来实现浅克隆和深克隆。对于引用类型的对象，可以在clone()方法中通过赋值的方式来实现复制，这是一种浅克隆实现方案；如果在clone()方法中通过创建一个全新的成员对象来实现复制，则是一种深克隆实现方案。 2.3.2 Java语言中的clone()方法和Cloneable接口 在Java语言中，所有的Java类均继承自java.lang.Object类，Object类提供了一个clone()方法，可以将一个Java对象复制一份。因此在Java中可以直接使用Object提供clone()方法来实现对象的浅克隆。 需要注意的是能够实现克隆的Java类都必须实现一个标识接口Cloneable，表示这个Java类支持被复制。如果一个类没有实现这个接口但是调用了clone()方法，Java编译器将会抛出一个CloneNotSupportedException异常。如下代码所示： public class ConcretePrototype implements Cloneable { public Prototype clone() { Object object = null; try { object = super.clone(); // 浅克隆 } catch (CloneNotSupportedException exception) { System.err.println(\"Not support Cloneable\"); } return (Prototype)object; } } 为了获取对象的一个克隆，可以直接利用Object类的clone()方法，其具体步骤如下： 在派生类中覆盖基类的clone()方法，并声明为public。 在派生类的clone()方法中调用super.clone()。 派生类需实现Cloneable接口。 此时，Object类相当于抽象原型类，所有实现了Cloneable接口的类相当于具体原型类。 ","date":"2022-04-24","objectID":"/posts/03.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:3","tags":["原型模式"],"title":"设计模式之原型模式详解（Java实现）","uri":"/posts/03.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.4 原型模式应用举例 题目描述 某数据处理软件需要增加一个图表复制功能。在图表对象（DataChart）中包含一个数据集对象(DataSet)。数据集对象用于封装要显示的数据，用户可以通过界面上的复制按钮将该图表复制一份，复制后，即可得到新的图表对象，然后可以修改新图表的编号、颜色、数据。试用原型模式设计软件实现深克隆。 UML类图 在该设计方案中，DataChart 类包含一个 DataSet 对象，在复制 DataChart 对象的同时将 复制 DataSet 对象，因此需要使用深克隆技术，可使用流来实现深克隆。其中Serializable是java.io包中定义的、用于实现Java类的序列化操作而提供的一个语义级别的接口。Serializable序列化接口没有任何方法或者字段，只是用于标识可序列化的语义。实现了Serializable接口的类可以被ObjectOutputStream转换为字节流，同时也可以通过ObjectInputStream再将其解析为对象。故我们实现这个接口即可使用流来实现深克隆 代码 代码地址 ","date":"2022-04-24","objectID":"/posts/03.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:4","tags":["原型模式"],"title":"设计模式之原型模式详解（Java实现）","uri":"/posts/03.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"3 原型管理器 ","date":"2022-04-24","objectID":"/posts/03.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:3:0","tags":["原型模式"],"title":"设计模式之原型模式详解（Java实现）","uri":"/posts/03.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"3.1 原型管理器实现 原型管理器(Prototype Manager)是将多个原型对象存储在一个集合中供客户端使用，它是一个专门负责克隆对象的工厂，其中定义了一个集合用于存储原型对象， 如果需要某个原型对象的一个克隆，可以通过复制集合中对应的原型对象来获得。 在原型管理器中针对抽象原型类进行编程，以便扩展。 其结构如图所示： 其中典型的原型管理器PrototypeManager类的实现代码片段如下： package prototype_pattern; import java.util.Hashtable; /** * @author Cnc_hzf * @date 2022/4/22 15:00 */ public class PrototypeManager { private Hashtable prototypeTable = new Hashtable(); // 使用Hashtable存储原型对象 public PrototypeManager() { prototypeTable.put(\"A\", new ConcretePrototypeA()); prototypeTable.put(\"B\", new ConcretePrototypeB()); } public void add(String key, Prototype prototype) { prototypeTable.put(key, prototype); } public Prototype get(String key) { Prototype clone = ((Prototype) prototypeTable.get(key)).clone(); // 通过克隆方法创建新对象 return clone; } } 在实际开发中可以将PrototypeManger设计为单例类，确保系统中有且仅有一个PrototypeManager对象，这样既有利于节省系统资源，还可以更好地对原型管理器对象进行控制。 ","date":"2022-04-24","objectID":"/posts/03.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:3:1","tags":["原型模式"],"title":"设计模式之原型模式详解（Java实现）","uri":"/posts/03.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"3.2 原型管理器应用举例 题目描述 某公司需要创建一个公文管理器，公文管理器中需要提供一个集合对象来存储一些公文模板，用户可以通过复制这些模板快速的创建新的公文，试使用带有原型管理器的原型模式来设计该公文管理器并使用Java代码编程模拟。 UML类图 其中，OfficialDocument （抽象公文类）充当抽象原型类，其子类 FAR（Feasibility Analysis Report，可行性分析报告）和 SRS（Software Requirements Specification，软件需求规格说明书）充当具体原型类，PrototypeManager 充当原型管理器。 代码 代码地址 ","date":"2022-04-24","objectID":"/posts/03.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:3:2","tags":["原型模式"],"title":"设计模式之原型模式详解（Java实现）","uri":"/posts/03.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"1 单例模式介绍 单例模式（Singleton Pattern）确保一个类只有一个实例，并提供一个全局访问点来访问这个唯一实例。 例如Windows任务管理器，在正常情况下只能打开唯一一个任务管理器。 单例模式是一种对象创建型模式，其有三个要点：一是某个类只能有一个实例；二是它必须自行创建这个实例；三是它必须自行向整个系统提供这个实例。 主要解决： 一个全局使用的类频繁地创建与销毁。 何时使用： 当您想控制实例数目，节省系统资源的时候。 如何解决： 判断系统是否已经有这个单例，如果有则返回，如果没有则创建。 关键代码： 构造函数是私有的。 应用实例： 1、一个班级只有一个班主任。 2、Windows 是多进程多线程的，在操作一个文件的时候，就不可避免地出现多个进程或线程同时操作一个文件的现象，所以所有文件的处理必须通过唯一的实例来进行。 3、一些设备管理器常常设计为单例模式，比如一个电脑有两台打印机，在输出的时候就要处理不能两台打印机打印同一个文件。 优点： 1、在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如管理学院首页页面缓存）。 2、避免对资源的多重占用（比如写文件操作）。 缺点： 没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。 使用场景： 1、要求生产唯一序列号。 2、WEB 中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来。 3、创建的一个对象需要消耗的资源过多，比如 I/O 与数据库的连接等。 注意事项： getInstance() 方法中需要使用同步锁 synchronized (Singleton.class) 防止多线程同时进入造成 instance 被多次实例化。 ","date":"2022-04-24","objectID":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:1:0","tags":["单例模式"],"title":"设计模式之单例模式详解（Java实现）","uri":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2 单例模式详解 ","date":"2022-04-24","objectID":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:0","tags":["单例模式"],"title":"设计模式之单例模式详解（Java实现）","uri":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.1 单例模式结构 单例模式是结构最简单的设计模式，它只包含一个类，即单例类。单例模式的结构图如下。 由图可知，单例模式只包含一个单例角色，也就是Singleton。对于Singleton（单例），在单例类的内部创建它的唯一实例，并通过静态方法getInstance()让客户端可以使用它的唯一实例；为了防止在外部对单例类实例化，将其构造函数的可见性设为private；在单例类内部定义了一个Singleton类型的静态对象作为可供外部访问的唯一实例。 ","date":"2022-04-24","objectID":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:1","tags":["单例模式"],"title":"设计模式之单例模式详解（Java实现）","uri":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.2 单例模式实现 典型的单例模式的实现代码如下： public class Singleton { // 静态私有成员变量 private static Singleton instance = null; // 私有构造函数 private Singleton() { } // 静态公有工厂方法，返回唯一实例 public static Singleton getInstance() { if(instance == null) instance = new Singleton(); return instance; } } ","date":"2022-04-24","objectID":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:2","tags":["单例模式"],"title":"设计模式之单例模式详解（Java实现）","uri":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.3 单例模式应用举例 题目描述 某软件公司承接了一个服务器负载均衡(Load Balance)软件的开发工作，该软件运行在一台负载均衡服务器上，可以将并发访问和数据流量分发到服务器集群中的多台设备上进行并发处理，提高了系统的整体处理能力，缩短了响应时间。由于集群中的服务器需要动态删减，且客户端请求需要统一分发，因此需要确保负载均衡器的唯一性，只能有一个负载均衡器来负责服务器的管理和请求的分发，否则将会带来服务器状态的不一致以及请求分配冲突等问题。如何确保负载均衡器的唯一性是该软件成功的关键，试使用单例模式设计服务器负载均衡器。 UML类图 其中将负载均衡器LoadBalance设计为单例类，其中包含一个存储服务器信息的集合serverList，每次在serverList中随机选择一台服务器来响应客户端的请求。 代码 代码地址 ","date":"2022-04-24","objectID":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:3","tags":["单例模式"],"title":"设计模式之单例模式详解（Java实现）","uri":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"3 饿汉式单例与懒汉式单例 ","date":"2022-04-24","objectID":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:3:0","tags":["单例模式"],"title":"设计模式之单例模式详解（Java实现）","uri":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"3.1 饿汉式单例 饿汉式单例（Eager Singleton）是实现起来最简单的单例类，饿汉式单例类结构图如下。 有图中我们可以看出，由于在定义静态变量的时候实例化单例类，因此在类加载时单例对象就已创建，代码如下： public class EagerSingleton { private static final EagerSingleton instance = new EagerSingleton(); private EagerSingleton() { } public static EagerSingleton getInstance() { return instance; } } 当类被加载时，静态变量instance会被初始化，此时类的私有构造函数就会被调用，单例类的唯一实例将被创建。 ","date":"2022-04-24","objectID":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:3:1","tags":["单例模式"],"title":"设计模式之单例模式详解（Java实现）","uri":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"3.2 懒汉式单例与双重检查锁定 与饿汉式单例相同的是，懒汉式单例（Lazy Singleton）的构造函数也是私有的；与饿汉式单例类不同的是，懒汉式单例类在第一次被引用时将自己实例化，在懒汉式单例类被加载时不会将自己实例化。懒汉式单例类的结构图如下。 但如果多个线程同时访问将导致创建多个单例对象！这个时候为了避免多个线程同时调用getInstance()方法，可以使用关键字synchronized，代码如下： public class LazySingleton { private static LazySingleton instance = null; private LazySingleton() { } // 使用synchronized关键字对方法加锁，确保任意时刻只有一个线程可以执行该方法 synchronized public static LazySingleton getInstance() { if (instance == null) { instance = new LazySingleton(); } return instance; } } 在上述懒汉式单例类中，在getInstance()方法前面增加了关键字synchronized进行线程锁定，已处理多个线程同时访问问题。但我们每次调用getInstance()时都需要进行线程锁定判断，在多线程高并发环境中将会导致性能大大降低。因此可以继续对懒汉式单例进行改进，我们发现无需对getInstance()方法进行锁定，仅需锁定代码段instance = new LazySingleton()即可。故可进行如下改进： public static LazySingleton getInstance() { if (instance == null) { synchronized (LazySingleton.class) { instance = new LazySingleton(); } } return instance; } 问题看似解决，但如果使用上述代码，实际上还是会存在单例对象不唯一的情况。因为线程A和线程B如果同时进入判断，由于锁的原因，一个会先创建，但是另一个并不知道对象已经创建，这样就会导致产生多个实例对象。违背了单例模式的设计思想。我们需要使用双重检查锁定，即在锁内再进行一次instance == null的判断。使用双重检查锁定实现的懒汉式单例类的完整代码如下： public class LazySingleton { private volatile static LazySingleton instance = null; private LazySingleton() { } public static LazySingleton getInstance() { //第一重判断 if (instance == null) { //锁定代码块 synchronized (LazySingleton.class) { //第二重判断 if (instance == null) { instance = new LazySingleton(); //创建单例实例 } } } return instance; } } 需要注意的时，如果使用双重检查锁定来实现懒汉式单例类，需要在静态成员变量instance之前增加修饰符volatile，被volatile修饰的成员变量可以确保多个线程都能够正确处理。 ","date":"2022-04-24","objectID":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:3:2","tags":["单例模式"],"title":"设计模式之单例模式详解（Java实现）","uri":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"3.3 饿汉式单例类与懒汉式单例类的比较 饿汉式单例类：无须考虑多个线程同时访问的问题；调用速度和反应时间优于懒汉式单例；资源利用效率不及懒汉式单例；系统加载时间可能会比较长。 懒汉式单例类：实现了延迟加载；必须处理好多个线程同时访问的问题；需通过双重检查锁定等机制进行控制，将导致系统性能受到一定影响。 ","date":"2022-04-24","objectID":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:3:3","tags":["单例模式"],"title":"设计模式之单例模式详解（Java实现）","uri":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"4 使用静态内部类实现单例模式 饿汉式单例类不能实现延迟加载，不管将来用不用始终占用内存；懒汉式单例类安全控制烦琐，而且性能受影响。可见它们都存在一些问题，为了克服这些问题，在Java语言中可以通过Initialization on Demand Holder（IoDH）技术来实现单例模式。 在IoDH中，需要在单例类中增加一个静态内部类，在该内部类中创建单例对象，再将该单例对象通过getInstance()方法返回给外部使用，实现代码如下： //Initialization on Demand Holder public class Singleton { private Singleton() { } //静态内部类 private static class HolderClass { private final static Singleton instance = new Singleton(); } public static Singleton getInstance() { return HolderClass.instance; } public static void main(String args[]) { Singleton s1, s2; s1 = Singleton.getInstance(); s2 = Singleton.getInstance(); System.out.println(s1==s2); } } 通过使用IoDH既可以实现延迟加载，又可以保证线程安全，不影响系统性能，不失为一种最好的Java语言单例模式实现方式；其缺点是与编程语言本身的特性相关，很多面向对象语言并不支持IoDH。 ","date":"2022-04-24","objectID":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:4:0","tags":["单例模式"],"title":"设计模式之单例模式详解（Java实现）","uri":"/posts/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"1 工厂模式介绍 工厂顾名思义就是创建产品，根据产品是具体产品还是具体工厂可分为简单工厂模式（Simple Factory Pattern）和工厂方法模式（Factory Method Pattern），根据工厂的抽象程度可分为工厂方法模式和抽象工厂模式（Abstract Factory Pattern）。该模式用于封装和管理对象的创建，是一种创建型模式。 这样看我们工厂模式（Factory Pattern）可以分为三类，但其中简单工厂其实不是一个标准的的设计模式。GOF 23 种设计模式中只有「工厂方法模式」与「抽象工厂模式」。简单工厂模式可以看为工厂方法模式的一种特例。 在工厂模式中，我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指向新创建的对象。 它的优点如下： 可以使代码结构清晰，有效地封装变化。 对调用者屏蔽具体的产品类 降低耦合度。 适用场景：作为一种创建类模式，在任何需要生成复杂对象的地方，都可以使用工厂方法模式。有一点需要注意的地方就是复杂对象适合使用工厂模式，而简单对象，特别是只需要通过 new 就可以完成创建的对象，无需使用工厂模式。如果使用工厂模式，就需要引入一个工厂类，会增加系统的复杂度。 其次，工厂模式是一种典型的解耦模式，迪米特法则在工厂模式中表现的尤为明显。假如调用者自己组装产品需要增加依赖关系时，可以考虑使用工厂模式，将会大大降低对象之间的耦合度。再次，由于工厂模式是依靠抽象架构的，它把实例化产品的任务交由实现类完成，扩展性比较好。也就是说，当需要系统有比较好的扩展性时，可以考虑工厂模式，不同的产品用不同的实现工厂来组装。 ","date":"2022-04-21","objectID":"/posts/01.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:1:0","tags":["工厂模式"],"title":"设计模式之工厂模式详解（Java实现）","uri":"/posts/01.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2 工厂模式详解 ","date":"2022-04-21","objectID":"/posts/01.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:0","tags":["工厂模式"],"title":"设计模式之工厂模式详解（Java实现）","uri":"/posts/01.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.1 简单工厂模式 2.1.1 简单工厂模式结构 该模式对对象创建管理方式最为简单，因为其仅仅简单的对不同类对象的创建进行了一层薄薄的封装。该模式通过向工厂传递类型来指定要创建的对象，其UML类图如下： 其中根据上图可知，简单工厂模式包含以下3个角色。 Factory（工厂角色）：即工厂类，它是简单工厂模式的核心，负责实现创建所有产品实例的内部逻辑；其可以被外界直接调用，创建所需的产品对象。 AbstractProduct（抽象产品角色）：它是工厂类创建的所有对象的父类，封装了各种产品对象的共有方法。 Product1（具体产品角色）：它是简单工厂模式的创建目标，所有被创建的对象都充当这个角色的某个具体类的实例。 2.1.2 简单工厂模式实现 典型的抽象产品类代码如下： public abstract class AbstractProduct { // 所有产品类的公共业务方法 public void methodSame() { // 公有方法的实现 } // 声明抽象业务方法 public abstract void methodDiff() { } } 典型的具体产品类的代码如下： public class Product1 extends AbstractProduct { // 实现业务方法 public void methodDiff() { // 业务方法的实现 } } 典型的工厂类的代码如下： public class Factory { // 静态工厂方法 public static AbstractProduct createProduct(String arg) { AbstractProduct product = null; if (arg.equalsIgnoreCase(\"1\")) { product = new Product1(); } else if (arg.equalsIgnoreCase(\"2\")) { product = new Product2(); } return product; } } 客户端代码中，通过调用工厂类的工厂方法即可得到产品对象。 2.1.3 简单工厂模式应用举例 题目描述 使用简单工厂模式设计一个可以创建不同几何图形（Shape），如Circle，Rectangle，Triangle等绘图工具类，每个几何图形均具有绘制draw()和擦除erase()两个方法；要求在绘制不支持的几何图形时，抛出一个UnsuppShapeException异常，绘制类图并使用Java语言实现。 UML类图 其中，Shape接口充当抽象产品，其子类Circle、Rectangle、Triangle等充当具体产品，ShapeFactory充当工厂类。 代码 代码地址 ","date":"2022-04-21","objectID":"/posts/01.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:1","tags":["工厂模式"],"title":"设计模式之工厂模式详解（Java实现）","uri":"/posts/01.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.2 工厂方法模式 2.2.1 工厂方法模式结构 和简单工厂模式中工厂负责生产所有产品相比，工厂方法模式将生成具体产品的任务分发给具体的产品工厂，也就是定义一个抽象工厂，其定义了产品的生产接口，但不负责具体的产品，将生产任务交给不同的派生类工厂。这样不用通过指定类型来创建对象了。其UML类图如下： 由上图可知，工厂方法模式包含以下四个角色。 AbstractProduct（抽象产品）：它是定义产品的接口，是工厂方法模式所创建对象的公共父类。 Product1（具体产品）：它实现了抽象产品接口，某种类型的具体产品由专门的具体工厂创建，具体工厂和具体产品之间一一对应。 AbstractFactory（抽象工厂）：在抽象工厂类中声明了工厂方法，用于返回一个产品。抽象工厂是工厂方法模式的核心，所有创建对象的工厂类都必须实现该接口。 ConcreteFactory1（具体工厂）：它是抽象工厂类的子类，实现了在抽象工厂中声明的工厂方法，并可由客户端调用，返回一个具体产品类的实例。 2.2.2 工厂方法模式实现 典型的抽象产品类代码如下： public abstract class AbstractProduct { // 所有产品类的公共业务方法 public void methodSame() { // 公有方法的实现 } // 声明抽象业务方法 public abstract void methodDiff() { } } 典型的具体产品类的代码如下： public class Product1 extends AbstractProduct { // 实现业务方法 public void methodDiff() { // 业务方法的实现 } } 典型的抽象工厂代码如下： public interface AbstractFactory { public Product createProduct(); } 典型的具体工厂代码如下： public class ConcreteFactory1 implements Factory { public Product createProduct() { return new Product1(); } } 2.2.3 工厂方法模式应用举例 题目描述 现需要设计一个程序来读取多种不同类型的图片格式，针对每一种图片格式都设计一个图片读取器（ImgReader），如gif图片读取器（GifReader）用于读取gif格式的图片,jpg图片读取器（JpgReader）用于读取jpg格式的图片。图片读取器对象通过图片读取器工厂ImgReaderFactory来创建。ImgReaderFactory是一个抽象类，用于定义创建图片读取器的工厂方法，其GifReaderFactory和JpgReaderFactory用于创建具体的图片读取器对象。 UML类图 其中，接口ImageReaderFactory充当抽象工厂，GifReaderFactory和JpgReaderFactory充当具体工厂，ImageReader充当抽象产品，GifReader和JpgReader充当具体产品。 代码 代码地址 ","date":"2022-04-21","objectID":"/posts/01.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:2","tags":["工厂模式"],"title":"设计模式之工厂模式详解（Java实现）","uri":"/posts/01.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["设计模式"],"content":"2.3 抽象工厂模式 2.3.1 抽象工厂模式结构 上面两种模式不管工厂怎么拆分抽象，都只是针对一类产品（AbstractProduct），应该怎么表示呢？ 最简单的方式是把2中介绍的工厂方法模式完全复制一份，不过这次生产的是另一类产品。但同时也就意味着我们要完全复制和修改原来生产管理的所有代码，显然这是一个笨办法，并不利于扩展和维护。 抽象工厂模式通过在AbstarctFactory中增加创建产品的接口，并在具体子工厂中实现新加产品的创建，当然前提是子工厂支持生产该产品。否则继承的这个接口可以什么也不干。其UML图如下： 由上图可知，抽象工厂模式包含以下四个角色。 AbstractProduct（抽象产品）：它为每种产品声明接口，在抽象产品中声明了产品所具有的业务方法。 Product1（具体产品）：它定义具体工厂生产的具体产品的具体产品对象，实现抽象产品接口中声明的业务方法。 AbstractFactory（抽象工厂）：它声明了一组用于创建一族产品的方法，每一个方法对应一种产品。 ConcreteFactory1（具体工厂）：它实现了在抽象工厂中声明的创建产品的方法，生成一组具体产品，这些产品构成了一个产品族，每一个产品都位于某个产品等级结构中。 2.3.2 抽象工厂模式实现 抽象工厂类典型代码如下： public interface AbstractFactory { public AbstractProduct1 createProduct1(); // 工厂方法一 public AbstractProduct2 createProduct2(); // 工厂方法、二 } 具体工厂类典型代码如下： public class ConcreteFactory1 implements AbstractFactory { // 工厂方法一 public AbstractProduct1 createProduct1() { return new Product1(); } // 工厂方法二 public AbstractProduct2 createProduct2() { return new Product2(); } } 2.3.3 抽象工厂模式应用举例 题目描述 抽象工厂模式最早的应用是用于创建分属于不同操作系统的视窗构建。比如:命令按键(Button)与文字框(Text)都是视窗构件，在Unix、Windows和Linux操作系统的视窗环境中，这两个构件有不同的本地实现，它们的细节也有所不同。试使用抽象工厂模式来设计并模拟实现该结构。 UML类图 其中，接口AbstractFactory充当抽象工厂，其子类WindowsFactory、UnixFactory和LinuxFactory充当具体工厂；Text和Button充当抽象产品，其子类WindowsText、UnixText、LinuxText和WindowsButton、UnixButton、LinuxButton充当具体产品。 代码 代码地址 ","date":"2022-04-21","objectID":"/posts/01.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/:2:3","tags":["工厂模式"],"title":"设计模式之工厂模式详解（Java实现）","uri":"/posts/01.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3java%E5%AE%9E%E7%8E%B0/"},{"categories":["技术基础"],"content":"1 前言 我们知道，当程序运行起来，生成一个进程，该进程所属的主线程开始自动运行，C/C++的主线程就是main函数；当主线程从main()函数返回，则整个进程执行完毕。 所以主线程是从main()开始执行，其中我们自己创建的线程，也需要从一个函数开始运行（初始函数），一旦这个函数运行完毕，线程也结束运行。所以整个进程是否执行完毕的标志是：主线程是否执行完，如果主线程执行完毕了，就代表整个进程执行完毕了，此时如果其他子线程还没有执行完，也会被强行终止（符合大部分规律，也有例外）。 我们需要明白，如果有两个线程在跑，相当于整个程序中有两条线在同时走，即使一条被阻塞，另一条也能运行。 在C++11以前，使用线程库特别麻烦，C++11提供了一个新标准线程库，即thread，意味着C++语言本身增加对多线程的支持，意味着可移植性（跨平台），这大大减少开发人员的工作量。 ","date":"2022-04-07","objectID":"/posts/01.c-11%E5%A4%9A%E7%BA%BF%E7%A8%8B-stdthread%E8%AF%A6%E8%A7%A3/:1:0","tags":["多线程","C++"],"title":"C++11多线程 std::thread详解","uri":"/posts/01.c-11%E5%A4%9A%E7%BA%BF%E7%A8%8B-stdthread%E8%AF%A6%E8%A7%A3/"},{"categories":["技术基础"],"content":"2 std::thread ","date":"2022-04-07","objectID":"/posts/01.c-11%E5%A4%9A%E7%BA%BF%E7%A8%8B-stdthread%E8%AF%A6%E8%A7%A3/:2:0","tags":["多线程","C++"],"title":"C++11多线程 std::thread详解","uri":"/posts/01.c-11%E5%A4%9A%E7%BA%BF%E7%A8%8B-stdthread%E8%AF%A6%E8%A7%A3/"},{"categories":["技术基础"],"content":"2.1 构造函数 构造函数如下，其含义分别注释： thread() noexcept; // 创建不代表线程的新线程对象。 thread( thread\u0026\u0026 other ) noexcept; // 移动构造函数。构造表示曾为 other 所表示的执行线程的 thread 对象。此调用后 other 不再表示执行线程。一般需要使用move方法 template\u003c class Function, class... Args \u003e explicit thread( Function\u0026\u0026 f, Args\u0026\u0026... args ); // 构造新的 std::thread 对象并将它与执行线程关联。新的执行线程开始执行。其中f为可调用函数对象，args为传递的函数参数，一定要相互对应。 thread(const thread\u0026) = delete; // 复制构造函数被删除，线程不可复制。 创建线程对象总共有以下几种方法： #include \u003ciostream\u003e #include \u003cthread\u003e #include \u003cunistd.h\u003e // 提供sleep函数 void sum(int a, int b) { std::cout \u003c\u003c a + b \u003c\u003c std::endl; } int main() { std::thread t1(); // 不是线程，使用第一种构造方法 int a = 1, b = 2; std::thread t2(sum, a, b); // 是线程，按值传递，使用第三种构造方法 std::thread t3(sum, std::ref(a), std::ref(b)); // 是线程，按引用传递，使用第三种构造方法 std::thread t4(std::move(t2)); // t3现在是线程，运行sum，t2不再是线程。这是使用第二种构造方法。 t2.join(); t4.join(); return 0; } 官网上的给的代码如下（这种种类更多，适合用来分析学习，上面列举的内容实际上就够用了）： #include \u003ciostream\u003e #include \u003cutility\u003e #include \u003cthread\u003e #include \u003cchrono\u003e void f1(int n) { for (int i = 0; i \u003c 5; ++i) { std::cout \u003c\u003c \"Thread 1 executing\\n\"; ++n; std::this_thread::sleep_for(std::chrono::milliseconds(10)); } } void f2(int\u0026 n) { for (int i = 0; i \u003c 5; ++i) { std::cout \u003c\u003c \"Thread 2 executing\\n\"; ++n; std::this_thread::sleep_for(std::chrono::milliseconds(10)); } } class foo { public: void bar() { for (int i = 0; i \u003c 5; ++i) { std::cout \u003c\u003c \"Thread 3 executing\\n\"; ++n; std::this_thread::sleep_for(std::chrono::milliseconds(10)); } } int n = 0; }; class baz { public: void operator()() { for (int i = 0; i \u003c 5; ++i) { std::cout \u003c\u003c \"Thread 4 executing\\n\"; ++n; std::this_thread::sleep_for(std::chrono::milliseconds(10)); } } int n = 0; }; int main() { int n = 0; foo f; baz b; std::thread t1; // t1 is not a thread std::thread t2(f1, n + 1); // pass by value std::thread t3(f2, std::ref(n)); // pass by reference std::thread t4(std::move(t3)); // t4 is now running f2(). t3 is no longer a thread std::thread t5(\u0026foo::bar, \u0026f); // t5 runs foo::bar() on object f std::thread t6(b); // t6 runs baz::operator() on a copy of object b t2.join(); t4.join(); t5.join(); t6.join(); std::cout \u003c\u003c \"Final value of n is \" \u003c\u003c n \u003c\u003c '\\n'; std::cout \u003c\u003c \"Final value of f.n (foo::n) is \" \u003c\u003c f.n \u003c\u003c '\\n'; std::cout \u003c\u003c \"Final value of b.n (baz::n) is \" \u003c\u003c b.n \u003c\u003c '\\n'; } ","date":"2022-04-07","objectID":"/posts/01.c-11%E5%A4%9A%E7%BA%BF%E7%A8%8B-stdthread%E8%AF%A6%E8%A7%A3/:2:1","tags":["多线程","C++"],"title":"C++11多线程 std::thread详解","uri":"/posts/01.c-11%E5%A4%9A%E7%BA%BF%E7%A8%8B-stdthread%E8%AF%A6%E8%A7%A3/"},{"categories":["技术基础"],"content":"2.2 观察器 2.2.1 std:🧵:joinable bool joinable() const noexcept; 这个函数用来检查this是否标识了一个活动的执行线程，即如果this标识了一个活动的执行线程，就返回true，否则返回false。 #include \u003ciostream\u003e #include \u003cthread\u003e #include \u003cchrono\u003e void foo() { std::this_thread::sleep_for(std::chrono::seconds(1)); } int main() { std::thread t; std::cout \u003c\u003c \"before starting, joinable: \" \u003c\u003c std::boolalpha \u003c\u003c t.joinable() \u003c\u003c '\\n'; t = std::thread(foo); std::cout \u003c\u003c \"after starting, joinable: \" \u003c\u003c t.joinable() \u003c\u003c '\\n'; t.join(); std::cout \u003c\u003c \"after joining, joinable: \" \u003c\u003c t.joinable() \u003c\u003c '\\n'; } Output: before starting, joinable: false after starting, joinable: true after joining, joinable: false 2.2.2 std:🧵:get_id std::thread::id get_id() const noexcept; 返回标识与 *this 关联的线程的 std::thread::id 。如果没有关联线程，则返回默认构造的std::thread::id。 #include \u003ciostream\u003e #include \u003cthread\u003e #include \u003cchrono\u003e void foo() { std::this_thread::sleep_for(std::chrono::seconds(1)); } int main() { std::thread t1(foo); std::thread::id t1_id = t1.get_id(); std::thread t2(foo); std::thread::id t2_id = t2.get_id(); std::cout \u003c\u003c \"t1's id: \" \u003c\u003c t1_id \u003c\u003c '\\n'; std::cout \u003c\u003c \"t2's id: \" \u003c\u003c t2_id \u003c\u003c '\\n'; t1.join(); t2.join(); } Possible output: t1's id: 2 t2's id: 3 ","date":"2022-04-07","objectID":"/posts/01.c-11%E5%A4%9A%E7%BA%BF%E7%A8%8B-stdthread%E8%AF%A6%E8%A7%A3/:2:2","tags":["多线程","C++"],"title":"C++11多线程 std::thread详解","uri":"/posts/01.c-11%E5%A4%9A%E7%BA%BF%E7%A8%8B-stdthread%E8%AF%A6%E8%A7%A3/"},{"categories":["技术基础"],"content":"2.3 操作 2.3.1 std:🧵:join void join(); 阻塞当前线程直至 *this所标识的线程结束其执行。*this 所标识的线程的完成同步于对应的从 join() 成功返回。*this 自身上不进行同步。同时从多个线程在同一 thread 对象上调用 join() 构成数据竞争，导致未定义行为。 可能引发的异常为：std::system_error #include \u003ciostream\u003e #include \u003cthread\u003e #include \u003cchrono\u003e void foo() { // simulate expensive operation std::this_thread::sleep_for(std::chrono::seconds(1)); } void bar() { // simulate expensive operation std::this_thread::sleep_for(std::chrono::seconds(1)); } int main() { std::cout \u003c\u003c \"starting first helper...\\n\"; std::thread helper1(foo); std::cout \u003c\u003c \"starting second helper...\\n\"; std::thread helper2(bar); std::cout \u003c\u003c \"waiting for helpers to finish...\" \u003c\u003c std::endl; helper1.join(); helper2.join(); std::cout \u003c\u003c \"done!\\n\"; } Output: starting first helper... starting second helper... waiting for helpers to finish... done! 2.3.2 std:🧵:detach void detach(); 从 thread 对象分离执行线程，允许执行独立地持续。一旦该线程退出，则释放任何分配的资源。调用 detach 后 *this 不再占有任何线程。 可能引发的异常为：std::system_error #include \u003ciostream\u003e #include \u003cchrono\u003e #include \u003cthread\u003e void independentThread() { std::cout \u003c\u003c \"Starting concurrent thread.\\n\"; std::this_thread::sleep_for(std::chrono::seconds(2)); std::cout \u003c\u003c \"Exiting concurrent thread.\\n\"; } void threadCaller() { std::cout \u003c\u003c \"Starting thread caller.\\n\"; std::thread t(independentThread); t.detach(); std::this_thread::sleep_for(std::chrono::seconds(1)); std::cout \u003c\u003c \"Exiting thread caller.\\n\"; } int main() { threadCaller(); std::this_thread::sleep_for(std::chrono::seconds(5)); } Possible output: Starting thread caller. Starting concurrent thread. Exiting thread caller. Exiting concurrent thread. 这个示例即表明了主线程将先执行完。 ","date":"2022-04-07","objectID":"/posts/01.c-11%E5%A4%9A%E7%BA%BF%E7%A8%8B-stdthread%E8%AF%A6%E8%A7%A3/:2:3","tags":["多线程","C++"],"title":"C++11多线程 std::thread详解","uri":"/posts/01.c-11%E5%A4%9A%E7%BA%BF%E7%A8%8B-stdthread%E8%AF%A6%E8%A7%A3/"},{"categories":["云原生"],"content":"1 初识Docker ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:1:0","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"1.1 Docker开源项目 Docker是基于Go语言实现的云开源项目，诞生于2013年初，用于支持创建和使用 Linux容器。它的主要目标是“Build, Ship and Run Any App, Anywhere”，即通过对应用封装（Packaging）、分发（Deployment）、运行（Runtime）等生命管理，达到应用组件级别的 “一次封装、到处运行” 。这里的应用组件既可以是一个应用，也可以是一套数据库服务，甚至是一个操作系统或编译器。 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:1:1","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"1.2 Linux容器技术 Docker引擎的基础是Linux容器（Linux Containers，LXC）技术。容器则是有效地将由单个操作系统管理的资源划分到孤立的组中，以便更好地在孤立间平衡有冲突的资源使用需求，而LXC项目则是借助容器设计理念，并基于一系列新的内核特性实现了更具有扩展性的虚拟化容器方案。更关键的是，LXC被集成到了主流Linux内核中，进而成为Linux系统轻量级容器技术的事实标准。 那么在LXC的基础上，Docker进一步优化了容器的使用体验。Docker提供了各种容器管理工具（如分发、版本、移植等）让用户无需关注底层的操作，可以简单明了管理和使用容器。用户操作Docker容器就像操作一个轻量级的虚拟机那样简单。 我们可以将Docker容器理解为一种沙盒，每个容器运行一个应用，不同的容器相互隔离，容器之间也可以建立通信机制。容器的创建和停止都十分迅速，容器自身对资源的需求也十分有限，远远低于虚拟机。很多时候，甚至将容器比作是应用本身也没有问题。 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:1:2","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"1.3 为什么要使用Docker Docker容器虚拟化 举个简单的应用场景的例子，假设用户试图基于最常用的LAMP（Linux+Apache+MySQL+PHP）组合来运维一个网站。按照最传统的做法，首先需要安装Apache、Mysql和PHP以及它们各自运行所依赖的环境；之后分别对它们进行配置。经过大量操作后，然后还需要进行功能测试，看是否工作正常；如果不正常，则意味着更多的时间代价和不可控的风险。可以想象，如果再加上更多的应用，事情会变得更加难以处理。更为可怕的是，如果需要进行服务器迁移，如从腾讯云迁移到阿里云，往往需要重新部署和调试。而Docker提供了一种更为聪明的方式，通过容器来打包应用，意味着迁移只需要再服务器上启动需要的容器就可以了，节约大量的宝贵时间，并降低部署过程中出现问题的风险。 Docker在开发和运维的优势 Docker可以在任何环境、任意时间让应用正常运行。在开发和运维中有4大优势：更快速的交付和部署；更高效的资源利用；更轻松的迁移和扩展；更简单的更新管理。 Docker与虚拟机的比较 特性 容器 虚拟机 启动速度 秒级 分钟级 硬盘使用 一般为MB 一般为GB 性能 接近原生 弱于 系统支持量 单机支持上千个容器 一般为几十个 隔离性 安全隔离 完全隔离 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:1:3","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"1.4 Docker的核心概念 Docker有三大核心概念，如果我们理解了这三个核心概念，就能顺利理解Docker的整个生命周期。 镜像（Image） Docker镜像（Image）类似于虚拟机镜像，可以理解为一个面向Docker引擎的只读模板，包含了文件系统。例如一个镜像可以只包含一个完整的Ubuntu操作系统环境，可以把它称为一个Ubuntu镜像。镜像也可以安装了Apache应用程序，可以把它称为一个Apache镜像。 镜像是创建Docker容器的基础。通过版本管理和增量的文件系统，Docker提供了一套十分简单的机制来创建和更新现有的镜像，用户甚至可以从网上下载一个已经做好的应用镜像，并通过简单的命令就可以直接使用。 容器（Container） Docker容器（Container）类似于一个轻量级的沙箱，Docker利用容器来运行和隔离应用。容器是从镜像创建的应用运行实例，可以将其启动、开始、停止、删除，而这些容器都是相互隔离、互不可见的。我们实际是可以将容器看作是一个简易版的Linux系统环境（包括root用户权限、进程空间、用户空间和网络空间等），以及运行在其中的应用程序打包而成的应用盒子。 镜像自身是只读的。容器从镜像启动的时候，Docker会在镜像的最上层创建一个可写层，镜像本身将保持不变。如果认为虚拟机是模拟运行的一整套操作系统（提供了运行态环境和其他系统环境）和跑在上面的应用，那么Docker容器就是独立运行的一个或一组应用，以及它们的必需运行环境。 仓库（Repository） Docker仓库（Repository）类似于代码仓库，是Docker集中存放镜像文件的场所。而注册服务器（Registry）是存放仓库的地方，其上往往存放着多个仓库。每个仓库集中存放某一类镜像，往往包括多个镜像文件，通过不同的标签（tag）来进行区分。例如存放Ubuntu操作系统镜像的仓库，称为Ubuntu仓库，其中可能包括20.04等不同版本的镜像。根据所存储的镜像公开分享与否，Docker仓库可以分为公开仓库（Public）和私有仓库（Private）两种形式。目前，最大的公开仓库是Docker Hub，存放着数量庞大的镜像供用户下载，国内的公开仓库包括Docker Pool等，可提供稳定的国内访问。 当然，用户如果不希望公开分享自己的镜像文件，Docker也支持用户在本地网络内创建一个只能自己访问的私有仓库。当用户创建了自己的镜像之后就可以使用push命令将它上传到指定的公有或者私有仓库。这样用户下次在另外一台机器上使用该镜像时，只需将其从仓库上pull下来就可以了。 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:1:4","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"1.5 Docker安装（Linux） 安装教程 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:1:5","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"2 镜像具体操作 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:2:0","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"2.1 获取镜像 镜像是Docker运行容器的前提。使用docker pull命令即可从镜像仓库上下载指定镜像到本地。命令格式如下： docker pull [options] NAME[:TAG] options参数说明： -a：拉取所有tagged镜像 例如从Docker Hub的Ubuntu仓库下载一个最新版的Ubuntu操作系统的镜像 docker pull ubuntu:20.04 # 指定版本号，目前最新为20.04 docker pull ubuntu #该命令实际上下载的就是ubuntu:latest镜像。 上面这两条命令实际上相当于docker pull registry.hub.docker.com/ubuntu:latest命令，即从默认的注册服务器registry.hub.docker.com中的ubuntu仓库来下载标记为latest的镜像。 我们也可以选择其他注册服务器的仓库下载。那么这个时候我们需要在仓库前指定完整的仓库注册服务器地址。例如从Docker Pool社区的镜像源d1.dockerpool.com下载最新的ubuntu镜像。 docker pull d1.dockerpool.com:5000/ubuntu ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:2:1","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"2.2 查看镜像信息 使用docker images命令可以列出本地主机上的所有镜像。命令格式如下： docker images [options] [repository:[tag]] options参数说明： -a :列出本地所有的镜像（含中间映像层，默认情况下，过滤掉中间映像层）； -f :显示满足条件的镜像； -q :只显示镜像ID。 如果没有给出仓库名，那么默认列出本地主机上已有的镜像。我们使用docker images可以查看到如下信息： 可以看到几个字段信息： repository：来自于哪个仓库，比如ubuntu仓库。 tag：镜像的标签信息，比如20.04或latest。用于标记来自同一个仓库的不同镜像。 image id：镜像的ID号，这个特别重要，唯一标识镜像。 created：镜像创建时间。 size：镜像大小。 我们从图中可以发现，20.04和latest标签的镜像ID是完全一致的，说明它们实际上指向了同一个镜像文件，只是别名不同而已。标签在这里起到了引用或者快捷方式的作用。 我们使用docker inpsect NAME|ID即可查看该镜像的详细信息，为json格式。 我们还可以使用docker history命令查看指定镜像的创建历史，命令格式如下： docker history [options] IMAGE options说明： -q :仅列出提交记录ID。 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:2:2","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"2.3 搜寻镜像 使用docker search命令可以搜索云端仓库中共享的镜像，默认搜寻Docker Hub官方仓库的镜像。命令格式如下： docker search [options] TERM options说明： –automated :只列出 automated build类型的镜像； –no-trunc :显示完整的镜像描述； -f \u003c过滤条件\u003e:例如列出收藏数不小于指定值的镜像。 例如搜寻带mysql关键字的镜像如下： ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:2:3","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"2.4 删除镜像 使用docker rmi命令可以删除镜像，命令格式如下： docker rmi IMAGE [IMAGE...] 其中IMAGE可以为镜像标签或者镜像ID，这ID可以为能进行区分的部分前缀串。 需要注意的是，当有该镜像创建的容器存在时，镜像文件时默认无法删除的，若想要强行删除文件则需要加入-f参数来强制删除一个存在容器依赖的镜像，但这样往往会造成一些遗留问题。正确的做法应该是先删除依赖该镜像的所有容器，再来删除镜像。 若要删除所有镜像，可用docker images -q列出所有的ID，正确命令为：docker rmi $(docker images -q)。 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:2:4","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"2.5 创建镜像 创建镜像的方法有三种：基于已有镜像的容器创建、基于本地模板导入、基于Dockerfile创建。 2.5.1 基于已有镜像的容器创建 使用docker commit命令即可从容器创建一个镜像，命令格式如下： docker commit [options] CONTAINER [REPOSITORY[:TAG]] options说明： -a :提交的镜像作者； -c :使用Dockerfile指令来创建镜像； -m :提交时的说明文字； -p :在commit时，将容器暂停。 CONTAINER为容器ID。 顺利的话，命令会返回新创建的镜像的ID信息。 实例如下： docker commit -a \"pursuit\" -m \"my ubuntu\" 3c61e963210c myubuntu:v1 2.5.2 基于本地模板导入 可以从一个操作系统模板文件导入一个镜像，也可以从网上下载一个模板。一般使用OpenVZ提供的模板来创建。OpenVZ下载地址。 首先下载一个，命令如下： wget https://download.openvz.org/template/precreated/contrib/arch-20161108-x86_64.tar.gz 然后将导入该镜像： cat arch-20161108-x86_64.tar.gz | docker import - arch:x86_64 查看新导入的镜像，已经本地存在了： 2.5.3 基于Dockerfile创建 其中Dockerfile是一个文本格式的配置文件，用户可以使用 Dockerfile 快速创建自定义的镜像。 Dockerfile由一行行命令语句组成，并且支持以#开头的注释。Dockerfile分为四部分：基础镜像信息、维护者信息、镜像操作指令和容器启动时执行指令。例如下面的文件模板： # This dockerfile user the ubuntu image # VERSION 2 - EDITON 1 # Author: docker_user # Command format: Instruction [arguments / command] .. # 第一行必须指定基于的基础镜像 FROM ubuntu # 维护者信息 # 例如MAINTAINER docker_user docker_user@email.com MAINTAINER pursuit unique.hzf@gmail.com # 镜像的操作指令 # RUN \u003ccommand\u003e，当命令较长，可以用\\来换行。 RUN echo \"Hello, World!\" # 容器启动时执行指令 CMD /bin/bash 创建好Dockerfile后，我们利用docker build命令，命令格式如下： docker build -t PATH|URL repository:tag 如，我们利用Dockerfile生成镜像 sudo docker build . -t arch:x86_64_01 查看本地镜像如下： ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:2:5","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"2.6 存出和载入镜像 我们可以使用docker save和docker load命令来存出和载入镜像。 存出即将镜像保存成tar归档文件，载入即将使用docker save命令导出的tar归档文件载入称为镜像文件。 命令格式如下： docker save -o filename IMAGE 或者 docker save IMAGE\u003efilename docker load --input filename 或者 docker load \u003cfilename 实例： docker save -o files/ubuntu_20_04.tar ubuntu:20.04 然后我们需要删除ubuntu:20.04镜像，再导入。 docker rmi ubuntu:20.04 docker load \u003cubuntu_20_04.tar ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:2:6","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"2.7 修改镜像 使用docker tag命令可以标记本地镜像，将其归入某一仓库。命令格式如下： docker tag [OPTIONS] IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG] 实例： docker tag ubuntu:20.04 myubuntu/ubuntu:20.04 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:2:7","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"2.8 上传镜像 使用docker push命令将本地的镜像上传到镜像仓库，默认上传到DockerHub官方仓库。要先登陆到镜像仓库。命令格式如下： docker push NAME[:TAG] 例如用户user上传自己的本地镜像ubuntu:20.04，需要注意的是我们需要添加新的标签user/ubuntu:20.04（其中user一定要和我们的dockerhub中用户名同名，否则会报错）然后再上传。 之后，我们即可在DockerHub官网看到自己的仓库和上传的镜像了。 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:2:8","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"3 容器具体操作 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:3:0","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"3.1 查看容器 使用docker ps命令即可列出容器，命令格式如下： docker ps [OPTIONS] 其中options说明： -a :显示所有的容器，包括未运行的。 -f :根据条件过滤显示的内容。 -q :静默模式，只显示容器编号。 我们运行docker ps -a可以得到如图： 其中输出字段说明如下： CONTAINER ID: 容器 ID。 IMAGE: 使用的镜像。 COMMAND: 启动容器时运行的命令。 CREATED: 容器的创建时间。 STATUS: 容器状态。 PORTS: 容器的端口信息和使用的连接类型（tcp\\udp）。 NAMES: 自动分配的容器名称。 我们也可以使用docker inspect命令列出容器的元信息，输出格式为json格式，这个命令在查看镜像章节已经说明了，用法相同，这里不再叙述。 使用docker stats可以查看所有容器的统计信息，包括CPU、内存、存储、网络等信息。 使用docker top CONTAINER可查看某个容器内的所有进程。 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:3:1","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"3.2 创建容器 Docker的容器十分轻量级，用户可以随时创建或删除容器。 新建容器 可以使用docker create命令新建一个容器，例如： docker create -it ubuntu:20.04 即利用镜像ubuntu:20.04创建容器。 新建并启动一个容器 使用docker run命令创建并启动容器。其命令格式如下： docker run [OPTIONS] IMAGE [COMMAND] [ARG...] 其中options说明： 1.--name：为容器指定一个名称； 2.-t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用； 3.-d: 后台运行容器，并返回容器ID。 4.-i: 以交互模式运行容器，通常与 -t 同时使用。 当使用docker创建并启动容器时，Docker在后台运行的标准操作如下： 1.检查本地是否有指定的镜像，不存在就从公有仓库下载; 2.利用镜像创建并启动一个容器； 3.分配一个文件系统，并在只读的镜像层外面挂载一层可读写层； 4.从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去； 5.从地址池配置一个IP地址给容器； 6.执行用户指定的应用程序； 7.执行完毕后容器被终止。 下面这个实例将启动一个bash终端，允许用户进行交互，可以使用Linux命令。 docker run -it ubuntu:20.04 /bin/bash 其中root为用户名，@后面的为容器ID。我们用ps命令查看进程发现只运行了bash应用，并没有运行其他不需要的进程。可以使用Ctrl+d或输入exit命令来退出容器。当退出容器之后，该容器就自动处于终止状态了。 这是因为对于Docker容器来说，当运行的应用（此例子中为bash）退出后，容器也就没有再运行的必要了。 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:3:2","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"3.3 启动终止容器 启动容器 使用docker start可以启动一个已存在的容器。命令格式如下： docker start CONTAINER 终止容器 使用docker stop可以启动一个已存在的容器。命令格式如下： docker stop CONTAINER 重启容器 使用docker restart可以启动一个已存在的容器。命令格式如下： docker restart CONTAINER ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:3:3","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"3.4 获取容器的日志 使用docker logs即可获取容器的日志。命令格式如下： docker logs [OPTIONS] CONTAINER 其中OPTIONS说明： -f : 跟踪日志输出 –since :显示某个开始时间的所有日志 -t : 显示时间戳 –tail :仅列出最新N条容器日志 实例： ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:3:4","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"3.5 进入容器 在使用-d参数后，容器启动后会自动进入后台，用户无法看到容器中的信息。我们如果需要进入容器进行操作，有多种方法，这里介绍两种。 使用docker attach 命令格式为：docker attach CONTAINER 在容器中，我们可以先按Ctrl-p，再按Ctrl-q可以挂起容器。 但是使用attach命令有时候并不方便。当多个窗口同时attach到同一个容器的时候，所有窗口都会同步显示。当某个窗口因命令阻塞后，其他窗口也无法执行操作了。 使用docker exec命令 Docker自1.3版本起，提供了一个更方便的工具exec，该命令可以在运行的容器中执行命令，命令格式如下： docker exec [OPTIONS] CONTAINER COMMAND [ARG...] 其中OPTIONS说明： 1.-d :分离模式: 在后台运行 2.-i :即使没有附加也保持STDIN 打开 3.-t :分配一个伪终端 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:3:5","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"3.6 删除容器 可以使用docker rm命令来删除处于终止状态的容器，命令格式如下： docker rm [OPTIONS] CONTAINER [CONTAINER...] 其中OPTIONS说明： -f :通过 SIGKILL 信号强制删除一个运行中的容器。 -l:移除容器间的网络连接，而非容器本身。即删除容器的连接，但保留容器。 -v :删除与容器关联的卷。 如果需要删除所有容器，可使用docker rm $(docker ps -aq)。 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:3:6","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"3.7 在本地和容器之间复制文件 使用docker cp命令用于主机和容器之间的数据拷贝，命令格式如下： docker cp xxx CONTAINER:xxx docker cp CONTAINER:xxx xxx 实例： docker cp data.txt 3c61e963210c:data.txt ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:3:7","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"3.8 修改容器 使用docker rename可以重命名容器，命令格式如下： docker rename CONTAINER1 CONTAINER2 使用docker update可以修改容器配置，命令格式如下： docker update CONTAINER [options] 其中OPTIONS参数过多，使用的时候可以自行百度，例如我们修改容器的内存限制： docker update 3c61e963210 --memory 500MB ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:3:8","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"3.9 导入和导出容器 3.9.1 导出容器 导出容器是指导出一个已经创建的容器到一个文件，不管此时这个容器是否处于运行状态，可以使用docker export命令导出容器。该命令格式如下： docker export [options] xxx.tar CONTAINER 或者 docker export [options] CONTAINER\u003exxx.tar 其中options说明： -o :将输入内容写到文件。 例如将id为3c61e963210的容器按日期保存为tar文件： 可以将这些文件传输到其他的机器上，在其他机器上通过导入命令实现容器的迁移。 3.9.2 导入容器 导出的文件又可以使用docker import命令导入，成为镜像，命令格式如下： docker import [OPTIONS] xxx.tar image_name:tag 其中OPTIONS说明： -c :应用docker 指令创建镜像； -m :提交时的说明文字。 实例： docker import ubuntu-20220212.tar myubunt:latest 我们知道，前面我们学习过docker load命令来导入一个镜像文件。实际上，既可以使用docker load命令来导入镜像存储文件到本地的镜像库，也可以使用docker import命令来导入一个容器快照到本地镜像库。 这两者的区别在于容器快照文件将丢弃所有的历史记录和元信息（仅保存容器当时的快照状态)，，而镜像存储文件将保存完整记录，体积也要大。 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:3:9","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"4 仓库 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:4:0","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"4.1 Docker Hub 4.1.1 Linux登录登出DockerHub 首先在dockerhub官网注册一个账号，然后使用docker login即可登录。登出则直接输入docker logout即可。 实例： 4.1.2 基本操作 用户无需登录即可通过docker search命令来查找官网仓库的镜像，并利用docker pull命令来将它下载到本地。 根据是否为官方提供， 可将这些镜像资源分为两类。一种类似ubuntu这样的基础镜像，称为基础或根镜像。这些镜像是由Docker公司创建、验证、支持、提供的。这样的镜像往往使用单个单词作为名字。还有一种类型，比如pursuit/ubuntu镜像，它是由DockerHub用户pursuit创建并维护的，带有用户名称为前缀，表明是某用户的某仓库。可通过用户名称前缀user_name/ 来指定使用某个用户提供的镜像，比如pursuit用户的镜像前缀为pursuit/。 4.1.3 自动创建 自动创建（Automated Builds）功能对于需要经常升级镜像内程序来说十分方便。有时候，用户创建了镜像，安装了某个软件，如果软件发布新版本则需要手动更新镜像。 而自动创建功能使得用户通过DockerHub指定追踪一个目标网站（目前支持Github或BitBucket）上的项目，一但发现项目新的提交，则自动执行创建。 要配置自动创建，有如下步骤： 1）创建并登录Docker Hub，以及目标网站； * 在目标网站中连接账户到Docker Hub。 2）在Docker Hub中配置一个自动创建。 3）选取一个目标网站中的项目（需要含Dockerfile）和分支。 4）指定Dockerfile的位置，并提交创建。 之后，就可以在DockerHub的”自动创建“页面跟踪每次创建的状态。 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:4:1","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"5 网络基础配置 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:5:0","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["云原生"],"content":"5.1 端口映射实现访问容器 大量的互联网应用服务包括多个服务组件，这往往需要多个容器之间通过网络通信进行相互配合。Docker目前提供了映射容器端口到宿主主机和容器互联机制来为容器提供互联网服务。 在启动容器时，如果不指定对应参数，在容器外部是无法通过网络来访问容器内的网络应用和服务的。当容器中运行一些应用，要让外部访问这些应用时，可以通过-p参数来指定端口映射，并且，在一个指定的端口上只可以绑定一个容器。支持的格式有ip:hostPort:containerPort、ip::containerPort、hostPort:containerPort。 映射所有接口地址 使用hostPort:containerPort格式将本地的4000端口映射到容器的4000端口，可以执行如下命令： docker run -itd -p 4000:4000 --name my_docker_ubuntu ubuntu:20.04 我们可以看到，已经实现了端口映射。多次使用-p标记可以绑定多个端口。例如： docker run -itd -p 4000:4000 -p 3000:3000 --name my_docker_ubuntu ubuntu:20.04 映射到指定地址的指定端口 可以使用ip:hostPort:containerPort格式指定映射使用一个特定地址，比如localhost地址127.0.0.1： docker run -itd -p 127.0.0.1:3000:3000 --name my_docker_ubuntu ubuntu:20.04 映射到指定地址的任意端口 使用ip::containerPort绑定localhost的任意端口到容器的5000端口，本地主机会自动分配一个端口： docker run -itd -p 127.0.0.1::5000 --name my_docker_ubuntu ubuntu:20.04 查看映射端口配置 可以使用docker port container命令来查看当前映射的端口配置，也可以查看到绑定的地址。 ","date":"2022-02-13","objectID":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/:5:1","tags":["Docker"],"title":"Docker入门教程","uri":"/posts/01.docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"1 Linux常用命令 ","date":"2022-02-05","objectID":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/:1:0","tags":["Linux"],"title":"Linux常用命令、管道、环境变量","uri":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"1.1 系统状况 top：查看所有进程的信息（Linux的任务管理器）。 打开后输入M：按使用内存排序； 打开后输入P：按使用CPU排序； 打开后输入q：退出。 df -h：查看硬盘使用情况。 free -h：查看内存使用情况。 du -sh：查看当前目录占用的硬盘空间。 ps aux：查看所有进程。 kill -9 pid：杀死编号为pid的进程。 kill -s SIGTERM pid：传递某个具体的信号。 netstat -nt：查看所有网络连接。 w：列出当前登录的用户。 ping www.baidu.com：测试网络连接，检查是否联网。 ","date":"2022-02-05","objectID":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/:1:1","tags":["Linux"],"title":"Linux常用命令、管道、环境变量","uri":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"1.2 文件权限 chmod：修改文件权限 chmod +x filename：给filename添加可执行权限； chmod -x filename：去掉filename的可执行权限； chmod abc filename:其中a，b，c各为一个数字，表示User、Group以及Other的权限。r=4，w=2，x=1，为读，写，可执行。 如设置所有人对该文件都可读可写可执行，则设置chmod 777 filename。 ","date":"2022-02-05","objectID":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/:1:2","tags":["Linux"],"title":"Linux常用命令、管道、环境变量","uri":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"1.3 文件检索 find \u003cpath\u003e(文件路径) -name '*.py'：搜索path路径下的所有py文件。 grep xxx：从stdin中读入若干行数据，如果某行中包含xxx，则输出该行，否则忽略该行。 wc：统计行数、单词数、字节数。 既可以从stdin中直接读取内容，也可以在命令行参数中传入文件名列表。 wc -l：统计行数。 wc -w：统计单词数。 wc -c：统计字节数。 tree：展示当前目录的文件结构。 tree path：展示某个目录的文件结构。 tree -a：显示隐藏文件。 ag xxx：搜索当前目录下的所有文件，检索xxx字符串。 cut：分割一行内容。 从stdin中读入多行数据。 echo $PATH | cut -d ':' -f 3, 5：输出PATH用:分割后的第3、5列数据。 echo $PATH | cut -d ':' -f 3-5：输出PATH用:分割后的第3-5列数据。 echo $PATH | cut -c 3, 5：输出PATH的第3、5个字符。 echo $PATH | cut -c 3-5：输出PATH的第3-5个字符。 sort：将每行内容按字典序排序。 可以从stdin中读取多行数据。 可以从命令行参数中读取文件名列表。 xargs：将stdin中的数据用空格或回车分割成命令行参数，作为其他命令使用。 find . -name '*.py' | xargs cat | wc -l：统计当前目录下所有python文件的总行数。 ","date":"2022-02-05","objectID":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/:1:3","tags":["Linux"],"title":"Linux常用命令、管道、环境变量","uri":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"1.4 查看文件内容 more：浏览文件内容。 回车或空格：下一行。 b：上一页。 q：退出。 less：和more类似，功能更全。 回车：下一行。 y：上一行。 Page Down：下一页。 Page Up：上一页。 q：退出。 head -3 xxx：显示xxx的前3行内容。 同时支持从stdin读入内容。 tail -3 xxx：显示xxx末尾3行内容。 同时支持从stdin读入内容。 ","date":"2022-02-05","objectID":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/:1:4","tags":["Linux"],"title":"Linux常用命令、管道、环境变量","uri":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"1.5 用户相关 history：展示当前用户的历史操作。内容存放在~/bash_history中。 ","date":"2022-02-05","objectID":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/:1:5","tags":["Linux"],"title":"Linux常用命令、管道、环境变量","uri":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"1.6 工具 md5Sum：计算md5的哈希值。 也可以从stdin中读入内容，也可以在命令行参数中传入文件名列表。 time command：统计command命令的执行时间。 ipython3：交互式python环境。可以当作计算器，或者批量管理文件。 i command：!表示执行shell脚本命令。 watch -n 0.1 command：每隔0.1s就执行一次command命令。 tar：压缩文件。 tar -zcvf xxx.tar.gz /path：压缩。 tar -zxvf xxx.tar.gz ：解压缩。 diff xxx yyy：查看文件xxx和yyy的不同点。 ","date":"2022-02-05","objectID":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/:1:6","tags":["Linux"],"title":"Linux常用命令、管道、环境变量","uri":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"1.7 安装软件 sudo command：以root身份运行command命令。 apt-get install xxx：安装xxx软件。 pip install xxx --user --upgrade：安装python包。 ","date":"2022-02-05","objectID":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/:1:7","tags":["Linux"],"title":"Linux常用命令、管道、环境变量","uri":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"2 管道 ","date":"2022-02-05","objectID":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/:2:0","tags":["Linux"],"title":"Linux常用命令、管道、环境变量","uri":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"2.1 管道命令 管道命令操作符是|，,它只能处理经由前面一个指令传出的正确输出信息，对错误信息信息没有直接处理能力。然后传递给下一个命令，作为标准的输入。 下图为管道命令的输出说明： 【指令1】正确输出，作为【指令2】的输入，然后【指令2】的输出作为【指令3】的输入 ，【指令3】输出就会直接显示在屏幕上面了。 通过管道之后，我们发现【指令1】和【指令2】的正确输出不显示在屏幕上面，只显示指令3的输出。 其类似于之前学习的文件重定向，可以将前面一个命令的stdout重定向下一个命令的stdin。但与文件重定向有很大区别：文件重定向左边为命令，右边为文件；管道左右两边均为命令，左边有stdout，右边有stdin。 值得注意的点： 管道命令仅能处理stdout，忽略stderr。 管道右边的命令必须能接受stdin。 多个管道命令可以串联。 ","date":"2022-02-05","objectID":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/:2:1","tags":["Linux"],"title":"Linux常用命令、管道、环境变量","uri":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"2.2 实例 统计当前目录下所有python文件的总行数 统计总行数，在前面常用命令学习中，我们已经会了：wc -l，统计当前目录所有的python文件，也易得为：find . -name '*.py'。那么我们需要解决的问题则是将所有python文件选出来得到其内容再统计。我们则可能会这样：find . -name '*.py' | cat | wc -l。但find . -name '*.py'得到的是字符串，我们还需要利用xargs将字符串分割作为命令行参数，这样即可达到效果。 即：find . -name '*.py' | xargs cat | wc -l。 ","date":"2022-02-05","objectID":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/:2:2","tags":["Linux"],"title":"Linux常用命令、管道、环境变量","uri":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"3 环境变量 ","date":"2022-02-05","objectID":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/:3:0","tags":["Linux"],"title":"Linux常用命令、管道、环境变量","uri":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"3.1 概念 Linux系统中会用很多环境变量来记录配置信息。环境变量类似于全局变量，可以被各个进程访问到。我们可以通过修改环境变量来方便地修改系统配置。 ","date":"2022-02-05","objectID":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/:3:1","tags":["Linux"],"title":"Linux常用命令、管道、环境变量","uri":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"3.2 查看环境变量 列出当前环境下的所有环境变量： env # 显示当前用户的变量； set # 显示当前shell的变量，包含当前用户的变量； export # 显示当前导出成用户变量的shell变量。 输出某个环境变量的值：echo $PATH ","date":"2022-02-05","objectID":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/:3:2","tags":["Linux"],"title":"Linux常用命令、管道、环境变量","uri":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"3.3 修改环境变量 修改环境变量我们可以先将修改命令放到~/.bashrc文件中。修改完之后需执行source ~/.bashrc，来将修改应用到当前的bash环境下。 为何将修改命令放到~/.bashrc，就可以确保修改会影响未来所有的环境呢？ 每次启动bash，都会先执行~/.bashrc。 每次ssh登录远程服务器，都会启动一个bash命令行给我们。 每次tmux新开一个pane，都会启动一个bash命令行给我们。 未来所有的新开环境都会加载我们修改的内容。 ","date":"2022-02-05","objectID":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/:3:3","tags":["Linux"],"title":"Linux常用命令、管道、环境变量","uri":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"categories":["系统架构"],"content":"3.4 常见环境变量 HOME：用户的家目录 PATH：可执行文件（命令）的存储路径。路径与路径之间用:分隔。当某个可执行文件同时出现多个路径中时，会选择从左到右数第一个路径中的执行。下列所有存储路径的环境变量，均采用从左到右的优先顺序。 LD_LIBRARY_PATH：用于指定动态链接库(.so文件)的路径，其内容是以冒号分隔的路径列表。 C_INCLUDE_PATH：C语言的头文件路径，内容是以冒号分隔的路径列表。 CPLUS_INCLUDE_PATH：CPP的头文件路径，内容是以冒号分隔的路径列表。 PYTHONPATH：Python导入包的路径，内容是以冒号分隔的路径列表。 JAVA_HOME：jdk的安装目录。 CLASSPATH：存放Java导入类的路径，内容是以冒号分隔的路径列表。 ","date":"2022-02-05","objectID":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/:3:4","tags":["Linux"],"title":"Linux常用命令、管道、环境变量","uri":"/posts/01.linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AE%A1%E9%81%93%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"categories":["工具"],"content":"1 git简介 ","date":"2022-01-26","objectID":"/posts/02.git%E6%95%99%E7%A8%8B/:1:0","tags":["Git"],"title":"Git教程","uri":"/posts/02.git%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1.1 什么是版本控制 版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。 除了项目源代码，你可以对任何类型的文件进行版本控制。 有了它你就可以将某个文件回溯到之前的状态，甚至将整个项目都回退到过去某个时间点的状态，你可以比较文件的变化细节，查出最后是谁修改了哪个地方，从而找出导致怪异问题出现的原因，又是谁在何时报告了某个功能缺陷等等。 而版本控制系统（VCS）则是一种软件，可以帮助软件团队的开发人员协同工作，并存档他们工作的完整历史记录。 目前版本控制系统有如下三种： 本地版本控制系统：即通过用文件目录形式保存每个项目版本，其中目录名会备注一些版本信息、修改时间等。其最大的好处就是简单，但特别容易犯错，不利于管理，容易覆盖重要的文件，而且不适合协同工作。 集中式版本控制系统（Centralized Version Control Systems，CVCS）：集中化的版本控制系统都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。这么做虽然解决了本地版本控制系统无法让在不同系统上的开发者协同工作的诟病，但也还是存在下面的问题：如果中央服务器宕机，则其他人无法使用；必须联网才能工作。 分布式版本控制系统（Distributed Version Control Systems，DVCS）：在这类系统中，像 Git、Mercurial、Bazaar 以及 Darcs 等，客户端并不只提取最新版本的文件快照， 而是把代码仓库完整地镜像下来，包括完整的历史记录。 这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。 因为每一次的克隆操作，实际上都是一次对代码仓库的完整备份。 分布式版本控制系统可以不用联网就可以工作，因为每个人的电脑上都是完整的版本库，当你修改了某个文件后，你只需要将自己的修改推送给别人就可以了。但是，在实际使用分布式版本控制系统的时候，很少会直接进行推送修改，而是使用一台充当“中央服务器”的东西。这个服务器的作用仅仅是用来方便“交换”大家的修改，没有它大家也一样干活，只是交换修改不方便而已。 分布式版本控制系统的优势不单是不必联网这么简单，后面我们还会看到 Git 极其强大的分支管理等功能。 ","date":"2022-01-26","objectID":"/posts/02.git%E6%95%99%E7%A8%8B/:1:1","tags":["Git"],"title":"Git教程","uri":"/posts/02.git%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1.2 什么是git Git是一款免费、开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。其是 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。Git 与常用的版本控制工具 CVS, Subversion 等不同，它采用了分布式版本库的方式，不必服务器端软件支持。 官网地址为：https://git-scm.com/，在上面有权威的git介绍以及git下载地址。 SVN是集中式版本控制系统，而Git是分布式版本控制系统，Git与SVN的区别可参考Git与SVN的区别。 git有以下优点： 适合分布式开发，强调个体；公共服务器压力和数据量都不会太大； 速度快、灵活； 任意两个开发者之间可以很容易的解决冲突； 离线工作。 ","date":"2022-01-26","objectID":"/posts/02.git%E6%95%99%E7%A8%8B/:1:2","tags":["Git"],"title":"Git教程","uri":"/posts/02.git%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1.3 git的几个核心概念 工作区（workspace）：仓库的目录。工作区是独立于各个分支的。在当前仓库中，新增，更改，删除文件这些动作，都发生在工作区里面。 暂存区（index/stage）：数据暂时存放的区域，类似于工作区写入版本库前的缓存区。暂存区是独立于各个分支的。一般存放在 .git 目录下的 index 文件（.git/index）中，所以我们把暂存区有时也叫作索引（index）。 版本库（Repository）：也可以叫仓库区，实际上就是我们的本地仓库。就是安全存放数据的位置，这里面有你提交到所有版本的数据。其中HEAD指向最新放入仓库的版本 版本结构：树结构，树中每个节点代表一个代码版本。 远程仓库（Remote Repository）： 托管代码的服务器，可以简单的认为是你项目组中的一台电脑用于远程数据交换。目前流行的远程仓库有：Github、Gitee。 ","date":"2022-01-26","objectID":"/posts/02.git%E6%95%99%E7%A8%8B/:1:3","tags":["Git"],"title":"Git教程","uri":"/posts/02.git%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1.4 git工作流程 一般工作流程如下： 从远程仓库中克隆 Git 资源作为本地仓库； 从本地仓库中checkout代码然后进行代码修改； 在提交本地仓库前先将代码提交到暂存区； 提交修改，提交到本地仓库；本地仓库中保存修改的各个历史版本； 在需要和团队成员共享代码时，可以将修改代码push到远程仓库。 ","date":"2022-01-26","objectID":"/posts/02.git%E6%95%99%E7%A8%8B/:1:4","tags":["Git"],"title":"Git教程","uri":"/posts/02.git%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"2 git安装配置 ","date":"2022-01-26","objectID":"/posts/02.git%E6%95%99%E7%A8%8B/:2:0","tags":["Git"],"title":"Git教程","uri":"/posts/02.git%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"2.1 windows平台安装 主要学linux，这里列出其他blog的windows平台安装教程：安装教程 ","date":"2022-01-26","objectID":"/posts/02.git%E6%95%99%E7%A8%8B/:2:1","tags":["Git"],"title":"Git教程","uri":"/posts/02.git%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"2.2 Linux平台安装 首先，我们可以尝试着输入git，看看系统有没有安装Git： $ git The program 'git' is currently not installed. You can install it by typing: sudo apt-get install git 如果出现这个，则说明Git还没有安装，如果我们使用得是Debian或者Ubuntu Linux，通过命令：sudo apt-get install git就可以直接完成Git的安装，非常简单。 ","date":"2022-01-26","objectID":"/posts/02.git%E6%95%99%E7%A8%8B/:2:2","tags":["Git"],"title":"Git教程","uri":"/posts/02.git%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"2.3 Mac平台安装 主要学linux，这里列出其他blog的Mac平台安装配置教程：安装配置教程 ","date":"2022-01-26","objectID":"/posts/02.git%E6%95%99%E7%A8%8B/:2:3","tags":["Git"],"title":"Git教程","uri":"/posts/02.git%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"2.4 配置 安装好git之后，就需要对git进行配置操作了，需要配置自己的用户名和Email。配置的命令如下： $ git config --global user.name \"用户名\" $ git config --global user.email \"邮箱\" 如果你需要检查你的配置信息，可以使用git config --list命令来列出所有配置信息： ","date":"2022-01-26","objectID":"/posts/02.git%E6%95%99%E7%A8%8B/:2:4","tags":["Git"],"title":"Git教程","uri":"/posts/02.git%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"3 git基本命令 ","date":"2022-01-26","objectID":"/posts/02.git%E6%95%99%E7%A8%8B/:3:0","tags":["Git"],"title":"Git教程","uri":"/posts/02.git%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"3.1 建立本地仓库 (1). 创建一个目录，并将其初始化为本地仓库 git init 本地仓库名 (2). 使用当前目录作为本地仓库 git init (3). 将远程仓库克隆下来作为本地仓库 此命令支持多种协议，但我一般是通过SSH协议，其内部实现是通过SSH，所以进行这步操作之前我们需要确保在远程仓库添加了SSH公钥，如果没有添加需要在本地主机通过ssh-keygen，然后会生成ssh公钥和密钥，我们将公钥添加到远程仓库即可。 git clone git@服务器名:仓库路径 该格式和scp命令一致，@前面表示用户名，这个一般都是git，后面表示服务器名，可以是IP地址，也可以是域名，例如github.com，:后面表示仓库路径。不过不需要担心，这个远程仓库会给出。 ","date":"2022-01-26","objectID":"/posts/02.git%E6%95%99%E7%A8%8B/:3:1","tags":["Git"],"title":"Git教程","uri":"/posts/02.git%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"3.2 提交、修改和删除 (1). 将文件提交到暂存区 # 将指定文件添加到暂存区 git add file1 file2 ... fileN # 将指定目录添加到暂存区 git add dir1 dir2 ... dirN # 添加当前目录下的所有文件到暂存区 git add . (2). 将文件从暂存区中撤出，但不会撤销文件的更改 git restore --staged (3). 将不在暂存区的文件撤销更改，需要和(2)作区分，两者作用完全不一样。 git restore file 或 git checkout -- file (4). 比较暂存区和工作区文件之间的差异 # 显示暂存区和工作区之间的差异 git diff [file] # 显示暂存区和上一次提交的差异 git diff --cached [file] 或 git diff --staged [file] # 显示两次提交的差异 该file可以省略，如果省略，则是比较暂存区中的所有文件。注意，如果暂存区没有内容，则是比较HEAD指针指向的版本库内容。 (5). 查看仓库状态 git status 该命令用于查看在你上次提交之后是否有对文件进行再次修改，如果我们需要获取简短的输出结果，可添加-s参数来实现。 (6). 提交暂存区内容到本地仓库 暂存区的内容可以通过git commit来提交到本地仓库。 git commit [file1] [file2]...[fileN] -m [备注信息] 其中file1等是可以直接省略的，如果意味着提交所有信息，而-m是参数，后面接备注信息。当然，在进行git commit之前，我们需要通过git add命令将修改添加到暂存区。 (7). 回退版本 我们可以通过git reset命令来回退版本，可以指定退回某一次提交的版本。具体如下： # 将代码库回退到上一个版本 git reset --hard HEAD^ 或 git reset --hard HEAD~ # 向上回滚两次，一次类推 git reset --hard HEAD^^ # 向上回滚n次。 git rest --hard HEAD~n # 回滚到某一特定版本，用版本号实现，版本号唯一标识一个版本 git reset --hard 版本号 (8). 删除文件 在Git中，删除文件也是一种修改操作，删除文件有三种形式： 利用rm file 实现删除，此形式只是会删除工作区的文件，并没有删除版本库的文件，如果还需要删除版本库的文件还需要执行下列命令，这样就可以实现工作区和版本库的文件： git add file # 加入暂存区 git commit -m \"delete file\" 利用git rm file实现删除，会删除工作区的文件，并且将此次删除加入暂存区。但需要注意要删除的文件是没有修改过的，如果需要删除修改过的，需要加入-f，当然，这个时候我们也还没有删除版本库的文件，只是我们只需要执行git commit -m \"delete file\"就可以。 利用git rm --cached file实现删除，只会删除暂存区的文件，但会保留工作区的文件，并且会将这次删除放入暂存区，然后我们执行git commit -m \"delete file\"就可以实现删除暂存区和版本库的文件。 (9). 移动或者重命名文件 git mv [file] [newFile]可以用来移动或者重命名一个文件、目录或者软连接。如果新文件名已经存在，还需要添加-f参数。 ","date":"2022-01-26","objectID":"/posts/02.git%E6%95%99%E7%A8%8B/:3:2","tags":["Git"],"title":"Git教程","uri":"/posts/02.git%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"3.3 查看日志 (1). 查看当前分支的所有版本 git log，我们可以用这个命令历史提交记录，当然这个命令还有许多参数供我们使用： --oneline：查看历史记录的简洁版本。 --graph：查看历史中什么时候出现了分支、合并。开启拓扑图选项。 --reverse：逆向显示所有日志。 --author=user：指定查看user提交的部分。 --since、--before、--after等：指定日期。 (2). 查看HEAD指针的移动历史（包括被回滚的版本） git reflog ","date":"2022-01-26","objectID":"/posts/02.git%E6%95%99%E7%A8%8B/:3:3","tags":["Git"],"title":"Git教程","uri":"/posts/02.git%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"3.4 分支管理 几乎每一种版本控制系统都以某种形式支持分支。使用分支意味着你可以从开发主线上分离开来，然后在不影响主线的同时继续工作。 有人把 Git 的分支模型称为必杀技特性，而正是因为它，将 Git 从版本控制系统家族里区分出来。 (1). 创建分支 git branch (branchName) (2). 切换分支 git checkout (branchName) 当你切换分支的时候，Git 会用该分支的最后提交的快照替换你的工作目录的内容， 所以多个分支不需要多个目录。 添加-b参数可以创建并切换分支。 (3). 合并分支 git merge (branchName) 将branch_name合并到当前分支上。 (4) 删除分支 git branch -d (branchName) 删除本地仓库的branchName分支。 (5). 列出分支 git branch 没有参数时，git branch会列出你在本地的分支。 (6). 合并冲突 合并并不仅仅是简单的文件添加、移除的操作。Git也会合并修改，当两个分支对同一个文件都进行了修改，那么就会产生合并冲突，我们需要去手动修改它。然后需要使用git add命令来告诉Git冲突已经解决了。 ","date":"2022-01-26","objectID":"/posts/02.git%E6%95%99%E7%A8%8B/:3:4","tags":["Git"],"title":"Git教程","uri":"/posts/02.git%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"3.5 远程操作 (1). 将本地仓库关联到远程仓库 git remote add [short-name] [url] 其中short-name指定一个方便使用的简写，为远程仓库的别名。例如git remote add origin git@git.acwing.com:unique_pursuit/test.git 即可添加远程仓库。 (2). 查看当前配置有哪些远程库 git remote 执行时添加上-v参数可查看到每个别名的实际链接地址。 (3). 删除远程仓库 git remote rm name 其中name为仓库的别名。 (4). 修改仓库名 git remote rename old_name new_name (5). 查看主机的详细信息 git remote show \u003c主机名\u003e (6) 设置本地分支与远程仓库分支对应 git push --set-upstream \u003c远程主机名\u003e \u003cbranchName\u003e 设置本地的branchName分支对应远程仓库的branchName分支，远程主机名为git clone设置的仓库别名。 git branch --set-upstream-to=origin/branchName1 branchName2 将远程仓库的branchName1分支与本地的branchName2分支对应。 (7). 将本地当前分支推送到远程主机 git push \u003c远程主机名\u003e \u003c本地分支名\u003e:\u003c远程分支名\u003e 如果本地分支名和远程分支名相同，则可以直接使用下面的命令。 git push \u003c远程主机名\u003e \u003cbranchName\u003e 将本地的branchName分支推到远程仓库，在此之前需要先设置与远程仓库对应分支。 如果当前分支与多个主机存在追踪关系，需要使用-u参数指定一个默认主机，这样后面可以不加任何参数使用git push 。 (8). 删除远程仓库的branchName分支 git push -d \u003c远程主机名\u003e branchName (9). 将远程仓库的分支与本地仓库的分支合并 git pull \u003c远程主机名\u003e \u003c远程分支名\u003e:\u003c本地分支名\u003e 如果本地分支名和远程分支名相同，则可以使用下面的命令。 git push \u003c远程分支名\u003e \u003cbranchName\u003e ","date":"2022-01-26","objectID":"/posts/02.git%E6%95%99%E7%A8%8B/:3:5","tags":["Git"],"title":"Git教程","uri":"/posts/02.git%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"3.6 保存和恢复进度 我们有时会遇到这样的情况，正在dev分支开发新功能，做到一半时有人过来反馈一个bug，让马上解决，但是新功能做到了一半你又不想提交，又想保存它，这个时候就可以使用git stash命令先把进度保存起来。 (1). 保存当前工作进度 git stash 将工作区和暂存区尚未提交的修改存入栈中。再运行git status可以发现是一个干净的工作区，没有任何改动。使用git stash save 'message'可以添加一些注释 (2). 恢复工作进度 恢复最新的进度到工作区。git会默认把工作区和暂存区的改动都恢复到工作区。 git stash pop 恢复最新的进度到工作区和暂存区。 git stash pop --index 恢复指定的进度到工作区。 git stash pop stash_id 其中stash_id是通过git stash list获取的。 通过git stash pop恢复进度后，会删除当前进度。 还有一个git stash apply命令除了不删除进度，其他和git stash pop一样。 (3). 显示保存进度的列表 git stash list (4) 删除进度 删除所有进度 git stash clear 删除一个存储的进度，如果不指定stash_id，则默认删除最新的进度。 git stash drop [stash_id] ","date":"2022-01-26","objectID":"/posts/02.git%E6%95%99%E7%A8%8B/:3:6","tags":["Git"],"title":"Git教程","uri":"/posts/02.git%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"4 Git用法思维导图 ","date":"2022-01-26","objectID":"/posts/02.git%E6%95%99%E7%A8%8B/:4:0","tags":["Git"],"title":"Git教程","uri":"/posts/02.git%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1 SSH基本知识 ","date":"2022-01-23","objectID":"/posts/02.ssh%E6%95%99%E7%A8%8B/:1:0","tags":["SSH"],"title":"SSH教程","uri":"/posts/02.ssh%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1.1 SSH是什么 SSH为Secure Shell的缩写，是一种网络协议，用于加密两台计算机之间的通信，保证不被窃听或篡改，并且支持各种身份验证机制。在事务中，它主要用户保证远程登录贺远程通信的安全，任何网络服务都可以用这个协议来加密。 ","date":"2022-01-23","objectID":"/posts/02.ssh%E6%95%99%E7%A8%8B/:1:1","tags":["SSH"],"title":"SSH教程","uri":"/posts/02.ssh%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1.2 SSH架构 SSH的软件架构是C/S模式，即客户端-服务器模式。在这个架构中，SSH软件分成了两个部分：向服务器发出请求的部分，称为客户端，OpenSSH的实现为ssh；接受客户端发出的请求的部分，称为服务器，OpenSSH的实现为sshd。 其中大写的SSH表示协议，小写的ssh表示客户端软件。 OpenSSH的客户端是二进制程序ssh。它在Linux/Unix系统的位置是/usr/local/bin/ssh，windows系统的位置是/Program Files/OpenSSH/bin/ssh.exe。Linux系统一般都自带ssh，如果没有则需要自己安装。安装命令如下： # Ubuntu 和 Debian sudo apt install openssh-client # CentOS 和 Fedora sudo dnf install openssh-clients ","date":"2022-01-23","objectID":"/posts/02.ssh%E6%95%99%E7%A8%8B/:1:2","tags":["SSH"],"title":"SSH教程","uri":"/posts/02.ssh%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"2 ssh登录 ","date":"2022-01-23","objectID":"/posts/02.ssh%E6%95%99%E7%A8%8B/:2:0","tags":["SSH"],"title":"SSH教程","uri":"/posts/02.ssh%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"2.1 基本用法 远程登录服务器有以下几种方式： ssh hostname # 没有指定用户名，将使用客户端的当前用户名 ssh user@hostname # 指定用户名 ssh user@hostname -p 22 # 登录端口为22，使用-p可以登录到某一特定的端口。 其中user为用户名，hostname为IP地址或域名 第一次登录时会提示： The authenticity of host '123.57.47.211 (123.57.47.211)' can't be established. ECDSA key fingerprint is SHA256:iy237yysfCe013/l+kpDGfEG9xxHxm0dnxnAbJTPpG8. Are you sure you want to continue connecting (yes/no/[fingerprint])? 上述这段文字告诉用户，这台服务器的指纹是陌生的，让用户选择是否要继续连接（输入yes或no）。 所谓“服务器指纹”，指的是 SSH 服务器公钥的哈希值。每台 SSH 服务器都有唯一一对密钥，用于跟客户端通信，其中公钥的哈希值就可以用来识别服务器。 输入yes，然后回车即可。这样会将服务器的信息记录在~/.ssh//known_hosts文件中，然后输入密码即可登录到远程服务器。 在~/.ssh/known_hosts文件中保存了本机连接过的所有服务器的公钥指纹信息，每次通过ssh连接一台服务器，系统会通过该文件判断当前需要连接的服务器是否为陌生主机。而如果之前ssh登陆过的服务器的密钥发生了更改，那么登录就会收到提示Host key verification failed，由于发生改变了，所以西我们需要删除之前的主机的指纹信息，添加新的。这个可以使用ssh-keygen -R \u003chostname\u003e来进行删除。 如果我们需要退出登录，输入logout或exit都可以实现，也可以使用快捷键Ctrl+d退出。 ","date":"2022-01-23","objectID":"/posts/02.ssh%E6%95%99%E7%A8%8B/:2:1","tags":["SSH"],"title":"SSH教程","uri":"/posts/02.ssh%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"2.2 配置文件 创建文件~/.ssh/config，此为用户的个人配置文件，其保存相关配置信息。我们可以在文件中输入： Host myServer1 HostName IP地址或域名 User 用户名 Host myServer2 HostName IP地址或域名 User 用户名 之后再使用服务器时，就可以直接使用别名myServer1、myServer2进行登录。 SSH客户端的全局配置文件为/etc/ssh/ssh_config，其优先级低于用户个人配置文件。除了配置文件，~/.ssh还有一些用户个人的密钥文件和其他文件 ","date":"2022-01-23","objectID":"/posts/02.ssh%E6%95%99%E7%A8%8B/:2:2","tags":["SSH"],"title":"SSH教程","uri":"/posts/02.ssh%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"2.3 密钥登录 创建密钥 首先在本台主机上创建密钥，输入ssh-keygen指令，然后一直回车即可。该命令会为本机生成公私钥对，通过密钥来进行远程登录的验证机制使用了密码学中的非对称加密体系。执行命令后，会在~/.ssh/文件夹下生成两个新的文件： 1. `id_rsa`：私钥 2. `id_rsa.pub`：公钥 注意，一定要保护好生成的私钥`id_rsa`，一旦暴露，利用上述指令可以重新生成新的密钥。 免密登录 如果想要免密登录某个服务器，我们只需要将刚才生成的公钥保存在需要登录的远程服务器~/.ssh/authorized_keys文件中。例如我想免密登录到myServer1服务器，则将~/.ssh/id_rsa.pub公钥中的内容，复制到myServer1中的~/.ssh/authorized_keys文件中。也可以使用如下命令一键添加公钥： ssh-copy-id myServer1。 第一次应用ssh-copy-id系统会提示输入远程服务器的密码，之后登录时就可以免密登录了。 一般来说，应用密钥登录比使用密码登录更加安全，所以启用密钥登录之后，最好关闭服务器的密码登录。如果需要在远程服务器上关闭密码登录。具体方法是先远程登录到服务器中，然后找到sshd的配置文件/etc/ssh/sshd_config，最后将PasswordAuthentication这一项设置为no。 PasswordAuthentication no sshd是服务器运行的后台进程，当我们修改配置文件以后，需要重新启动sshd，然后修改才能生效。可应用下面语句重启远程服务器上的ssh和sshd服务。 sudo systemctl restart ssh.service sudo systemctl restart sshd.service 执行远程命令 免密登录后，我们可以在命令行下直接执行远程命令：ssh user@hostname command。这样的命令会使SSH在登录成功后，立刻在远程主机上执行命令comand。但并不是真正的登录，执行完命令后还在原主机。 测试：ssh myServer1 ls ","date":"2022-01-23","objectID":"/posts/02.ssh%E6%95%99%E7%A8%8B/:2:3","tags":["SSH"],"title":"SSH教程","uri":"/posts/02.ssh%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"3 scp传文件 ","date":"2022-01-23","objectID":"/posts/02.ssh%E6%95%99%E7%A8%8B/:3:0","tags":["SSH"],"title":"SSH教程","uri":"/posts/02.ssh%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"3.1 scp命令简介 scp是secure copy的缩写，相当于cp命令+SSH。它的底层是SSH协议，默认端口是22，相当于先使用ssh命令登录远程主机，然后再进行拷贝操作。 scp主要用于以下三种复制操作： 本地复制到远程。 远程复制到本地。 两个远程系统之间的复制。 使用scp传输数据时，文件和密码都是加密的，不会泄露敏感信息。 ","date":"2022-01-23","objectID":"/posts/02.ssh%E6%95%99%E7%A8%8B/:3:1","tags":["SSH"],"title":"SSH教程","uri":"/posts/02.ssh%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"3.2 基本语法 scp的语法类似cp的语法。 scp source destination 上面命令中，source是文件当前的位置，destination是文件所要复制到的位置。它们都可以包含用户名和主机名。例如： scp myServer1:main.cpp main.cpp 上面命令即是将远程主机（myServer1）用户主目录下的main.cpp复制为本机当前目录下的main.cpp。注意主机与文件之间要使用:分隔。 scp会先用SSH登录到远程主机，然后在加密连接之中复制文件。客户端发起连接后，会提示用户输入密码。其中用户名和主机名若省略则是代表当前主机下的当前用户名。 scp支持一次复制多个文件。scp source1 source2 destination。如果存在同名文件，scp会在没有警告的情况下覆盖同名文件。 ","date":"2022-01-23","objectID":"/posts/02.ssh%E6%95%99%E7%A8%8B/:3:2","tags":["SSH"],"title":"SSH教程","uri":"/posts/02.ssh%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"4 参考文献 Linux基础课 菜鸟教程 ","date":"2022-01-23","objectID":"/posts/02.ssh%E6%95%99%E7%A8%8B/:4:0","tags":["SSH"],"title":"SSH教程","uri":"/posts/02.ssh%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"1 Shell概论 Shell是一个用C语言编写的程序，它诞生于Unix，是我们通过命令行与Unix/Linux交互的工具。笼统地说：Shell既是一种命令语言，又是一种程序设计语言。 而Shell脚本是一种为Shell编写的脚本程序，有的时候也被称为Shell（但二者是两个完全不同的概念！），它可以直接在命令行中执行，也可以将一套逻辑组织成一个文件，方便复用。 Acwing网站提供给的AC Terminal中的命令行就可以看成是一个“Shell脚本在逐行执行”。 Unix/Linux系统中常见的shell脚本有很多： Bourne Shell（/usr/bin/sh或/bin/sh） Bourne Again Shell（/bin/bash） C Shell（/usr/bin/csh） K Shell（/usr/bin/ksh） Shell for Root（/sbin/sh） 由于Linux系统中一般默认使用bash，而且其易用免费，所以我们接下来学习bash中的语法。 脚本示例 进入终端，新建一个hello.sh文件，内容如下： #! /bin/bash echo \"Hello, World!\" 说明： sh后缀则表示该文件是Shell脚本文件。 #!告诉系统这个脚本用什么解释器来执行，后面所跟的就是你所需要用的解释器。这个一般都需要添加上，具体解释见运行。 echo指令用于字符串的输出，所以运行该文件会输出Hello,World。 运行方式： 作为可执行文件 该方法将hello.sh作为可执行程序运行，由于未指定解释器，所以使用该方法第一行一定要指定解释器。 #! /bin/bash chmod +x hello.sh #使脚本具有可执行权限； ./hello.sh #当前路径下执行 用解释器执行 该方法直接运行解释器，此时hello.sh作为Shell解释器的参数。此时Shell脚本就不需要指定解释器信息，则不需要第一行的注释了。 bash hello.sh #当然也可以用缩写 sh hello.sh 输出： ","date":"2022-01-22","objectID":"/posts/06.shell%E6%95%99%E7%A8%8B/:1:0","tags":["Shell"],"title":"Shell 教程","uri":"/posts/06.shell%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2 Shell语法 ","date":"2022-01-22","objectID":"/posts/06.shell%E6%95%99%E7%A8%8B/:2:0","tags":["Shell"],"title":"Shell 教程","uri":"/posts/06.shell%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.1 注释 单行注释 每一行中#之后的内容均是注释。 # 这是一行注释 echo \"Hello, World\" # 这也是一行注释 多行注释 Shell中的多行注释有点特别，格式为： :\u003c\u003cEOF 第一行注释 ... 第n行注释 EOF 其中EOF可以替换成其他任意字符串，如： :\u003c\u003c! 第一行注释 ... 第n行注释 ! ","date":"2022-01-22","objectID":"/posts/06.shell%E6%95%99%E7%A8%8B/:2:1","tags":["Shell"],"title":"Shell 教程","uri":"/posts/06.shell%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.2 变量 定义变量 定义变量时，变量名不加美元符号$，同时特别需要注意的一点就是变量名与等号之间不能有空格（如果有自动打空格的习惯在这里最好克制）。shell中的变量命名同样须遵循如下规则： 命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。 中间不能有空格，可以使用下划线 _。 不能使用标点符号。 不能使用bash里的关键字（可用help命令查看保留关键字）。 如下： # 有效的Shell变量名称 _var var123 LF_DDFHI_X # 无效的Shell变量名称 ?var 123abc echo 和现在大多数的语言一样，Shell定义变量不需要指定变量类型，如下： name1=\"a\" #单引号定义字符串 name2='a' #双引号定义字符串 name3=a #也可以不加引号，同样表示字符串 在Bash shell中，每一个变量的值都是字符串，无论你给变量赋值用的时单引号双引号还是没有使用引号，都是使用字符串的i形式存储的，这很特殊。串的i形式存储的，这很特殊。串的i形式存储的，这很特殊。串的i形式存储的，这很特殊。 使用变量 使用变量我们需要加上$符号或者${}符号。花括号时可选的，主要是为了帮助解释器识别变量边界。 一定要注意：只有使用变量的时候才加美元符号$变量的时候才加美元符号$变量的时候才加美元符号$ name=hzf echo $name echo ${name} echo ${name}123 只读变量 我们可以使用readOnly或者declare将变量设置为只读。 name=hzf readOnly name #declare -r name #两种写法均可。 name=ylf #此时会报错，因为已经设置成了只读变量。 删除变量 unset可以删除变量。 name=hzf unset name echo $name 此时没有输出hzf，代表已经删除了，这里没有报错是因为Shell将没有定义的变量设置为空字符串。 变量类型 根据访问权限划分可以分为： 自定义变量（局部变量） 在脚本或命令中定义，仅在当前Shell示例中有效，其他Shell启动的程序不能访问局部变量。即为子进程不能访问的变量。 环境变量（全局变量） 所有程序，包括shell启动程序，都能访问环境变量，有些程序需要环境变量来保证其正常运行。即为子进程可以访问的变量。 自定义变量转换为环境变量： name=hzf#定义自定义变量 export name delcare -x name#两种方法均可 环境变量转化为自定义变量 export name=hzf#定义环境变量。 delcare +x name#改为自定义变量。 Shell字符串 字符串可以用单引号，也可以用双引号，也可以不用引号。但其中是有区别的： 使用单引号字符串，其中的变量名不会输出，但可以输出转义字符。单引号字串中不能出现单独一个的单引号（对单引号使用转义符后也不行），但可成对出现，作为字符串拼接使用。 不用引号的字符串，其中变量可以输出，但是不能输出转移字符。 使用双引号的字符串，既可以输出变量也可以输出转义字符。 示例： name=hzf echo 123$name\\n echo \"123$name\\n\" echo '123$name\\n' 输出： 字符串操作 拼接字符串 name=xyz #双引号字符串拼接 s1=\"Hello, $ {name} !” s2=\"Hello, \"$ {name}\"!\" echo $s1 $s2 获取字符串长度 name=hzf echo ${#name} 提取字符串 注意，第一个字符的索引为$0$，给出的两个参数第一个为起始位置，第二个为截取长度。 name=\"Hello, World!\" echo ${name} echo ${name:0:4} echo ${name:0} echo ${name:1} 文件参数变量 在执行Shell脚本时，可以向脚本传递参数。$1是第一个参数，$2是第二个参数，以此类推。特殊的，$0是文件名（包含路径）。例如： echo \"文件名:$0\" echo \"第一个参数:$1\" echo \"第二个参数:$2\" echo \"$*\" echo \"$@\" 然后我们执行的时候在后面添加参数即可。如果没有给出，那么则为空字符。 其他参数相关变量 参数 说明 $#` | ��表文件传入的参数个数，如上例中值为2 | $*` | ��所有参数构成的用空格隔开的字符串，如上例中值为\"$1 $2\" | $@` | ��个参数分别用双引号括起来的字符串，如上例中值为\"$1\" \"$2\" | $$` | ��本当前运行的进程ID | $?` | ��一条命令的退出状态（注意不是stdout，而是exit code）。0表示正常退出，其他值表示错误 | $(command)` | ��回command这条命令的stdout（可嵌套） | command` | ��回command这条命令的stdout（不可嵌套） | ","date":"2022-01-22","objectID":"/posts/06.shell%E6%95%99%E7%A8%8B/:2:2","tags":["Shell"],"title":"Shell 教程","uri":"/posts/06.shell%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.3 数组 数组中可以存放多个值。Bash Shell 只支持一维数组（不支持多维数组），初始化时不需要定义数组大小（与 PHP 类似）。与大部分编程语言类似，数组元素的下标由 0 开始。 定义 Shell 数组用括号来表示，元素用\"空格\"符号分割开，语法格式如下： array_name=(value1 value2 ... valuen) 如： name=(张三 \"李四\" '王五') 也可以直接通过定义数组中元素的值来创建数组，如： name[0]=\"张三\" 这样就创建了name数组。 访问数组元素 访问单个元素 语法格式为：${array_name[index]} 如： name[0]=\"123\" name[3]=\"124\" echo \"${name[0]}\" echo \"${name[3]}\" 访问所有元素 格式： ${array[@]}#第一种写法 ${array[*]}#第二种写法 示例： array=(1 abc \"def\" yxc) echo ${array[@]} # 第一种写法 echo ${array[*]} # 第二种写法 获取数组长度 同字符串写法： array=(1 abc \"def\" yxc) echo ${#array[@]} #第一种写法 echo ${#array[*]} #第二种写法 ","date":"2022-01-22","objectID":"/posts/06.shell%E6%95%99%E7%A8%8B/:2:3","tags":["Shell"],"title":"Shell 教程","uri":"/posts/06.shell%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.4 expr命令与基本运算符 Shell 和其他编程语言一样，支持多种运算符，包括： 算数运算符 关系运算符 布尔运算符 字符串运算符 文件测试运算符 但是原生Bash不支持简单的数学运算，我们需要通过其他命令来实现，如awk,expr，expr命令最常用，所以这里介绍expr。 expr是一款表达式计算工具，使用它能完成表达式的求值操作。格式为： expr 表达式 表达式说明 用空格隔开每一项 用反斜杠放在shell特定的字符前面（发现表达式运行错误时，可以试试转义） 对包含空格和其他特殊字符的字符串要用引号括起来 expr会在stdout中输出结果。如果为逻辑关系表达式，则结果为真，stdout为1，否则为0。 expr的exit code：如果为逻辑关系表达式，则结果为真，exit code为0，否则为1。 完整的表达式要被 ` ` 包含，注意这个字符不是常用的单引号，而是反引号，代表执行该命令。通常在 Esc 键下边。 算数表达式 下表列出了常用的算术运算符，假定变量 a 为 10，变量 b 为 20： 运算符 说明 举例 | ��法 | expr $a + $b` 结果为 30。 | | ��法 | expr $a - $b` 结果为 -10。 | | ��法 | expr $a * $b` 结果为 200。 | | ��法 | expr $b / $a` 结果为 2。 | | ��余 | expr $b % $a` 结果为 0。 | | ��值 | a=$b` 将把变量 b 的值赋给 a。 | font color=“red”\u003e | ��等。用于比较两个数字，相同则返回 true。 | [ $a $b ]` 返回 false。 | = | ��相等。用于比较两个数字，不相同则返回 true。 | [ $a != $b ]` 返回 true。 | **注意：**条件表达式要放在方括号之间，并且要有空格，例如: [$a\u003cfont color=\"red\"\u003e$b] 是错误的，必须写成 [ $a \u003c/font\u003e $b ]。注意乘号等特殊符号需要转义。()可表优先级，但同样需要反斜杠转移。 实例： a=10 b=20 echo \"a + b = `expr $a + $b`\" echo \"a - b = `expr $a - $b`\" echo \"a * b = `expr $a \\* $b`\" echo \"a / b = `expr $a / $b`\" echo \"a % b = `expr $a % $b`\" echo \"a \u003cfont color=\"red\"\u003e b = `expr [$a \u003c/font\u003e $b]`\" echo \"a != b = `expr [$a != $b]`\" a=$b echo \"$a\" 关系运算符 Shell支持正常的关系比较运算符，即\u003c,\u003c=,\u003e,\u003e=等。其会返回01代表结果。 实例： a=10 b=20 echo \"a \u003c b : `expr $a \\\u003c $b`\" #需要转义 echo \"a \u003e b : `expr $a '\u003e' $b`\" #也可以用引号括起来。 echo \"a \u003e= b : `expr $a '\u003e=' $b`\" 同时，Shell也给出了自己特定的比较命令，如下表： 运算符 说明 举例 -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ] 返回 false。 -ne 检测两个数是否不相等，不相等返回 true。 [ $a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。 -ge 检测左边的数是否大于等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ] 返回 true。 实例（注：if…then是条件语句，之后会讲解）： #!/bin/bash a=10 b=20 if [ $a -eq $b ] then echo \"$a -eq $b : a 等于 b\" else echo \"$a -eq $b: a 不等于 b\" fi if [ $a -ne $b ] then echo \"$a -ne $b: a 不等于 b\" else echo \"$a -ne $b : a 等于 b\" fi if [ $a -gt $b ] then echo \"$a -gt $b: a 大于 b\" else echo \"$a -gt $b: a 不大于 b\" fi if [ $a -lt $b ] then echo \"$a -lt $b: a 小于 b\" else echo \"$a -lt $b: a 不小于 b\" fi if [ $a -ge $b ] then echo \"$a -ge $b: a 大于或等于 b\" else echo \"$a -ge $b: a 小于 b\" fi if [ $a -le $b ] then echo \"$a -le $b: a 小于或等于 b\" else echo \"$a -le $b: a 大于 b\" fi 字符串表达式 即结合expr命令实现对字符串的操作，常见有以下： length str：返回str的长度。 index str charSet:返回字符集charSet中任意一个字符在str中最前面字符的位置。下标从1开始，如果不存在，则返回0。 substr str st len：截取字符串str，从st位置开始，长度最大为len的子串。如果截取不成功，则返回空字符串。 实例： str=\"Hello,World!\" echo `expr length \"$str\"` #`不是单引号，而是反引号，代表执行该命令。 echo `expr index \"$str\" llo` echo `expr substr \"$str\" 1 4` 文件测试运算符 文件测试运算符用于检测 Unix 文件的各种属性。 属性检测描述如下： 操作符 说明 举例 b file | ��测文件是否是块设备文件，如果是，则返回 true。 | -b $file ] 返回 false。 | c file | ��测文件是否是字符设备文件，如果是，则返回 true。 | -c $file ] 返回 false。 | d file | ��测文件是否是目录，如果是，则返回 true。 | -d $file ] 返回 false。 | f file | ��测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 | -f $file ] 返回 true。 | g file | ��测文件是否设置了 SGID 位，如果是，则返回 true。 | -g $file ] 返回 false。 | k file | ��测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。 | -k $file ] 返回 false。 | p file | ��测文件是否是有名管道，如果是，则返回 true。 | -p $file ] 返回 false。 | u file | ��测文件是否设置了 SUID 位，如果是，则返回 true。 | -u $file ] 返回 false。 | r file | ��测文件是否可读，如果是，则返回 true。 | -r $file ] 返回 true。 | w file | ��测文件是否可写，如果是，则返回 true。 | -w $file ] 返回 true。 | x file | ��测文件是否可执行，如果是，则返回 true。 | -x $file ] 返回 true。 | s file | ��测文件是否为空（文件大小是否大于0），不为空返回 true。 | -s $file ] 返回 true。 | e file | ��测文件（包括目录）是否存在，如果是，则返回 true。 | -e $file ] 返回 true。 | ","date":"2022-01-22","objectID":"/posts/06.shell%E6%95%99%E7%A8%8B/:2:4","tags":["Shell"],"title":"Shell 教程","uri":"/posts/06.shell%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.5 read命令 read命令可用于从标准输入中读取单行数据，当读到文件结束符时，exit code为1，否则为0。 参数说明： -p：后面可以接提示信息。 -t：后面跟秒数，定义输入字符的等待时间，超过等待时间后会自动忽略此命令 实例： read name echo $name read -p \"please input your name:\" -t 30 name #读入name的值，等待30s。 echo $name ","date":"2022-01-22","objectID":"/posts/06.shell%E6%95%99%E7%A8%8B/:2:5","tags":["Shell"],"title":"Shell 教程","uri":"/posts/06.shell%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.6 echo命令 echo命令用于字符串的输出，在前面的过程中我们已经接触到了，其命令格式为： echo string 我们可以用echo实现更复杂的输出格式控制。 显示普通字符串 echo \"Hello, World!\" 这种情况下，我们不加双引号也是可以的。 显示转义字符 echo \"\\\"Hello,World!\\\"\" 同样，这里的双引号也可以省略。 显示变量 name=hzf echo \"My name is $name\" 显示换行等特殊字符 注意，这些字符都需要通过-e命令开启转义才能起作用的，如：\\\\ \\a \\b \\c \\d \\e \\f \\n \\r \\t \\v 这些是要在有 -e 的时候才能起作用, 其他时候的转义是不用- e也能转义的。 echo -e \"Hello\\n\" #-e开启转义。 echo \"World!\" 显示结果定向至文件 echo \"Hello, World!\" \u003e output.txt 原样输出字符串 前面有提及，如果想原样输出，不进行转义或者取变量，用单引号。 name=hzf echo '$name' 显示命令执行结果 使用反引号。 echo `date` echo `ls` ","date":"2022-01-22","objectID":"/posts/06.shell%E6%95%99%E7%A8%8B/:2:6","tags":["Shell"],"title":"Shell 教程","uri":"/posts/06.shell%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.7 printf命令 Shell的printf命令和C语言中的printf差不多，用于格式化输出。该命令不会像echo命令一样自动添加换行。其语法为： printf format-string [args] 其中format-string为格式控制字符串，[args]为参数列表。 实例： #-表示左对齐，没有则表示右对齐，d为宽度。%s表示输出字符串，%d整型输出。 #%-10s则表示输出宽度为10的左对齐字符串。而%-4.2f则表示输出4位整数，保留2位小数。 printf \"%-10s %-8s %-4s\\n\" 姓名 性别 体重kg printf \"%-10s %-8s %-4.2f\\n\" 郭靖 男 66.1234 printf \"%-10s %-8s %-4.2f\\n\" 杨过 男 48.6543 printf \"%-10s %-8s %-4.2f\\n\" 郭芙 女 47.9876 命令格式指示符 符号 说明 c | SCII字符.显示相对应参数的第一个字符 | d,%i | ��进制整数 | E | ��点格式([-d].precisionE [+-dd]) | e | ��点格式([-d].precisione [+-dd]) | g | e或%f转换,看哪一个较短,则删除结尾的零 | G | E或%f转换,看哪一个较短,则删除结尾的零 | s | ��符串 | u | ��带正负号的十进制值 | x | ��带正负号的十六进制.使用a至f表示10至15 | % | ��面意义的% | X | ��带正负号的十六进制.使用A至F表示10至15 | ","date":"2022-01-22","objectID":"/posts/06.shell%E6%95%99%E7%A8%8B/:2:7","tags":["Shell"],"title":"Shell 教程","uri":"/posts/06.shell%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.8 test命令与判断符号[] 在命令行中输入man test，即可查看test命令的用法。 test命令可以用于判断文件类型，以及对变量做比较。test命令用exit code返回结果，而不是使用stdout。0表示真，非0表示假。这里可以通过echo $?来输出上一条命令的结果。 文件判断 命令格式：test 测试参数 filename 其中常用测试参数如下表： 测试参数 代表意义 -e 文件是否存在 -f 是否为文件 -d 是否为目录 -r 文件是否可读 -w 文件是否可写 -x 文件是否可执行 -s 是否为非空文件 测试 整数之间的比较 命令格式：test $a 关系运算符 $b 其中关系运算符为上文所提及的，这里不作列举。 字符串比较 相关操作如表所示： 测试参数 代表意义 test -z str 判断str是否为空，如果为空，返回true，否则false test -n str 判断str是否为非空，如果非空，返回true，否则false.其中-n可以省略 test str1 == str2 判断str1是否等于str2 test str1 != str2 判断str1是否不等于str2 ` 多重条件判定 即判断多个条件是否符合要求，可以嵌套多层。具体操作图表所示： 测试参数 代表意义 -a 两条件是否同时成立 -o 两条件是否至少一个成立 ! 取反。对返回结果取反 判断符号[] 和test命令用法几乎一模一样，只是将需要判断的内容放入括号中。 更常用于if语句中，且[[]]是[]的加强版，支持的特性也更多。 值得注意的是一些特性：[]内的每一项都必须用空格隔开；中括号内的变量，最好用双引号括起来；中括号内的常数，最好用单或双引号括起来。 ","date":"2022-01-22","objectID":"/posts/06.shell%E6%95%99%E7%A8%8B/:2:8","tags":["Shell"],"title":"Shell 教程","uri":"/posts/06.shell%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.9 判断语句 if语句 和python的语法有点像，命令格式如下： if [ 条件 ] then 内容 elif [ 条件 ] then 内容 else 内容 fi 注意fi为结束标记，是一定需要加的，作为结尾闭合。 实例： case...esac形式 命令格式如下： case $变量名 in value1) 内容 ;; # ;;，类似break value2) 内容 ;; *) #类似default 内容 ;; esac # 也是结尾闭合语句 测试 ","date":"2022-01-22","objectID":"/posts/06.shell%E6%95%99%E7%A8%8B/:2:9","tags":["Shell"],"title":"Shell 教程","uri":"/posts/06.shell%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.10 循环语句 for...in...do...done语句 命令格式： for var in val1 val2 val3 ... valN do 内容 done # 结尾闭合 循环规则为：从左到右遍历，当变量值为列表时，则一次遍历完列表。 实例1：输出a 2 cc，每个元素一行： for var in a 2 cc do echo $var done for((...;...;...)) do...done语句 命令格式： for ((expression; condition; expression)) do 内容 done 测试：输出1-10。 for ((i=0; i\u003c=10; ++i)) do echo $i done while...do...done语句 命令格式： while 条件 do 内容 done 实例：文件结束符为ctrl+d，输入文件结束符后read指令返回false。 while reabashd name do echo $name done unti...do..done语句 和while语句相同，while能实现的脚本until同样可以实现。但区别是until循环的退出状态为0，与while刚好相反，即while循环在条件为真时继续执行循环而until在条件为假时继续执行循环。 break语句 跳出当前的一层循环，break不能跳出case语句。 continue语句 跳出当前循环。 死循环的处理方式 如果Terminal可以打开该程序，则输入Ctrl+c即可。否则可以直接关闭进程：使用top命令找到该进程的PID；输入kill -9 PID即可关掉此进程。 ","date":"2022-01-22","objectID":"/posts/06.shell%E6%95%99%E7%A8%8B/:2:10","tags":["Shell"],"title":"Shell 教程","uri":"/posts/06.shell%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.11 函数 定义格式： [ function ] function_name [()]{ 内容; [return int;] } 说明： 可以带function func()定义，也可以直接fun()定义，不带任何参数。 参数返回，可以显示加：return返回，如果不加，将以最后一条命令运行结果作为返回值。return后跟数值n(0-255，不能超过该范围)。 其中函数返回值通过$?获取。 函数体声明局部变量可以用local关键字声明。 实例： function add(){ echo \"相加预算函数\" echo \"请输入第一个数\" read a echo \"请输入第二个数\" read b return $(($a + $b)) } add echo \"结果为$?\" 函数参数 在shell中，调用函数可以向其传递参数。在函数体内部，通过$n的形式来获取参数的值。例如，$1表示第一个参数，$2表示第二个参数。这个规则和上文说的文件参数相同。也是在执行的后面添加参数。 ","date":"2022-01-22","objectID":"/posts/06.shell%E6%95%99%E7%A8%8B/:2:11","tags":["Shell"],"title":"Shell 教程","uri":"/posts/06.shell%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.12 exit命令 exit命令用来退出当前的shell进程，并返回一个退出状态（0-255，只有0表示成功，其他都表示失败）；使用$?即可接收这个退出状态。 exit命令可以接收一个整数值作为参数，代表退出状态。如果不指定，默认值为0。 ","date":"2022-01-22","objectID":"/posts/06.shell%E6%95%99%E7%A8%8B/:2:12","tags":["Shell"],"title":"Shell 教程","uri":"/posts/06.shell%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.13 文件重定向 每个进程默认打开3个文件描述符： stdin：标准输入，从命令行读取数据，文件描述符为0。 stdout：标准输出，向命令行输出数据，文件描述符为1。 stderr：标准错误输出，向命令行输出数据，文件描述符为2。 可以用文件重定向将这三个文件重定向到其他文件中去。重定向命令列表如下： 命令 说明 command \u003e file 将输出重定向到 file。 command \u003c file 将输入重定向到 file。 command \u003e\u003e file 将输出以追加的方式重定向到 file。 n \u003e file 将文件描述符为 n 的文件重定向到 file。 n \u003e\u003e file 将文件描述符为 n 的文件以追加的方式重定向到 file。 n \u003e\u0026 m 将输出文件 m 和 n 合并。 n \u003c\u0026 m 将输入文件 m 和 n 合并。 \u003c\u003c tag 将开始标记 tag 和结束标记 tag 之间的内容作为输入。 输入输出重定向实例 echo -e \"Hello \\c\" \u003e output.txt # 将stdout重定向到output.txt中 echo \"World\" \u003e\u003e output.txt # 将字符串追加到output.txt中 read str \u003c output.txt # 从output.txt中读取字符串 echo $str # 输出结果：Hello World 同时重定向stdin和stdout 创建main.sh编写脚本： read a read b echo $(expr \"$a\" + \"$b\") 创建input.txt，填写内容为： 10 20 执行结果如下： ","date":"2022-01-22","objectID":"/posts/06.shell%E6%95%99%E7%A8%8B/:2:13","tags":["Shell"],"title":"Shell 教程","uri":"/posts/06.shell%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"2.14 引入外部脚本 类似C/C++中的include操作，bash也可以引入其他文件中的代码。 语法格式为： . filename # 注意空格 或者 source filename ","date":"2022-01-22","objectID":"/posts/06.shell%E6%95%99%E7%A8%8B/:2:14","tags":["Shell"],"title":"Shell 教程","uri":"/posts/06.shell%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"3 参考文献 Linux基础课 菜鸟教程 ","date":"2022-01-22","objectID":"/posts/06.shell%E6%95%99%E7%A8%8B/:3:0","tags":["Shell"],"title":"Shell 教程","uri":"/posts/06.shell%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1 1. Vim ","date":"2022-01-21","objectID":"/posts/02.vim%E6%95%99%E7%A8%8B/:1:0","tags":["Vim"],"title":"Vim教程","uri":"/posts/02.vim%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1.1 Vim简介 vim就是linux系统上的一款文本编辑器，具有语法高亮，代码补全，代码缩进，根据扩展名识别编程语言以及编译等方便编程的功能。是程序开发者一款非常好用的工具，这也是我们为什么要学习vim。 需要注意的是，作为程序员一般认为vim是一个程序开发工具而不是文字处理软件。如果学会了vim，对编程效率有极大的提高。 如果没有安装vim，可以通过:sudo apt-get install vim来安装。 这个就是vim的界面，界面介绍在之后会介绍，同时vim对应的键盘功能图如下： ​ 图源：https://www.runoob.com/linux/linux-vim.html 这个键盘图特别重要，也是vim的核心。 ","date":"2022-01-21","objectID":"/posts/02.vim%E6%95%99%E7%A8%8B/:1:1","tags":["Vim"],"title":"Vim教程","uri":"/posts/02.vim%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1.2 Vim模式 在使用vim之间，我们有必要了解它的模式，也可以认为是状态，一共有四种模式： 正常模式(Normal-mode)； 插入模式(Insert-mode)； 命令模式(Command -mode)； 可视模式(Visual-mode)。 有的时候通常也认为是三个模式，即没有可视模式（可能是因为这个模式存在感低），我们可以参考下图理解模式之间的转换： 接下来我们分别介绍这几个模式。 1.2.1 正常模式(Normal-mode) 此模式一般用于浏览文件，包括一些复制，粘贴，删除等操作。我们从任何模式返回到正常模式，只需要按下ESC键。 当我们通过vim 文件名.后缀启动vim时，就进入到了正常模式，如果已有文件，则打开它，否则就打开一个新的文件，并命名为文件名。 此时我们是无法向文件写内容的，此状态下敲击键盘会被vim识别为命令，而不是输入字符。 当我们输入i，I, a,A 时会进入插入模式。 当我们输入v时会进入可视模式。 当我们输入:时会进入命令模式，即在最底下一行输入命令。所以也叫底线命令模式。 要重点介绍的一个内容就是如何删除、复制，剪切以及粘贴了。vim对于复制，剪切，粘贴有它自己的一套术语。其中复制被叫做yank(y)， 剪切被叫做delete(d)，粘贴被叫做put(p)。 删除 c -向下删除一行。如果要删除多行，则输入nc，即可向下删除$n$行。 x - 向后删除一个字符，相当于del按键。如果要连续删除多个字符，则输入nx，即可删除$n$个。 X -向前删除一个字符， 相当于Backspace按键。同理nX。 复制(yank) 我们如果需要复制文本，那么需要将光标放到你想要复制的地方，然后根据需求按下相应命令即可。 y -复制选中的文本（选中文本在视图模式中会讲到）。 yy -复制当前行，包括换行符。 \u003cnumber\u003eyy -复制从光标所在的当前行开始的number行文本。 例如3yy即可复制从当前行开始的$3$行文本。 y$ -复制从光标位置到行尾的文本。 y^ -复制从光标位置到行首的文本。 yw -复制到下一个词的开头。 yiw - 复制当前词。 y% -复制匹配符号范围的内容。默认支持的符号对为(),{},[]。这个在复制括号内容时，非常有用。 yG -复制游标所在行到最后一行的行的所有数据。 ynG -n为数组，复制游标所在行到第$n$行的所有数据。 剪切(delete) 这个命令正常来说也可以作删除用。剪切文本时将光标移动到想要的位置，根据需求按下相应命令即可。 d -剪切选中的文本。 dd -剪切当前行，包括换行符等。 \u003cnumber\u003edd -剪切从光标位置所在的行开始的number行文本。 d$ - 剪切从光标位置到行尾的内容。 …不难发现，这些命令和复制差不多，就是将y换成d。这里就不再做阐述了。 粘贴(put) 先将光标移动到想要粘贴的位置，然后按p键即可将剪贴板的内容复制到当前光标后面。 当然，大写的P则是复制到光标位置前面。 其他常用操作 快捷键 功能 J | 将光标所在行与下一行的数据结合成同一行 | gg=G | 将全文代码格式化 | u | 撤销。(常用) | Ctrl+r | 取消撤销。(常用) | ��个 u 与 Ctrl+r 是很常用的指令！一个是复原，另一个则是重做一次～ 利用这两个功能按键，你的编辑，嘿嘿！很快乐的啦！ | | . | ��要怀疑！这就是小数点！意思是重复前一个动作的意思。 如果你想要重复删除、重复贴上等等动作，按下小数点『.』就好了！ (常用) | n | 重复前一个查找操作（常用） | N | 反向重复前一个查找操作（常用） | 其他的不常用操作这里不作列举。 我们可以通过方向键操作光标位置，注意linux中的方向键可以通过hjkl分别代表左下上右。这里给出移动光标的方法表格： 快捷键 功能 h 或 向左箭头键(←) 光标向左移动一个字符 j 或 向下箭头键(↓) 光标向下移动一个字符 k 或 向上箭头键(↑) 光标向上移动一个字符 l 或 向右箭头键(→) 光标向右移动一个字符 如果你将右手放在键盘上的话，你会发现 hjkl 是排列在一起的，因此可以使用这四个按钮来移动光标。 如果想要进行多次移动的话，例如向下移动 30 行，可以使用 “30j” 或 “30↓” 的组合按键， 亦即加上想要进行的次数(数字)后，按下动作即可！ Ctrl] + f 屏幕『向下』移动一页，相当于 [Page Down]按键 (常用) Ctrl + b 屏幕『向上』移动一页，相当于 [Page Up] 按键 (常用) Ctrl + d 屏幕『向下』移动半页 Ctrl] + u 屏幕『向上』移动半页 + 光标移动到非空格符的下一行行首 - 光标移动到非空格符的上一行行首 n\u003cspace\u003e 那个 n 表示『数字』，例如 20 。按下数字后再按空格键，光标会向右移动这一行的 n 个字符。例如 20 则光标会向后面移动 20 个字符距离。 0 或功能键``Home` 这是数字『 0 』：移动到这一行的最前面字符处 (常用) $ 或功能键``End` 移动到这一行的最后面字符处(常用) H 光标移动到这个屏幕的最上方那一行的第一个字符 M 光标移动到这个屏幕的中央那一行的第一个字符 L 光标移动到这个屏幕的最下方那一行的第一个字符 G 移动到这个档案的最后一行(常用) :n或nG n 为数字。移动到这个档案的第 n 行。例如 20G 则会移动到这个档案的第 20 行(可配合 :set nu) gg 移动到这个档案的第一行，相当于 1G 啊！ (常用) n\u003cEnter\u003e n 为数字。光标向下移动 n 行(常用) f{char} 光标跳转到光标所在行从光标开始之后的char字符处。即从光标位置到该行尾检索char字符，光标位置前的不处理 F{char} 光标跳转到光标所在行从光标开始之前的char字符处。即从行开头到光标处检索char字符，光标位置前的不处理 W或者w（大小写均可） 跳转到下一个单词的开头。支持数字前缀 b或者B（大小写均可） 跳转到上一个单词的开头。支持数字前缀。 { 光标跳转到段首 } 光标跳转到段尾 ^ 光标跳转到软行首。即该行的最早非空格位置字符。 E或e（大小写均可） 移动到词尾。 ( 句首 ) 下一句首 % 括号匹配。 正常模式只有一些基本的命令，因此我们需要靠命令模式来输入更多的命令。 1.2.2 插入模式(Insert-mode) 由上相信大家应该知道怎么由正常模式进入输入模式，即按下i(insert)即可进入插入模式。 在插入模式中，操作和正常的文本编辑器差不多，这里不作叙述。给出对应的快捷键操作表。 快捷键 功能 Ctrl + m或者Ctrl + j 开启新行 Ctrl + e 插入光标下的字符 Ctrl + y 插入光标上的字符 Ctrl + a 插入上次插入的文本 Ctrl + @ 插入上次插入的文本并结束插入模式 Ctrl + w 删除光标前的一个单词 Ctrl + u 删除当前行的所有字符 Ctrl + T 在当前行首插入一个移位宽度的缩进 Ctrl + D 从当前行首删除一个位移宽度的缩进 1.2.3 命令模式(Command -mode) 我们在一般命令模式下按下:/?这三个字母中的任意一个就可以进入命令行模式了，命令行在最下面，可以进行查找、替换、保存、退出、配置编译器等操作。需要注意的就是我们每执行完一个命令之后就会回到正常模式，所以在需要操作的时候一定要输入:/?这三个字母中的其中一个。 当然输入三个字母进入实现的命令是不一样的，这里给出具体操作。 /word -向光标之下（向后搜索）寻找第一个值为word的字符串。 ?word -向光标之上（向前搜索）寻找第一个值为word的字符串。 :n1,n2s/word1/word2/g -n1与n2为数字，在第n1行与n2行之间寻找word1这个字符串，并将字符串替换为word2。 如果在g后面加上c命令，即:n1,n2s/word1/word2/gc那么会在替换前要求用户确认。 :1,$s/word1/word2/g -将全文的word1替换成word2。 同理，如果在g后面加上c命令，也会要求确认。 :w -保存。 :w! -强制保存，当文件属性为只读时强制写入。不过这还是跟你对该文档的权限有关。 :q -退出vim。 :q! -强制退出vim。 :wq -保存并退出。 :set paste -设置成粘贴模式，取消代码自动缩进。 :set nopaste -取消粘贴模式，开启代码自动缩进。 :set nu -显示行号。 set nonu -隐藏行号。 :noh -关闭查找关键词高亮。 1.2.4 可视模式(Visual-mode) 这个模式存在感很低，有的甚至将它归结为正常模式。因为进入可视模式最直接的一个目的就是选中区域，然后再这个区域上进行操作，例如删除，替换等。不过，我认为这个模式异常重要，因为技巧性特别多。用好了这个模式，效率能大大的提高。 如何选中一块区域？ 在vim中有三种激活可视模式并选择一块区域的方法： 模式类型 激活方式 选择效果 左下角提示（即提示你当前处于何种模式） ��符文本 | v`(小写) | 逐个字符选择文本 | VISUAL | 行文本 | V`(大写) | 逐行选择文本 | VISUAL LINE | 块文本 | Ctrl + v` | ��照块的方式选择文本 | VISUAL BLOCK | 可能看着有点懵。我们来解释一下， 对于字符文本选择，实际上就是从","date":"2022-01-21","objectID":"/posts/02.vim%E6%95%99%E7%A8%8B/:1:2","tags":["Vim"],"title":"Vim教程","uri":"/posts/02.vim%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1.3 快捷键速览图 ","date":"2022-01-21","objectID":"/posts/02.vim%E6%95%99%E7%A8%8B/:1:3","tags":["Vim"],"title":"Vim教程","uri":"/posts/02.vim%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"2 参考文献 y总Linux基础课 精通 VIM ，此文就够了-zempty Linux vi/vim - runoob.com vim编辑器 莫迟 ","date":"2022-01-21","objectID":"/posts/02.vim%E6%95%99%E7%A8%8B/:2:0","tags":["Vim"],"title":"Vim教程","uri":"/posts/02.vim%E6%95%99%E7%A8%8B/"},{"categories":["系统架构"],"content":"1 fork ","date":"2022-01-21","objectID":"/posts/08.linux-forkvforkclone%E8%AF%A6%E8%A7%A3/:1:0","tags":["Linux","系统调用"],"title":"Linux 系统调用函数fork、vfork、clone详解","uri":"/posts/08.linux-forkvforkclone%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"1.1 基本介绍 #include \u003csys/types.h\u003e #include \u003cunistd.h\u003e pid_t fork(void) 描述 fork用于创建一个子进程，它与父进程的唯一区别在于其PID和PPID，以及资源利用设置为0。文件锁和挂起信号（指已经被内核发送给一个进程，但尚未被该进程处理的信号）不会被继承，其他和父进程几乎完全相同：会获得父进程的内存空间、栈、数据段、堆、打开的文件描述符、信号处理函数、进程优先级、环境变量等资源的副本。 返回值 成功时，在父进程中返回子进程的 PID，在子进程中返回 $0$。失败时，父进程返回 $-1$，不创建子进程，并适当设置 errno。 其中errno是一个全局变量，它用于表示最近一次系统调用或库函数调用产生的错误代码。当系统调用或库函数失败时，它们通常会设置 errno 以指示错误的原因。 以下是一些常见的 errno 错误代码及其含义： EAGAIN：资源暂时不可用，通常是因为达到了系统限制，如文件描述符或内存限制。 ENOMEM：内存不足，无法分配请求的资源。 EACCES：权限不足，无法访问某个资源。 EINTR：系统调用被信号中断。 EINVAL：无效的参数。 重点 fork() 函数创建的子进程会从父进程复制执行顺序。具体来说，子进程会从父进程复制当前的执行上下文，包括指令指针（instruction pointer）和寄存器的状态。这意味着子进程将从 fork() 系统调用之后的指令开始执行，与父进程在 fork() 之后应该执行的指令完全相同。因此，fork() 之后通常会有一个基于返回值的分支结构，以区分父进程和子进程的执行路径。 ","date":"2022-01-21","objectID":"/posts/08.linux-forkvforkclone%E8%AF%A6%E8%A7%A3/:1:1","tags":["Linux","系统调用"],"title":"Linux 系统调用函数fork、vfork、clone详解","uri":"/posts/08.linux-forkvforkclone%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"1.2 fork实例 1.2.1 1.2.1多个fork返回值 #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e int main() { pid_t pid1 = fork(); pid_t pid2 = fork(); pid_t pid3 = fork(); pid_t pid = getpid(); printf(\"The PID of the current process is %d\\n Hello World from (%d, %d, %d)\\n\", pid, pid1, pid2, pid3); return 0; } 这段程序包含了三个 fork() 调用，每个 fork() 都会创建一个新的子进程。由于每次 fork() 调用都会导致进程数翻倍，所以总共会有$2^3=8$个进程 （包括最初的父进程）。每个进程都会打印出它的进程 ID (pid) 以及三个 fork() 调用的返回值 (pid1, pid2, pid3)。 得到的输出结果如下： 我们画个状态机来理解它们的输出，假设最初的父进程PID为291871： 1.2.2 C语言 fork与输出 #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003csys/wait.h\u003e int main(int argc, char *argv[]) { int n = 2; for (int i = 0; i \u003c n; i++) { fork(); printf(\"Hello\\n\"); } for (int i = 0; i \u003c n; i++) { wait(NULL); } } 这段代码中，按我们的理解，第一次fork后有2个进程，然后一起执行printf输出，得到两个Hello，然后第二次fork后有4个进程，然后执行printf，得到四个Hello，则会有6个``Hello`，如下： 但是当我们将输出通过管道传给cat等命令时，会看到8个Hello： 这是因为标准输出一般是行缓冲的，碰到\\n，缓冲区中的内容会被刷新，即输出到终端或文件中。这种缓冲方式的目的是为了提高效率，因为这样可以减少对磁盘 I/O 的调用次数。 如果标准输出被重定向到管道，它可能不再是行缓冲的，而是变为全缓冲的。这意味着缓冲区可能会在填满时刷新，而不是在每次遇到换行符时刷新。如果缓冲区足够大，以至于可以容纳所有的 Hello 输出，那么fork的时候子进程也会复制缓冲区，导致最后每个进程中的缓冲区都有2个Hello，最后输出为8个。 如果为了确保缓冲区在需要的时候被刷新，可以在 printf 调用之后显式地调用 fflush(stdout) 来刷新标准输出缓冲区。这样可以确保所有的输出都被立即写入，而不会受到缓冲行为的影响。 #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003csys/wait.h\u003e int main(int argc, char *argv[]) { int n = 2; for (int i = 0; i \u003c n; i++) { fork(); printf(\"Hello\\n\"); fflush(stdout); } for (int i = 0; i \u003c n; i++) { wait(NULL); } return 0; } 1.2.3 fork 💣 #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003csys/wait.h\u003e int main(int argc, char *argv[]) { while(1) { fork(); } return 0; } 这段代码会无限循环地调用 fork() 函数，每次循环都会创建一个新进程。由于每次 fork() 调用都会成功创建一个新进程，而且这个新进程又会立即进入下一次循环并再次调用 fork()，因此进程的数量会以指数速度增长，很快就会耗尽系统的可用资源。 绝对不要在任何生产环境或您没有权限的任何系统上运行fork炸弹。 ","date":"2022-01-21","objectID":"/posts/08.linux-forkvforkclone%E8%AF%A6%E8%A7%A3/:1:2","tags":["Linux","系统调用"],"title":"Linux 系统调用函数fork、vfork、clone详解","uri":"/posts/08.linux-forkvforkclone%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"2 vfork ","date":"2022-01-21","objectID":"/posts/08.linux-forkvforkclone%E8%AF%A6%E8%A7%A3/:2:0","tags":["Linux","系统调用"],"title":"Linux 系统调用函数fork、vfork、clone详解","uri":"/posts/08.linux-forkvforkclone%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"2.1 基本介绍 描述 #include \u003csys/types.h\u003e #include \u003cunistd.h\u003e pid_t vfork(void); vfork() 系统调用用于创建一个子进程，与 fork() 类似，但它使用父进程的地址空间，而不是复制父进程的地址空间。vfork() 调用后，父进程会阻塞，直到子进程调用 exec 函数或执行了 exit 函数。这是因为子进程需要独占父进程的地址空间，以确保数据一致性。一。在子进程调用 exec 函数或执行了 exit 函数之后，子进程将获得自己的内存空间。 返回值 和fork一致 重点 vfork() 创建的子进程会继承父进程的环境，但不会继承父进程的堆栈。 在子进程执行这些exec或exit操作之前，父进程和子进程可能会访问相同的内存地址，这可能导致数据竞争和不一致。 在 vfork() 调用成功后，子进程应该立即调用 exec 函数或执行 exit 函数。如果在子进程中修改除了用于存储从 vfork() 返回值的 pid_t 类型变量之外的任何数据，或者从调用 vfork() 的函数返回，或在成功调用 _exit() 或 exec() 函数族中的一个函数之前调用其他任何函数，则行为是未定义的。这可能会导致程序崩溃或表现出不可预测的行为。 因此，使用 vfork() 时，必须确保子进程在调用 exec 函数或执行 exit 函数之前不执行任何可能影响共享内存的操作。 vfork() 系统调用会阻塞父进程，直到子进程完成 exec 调用或 exit 调用。父进程不需要显式调用 wait() 或 waitpid() 来等待子进程结束。 ","date":"2022-01-21","objectID":"/posts/08.linux-forkvforkclone%E8%AF%A6%E8%A7%A3/:2:1","tags":["Linux","系统调用"],"title":"Linux 系统调用函数fork、vfork、clone详解","uri":"/posts/08.linux-forkvforkclone%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"2.2 验证vfork共享内存 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e #include \u003csys/wait.h\u003e #include \u003cstring.h\u003e #include \u003cassert.h\u003e int main() { // 在父进程中分配内存并初始化 char *buffer = malloc(1024); assert(buffer != NULL); memset(buffer, 'A', 1024); // 使用vfork创建子进程 pid_t pid = vfork(); if (pid \u003c 0) { perror(\"vfork error\"); exit(EXIT_FAILURE); } else if (pid == 0) { // 子进程 printf(\"Child process: PID = %d\\n\", getpid()); // 修改内容 memset(buffer, 'B', 1024); // 子进程 char * const argv[] = {\"/bin/echo\", \"Hello, Linux!\", NULL}; char * const envp[] = {NULL}; // 执行exec函数 execve(argv[0], argv, envp); } else { // 父进程 printf(\"Parent process: PID = %d, child's PID = %d\\n\", getpid(), pid); // 验证内存内容是否被子进程修改 for (int i = 0; i \u003c 1024; i++) { if (buffer[i] != 'B') { printf(\"Memory corruption detected at index %d\\n\", i); exit(EXIT_FAILURE); } } printf(\"Memory is consistent\\n\"); } return 0; } 这个程序的目的是验证在 vfork() 之后，子进程和父进程是否共享内存。首先在父进程中分配一块内存 ，并将其初始化为字符 ‘A’。然后，父进程调用 vfork() 创建一个子进程。在子进程中，程序试图将内容修改为字符 ‘B’，并执行 execve()。在父进程中，程序检查缓冲区的内容是否被修改为字符 ‘B’，以验证内存是否被正确共享。 程序运行结果如下： ","date":"2022-01-21","objectID":"/posts/08.linux-forkvforkclone%E8%AF%A6%E8%A7%A3/:2:2","tags":["Linux","系统调用"],"title":"Linux 系统调用函数fork、vfork、clone详解","uri":"/posts/08.linux-forkvforkclone%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"3 clone ","date":"2022-01-21","objectID":"/posts/08.linux-forkvforkclone%E8%AF%A6%E8%A7%A3/:3:0","tags":["Linux","系统调用"],"title":"Linux 系统调用函数fork、vfork、clone详解","uri":"/posts/08.linux-forkvforkclone%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"3.1 基本介绍 描述 #define _GNU_SOURCE #include \u003csched.h\u003e int clone(int (*fn)(void *), void *child_stack, int flags, void *arg, ... /* pid_t *parent_tid, void *tls, pid_t *child_tid */ ); clone与fork类似，是用于创建新进程的系统调用，但clone提供了更精确的控制，可以确定在调用进程（父进程）和子进程之间共享哪些执行上下文的部分。例如，调用者可以控制两个进程是否共享虚拟地址空间、文件描述符表和信号处理程序表。这些系统调用还允许将新的子进程放置在单独的命名空间中。 参数 fn是指向新进程要执行的函数的指针，这个函数接受一个 void* 参数，并返回一个 int 类型的值，这个返回值将被 clone 系统调用捕获，并作为子进程的退出状态； child_stack是新进程的堆栈地址，由于子进程和调用进程可能共享内存，因此子进程不可能与调用进程在同一堆栈中执行。调用进程必须为子堆栈设置内存空间，并将指向该空间的指针传递给clone()。 flags可以设置新进程的属性（通过二进制位设置），包括是否与原进程共享地址空间（CLONE_VM）、是否共享文件描述符表（CLONE_FILES）、是否共享信号处理器（CLONE_SIGHAND）等等； int flags = CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND | CLONE_THREAD | CLONE_SYSVSEM | CLONE_SETTLS; 标志 含义 CLONE_PARENT 创建的子进程的父进程是调用者的父进程，新进程与创建它的进程成了“兄弟”而不是“父子” CLONE_FS 子进程与父进程共享相同的文件系统，包括root、当前目录、umask CLONE_FILES 子进程与父进程共享相同的文件描述符（file descriptor）表 CLONE_NEWNS 在新的namespace启动子进程，namespace描述了进程的文件hierarchy CLONE_SIGHAND 子进程与父进程共享相同的信号处理（signal handler）表 CLONE_PTRACE 若父进程被trace，子进程也被trace CLONE_VFORK 父进程被挂起，直至子进程释放虚拟内存资源 CLONE_VM 子进程与父进程运行于相同的内存空间 CLONE_PID 子进程在创建时PID与父进程一致 CLONE_THREAD Linux 2.4中增加以支持POSIX线程标准，子进程与父进程共享相同的线程群 arg是传递给新进程的参数； 可选参数，包括 pid_t *parent_tid等。 返回值 成功时，在父进程中返回子进程的 PID。失败时，父进程返回 $-1$，不创建子进程，并适当设置 errno。 重点 clone 可以创建新的进程或线程，Linux创建线程使用的系统调用就是clone。而 fork 和vfork只能创建进程。这意味着 clone 可以在单个进程中创建多个线程，而 fork 则总是创建一个新的进程。 clone 提供比 fork 和 vfork 更多的选项，可以指定子进程或线程的堆栈、信号处理、权限等。 clone 的使用比 fork 和 vfork 更复杂，需要正确设置 flags、child_stack、parent_pidptr、ptr、stack_size 和 tls 等参数。 ","date":"2022-01-21","objectID":"/posts/08.linux-forkvforkclone%E8%AF%A6%E8%A7%A3/:3:1","tags":["Linux","系统调用"],"title":"Linux 系统调用函数fork、vfork、clone详解","uri":"/posts/08.linux-forkvforkclone%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"3.2 clone使用 #define _GNU_SOURCE #include \u003csched.h\u003e #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cstring.h\u003e #include \u003csys/wait.h\u003e #include \u003cunistd.h\u003e #define STACK_SIZE (1024 * 1024) /* Stack size for cloned child */ // 宏，简化错误处理 #define ERREXIT(msg) { perror(msg); exit(EXIT_FAILURE); } // 安全分配内存函数，分配失败报告错误 #define CHECKALLOC(ptr, msg) ({ void *p = ptr; if (p == NULL) {ERREXIT(msg);} p;}) /* * 子进程函数 * params: 接受一个void *类型参数，但是没有被使用过，后面的声明是用于告诉编译器这个参数是未被使用的 */ static int childFunc(void *arg __attribute__((unused))) { puts(\"child: start\"); sleep(2); puts(\"child: terminate\"); return 0; /* Child terminates now */ } int main(int argc, char *argv[]) { /* Start of stack buffer */ char **stacks; /* Child process's pids */ pid_t *pids; size_t nproc, i; // 接受两个参数 if (argc != 2) { puts(\"Wrong way to execute the program:\\n\" \"\\t\\t./waitpid nProcesses\\n\" \"example:\\t./waitpid 2\"); return EXIT_FAILURE; } // 初始化nproc，表示要创建的子进程数 nproc = atol(argv[1]); /* Process count */ // 分配内存空间 stacks = CHECKALLOC(malloc(nproc * sizeof(void *)), \"malloc\"); pids = CHECKALLOC(malloc(nproc * sizeof(pid_t)), \"malloc\"); for (i = 0; i \u003c nproc; i++) { char *stackTop; /* End of stack buffer */ stacks[i] = CHECKALLOC(malloc(STACK_SIZE), \"stack malloc\"); // 得到栈顶位置 stackTop = stacks[i] + STACK_SIZE; /* * 创建子进程 * 第一个标志表示在子进程清除线程组ID（TID），目的是为了避免子进程与父进程或其他子进程的线程组ID冲突 * 第二个表示告诉在子进程中设置线程ID，目的是为了允许父进程在子进程中追踪线程 * 告诉 clone 系统调用在子进程中重新安装信号处理程序，目的是为了允许子进程捕获和处理信号，而不是传递给父进程。 */ pids[i] = clone(childFunc, stackTop, CLONE_CHILD_CLEARTID | CLONE_CHILD_SETTID | SIGCHLD, NULL); if (pids[i] == -1) ERREXIT(\"clone\"); printf(\"clone() returned %ld\\n\", (long)pids[i]); } sleep(1); // 等待所有子进程 for (i = 0; i \u003c nproc; i++) { // 第一个参数为子进程id，第二个参数表示不关心子进程的退出状态，第三个参数表示等待任何子进程 if (waitpid(pids[i], NULL, 0) == -1) ERREXIT(\"waitpid\"); printf(\"child %ld has terminated\\n\", (long)pids[i]); } // 回收内存空间 for (i = 0; i \u003c nproc; i++) free(stacks[i]); free(stacks); free(pids); return EXIT_SUCCESS; } 运行：gcc clone-example.c \u0026\u0026 ./a.out 5，其中5为nproc，表示要创建的进程数。 运行结果如下： ","date":"2022-01-21","objectID":"/posts/08.linux-forkvforkclone%E8%AF%A6%E8%A7%A3/:3:2","tags":["Linux","系统调用"],"title":"Linux 系统调用函数fork、vfork、clone详解","uri":"/posts/08.linux-forkvforkclone%E8%AF%A6%E8%A7%A3/"},{"categories":["系统架构"],"content":"1 1. 通用基础知识 查询指令命令help，通过指令名 --help或者man 指令名。 例如，我们需要查询ls这个指令的参数用法以及作用，即通过ls --help即可得到如下： ctrl c：取消命令，并且换行。 ctrl u：清空本行命令 tab：补全命令和文件名，如果补全不了就快速按两下tab键，可以显示备选项。 ","date":"2022-01-21","objectID":"/posts/02.linux%E5%B8%B8%E7%94%A8%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:1:0","tags":["Linux"],"title":"Linux常用文件管理命令","uri":"/posts/02.linux%E5%B8%B8%E7%94%A8%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["系统架构"],"content":"2 2. 文件基础操作 注意事项 如果文件名或者文件夹名存在空格或者一些特殊字符，我们要进行转移表示，即通过转移字符\\来实现。 创建文件夹：mkdir [-p][dirNmae] 其中-p确保目录名称一定存在，如果不存在就会创建一个。 创建文件：touch [dirName + fileName] 显示当前目录下或者指定目录下的所有文件：ls [参数][dirName] 其中显示的蓝色是文件夹，白色是普通文件，绿色是可执行文件，如图： 参数有： -a显示所有文件及目录 (. 开头的隐藏文件也会列出) -l除文件名称外，亦将文件型态、权限、拥有者、文件大小等资讯详细列出 -r 将文件以相反次序显示(原定依英文字母次序) -t 将文件依建立时间之先后次序列出 -A 同 -a ，但不列出 “.” (目前目录) 及 “..” (父目录) -F 在列出的文件名称后加一符号；例如可执行档则加 “*”, 目录则加 “/” -R 若目录下有文件，则以下之文件亦皆依序列出 显示目前所在的工作目录的绝对路径名称：pwd 切换当前工作目录：cd [dirName] 其中dirName可为绝对路径或相对路径，如果没有给出，默认返回家目录。cd -会返回之前的工作目录 删除文件或文件夹：rm [dirName] [options]， 其中选项包括： ` -i` 删除前逐一询问确认。 -f 即使原档案属性设为唯读，亦直接删除，无需逐一确认。 -r 将目录及以下之档案亦逐一删除,递归所有的子目录,逐一询问。 一般删除普通文件直接使用rm [dirName] 创建编写文件：vim [dirName] 创建好之后会自动进入文件，这个时候我们事写不动东西的，所以我们需要输入小写字母i（为insert的缩写）即可写入，写完之后如何保存？我们先需要按ESC键锁住文件，再输入:wq即可，这个命令就是保存并退出的意思。 查看文件：cat [dirName] 复制文件：cp [options] source dest 其中参数说明： -a：此选项通常在复制目录时使用，它保留链接、文件属性，并复制目录下的所有内容。其作用等于dpR参数组合。 -d：复制时保留链接。这里所说的链接相当于 Windows 系统中的快捷方式。 -f：覆盖已经存在的目标文件而不给出提示。 -i：与 -f 选项相反，在覆盖目标文件之前给出提示，要求用户确认是否覆盖，回答 y 时目标文件将被覆盖。 -p：除复制文件的内容外，还把修改时间和访问权限也复制到新文件中。 -r：若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件。复制目录的时候一定要添加的参数 -l：不复制文件，只是生成链接文件。 即cp = 复制+粘贴+重命名，我们可以看一个例子cp a/tmp.txt b/tmp2.txt，那么会从a中的 tmp.txt复制到b中并重命名为tmp2.txt。 为文件或目录改名、或将文件或目录移入其它位置：mv [options] source dest。 如果需要重命名，就在后面加上新的文件名。 其中参数说明 -b: 当目标文件或目录存在时，在执行覆盖前，会为其创建一个备份。 -i: 如果指定移动的源目录或文件与目标的目录或文件同名，则会先询问是否覆盖旧文件，输入 y 表示直接覆盖，输入 n 表示取消该操作。 -f: 如果指定移动的源目录或文件与目标的目录或文件同名，不会询问，直接覆盖旧文件。 -n: 不要覆盖任何已存在的文件或目录。 -u：当源文件比目标文件新或者目标文件不存在时，才执行移动操作。 ","date":"2022-01-21","objectID":"/posts/02.linux%E5%B8%B8%E7%94%A8%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:2:0","tags":["Linux"],"title":"Linux常用文件管理命令","uri":"/posts/02.linux%E5%B8%B8%E7%94%A8%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["系统架构"],"content":"3 编译运行C/C++文件 编译 g++ 文件名.cpp -o 文件名 -std=版本 例如:g++ main.cpp -o main -std=c++11 值得注意的一点就是在AC Terminal里面是用不了万能头文件的。 运行 ./文件名，即可运行。 ","date":"2022-01-21","objectID":"/posts/02.linux%E5%B8%B8%E7%94%A8%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:3:0","tags":["Linux"],"title":"Linux常用文件管理命令","uri":"/posts/02.linux%E5%B8%B8%E7%94%A8%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["系统架构"],"content":"4 参考文献 y总Linux基础课 ","date":"2022-01-21","objectID":"/posts/02.linux%E5%B8%B8%E7%94%A8%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:4:0","tags":["Linux"],"title":"Linux常用文件管理命令","uri":"/posts/02.linux%E5%B8%B8%E7%94%A8%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["工具"],"content":"1 tmux使用教程 ","date":"2022-01-21","objectID":"/posts/01.tmux%E6%95%99%E7%A8%8B/:1:0","tags":["Tmux"],"title":"Tmux教程","uri":"/posts/01.tmux%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1.1 tmux安装 # Ubuntu 或 Debian $ sudo apt-get install tmux # CentOS 或 Fedora $ sudo yum install tmux # Mac $ brew install tmux ","date":"2022-01-21","objectID":"/posts/01.tmux%E6%95%99%E7%A8%8B/:1:1","tags":["Tmux"],"title":"Tmux教程","uri":"/posts/01.tmux%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1.2 tmux简介 tmux是一个非常优秀的终端复用器（terminal multiplexer），其可以使用一系列的终端session，它使您可以在一个终端中的多个程序之间轻松切换、分离它们（它们继续在后台运行）并将它们重新附加到不同的终端。 session：我们知道，在windows命令行中我们打开一个终端窗口，然后输入命令实现与计算机的交流。而这种用户与计算机的这种临时的交互就叫做session。 tmux的主要功能有： 分屏，即允许在单个窗口中访问多个会话。这对我们同时运行多个命令行程序非常有用。 允许断开Terminal连接后，继续运行进程。这样，我们可以随时随地放心的进行操作，即使工作进行到一半突然断开，我们打开tmux仍可以重新进入到操作现场。 会话共享（适用于结对编程或者远程教学）。我们可以将tmux的会话地址分享给其他人，这样他们就可以通过SSH接入该会话。更骚的是，如果你要给其他人演示远程服务器的操作，不必一直盯着屏幕，我们可以借助tmux，他就可以完全进入你的会话。 当然，tmux的功能还有很多，相比于其他的终端复用器，tmux更易用也更强大，这也是我们为什么要学习tmux的原因。 ","date":"2022-01-21","objectID":"/posts/01.tmux%E6%95%99%E7%A8%8B/:1:2","tags":["Tmux"],"title":"Tmux教程","uri":"/posts/01.tmux%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1.3 tmux结构 tmux是采用C/S模型构建的，我们输入tmux即相当于开启了一个服务器，此时默认将新建一个session，然后再session中新建一个window，window中新建一个pane。其联系为：一个tmux可以包含多个session，一个session可以包含多个window，一个window可以包含多个pane。 以下即是实例： tmux: session 0: window 0: pane 0 pane 1 pane 2 … window 1 window 2 … session 1 session 2 … ","date":"2022-01-21","objectID":"/posts/01.tmux%E6%95%99%E7%A8%8B/:1:3","tags":["Tmux"],"title":"Tmux教程","uri":"/posts/01.tmux%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"1.4 tmux操作 注：以下操作大多数都会给出命令和对应的快捷键，如果用于学习，建议两种操作都要学会，但在平常操作中，使用快捷键是更方便的。 1.4.1 前缀键 tmux提供了很多的快捷键。特别的是所有的快捷键都需要通过前缀键唤起，默认的快捷键为ctrl + b。我们可以通过tmux list-keys命令来查看所有快捷键指令。 当然如果觉得ctrl + b不好用，习惯用其他的键，这里提供修改前缀键的方法如下： # 首先打开文件~/.tmux.conf vim ~/.tmux.conf # 设置前缀为Ctrl + a。 set -g prefix C-a # 解除Ctrl + b与前缀的对应关系。 unbind C-b # 绑定ctrl + a 成为新的指令前缀。 bind C-a send-prefix #然后让它生效。我们也可以直接重启让它生效。 source ~/.tmux.conf 1.4.2 会话(session)操作 新建会话：tmux new -s sessionName。 这样，我们就可以创建一个名为sessionName的会话了。当然我们也可以直接简写为tmux，这样会新建一个无名称的会话。但为了我们方便管理，所以建议还是指定会话名称。 断开当前会话：tmux detach。 这样，我们就可以断开当前会话，但是会话 还是会在后台运行。当然，我们还可以使用快捷键：先按ctrl + b，再按 ctrl + d即可退出。 注意：这个并没有真正的关闭会话。 进入已存在的会话：tmux a -t sessionName或者直接输入tmux a。 前者可以指定进入的sessionName会话，而后者是默认进入第一个会话。其中的a命令实际上就是attach，我们可以简写为a。 关闭会话：tmux kill -session -t sessionName或者tmux kill -server。 我们可以使用tmux的kill命令，其中kill命令有四种：kill -pane, kill -server, kill -session, kill window。根据需求我们使用自己需要的命令，需要注意的是，根据前面的联系，我们关闭了session，那么其中的所有pane和window也都不存在了，同理关闭server,那么所有session也都不存在了。所以这里即是使用kill -session和kill -server，前者关闭sessionName这个会话，后者关闭所有的会话。 查看所有的会话：tmux ls。 切换会话：switch命令用于切换会话。 # 使用会话编号来切换 tmux switch -t 0 # 使用会话名称来切换 tmux switch -t sessionName 重命名会话：tmux rename-session -t sessionName new Name。 常用会话操作快捷键。 前缀 指令 功能 Ctrl+b` | d | 断开当前会话 | Ctrl+b` | D | 选择要断开的会话 | Ctrl+b` | $ | 重命名当前会话 | Ctrl+b` | s | ��出当前会话用于选择并切换 | Ctrl+b` | r | 强制重载当前会话 | Ctrl+b` | trl + z | 挂起当前会话 | tmux中复制/粘贴文本的通用方法。 (1).按下Ctrl + b前缀键，然后按[； (2).用鼠标选中文本，然后被选中的文本会被自动复制到tmux的剪贴板； (3).按下Ctrl + b后前缀键，然后按]，会自动将剪贴板的内容粘贴到光标处。 1.4.3 窗口(window)操作 新建窗口：tmux new-window -n windowName。 如此我们可创建一个新的名为windowName的窗口。当然我们也可以直接输入tmux new-window来创建一个没有指定名称的窗口。 创建一个新窗口后，原窗口我们是看不到了的，但依然存在。 切换窗口：tmux select-window -t windowName。 重命名窗口：tmux rename-window windowName。 常用窗口操作快捷键。 前缀 指令 功能 Ctrl+b` | c | 新建窗口 | Ctrl+b` | \u0026 | 关闭当前窗口，需要输入y or n确认 | Ctrl+b` | number\u003e编号 | 切换到指定编号的窗口 | Ctrl+b` | p | 切换到上一个窗口 | Ctrl+b` | n | 切换到下一个窗口 | Ctrl+b` | w | 显示窗口列表用于切换。 | Ctrl+b` | ,（逗号） | 重命名当前窗口 | Ctrl+b` | . | 修改当前窗口编号（适用于窗口排序） | Ctrl+b` | f | ��速定位到窗口（输入关键字匹配窗口） | 1.4.4 面板(pane)操作 划分面板。 注意，此划分是针对当前选中的面板，面板可以无限划分。 # 划分成上下两个面板 tmux split-window #划分成左右两个面板 tmux split-window -h 切换面板。 tmux select-pane命令用来移动光标位置，这个更严谨的说应该是切换光标，因为我们的光标正好可以选中面板，即可以通过鼠标点击选中。当然，前者过于简单且没有逼格，我们可以通过快捷键或者命令来实现。 # 光标切换到上方面板 tmux select-pane -U # 光标切换到下方面板 tmux select-pane -D # 光标切换到左方面板 tmux select-pane -L # 光标切换到右方面板 tmux select-pane -R 交换面板位置。 tmux swap-pane可用于交换面板位置。同切换面板差不多的形式。 # 上移 tmux swap-pane -U # 下移 tmux swap-pane -D # 左移 tmux swap-pane -L # 右移 tmux swap-pane -R 常用面板操作快捷键。 前缀 指令 描述 Ctrl+b` | \" | 当前面板上下一分为二，下侧新建面板 | Ctrl+b` | % | 当前面板左右一分为二，右侧新建面板 | Ctrl+b` | x | 关闭当前面板（关闭前需输入y or n确认） | Ctrl+b` | z | 最大化当前面板，再重复一次按键后恢复正常（v1.8版本新增） | Ctrl+b` | ! | ��当前面板移动到新的窗口打开（原窗口中存在两个及以上面板有效） | Ctrl+b` | ; | 切换到最后一次使用的面板 | Ctrl+b` | q | 显示面板编号，在编号消失前输入对应的数字可切换到相应的面板 | Ctrl+b` | 方向键 | 移动光标切换面板 | Ctrl+b` | hjkl(分别代表左下上右)` | 移动光标切换面板 | Ctrl+b` | { | 向前置换当前面板 | Ctrl+b` | } | 向后置换当前面板 | Ctrl+b` | Ctrl+o | 顺时针旋转当前窗口中的所有面板 | Ctrl+b` | o | 选择下一面板 | Ctrl+b` | 空格键 | 在自带的面板布局中循环切换 | Ctrl+b` | Alt+方向键 | 以5个单元格为单位调整当前面板边缘 | Ctrl+b` | Ctrl+方向键 | 以1个单元格为单位调整当前面板边缘（Mac下被系统快捷键覆盖） | Ctrl+b` | t | 显示时钟 | ","date":"2022-01-21","objectID":"/posts/01.tmux%E6%95%99%E7%A8%8B/:1:4","tags":["Tmux"],"title":"Tmux教程","uri":"/posts/01.tmux%E6%95%99%E7%A8%8B/"},{"categories":["工具"],"content":"2 参考文献 Tmux 使用教程-阮一峰 Tmux使用手册-路易斯 tmux使用教程-小可七 ","date":"2022-01-21","objectID":"/posts/01.tmux%E6%95%99%E7%A8%8B/:2:0","tags":["Tmux"],"title":"Tmux教程","uri":"/posts/01.tmux%E6%95%99%E7%A8%8B/"},{"categories":["问题记录"],"content":"1 打开DOSBox配置文件 DOSBox的配置文件名为DOSBOX 版本号 Options，对于有的版本配置文件好像名为bc31.conf。在DOSBOX的安装目录下，后缀为.bat。直接用记事本打开进行修改即可。 ","date":"2021-09-27","objectID":"/posts/02.%E4%BF%AE%E6%94%B9dosbox%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%B0%83%E6%95%B4%E7%AA%97%E5%8F%A3%E5%A4%A7%E5%B0%8F%E6%8C%82%E8%BD%BD%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%8A%A8%E8%BF%90%E8%A1%8C/:1:0","tags":["DOSBox"],"title":"修改DOSBox配置文件（调整窗口大小，挂载程序自动运行）","uri":"/posts/02.%E4%BF%AE%E6%94%B9dosbox%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%B0%83%E6%95%B4%E7%AA%97%E5%8F%A3%E5%A4%A7%E5%B0%8F%E6%8C%82%E8%BD%BD%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%8A%A8%E8%BF%90%E8%A1%8C/"},{"categories":["问题记录"],"content":"2 调整窗口大小 在实际使用DOSBox的时候，通常会觉得DOSBox的窗口有点小： 我们又不能直接调节。这个时候有两种方法调节： Alt+Enter进入全屏模式。 这种方法比较别扭，不过方便快捷。 利用配置文件修改。 进入配置文件后定位到： 第一个参数fullscreen代表是否填充屏幕，其是否进入全屏模式。如果你喜欢第一种方式，可以直接在这里修改，这样每次进入都是全屏模式了。 第二个参数和第三个参数都是调节全屏模式下的特征，这里我们不再作介绍了。 关键在于windowresolution和output，分别为窗口分辨率和输出。 我们将分辨率调为1280x1080（分辨率可以根据自己实际需要进行调节）,同时需要将输出改为opengl,即开启渲染。 保存重启DOSBox如下： ","date":"2021-09-27","objectID":"/posts/02.%E4%BF%AE%E6%94%B9dosbox%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%B0%83%E6%95%B4%E7%AA%97%E5%8F%A3%E5%A4%A7%E5%B0%8F%E6%8C%82%E8%BD%BD%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%8A%A8%E8%BF%90%E8%A1%8C/:2:0","tags":["DOSBox"],"title":"修改DOSBox配置文件（调整窗口大小，挂载程序自动运行）","uri":"/posts/02.%E4%BF%AE%E6%94%B9dosbox%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%B0%83%E6%95%B4%E7%AA%97%E5%8F%A3%E5%A4%A7%E5%B0%8F%E6%8C%82%E8%BD%BD%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%8A%A8%E8%BF%90%E8%A1%8C/"},{"categories":["问题记录"],"content":"3 挂载程序自动运行 当我们没有打开DOSBox的时候进入的是Z盘，即DOSBox的虚拟Z盘。 但是，我们需要使用本地的masm文件夹用来执行汇编程序和使用debug等操作。这个时候我们通常的方法是可以将masm文件夹挂载为DOSBox的C盘，即输入mount c d:\\masm即可将d:\\masm挂载到C盘。通俗的理解，该文件夹之后就是DOSBox的C盘了。我们用dos命令c:进入C盘即可使用masm文件夹下的内容了。 所以以上操作为： mount c d:\\masm c: 那么如果我们每次打开都要进行这样的操作，那未免太累了。所以我们可将两条语句添加到配置文件的文件末尾处。 保存重新打开DOSBox之后为： 当然，如果你想挂载其他的程序照此操作即可实现。 ","date":"2021-09-27","objectID":"/posts/02.%E4%BF%AE%E6%94%B9dosbox%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%B0%83%E6%95%B4%E7%AA%97%E5%8F%A3%E5%A4%A7%E5%B0%8F%E6%8C%82%E8%BD%BD%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%8A%A8%E8%BF%90%E8%A1%8C/:3:0","tags":["DOSBox"],"title":"修改DOSBox配置文件（调整窗口大小，挂载程序自动运行）","uri":"/posts/02.%E4%BF%AE%E6%94%B9dosbox%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%B0%83%E6%95%B4%E7%AA%97%E5%8F%A3%E5%A4%A7%E5%B0%8F%E6%8C%82%E8%BD%BD%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%8A%A8%E8%BF%90%E8%A1%8C/"},{"categories":null,"content":"Lruihao's friends","date":"2021-09-19","objectID":"/friends/","tags":null,"title":"友情鏈接","uri":"/friends/"},{"categories":null,"content":"  Subscribe ours https://lruihao.cn/friends/opml.xml ","date":"2021-09-19","objectID":"/friends/:0:0","tags":null,"title":"友情鏈接","uri":"/friends/"},{"categories":null,"content":"1 失效鏈接 公示一個月後刪除，如更換域名請及時聯繫！ liyangzone.com: 無妨訪問。 ayou10031.com: 無妨訪問。 ","date":"2021-09-19","objectID":"/friends/:1:0","tags":null,"title":"友情鏈接","uri":"/friends/"},{"categories":null,"content":"2 基本資訊 網絡 ID：Lruihao 頭像：https://lruihao.cn/images/avatar.jpg URL：https://lruihao.cn 描述：菠菜眾長 - 「不怕萬人阻擋，只怕自己投降」 ","date":"2021-09-19","objectID":"/friends/:2:0","tags":null,"title":"友情鏈接","uri":"/friends/"},{"categories":null,"content":"3 友情提醒 評論留言必要內容如下： ```yaml - nickname: \u003cyour nickname\u003e avatar: \u003cyour avatar\u003e url: \u003cyour site link\u003e description: \u003cdescription of your site\u003e ``` Notice 互換友鏈請按以上格式在評論留言。（僅限個人非商業部落格/網站）  網站失效、停止維護、內容不當都可能被取消連結！ 那些不尊重他人勞動成果，轉載不加出處的，或惡意行為的網站，還請你不要來進行交換了。 ","date":"2021-09-19","objectID":"/friends/:3:0","tags":null,"title":"友情鏈接","uri":"/friends/"},{"categories":null,"content":"互联网的广大朋友们，欢迎光临我的小博客！欢迎留言！","date":"2021-09-13","objectID":"/guestbook/","tags":null,"title":"留言","uri":"/guestbook/"},{"categories":null,"content":" Welcome 互联网的四海宾朋，我是HeZephyr，欢迎您莅临我的一方小天地！ 在此，诚邀您留下宝贵笔墨，让我们携手并肩，共探知识之海，同绘智慧长卷。 下面，请允许我为您呈上一首千古绝唱： 《将进酒》 君不见黄河之水天上来，奔流到海不复回。 君不见高堂明镜悲白发，朝如青丝暮成雪。 人生得意须尽欢，莫使金樽空对月。 天生我材必有用，千金散尽还复来。 烹羊宰牛且为乐，会须一饮三百杯。 —— 李白 在欣赏这首诗歌的同时，不妨点击下方的音乐播放器，让美妙的旋律陪伴您的阅读之旅。 温馨提示，音乐自动播放，请带好耳机～ From playlist, Powered By mmt-netease 给博主买杯卡布奇诺～ 赞赏 支付宝 微信 ","date":"2021-09-13","objectID":"/guestbook/:0:0","tags":null,"title":"留言","uri":"/guestbook/"},{"categories":["数据结构与算法"],"content":"1 前言 学了这么久，说真的，动态规划是一个特别难的领域，而状压$DP$我感觉是其中一个比较难的分支，其中的状态定义、状态转移、状态计算都是难点。如果要完全搞懂状压$DP$是需要花很多时间去吸收去实践的，所以建议读者多刷$DP$题。同时，学习本文的先修知识为二进制位运算操作、基础动态规划和动态规划的分析。这里指路一篇二进制讲解$blog$:点这里。 ","date":"2021-05-31","objectID":"/posts/02.%E7%8A%B6%E5%8E%8Bdp/:1:0","tags":["状压DP"],"title":"状压DP学习总结+经典例题精解","uri":"/posts/02.%E7%8A%B6%E5%8E%8Bdp/"},{"categories":["数据结构与算法"],"content":"2 状态压缩 我们知道状态压缩，顾名思义，就是需要考虑的状态非常多，我们如果用平常的思想去表示状态，那是非常不现实的，在时间和空间上都不允许，我们使用某种方法，以最小的代价表示某种状态。 那么，这通常是用进制来表示状态的，而选择几进制则根据要求使用的对象的点的状态有几种。一般来说，只有$0$和$1$，我们则是用二进制来表示，当然也有其他进制的题，在例题中会列举，需要我们灵活变通，主要谈二进制。 那么如何用二进制表示状态呢？我们发现，二进制上是按位分的，那么我们每一位可以看成一个点，而点上的取值则为该点的状态或者选择。例如$00001001$这个状态则表示第一个点和第四个点状态为$1$，其余的点状态为$0$。所以按照这种思想，我们能抽象的表示出一个很复杂的状态，实现了时间和空间的优化。 知道了这个，我们就按照正常动态规划的思想去写这类题目即可。 ","date":"2021-05-31","objectID":"/posts/02.%E7%8A%B6%E5%8E%8Bdp/:2:0","tags":["状压DP"],"title":"状压DP学习总结+经典例题精解","uri":"/posts/02.%E7%8A%B6%E5%8E%8Bdp/"},{"categories":["数据结构与算法"],"content":"3 使用场景 由上我们知道，状态压缩其实是有适用环境的： 状态需要有一定的状态单元。 即一个状态应该是保存一个集合，其中的元素值对应着$0$或$1$，例如我们常见的棋盘，我们可以用$0$或$1$来表示棋子的放置状态。而整个集合即是一个$01$串，即二进制数，我们通常用十进制表示。那么我们再进行状态转移或者判断的时候，需要先将十进制转化为二进制，再将二进制转化为十进制。 题目中限制的集合大小不会超过$20$。 这是最显著的特征，为什么呢？我们知道如果用二进制表示状态，那么集合大小为$20$的二进制状态有$2^{20} - 1$，已经达到$1e7$的数量级了。 具有动态规划的特性。 对于动态规划，一般都是要求最优化某个值，具有最优子结构的性质。同时也需要满足状态转移的特性，而不是前一个状态毫无关系的。 ","date":"2021-05-31","objectID":"/posts/02.%E7%8A%B6%E5%8E%8Bdp/:3:0","tags":["状压DP"],"title":"状压DP学习总结+经典例题精解","uri":"/posts/02.%E7%8A%B6%E5%8E%8Bdp/"},{"categories":["数据结构与算法"],"content":"4 常用模板 下面的模板适用于大多数题目，特殊题目需要灵活变动，总之，多刷题自然就都会了。 int n; int maxn = 1 \u003c\u003c n;//总状态数。 //枚举已有的集合数。按照状态转移的顺序，一般从小编号到大编号。 for(int i = 1; i \u003c= m; ++ i){ //枚举当前集合中的状态。 for(int j = 0; j \u003c maxn; ++ j){ //判断当前集合是否处于合法状态，通常我们需用一个数组提前处理好。如g数组; if(当前状态是否合格){ for(int k = 0; k \u003c maxn; ++ k){ //枚举上一个集合的状态。 if(上一个集合的状态是否合格 + 上一个集合的状态和当前状态的集合是否产生了冲突){ 列写状态转移方程。 } } } } } } ","date":"2021-05-31","objectID":"/posts/02.%E7%8A%B6%E5%8E%8Bdp/:4:0","tags":["状压DP"],"title":"状压DP学习总结+经典例题精解","uri":"/posts/02.%E7%8A%B6%E5%8E%8Bdp/"},{"categories":["数据结构与算法"],"content":"5 经典例题 ","date":"2021-05-31","objectID":"/posts/02.%E7%8A%B6%E5%8E%8Bdp/:5:0","tags":["状压DP"],"title":"状压DP学习总结+经典例题精解","uri":"/posts/02.%E7%8A%B6%E5%8E%8Bdp/"},{"categories":["数据结构与算法"],"content":"5.1 5.1 USACO06NOV Corn Fields G 题面 农场主John新买了一块长方形的新牧场，这块牧场被划分成M行N列(1 ≤ M ≤ 12; 1 ≤ N ≤ 12)，每一格都是一块正方形的土地。John打算在牧场上的某几格里种上美味的草，供他的奶牛们享用。 遗憾的是，有些土地相当贫瘠，不能用来种草。并且，奶牛们喜欢独占一块草地的感觉，于是John不会选择两块相邻的土地，也就是说，没有哪两块草地有公共边。 John想知道，如果不考虑草地的总块数，那么，一共有多少种种植方案可供他选择？（当然，把新牧场完全荒废也是一种方案） 输入格式 第一行：两个整数M和N，用空格隔开。 第2到第M+1行：每行包含N个用空格隔开的整数，描述了每块土地的状态。第i+1行描述了第i行的土地，所有整数均为0或1，是1的话，表示这块土地足够肥沃，0则表示这块土地不适合种草。 输出格式 一个整数，即牧场分配总方案数除以100,000,000的余数。 输入 2 3 1 1 1 0 1 0 输出 9 解题思路 我们先作出规定，定义$n$代表的是行，$m$代表的是列。那么牧场大小就是$n\\times m$。我们看到数据范围,$n,m$都特别小，同时所求为方案数，这很符合状压DP的适用条件。那么对于每一行，我们就可以看成一个未知集合，而集合的大小自然就是列$m$。对于每一个单元，其取值范围为$0,1$，而$1$代表放置奶牛，$0$代表不放置奶牛，所以我们自然可以用二进制表示，那么状态总数就是$(1 « m) - 1$。 对于每一个状态，我们需要判断是否合格，而其中明确不能选择两块相邻的土地，在集合内，即相邻位不能全为$1$，所以我们可以预处理$g$数组，处理方式即为:g[i] = !(i \u0026 (i \u003c\u003c 1))；同样，我们还应该知晓土地的状况，因为毕竟只有土地肥沃才可以放置奶牛，则我们可以通过一个$st$数组判断，集合与集合之间，我们也需要考虑相邻位不能全为$1$，所以在枚举上一个集合的状态也需要严格判断。对于状态定义，我们可以用$f[i][j]$表示第$i$行且状态为$j$的方案数。对于状态转移，假设上一行状态为$k$，则状态转移方程为： $f[i][j] += f[i - 1][k]$ 具体见$AC$代码。 AC代码 /** *@filename:Corn Field G *@author: pursuit *@csdn:unique_pursuit *@email: 2825841950@qq.com *@created: 2021-05-28 16:50 **/ #include \u003cbits/stdc++.h\u003e using namespace std; typedef long long ll; const int N = 10 + 5,M = 10 + 5; const int P = 1e8; int n,m;//n行m列的土地。 int a[N][M],st[N];//a代表土地，st代表每一行的土地状况。 bool g[1 \u003c\u003c N];//g得到所有状态中的合法状态。 int f[N][1 \u003c\u003c N];//f[i][j]表示的则是第i行且状态为j的方案数，是由上一行转移过来的，所以我们定义上一行的状态为k。 //则状态转移方程为f[i][j] += f[i - 1][k];//其中j和k必须满足条件。 void solve(){ } int main(){ scanf(\"%d%d\", \u0026n, \u0026m); for(int i = 1; i \u003c= n; ++ i){ for(int j = 1; j \u003c= m; ++ j){ scanf(\"%d\", \u0026a[i][j]); } } //得到每一行的土地状况。 for(int i = 1; i \u003c= n; ++ i){ for(int j = 1; j \u003c= m; ++ j){ st[i] = (st[i] \u003c\u003c 1) + a[i][j]; } } //得到所有状态中的合法状态。 int maxn = 1 \u003c\u003c m;//总状态。 f[0][0] = 1;//初始化，这种也算一种。 for(int i = 0; i \u003c maxn; ++ i){ g[i] = !( i \u0026 (i \u003c\u003c 1));//由于不能相邻，所以我们左移判断是否符合条件。 } for(int i = 1; i \u003c= n; ++ i){ //枚举每一行。 for(int j = 0; j \u003c maxn; ++ j){ //枚举每一行的状态，判断此状态是否符合条件。1.不能相邻。2.是全部状态的子集。 if(g[j] \u0026\u0026 (j \u0026 st[i]) == j){ //如果符合条件。则我们去判断上一行是否符合。 for(int k = 0; k \u003c maxn; ++ k){ //枚举上一行状态。注意，这里我们无需判断上一行状态是否存在，因为不存在即为0. //只需要判断j和k是否存在相邻草地。 if(!(j \u0026 k)){ f[i][j] = (f[i][j] + f[i - 1][k]) % P; } } } } } int ans = 0; for(int j = 0; j \u003c maxn; ++ j){ ans = (ans + f[n][j]) % P; } printf(\"%d\\n\", ans); solve(); return 0; } ","date":"2021-05-31","objectID":"/posts/02.%E7%8A%B6%E5%8E%8Bdp/:5:1","tags":["状压DP"],"title":"状压DP学习总结+经典例题精解","uri":"/posts/02.%E7%8A%B6%E5%8E%8Bdp/"},{"categories":["数据结构与算法"],"content":"5.2 5.2 吃奶酪 题面 房间里放着$n$块奶酪。一只小老鼠要把它们都吃掉，问至少要跑多少距离？老鼠一开始在 $(0,0)$点处。 输入格式 第一行有一个整数，表示奶酪的数量 n。 第 22 到第 (n + 1)行，每行两个实数，第 $(i + 1)$行的实数分别表示第 $i$ 块奶酪的横纵坐标 $x_i, y_i$。 输出格式 输出一行一个实数，表示要跑的最少距离，保留 2位小数。 输入 #1 4 1 1 1 -1 -1 1 -1 -1 输出 #1 7.41 数据规模与约定 对于全部的测试点，保证 $1\\leq n\\leq 15，|x_i|, |y_i| \\leq 200$，小数点后最多有 3位数字。 提示 对于两个点$$ (x_1,y_1)，(x_2, y_2)$$，两点之间的距离公式为$\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$。 解题思路 同样，根据数据量等信息我们很容易发现这是一个状压$DP$。奶酪的状态无非两种$0,1$，而根据题意我们的集合数量只有$1$个，集合大小自然是奶酪的数量，而奶酪有$n$个，所以我们的集合情况也有$(1 « n)-1$种，同样在此题我们需要先初始化好奶酪的合法状态，用$g$数组表示，更严格的说，$g[i]$表示第$i$个奶酪所在的二进制中的位置，用十进制数表示 。由于我们还需要计算距离，所以我们需要将每个点之间的距离也求出来，用$dist$数组预处理奶酪之间的距离以及起点与各个奶酪的距离。 那么在状态定义上，我们可以用$f[i][j]$表示当前为$i$状态，且处于第$j$个奶酪的最小距离，故状态转移方程易知为： $f[i][j]=min(f[i][j],f[i-g[j]][k]+dist[k][j])$ 据此，题目可解，具体看代码。 AC代码 /** *@filename:吃奶酪 *@author: pursuit *@csdn:unique_pursuit *@email: 2825841950@qq.com *@created: 2021-05-30 14:20 **/ #include \u003cbits/stdc++.h\u003e #define x first #define y second using namespace std; typedef long long ll; typedef pair\u003cdouble,double\u003e pdd; const int N = 16; const int P = 1e9+7; int n; pdd a[N]; double dist[N][N];//dist[i][j]表示第i个奶酪到第j个奶酪的距离。 int g[1 \u003c\u003c N];//奶酪的状态。 double f[1 \u003c\u003c N][N];//f[i][j]表示当前为i状态，且处于第j个奶酪的最小距离。 pdd st; double get(pdd a,pdd b){ return sqrt(pow(a.x - b.x,2) + pow(a.y - b.y,2)); } void solve(){ //先计算距离。 st.x = 0,st.y = 0; for(int i = 1; i \u003c= n; ++ i){ dist[0][i] = get(st,a[i]); } for(int i = 1; i \u003c= n; ++ i){ for(int j = 1; j \u003c= n; ++ j){ dist[i][j] = get(a[i],a[j]); } } int maxn = 1 \u003c\u003c n; //初始化奶酪的状态。 g[1] = 1; for(int i = 2; i \u003c= n; ++ i){ g[i] = g[i - 1] \u003c\u003c 1; } //初始化最大值。 fill(f[0],f[0] + (1 \u003c\u003c N) * N,0x3f3f3f3f); //确定只吃了一个奶酪的距离。 for(int i = 1; i \u003c= n; ++ i){ f[g[i]][i] = dist[0][i]; } f[0][0] = 0;//最开始自然为0，0. for(int i = 0; i \u003c maxn ; ++ i){ //枚举所有状态。 for(int j = 1; j \u003c= n; ++ j){ if(i \u0026 g[j]){ //该状态如果包含此奶酪就跳过。 for(int k = 1; k \u003c= n; ++ k){ if(k != j \u0026\u0026 i \u0026 g[k]){ //说明符合条件。 f[i][j] = min(f[i][j],f[i - g[j]][k] + dist[k][j]);//进行状态转移。 } } } } } double maxx = 0x3f3f3f3f; for(int i = 1; i \u003c= n; ++ i){ maxx = min(maxx,f[maxn - 1][i]); } printf(\"%.2lf\\n\",maxx); } int main(){ scanf(\"%d\", \u0026n); for(int i = 1; i \u003c= n; ++ i){ scanf(\"%lf%lf\", \u0026a[i].x, \u0026a[i].y); } solve(); return 0; } ","date":"2021-05-31","objectID":"/posts/02.%E7%8A%B6%E5%8E%8Bdp/:5:2","tags":["状压DP"],"title":"状压DP学习总结+经典例题精解","uri":"/posts/02.%E7%8A%B6%E5%8E%8Bdp/"},{"categories":["数据结构与算法"],"content":"5.3 5.3 USACO13NOV No Change G 题面 约翰到商场购物，他的钱包里有K(1 \u003c= K \u003c= 16)个硬币，面值的范围是1..100,000,000。 约翰想按顺序买 N个物品(1 \u003c= N \u003c= 100,000)，第i个物品需要花费c(i)块钱，(1 \u003c= c(i) \u003c= 10,000)。 在依次进行的购买N个物品的过程中，约翰可以随时停下来付款，每次付款只用一个硬币，支付购买的内容是从上一次支付后开始到现在的这些所有物品（前提是该硬币足以支付这些物品的费用）。不幸的是，商场的收银机坏了，如果约翰支付的硬币面值大于所需的费用，他不会得到任何找零。 请计算出在购买完N个物品后，约翰最多剩下多少钱。如果无法完成购买，输出-1 输入格式 *Line 1: Two integers, K and N. * Lines 2..1+K: Each line contains the amount of money of one of FJ’s coins. * Lines 2+K..1+N+K: These N lines contain the costs of FJ’s intended purchases. 输出格式 * Line 1: The maximum amount of money FJ can end up with, or -1 if FJ cannot complete all of his purchases. 输入 #1 3 6 12 15 10 6 3 3 2 3 7 输出 #1 12 说明/提示 FJ has 3 coins of values 12, 15, and 10. He must make purchases in sequence of value 6, 3, 3, 2, 3, and 7. FJ spends his 10-unit coin on the first two purchases, then the 15-unit coin on the remaining purchases. This leaves him with the 12-unit coin. 解题思路 此题状态定义比较简单，因为实际上我们只在乎了硬币的花费，这已经是一个集合了，花费为$1$不花费为$0$，而其他并不用在乎。所以我们完全可以用$f[i]$表示在$i$状态下能够购买的最大物品数。此题难点在于状态转移。同样在此题我们需要先初始化好硬币的合法状态，用$g$数组表示，更严格的说，$g[i]$表示第$i$个硬币所在的二进制中的位置。用十进制数表示。为了方便处理，我们需要用前缀和来优化本题，因为在处理过程中我们随时都要计算当前已有的总价值能够换取多少物品。 同样，在状态转移方面，我们需要根据前面的状态得到后者的状态，而由于我们是从小到大枚举状态的，故一定可以利用前面的状态而不会出现前面状态不是最优解，我们对于每一种状态，我们可以排除一个硬币获取前面的最优解，即枚举该状态已有的硬币，通过异或排除，最后利用二分查找所能购买的最大值得到最优解。 说起来有点乱，详情可见$AC$代码。 AC代码 /** *@filename:No_Change_G *@author: pursuit *@csdn:unique_pursuit *@email: 2825841950@qq.com *@created: 2021-05-28 17:14 **/ #include \u003cbits/stdc++.h\u003e using namespace std; typedef long long ll; const int N = 1000000 + 5,K = 20; const int P = 1e9+7; int n,k; int g[K];//每个硬币的状态。 int w[K];//硬币的价值 int sum[N];//物品价值的前缀和。 int ans; int f[1 \u003c\u003c K];//f[i]表示在i状态下能够购买的最大物品数。 void solve(){ //初始化硬币状态。 g[1] = 1; for(int i = 2; i \u003c= k; ++ i){ g[i] = g[i -1] \u003c\u003c 1; } int maxn = 1 \u003c\u003c k;//得到 for(int i = 0; i \u003c maxn; ++ i){ //枚举每一种状态。 for(int j = 1; j \u003c= k; ++ j){ //枚举所有的硬币。 if(i \u0026 g[j]){ //说明该硬币在当前状态使用过。 int te = f[i ^ g[j]];//获取该状态不使用j能获得的物品数。 te = upper_bound(sum + 1,sum + n + 1,sum[te] + w[j]) - sum;//这里需要减1. f[i] = max(f[i],te - 1); } } } ll maxx = -2,temp; for(int i = 0; i \u003c maxn; ++ i){ if(f[i] == n){ //说明该状态能够将所有物品都买完。 temp = 0; for(int j = 1; j \u003c= k; ++ j){ if(i \u0026 g[j]){ temp += w[j]; } } maxx = max(maxx,ans - temp); } } if(maxx \u003c 0)printf(\"%d\\n\", -1); else printf(\"%d\\n\",maxx); } int main(){ scanf(\"%d%d\", \u0026k , \u0026n); for(int i = 1; i \u003c= k; ++ i){ scanf(\"%d\", \u0026w[i]); ans += w[i];//求硬币总价值。 } for(int i = 1; i \u003c= n; ++ i){ scanf(\"%d\", \u0026sum[i]); sum[i] += sum[i - 1]; } solve(); return 0; } ","date":"2021-05-31","objectID":"/posts/02.%E7%8A%B6%E5%8E%8Bdp/:5:3","tags":["状压DP"],"title":"状压DP学习总结+经典例题精解","uri":"/posts/02.%E7%8A%B6%E5%8E%8Bdp/"},{"categories":["数据结构与算法"],"content":"5.4 5.4 SCOI2005互不侵犯 题面 在N×N的棋盘里面放K个国王，使他们互不攻击，共有多少种摆放方案。国王能攻击到它上下左右，以及左上左下右上右下八个方向上附近的各一个格子，共8个格子。 输入格式 只有一行，包含两个数N，K （ 1 \u003c=N \u003c=9, 0 \u003c= K \u003c= N * N） 输出格式 所得的方案数 输入 #1 3 2 输出 #1 16 解题思路 这道题跟$5.1$例题有点相似，只不过这里多了左上左下右上右下这几个点，处理方法一样，我们需要知道每个状态的放置国王数，所以这我们需要预处理。定义状态$f[i][j][k]$表示在第$i$行且处于$j$状态时已经放置了$k$个国王。其他的处理方式和$5.1$相同，这里不作叙述，可见$AC$代码。 AC代码 /** *@filename:互不侵犯 *@author: pursuit *@csdn:unique_pursuit *@email: 2825841950@qq.com *@created: 2021-05-31 16:32 **/ #include \u003cbits/stdc++.h\u003e using namespace std; typedef long long ll; const int N = 10; const int P = 1e9+7; int n,m; int tot,num[1 \u003c\u003c N];//num[i]表示第i种可行状态的国王所放数量。 ll f[N][1 \u003c\u003c N][N * N];//f[i][j][k]表示前i行，当前处于j状态且已经放置了k个国王。 int get(int x){ //获取该状态有多少国王。 int sum = 0; for(int i = 0; i \u003c n; ++ i){ sum += (x \u0026 1); x \u003e\u003e= 1; } return sum; } void init(){ int maxn = 1 \u003c\u003c n; for(int i = 0; i \u003c maxn; ++ i){ if(i \u0026 (i \u003c\u003c 1))continue;//说明存在相邻的。 num[i] = get(i); f[1][i][num[i]] = 1; } } void solve(){ init(); int maxn = 1 \u003c\u003c n; for(int i = 2; i \u003c= n; ++ i){ for(int j = 0; j \u003c maxn; ++ j){ //枚举所有状态。 if(j \u0026 (j \u003c\u003c 1))continue; for(int k = 0; k \u003c maxn; ++ k){ //枚举上一行的所有状态。 if(((k \u0026 (k \u003c\u003c 1)) || j \u0026 k || ((j \u003c\u003c 1) \u0026 k) || (j \u0026 (k \u003c\u003c 1)))){ continue; } for(int cnt = num[j]; cnt \u003c= m; ++ cnt){ f[i][j][cnt] += f[i - 1][k][cnt - num[j]]; } } } } ll ans = 0; for(int i= 0; i \u003c maxn; ++ i){ ans += f[n][i][m]; } printf(\"%lld\\n\",ans); } int main(){ scanf(\"%d %d\", \u0026n, \u0026m); solve(); return 0; } ","date":"2021-05-31","objectID":"/posts/02.%E7%8A%B6%E5%8E%8Bdp/:5:4","tags":["状压DP"],"title":"状压DP学习总结+经典例题精解","uri":"/posts/02.%E7%8A%B6%E5%8E%8Bdp/"},{"categories":["数据结构与算法"],"content":"1 位运算概述 我们知道，计算机中的数在内存中都是以二进制形式进行存储的 ，而位运算就是直接对整数在内存中的二进制位进行操作，因此其执行效率非常高，在程序中尽量使用位运算进行操作，这会大大提高程序的性能。 那么，涉及位运算的运算符如下表所示： 符号 描述 运算规则 实例（以四位二进制数为例） \u0026 与 两个位都为1时，结果才为1。 $0001\u00260001=1,0001\u00260000=0,0000\u00260000=0000$ | 或 两个位都为0时，结果才为0。 $0001|0001=0001,0001|0000=0001,0000|0000=0000$ ^ 异或 两个位相同为0，相异为1。 $0001 \\wedge0001=0000,0001\\wedge0000=1,0000\\wedge 0000=0$ ~ 取反 0变1，1变0。 $\\sim0=1,\\sim 1 = 0$ « 左移 各二进位全部左移若干位，高位丢弃，低位补0。 $0001«k=0100，k=2$，$k$是左移的位数，这里$k=2$ » 右移 各二进位全部右移若干位，对无符号数，高位补0，有符号数，右移补$1$。 $0100»k=0001，k=2$，$k$是右移的位数，这里$k=2$ 看完，你可能会觉得挺简单的， 但位运算的难点并不在这，而在于其性质、高级操作和它的应用。 ","date":"2021-05-28","objectID":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/:1:0","tags":["位运算"],"title":"位运算全面总结","uri":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/"},{"categories":["数据结构与算法"],"content":"2 位运算的性质 ","date":"2021-05-28","objectID":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/:2:0","tags":["位运算"],"title":"位运算全面总结","uri":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/"},{"categories":["数据结构与算法"],"content":"2.1 运算符的优先级 优先级需要弄清楚，如果不太清楚可以加小括号确保是想要的运算顺序，这里只是相对优先级，即只是和一些常用的算术运算符做比较。 优先级 运算符 结合方向 1 $-（符号运算符）,\\sim（取反运算符）， ++（自增），–（自减）$ 从右到左 2 $*（乘）,/（除）,%（取余）$ 从左到右 3 $+（加）,-（减）$ 从左到右 4 $«（左移），»（右移）$ 从左到右 5 $\u003e（大于）,\u003c(小于),\u003e=(大于等于),\u003c=(小于等于)$ 从左到右 6 $==(等于),!=（不等于）$ 从左到右 7 $\u0026（按位与）$ 从左到右 8 $\\wedge (按位异或)$ 从左到右 9 $|(按位或)$ 从左到右 ","date":"2021-05-28","objectID":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/:2:1","tags":["位运算"],"title":"位运算全面总结","uri":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/"},{"categories":["数据结构与算法"],"content":"2.2 位运算符的运算律 公式名称 运算规则 交换律 $A\u0026B=B\u0026A ,A\\wedge B=B\\wedgeA$ 结合律（注意结合律只能在同符号下进行） $(A\u0026B)\u0026C=A\u0026(B\u0026C)$ 等幂律 $A\u0026A=A，A|A=A$ 零律 $A\u00260=0$ 互补律（注意，这不同于逻辑运算） $A\u0026\\sim A=0, A|\\sim A=-1$ 同一律 $A|0=A, A\\wedge 0 =A$ 以上仅为已证明的运算律（可能存在遗漏），其余的博主均认为是不符合不成立的，注意：千万不要将逻辑运算的运算律或者其他的运算律与这混为一谈。 ","date":"2021-05-28","objectID":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/:2:2","tags":["位运算"],"title":"位运算全面总结","uri":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/"},{"categories":["数据结构与算法"],"content":"3 位运算高级操作 如下表，请读者认真阅读理解，在阅读的过程中可以对示例进行运算。 功能 示例 位运算 去掉最后一位 $0100-\u003e0010$ $x»1$ 在最后加一个$0$ $0100-\u003e1000$ $x«1$ 在最后加一个1 $0100-\u003e1001$ $(x«1)+1$ 将最后一位变为$1$ $0100-\u003e0101$ $x|1$ 将最后一位变为$0$ $0101-\u003e0100$，这里实际上就是先确保最低位变为$1$，再减去$1$。 $(x|1)-1$ 最后一位取反 $0100-\u003e0101$ ，利用异或性质，其中除最后一位其余不变。 $x\\wedge1$ 把右数的第$k$位变为$1$ $0001-\u003e1001,k=4$ $x|(1«(k-1))$ 把右数的第$k$位变为$0$ $1001-\u003e0001,k=4$，这个操作实际上就是先得到了$1000$，然后取反得到$0111$，最后利用按位与的性质其余位不变，最高位为$0$ $x\u0026(\\sim(1«(k-1)))$ 把右数的第$k$位取反 $1000-\u003e0000,k=4$，利用异或性质 $x\\wedge (1«(k-1))$ 由于表长限制，这里接下表继续： 功能 示例 位运算 取末$k$位 $1011-\u003e0011,k=2$ $x\u0026((1«k)-1)$ 取右数的第$k$位 $1011-\u003e0001,k=4$，右移$k-1$位则是去掉了最后的$k-1$位，我们利用按位与即可将其提取出来 $x»(k-1)\u00261$ 把末$k$位全变为$1$ $1000-\u003e1111,k=3$ $x|((1«k)-1)$ 把末$k$位取反 $0101-\u003e1010,k=4$ $x\\wedge ((1«k)-1)$ 把右边连续的$1$变为$0$ $0111-\u003e0000$ ，注意是右起连续的$1$ $x\u0026(x+1)$ 把右起的第一个$0$变为$1$ $0011-\u003e0111$ $x|(x+1)$ 把右起连续的$0$变为$1$ $1000-\u003e1111$，注意是右起连续的$0$ $x|(x-1)$ 取右边连续的$1$ $1011-\u003e0011$ $(x\\wedge (x+1))»1$ 去掉右起的第一个$1$的左边 $1101-\u003e0001$ $x\u0026(x\\wedge (x-1))$ 当然，这里只是一些常用的，并不是全部，位运算的神奇远不止于此。 ","date":"2021-05-28","objectID":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/:3:0","tags":["位运算"],"title":"位运算全面总结","uri":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/"},{"categories":["数据结构与算法"],"content":"4 负数的位运算 首先，我们要知道，在计算机中，运算是使用的二进制补码，而正数的补码是它本身，负数的补码则是符号位不变，其余按位取反，最后再$+1$得到的， 例如： $15$,原码:$00001111\\space$补码:$00001111$ $-15$,原码:$10001111\\space$补码:$11110001$ 那么对于负数的位运算而言，它们的操作都是建立在补码上的，得到的运算结果是补码，最后将补码结果转化成一个普通的十进制数结果。 但需要注意的是，对于有符号数的右移操作，不同的处理器架构可能有不同的规定。在某些架构中（如x86），如果对有符号数执行算术右移（arithmetic right shift），则高位空出来的位置会补上符号位；对于无符号数的右移操作，所有架构都遵循相同的规则：高位空出来的位置会补0。例如对于$-15$，其补码为$11110001,$右移一位$(-15»1)$得到的是$11111000$，即$-8$，其他的同理。 在大多数现代处理器上，无论是有符号数还是无符号数，左移操作总是将空出来的低位补0。 这里我们介绍几个特殊的性质： 快速判断是否为$-1$ 在链式前向星中，我们初始化$head$数组为$-1$，最后判断是否遍历完$u$的所有边时，即判断$i$是否为$-1$，我们直接用$\\sim i$即可。原因就在于$-1$的补码是$11111111$，按位取反就变为$00000000$，这实际上就是$0$。 取最低位的$1$，lowbit函数 也就是$x\u0026(-x)$，这在树状数组中起着巨大作用，这里指路一篇树状数组讲解$blog$:点这里，我们来证明一下，这里取$x=15$，对于$15\u0026(-15)$，我们知道，在补码上进行运算得到的是$00000001$，需要注意二元运算的符号位我们需要进行运算。 ","date":"2021-05-28","objectID":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/:4:0","tags":["位运算"],"title":"位运算全面总结","uri":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/"},{"categories":["数据结构与算法"],"content":"5 位运算的一些应用 位运算实现乘除法 将$x$左移一位实现$\\times 2$，将$x$右移一位实现$\\div2$。 $a«1 \\equiv a*2$ $a »1 \\equiv a/2$ 位运算交换两整数 void swap(int \u0026a,int \u0026b){ a ^= b; b ^= a; a ^= b; } 这效率非常高，我们来剖析其原理，对于$a=a\\wedge b$，则$b = b\\wedge(a\\wedge b)$，根据交换律以及异或性质，得$b=b\\wedge b\\wedge a=0\\wedge a=a$，同理$a=(a\\wedge b)\\wedge a=0\\wedge b=b$。这样就实现了交换操作。 位运算判断奇偶数 我们知道，在二进制中，最低位决定了是奇数还是偶数，所以我们可以提取出最低位的值，即与$1$相与即可实现目的，为$0$则是偶数，为$1$则是奇数。 位运算改变正负性和求绝对值 int change(int a){ return ~ a + 1; } 对于正数而言，补码就是原码，所以按位取反再$+1$则得到对应真值负数的补码，而对于负数，其补码进行按位取反再$+1$则得到对应真值正数的补码，变为原码。那么知道这个我们就可以特判是否为负数 ==（这里通过右移$31$位，若为正数，则得到的是$0$，若为负数，则得到的是$-1$，而$0$的补码为$0000$,$-1$的补码为$1111$，根据异或性质即可判断感谢读者 （恢。）指出错误，这里应该是要进行按位取反操作，这样如果为负数判断结果才为0 。）== ，利用条件表达式就可以根据判断结果求绝对值了。如下： int abs(int a){ return ~(a \u003e\u003e 31) ? a : ~a + 1; } 位运算实现对$p$取余（p为$2^k$） int mod(int a,int p){ return a \u0026 (p - 1); } 取余实际上就是舍去大于等于$p$的位数，所以我们只需要保留在$p$范围内的数。由于我们限定了$p$为$2^k$，所以$(p - 1)$一定是将小于$p$的最高位全部变为了$1$，这样再进行与操作即可得到余数。 位运算统计二进制数$1$的个数 int count(int x){ int cnt = 0; while(x){ x = x \u0026 (x - 1); cnt ++; } return cnt; } 对于任意的$x$，转换成二进制后，是形如这样的数字：$aa…aa10…00$，从右向左数有任意多个$0$，直到遇见第一个$1$，字母$a$用来占位，代表$1$左边的任意数字。$x-1$转换成二进制后，是形如这样的数字：$aa…aa01…11$，从右向左数，原来的任意多个$0$都变成$1$，原来的第一个$1$，变成$0$，字母$a$部分不变。对$x$ 和 $x-1$ 进行 按位与 计算，会得到：$aa…aa00…00$，从右向左数，原来的第一个$1$变成了$0$，字母a部分不变。所以 $x \u0026 (x-1)$相当于消除了 $x$ 从右向左数遇到的第一个$1$。那么，$x$转换成二进制后包含多少个$1$，count函数里的循环就会进行多少次，直到$x$所有的$1$都被“消除”。 ","date":"2021-05-28","objectID":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/:5:0","tags":["位运算"],"title":"位运算全面总结","uri":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/"},{"categories":["数据结构与算法"],"content":"6 位运算例题 ","date":"2021-05-28","objectID":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/:6:0","tags":["位运算"],"title":"位运算全面总结","uri":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/"},{"categories":["数据结构与算法"],"content":"6.1 更新二进制位 题面 给出两个32位的整数N和M，以及两个二进制位的位置i和j。写一个方法来使得N中的第i到j位等于M（M会是N中从第i为开始到第j位的子串） 样例： 输入: N=(10000000000)2 M=(10101)2 i=2 j=6 输出: N=(10001010100)2 输入: N=(10000000000)2 M=(11111)2 i=2 j=6 输出: N=(10001111100)2 解题思路 结合所学，我们的思路应该就是先将第$i$位到第$j$位全部变为$0$，再将与左移$i$位的$M$进行或操作。 AC代码 class Solution { public: int updateBits(int n, int m, int i, int j) { // 循环遍历从第 i 位到第 j 位 for(int pos = i; pos \u003c= j; pos ++ ){ // 将 n 的第 pos 位设为 0 // ~(1 \u003c\u003c pos) 创建一个在第 pos 位为 0 其他位为 1 的掩码 // 然后使用按位与运算符（\u0026）来将 n 的第 pos 位设置为 0 n \u0026= ~(1 \u003c\u003c pos); } // 将 m 左移 i 位，使 m 的低位对齐到 n 的第 i 位 // 然后使用按位或运算符（|）合并 n 和 m // 这样 n 的第 i 到第 j 位就被 m 的相应位所替换 return n | (m \u003c\u003c i); } }; ","date":"2021-05-28","objectID":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/:6:1","tags":["位运算"],"title":"位运算全面总结","uri":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/"},{"categories":["数据结构与算法"],"content":"6.2 A+B问题 题面 给出两个整数 a 和 b , 求他们的和并以整数（int）的形式返回。不能使用 + 等数学运算符。 样例： 输入： a = 1 b = 2 输出： 3 输入： a = -1 b = 1 输出： 0 解题思路 这题我们可以利用异或操作来实现，因为异或操作有一个别名叫不进位加法。那么进位操作我们实际上就可以通过$a\u0026b$来实现，因为$a\u0026b$得到的都是$a$和$b$上都有的$1$，我们再左移即得到的是进位之后的结果，所以$a+b=(a\\wedge b)+(a\u0026b«1)$。通过这样模拟竖式加法操作即可。 AC代码 class Solution { public: int aplusb(int a, int b) { // 当没有进位需要处理时循环结束 while(b != 0){ // temp_a 存储 a 和 b 的按位异或结果，这相当于不带进位的加法 int temp_a = a ^ b; // temp_b 存储 a 和 b 的按位与结果并左移一位，这相当于计算进位 // 因为只有两个位都是1时才会产生进位 int temp_b = (a \u0026 b) \u003c\u003c 1; // 更新 a 为不带进位的加法结果 a = temp_a; // 更新 b 为进位 b = temp_b; } // 当没有进位时，a 中存储了最终结果，返回 a return a; } }; ","date":"2021-05-28","objectID":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/:6:2","tags":["位运算"],"title":"位运算全面总结","uri":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/"},{"categories":["数据结构与算法"],"content":"6.3 O(1)时间检测2的幂次 题面 用 O(1) 时间检测整数 n 是否是 2 的幂次。 样例 n=4，返回 true; n=5，返回 false. 挑战 O(1) 时间复杂度 解题思路 首先我们知道$2^k$是大于$0$的，这里我们需要特判，同理，$2^k$的二进制表示中只有$1$个$1$，故我们可以利用$x\u0026(x-1)$来消除唯一的$1$判断是否等于$0$即可。 AC代码 class Solution { public: bool checkPowerOf2(int n) { // 检查 n 是否大于 0 // 2 的幂必须是正数，因为 0 和负数都不是 2 的幂 // 检查 n 和 n - 1 的按位与操作是否为 0 // 如果 n 是 2 的幂，则其二进制表示中只有一个 1 // 例如 2 (10), 4 (100), 8 (1000) // 当 n 是 2 的幂时，n - 1 的二进制表示是 n 的最高位 1 变为 0， // 其余位从 0 变为 1，例如 2 (10) - 1 = 1 (01), 4 (100) - 1 = 3 (011) // 因此 n \u0026 (n - 1) 将得到 0 return n \u003e 0 \u0026\u0026 (n \u0026 (n - 1)) == 0; } }; ","date":"2021-05-28","objectID":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/:6:3","tags":["位运算"],"title":"位运算全面总结","uri":"/posts/01.%E4%BD%8D%E8%BF%90%E7%AE%97%E5%85%A8%E9%9D%A2%E6%80%BB%E7%BB%93/"},{"categories":["数据结构与算法"],"content":"不会数位$DP$的这里指路一篇介绍非常详细的数位$DP$的$blog$:点这里。 链接 恨7不成妻 题面 单身! 依然单身！ 吉哥依然单身！ DS级码农吉哥依然单身！ 所以，他生平最恨情人节，不管是214还是77，他都讨厌！ 吉哥观察了214和77这两个数，发现： $2+1+4=7$　$7+7=72$ $77=711$ 最终，他发现原来这一切归根到底都是因为和7有关！所以，他现在甚至讨厌一切和7有关的数！什么样的数和7有关呢？如果一个整数符合下面3个条件之一，那么我们就说这个整数和7有关—— 1、整数中某一位是7； 2、整数的每一位加起来的和是7的整数倍； 3、这个整数是7的整数倍； 现在问题来了：吉哥想知道在一定区间内和7无关的数字的平方和。 Input 输入数据的第一行是case数T(1 \u003c= T \u003c= 50)，然后接下来的T行表示T个case;每个case在一行内包含两个正整数L, R(1 \u003c= L \u003c= R \u003c= 10^18)。 Output 请计算[L,R]中和7无关的数字的平方和，并将结果对10^9 + 7 求模后输出。 Sample Input 3 1 9 10 11 17 17 Sample Output 236 221 0 解题思路 根据题意我们做出预处理，利用闫式$DP$分析法分析如下： 以上只是简单分析，我们还并没有真正的进行状态转移和计算，那么根据题意，首先是需要知道整数的每一位加起来的和是$7$的整数倍以及该整数是$7$的整数倍，这个好处理，在我们的前面的题中有类似的题型，这已经在我们的$f$数组的第三维和第四维了。所以难点就在于怎么处理整数的平方和。我们看下面的公式推导： 我们用$jA$来表示$i$位数，而其中的$A$为$i-1$位数。设这个状态有$t$个符合要求的数，分别是$A_1$~$A_t$。 那么，平方和易得为： $(jA_1)^2+(jA_2)^2+(jA_3)^2+…+(jA_{t-1})^2+(jA_t)^2$ （我们分割表示将$A$提取出来。） $=(j10^{i-1}+A_1)^2+(j10^{i-1}+A_2)^2+(j10^{i-1}+A_3)^2+…+(j10^{i-1}+A_{t-1})^2+(j*10^{i-1}+A_t)^2$ （平方和公式） $=t*(j10^{i-1})^2+2(j10^{i-1})(A_1+…+A_t)+(A_1^2+…+A^2)$ 这样，在这个式子中，由于$j$已知，所以我们发现$f$数组需要保存三个值。$A$的$0$次方之和，也就是符合要求的数，$A$的$1$次方之和，也就是符合要求的除去$j$的$i-1$位数相加，$A$的$2$次方之和，也就是符合要求的除去$j$的$i-1$位数平方相加。我们分别用$s_0,s_1,s_2$ 分别代表上述的三个值。 那么这里我们需要怎么求$s_1$，如下： 注：这里的$s_1$为$i+1$位的$s_1$，而它存储的就是$i$位的$A$。 $jA_1+…+jA_t$ $=j*10^{i-1}+(A_1+…+A_t)$ 所以我们的$f$应该是一个结构体数组，它需要存取$s_0,s_1,s_2$。那么预处理根据上述分析其实就简单了。那么就按照数位$DP$的套路解决这道题即可。需要注意这道题好多坑点，多取模，足够细心才可以解决。（调$Bug$调了好久。快绝望了。） 代码 /** *@filename:恨7不成妻 *@author: pursuit *@csdn:unique_pursuit *@email: 2825841950@qq.com *@created: 2021-05-12 21:19 **/ #include \u003cbits/stdc++.h\u003e using namespace std; typedef long long ll; const int N = 20; const ll P = 1e9+7; //需要满足三个性质。 //1.不含7. //2.各位数字之和模7不为0.an-1+...+a0%7!=0. //3.该数模7不为0.an-1*pow(10,n-1)+...+a0+pow(10,0)%7!=0 struct F{ ll s0,s1,s2;//s0为符合要求的数。s1为符合要求的数1次方之和，s2为符合要求的数的2次方之和。 }f[N][10][7][7];//f[i][j][k][u]表示总共有i位数且最高位是j，该数值模7为k，各位数数字之和模7为u的所有数的s0,s1,s2. //进行初始化。 int t;//测试数。 ll l,r; ll power7[N],power9[N];//power7[i]存储10^i余7的余数，power9[i]存储10^i余P的余数。 ll mod(ll x,ll y){ return (x%y+y)%y; } void init(){ //确定初始值，位数为1的情况。 for(int j=0;j\u003c10;j++){ if(j==7)continue; //根据性质排除不符合要求的。 F \u0026v=f[1][j][j%7][j%7];//这里用引用减少代码量。 v.s0++; v.s1+=j; v.s2+=j*j; } ll power = 10;//辅助作用，表示10的i-1次方。 for(int i=2;i\u003cN;i++,power*=10){ for(int j=0;j\u003c10;j++){ if(j==7)continue;//排除不符合要求的数。 for(int k=0;k\u003c7;k++){ for(int u=0;u\u003c7;u++){ for(int q=0;q\u003c10;q++){ //枚举i-1的最高位。 if(q==7)continue; F \u0026x=f[i][j][k][u],y=f[i-1][q][mod(k-j*(power%7),7)][mod(u-j,7)]; //s0,s1,s2都是通过公式就算得到。 x.s0=mod(x.s0+y.s0,P); x.s1=mod(x.s1+1LL*j%P*(power%P)%P*y.s0%P+y.s1,P); x.s2=mod(x.s2+ 1LL*j%P*y.s0%P*(power%P)%P*j%P*(power%P)%P+ 1LL*y.s1%P*2%P*j%P*(power%P)%P+y.s2,P); } } } } } //这里处理为了方便以及降低时间复杂度。 power7[0]=1,power9[0]=1; for(int i=1;i\u003cN;i++){ power7[i]=power7[i-1]*10%7; power9[i]=power9[i-1]*10%P; } } F get(int i,int j,int k,int u){ //因为f[i][j][k][u]是本身模7等于k，且各位数之和模7等于u的，所以我们需要找出符合条件的集合。 ll s0=0,s1=0,s2=0; for(int x=0;x\u003c7;x++){ for(int y=0;y\u003c7;y++){ if(x==k||y==u)continue; F v=f[i][j][x][y]; s0=mod(s0+v.s0,P); s1=mod(s1+v.s1,P); s2=mod(s2+v.s2,P); } } return {s0,s1,s2}; } ll dp(ll n){ if(!n)return 0;//0的平方和为0. vector\u003cint\u003e a; ll temp=n%P;//备份一个n，供后面判断n使用。 while(n)a.push_back(n%10),n/=10; ll last_a=0,last_b=0;//这里我们需要存储前缀的本身值和前缀的个位数之和。 ll ans=0;//答案。 for(int i=a.size()-1;i\u003e=0;i--){ int x=a[i]; for(int j=0;j\u003cx;j++){ //走左分支。 if(j==7)continue; //我们需要将符合条件的数筛出来，这里要用到一个get函数。 //求得本身模7不等于a，并且各位数之和模7不等b的集合，此时就可以使用预处理出来的结构体 int k=mod(-last_a*power7[i+1],7),u=mod(-last_b,7); F v=get(i+1,j,k,u); //cout\u003c\u003cv.s0\u003c\u003c\" \"\u003c\u003cv.s1\u003c\u003c\" \"\u003c\u003cv.s2\u003c\u003cendl; //根据公式求解s2. //j就是last_a. ans=mod(ans+ 1LL*(last_a%P)*(last_a%P)%P*(power9[i+1]%P)%P*(power9[i+1]%P)%P*v.s0%P+ 1LL*2*last_a%P*(power9[i+1]%P)%P*v.s1%P+ v.s2,P); //cout\u003c\u003cans\u003c\u003cendl; } //判断x。 if(x==7)break; //走右分支更新。 last_a=last_a*10+x; last_b+=x; //判断自己本身是否符合要求。 if(!i\u0026\u0026last_a%7\u0026\u0026last_b%7){ ans=mod(ans+temp*temp%P,P); } } return ans; } int main(){ init(); cin\u003e\u003et; while(t--){ cin\u003e\u003el\u003e\u003er; cout\u003c\u003cmod(dp(r)-dp(l-1),P)\u003c\u003cendl; } return 0; } /* 1 1 1000000000000000000 */ ","date":"2021-05-13","objectID":"/posts/03.hdu-4507-%E6%81%A87%E4%B8%8D%E6%88%90%E5%A6%BB-%E6%95%B0%E4%BD%8Ddp%E5%A5%97%E8%B7%AF%E9%A2%98%E8%AF%A6%E7%BB%86%E8%A7%A3%E6%9E%90/:0:0","tags":["数位DP"],"title":"HDU 4507 恨7不成妻 （数位DP套路题）","uri":"/posts/03.hdu-4507-%E6%81%A87%E4%B8%8D%E6%88%90%E5%A6%BB-%E6%95%B0%E4%BD%8Ddp%E5%A5%97%E8%B7%AF%E9%A2%98%E8%AF%A6%E7%BB%86%E8%A7%A3%E6%9E%90/"},{"categories":["数据结构与算法"],"content":"1 数位DP介绍 数位DP往往都是这样的题型，给定一个闭区间$[l,r]$，让你求这个区间中满足某种条件的数的总数。而这个区间可能很大，简单的暴力代码如下： int ans=0; for(int i=l;i\u003c=r;i++){ if(check(i))ans++; } 我们发现，若区间长度超过$1e8$，我们暴力枚举就会超时了，而数位$DP$则可以解决这样的题型。数位$DP$实际上就是在数位上进行$DP$。 ","date":"2021-05-12","objectID":"/posts/01.%E6%95%B0%E4%BD%8Ddp/:1:0","tags":["数位DP"],"title":"数位DP学习整理","uri":"/posts/01.%E6%95%B0%E4%BD%8Ddp/"},{"categories":["数据结构与算法"],"content":"2 数位DP解法 数位$DP$就是换一种暴力枚举的方式，使得新的枚举方式符合$DP$的性质，然后预处理好即可。我们来看：我们可以用$f(n)$表示$[0,n]$的所有满足条件的个数，那么对于$[l,r]$我们就可以用$[l,r]\\iff f(r)-f(l-1)$，相当于前缀和思想。那么也就是说我们只要求出$f(n)$即可。那么数位$DP$关键的思想就是从树的角度来考虑。将数拆分成位，从高位到低位开始枚举。我们可以视$N$为$n$位数，那么我们拆分$N:a_{n}、a_{n-1}…a_1$。那么我们就可以开始分解建树，如下。之后我们就可以预处理再求解$f(n)$了，个人认为求解$f(n)$是最难的一步。 听完是不是有点绕，我们可以来点题目练习一下，做完就会发现了数位$DP$的套路了。 ","date":"2021-05-12","objectID":"/posts/01.%E6%95%B0%E4%BD%8Ddp/:2:0","tags":["数位DP"],"title":"数位DP学习整理","uri":"/posts/01.%E6%95%B0%E4%BD%8Ddp/"},{"categories":["数据结构与算法"],"content":"3 数位DP经典例题 ","date":"2021-05-12","objectID":"/posts/01.%E6%95%B0%E4%BD%8Ddp/:3:0","tags":["数位DP"],"title":"数位DP学习整理","uri":"/posts/01.%E6%95%B0%E4%BD%8Ddp/"},{"categories":["数据结构与算法"],"content":"3.1 3.1 度的数量 题面 求给定区间$ [X,Y]$ 中满足下列条件的整数个数：这个数恰好等于 $K$ 个互不相等的 $B$ 的整数次幂之和。例如，设 $X=15,Y=20,K=2,B=2$，则有且仅有下列三个数满足题意： $17=2^4+2^0$ $18=2^4+2^1$ $20=2^4+2^2$ 输入格式 第一行包含两个整数 X 和 Y，接下来两行包含整数 $K$ 和 $B$。 输出格式 只包含一个整数，表示满足条件的数的个数。 数据范围 $1≤X≤Y≤2^{31}−1,$ $1≤K≤20,$ $2≤B≤10$ 输入样例： 15 20 2 2 输出样例： 3 解题思路 此题实际上就是将十进制数转化为$B$进制数，判断位数上的值是否为$1$。那么我们可以视$N$为$n$位数，那么我们拆分$N:a_{n}、a_{n-1}…a_1$。从树的角度考虑：我们设$N=76543210,B=10$，那么我们从高位往最低位开始枚举如下；枚举$a_n$时，我们有两种选择： 走右边分支，那么我们填$7(a_n)$，而题目要求每一位只能填$1$或者$0$,而$a_n\u003e1$，所以不是合法方案，我们直接剔除。 走左边分支，那么我们可以填$0$~$6$，即$0-{a_n}-1$，那么由于每一位只能填$1$或者$0$，所以我们累加这两种选择的方案。 记住，走到了左边分支是可以直接累加的。 所以我们实际上还是要做一个预处理的，我们用$f[i][j]$表示还剩下$i$位没有填，且需要填写$j$个$1$的方案数。那么在$(i,j)$这个状态，我们可以选择填$1$，那么接下来的状态就是$f[i-1][j-1]$，而如果填$0$，那么接下来的状态就是$f[i-1][j]$，那么状态转移方程就是$f[i][j]=f[i-1][j]+f[i][j-1]$。而初始状态即是当$j=0$时，$f[i][0]=1$。这样我们就可以预处理$f$数组了。 处理完之后我们就可以直接模拟做了。 代码 /** *@filename:度的数量 *@author: pursuit *@csdn:unique_pursuit *@email: 2825841950@qq.com *@created: 2021-05-12 11:23 **/ #include \u003cbits/stdc++.h\u003e using namespace std; typedef long long ll; const int maxn = 100000 + 5; const int mod = 1e9+7; int l,r,k,b; int f[35][35]; //首先我们先预处理f数组。其中f[i][j]表示剩下还有i个没填，需要填写j个1的方案数。 void init(){ for(int i=0;i\u003c35;i++){ for(int j=0;j\u003c=i;j++){ if(!j)f[i][j]=1; else{ f[i][j]=f[i-1][j]+f[i-1][j-1]; } } } } int dp(int n){ //求解f(n)。我们需要避免n为0的情况，这里需要特判。 if(!n)return 0; vector\u003cint\u003e nums;//将n分割，存储位数。 while(n){ nums.push_back(n%b); n/=b; } int ans=0;//答案。 int last=0;//前面的信息，这里代表的是前面分支选取了多少个1. for(int i=nums.size()-1;i\u003e=0;i--){ int x=nums[i]; if(x){ //说明x\u003e0，我们可以选择左边分支填0. ans+=f[i][k-last]; if(x\u003e1){ //当x\u003e1我们才可以枚举左边分支填1. if(k-last-1\u003e=0){ //如果还可以填1的话。 ans+=f[i][k-last-1]; } break;//因为右边分支只能为0或1，所以不符合条件。break。 } else{ //当x=1就可以进入右边的分支继续讨论。 last++; if(last\u003ek)break; } } //考虑到最后一位，如果符合条件那么末位填0也算一种方案。 if(!i\u0026\u0026last==k)ans++; } return ans; } void solve(){ } int main(){ cin\u003e\u003el\u003e\u003er\u003e\u003ek\u003e\u003eb; init(); cout\u003c\u003cdp(r)-dp(l-1)\u003c\u003cendl; solve(); return 0; } ","date":"2021-05-12","objectID":"/posts/01.%E6%95%B0%E4%BD%8Ddp/:3:1","tags":["数位DP"],"title":"数位DP学习整理","uri":"/posts/01.%E6%95%B0%E4%BD%8Ddp/"},{"categories":["数据结构与算法"],"content":"3.2 3.2 计数问题 题面 给定两个整数 a 和 b，求 a 和 b 之间的所有数字中 0∼90∼9 的出现次数。 例如，$a=1024，b=1032$，则 a 和 b 之间共有 99 个数如下： 1024 1025 1026 1027 1028 1029 1030 1031 1032 其中 0 出现 10次，1 出现 10 次，2 出现 7 次，3 出现 3 次等等… 输入格式 输入包含多组测试数据。 每组测试数据占一行，包含两个整数 a 和 b。 当读入一行为 0 0 时，表示输入终止，且该行不作处理。 输出格式 每组数据输出一个结果，每个结果占一行。 每个结果包含十个用空格隔开的数字，第一个数字表示 0 出现的次数，第二个数字表示 1 出现的次数，以此类推。 数据范围 $0\u003ca,b\u003c1000000000\u003ca,b\u003c100000000$ 输入样例： 1 10 44 497 346 542 1199 1748 1496 1403 1004 503 1714 190 1317 854 1976 494 1001 1960 0 0 输出样例： 1 2 1 1 1 1 1 1 1 1 85 185 185 185 190 96 96 96 95 93 40 40 40 93 136 82 40 40 40 40 115 666 215 215 214 205 205 154 105 106 16 113 19 20 114 20 20 19 19 16 107 105 100 101 101 197 200 200 200 200 413 1133 503 503 503 502 502 417 402 412 196 512 186 104 87 93 97 97 142 196 398 1375 398 398 405 499 499 495 488 471 294 1256 296 296 296 296 287 286 286 247 解题思路 我们需要预处理$f$数组，那么我们可以用$f[i,j,u]$表示$i$位，最高位为$j$的数拥有$u$的个数。那么如果$j$不等于$u$时，则$f[i][j][u]+=f[i-1][k][u],0\\leq k \\leq 9$。这个应该不难理解，因为这个状态就是由之前的状态得到的。 而当$j$等于$u$时，那么同样也可以由之前的$9$个状态得到。为$f[i][j][u]+=f[i-1][k][u],0\\leq k \\leq 9$。记住，我们是还没有计算最高位的$u$个数的，因为最高位本身就为$u$，也是一种可能，所以我们需要加上。那么总共有$10^{i-1}$多的数，所以增加的u的数量为$10^{i-1}$。初始状态就是$f[1][i][i]=1$，到这，我们的$f$数组就初始化完了，那么接下来。就是拆位分支的数位$DP$套路讨论了，这里不在叙述，代码附详细注释。 代码 /** *@filename:计数问题 *@author: pursuit *@csdn:unique_pursuit *@email: 2825841950@qq.com *@created: 2021-05-12 13:12 **/ #include \u003cbits/stdc++.h\u003e using namespace std; typedef long long ll; const int maxn = 100000 + 5; const int mod = 1e9+7; int l,r; int f[11][10][10];//预处理f数组。其中f[i][j][u]表示i位最高位为j的数拥有u的个数。 void init(){ for(int i=0;i\u003c10;i++)f[1][i][i]=1; for(int i=2;i\u003c11;i++){ for(int j=0;j\u003c10;j++){ for(int u=0;u\u003c10;u++){ //判断j是否等于u。 if(j==u)f[i][j][u]+=pow(10,i-1); for(int k=0;k\u003c10;k++){ f[i][j][u]+=f[i-1][k][u]; } } } } } ll dp(int n,int u){ //1~n,求x的出现次数。 if(!n)return u?0:1;//特判n是否为0.根据u的值确定返回值。 vector\u003cint\u003e nums;//存储分割后的位数。 while(n)nums.push_back(n%10),n/=10; int last=0;//last记录前面u出现的次数。 ll ans=0;//答案。 for(int i=nums.size()-1;i\u003e=0;i--){ int x=nums[i]; //左边分支，0~x。 for(int j=(i==nums.size()-1);j\u003cx;j++){ //由于此题不能有前导0. ans+=f[i+1][j][u];//注意这里i需要+1，因为我们i下标从0开始。而位数从1开始。 } //走左边分支，那么我们需要加上前面的个数。注意这里需要乘上x，因为左边分支有x中选择。 ans+=x*last*pow(10,i); if(x==u)last++;//记录last。 if(!i)ans+=last;//加上这个数本身含有的。 } //由于我们前面都是枚举n位数的，我们还需要统计所有0~n-1位数的方案数量。 //例如000011是不合法的，但11是合法的。 //这一步确实很容易忽略，没办法，数位DP就是这么难。 for(int i=1;i\u003cnums.size();i++){ for(int j=(i!=1);j\u003c=9;j++){ ans+=f[i][j][u]; } } return ans; } void solve(){ } int main(){ init(); while(cin\u003e\u003el\u003e\u003er\u0026\u0026(l||r)){ if(l\u003er)swap(l,r); for(int i=0;i\u003c=9;i++){ cout\u003c\u003cdp(r,i)-dp(l-1,i); i==9?cout\u003c\u003cendl:cout\u003c\u003c\" \"; } } solve(); return 0; } ","date":"2021-05-12","objectID":"/posts/01.%E6%95%B0%E4%BD%8Ddp/:3:2","tags":["数位DP"],"title":"数位DP学习整理","uri":"/posts/01.%E6%95%B0%E4%BD%8Ddp/"},{"categories":["数据结构与算法"],"content":"3.3 3.3 数字游戏 题面 科协里最近很流行数字游戏。 某人命名了一种不降数，这种数字必须满足从左到右各位数字呈非下降关系，如 123，446。 现在大家决定玩一个游戏，指定一个整数闭区间 [a,b]，问这个区间内有多少个不降数。 输入格式 输入包含多组测试数据。 每组数据占一行，包含两个整数 a 和 b。 输出格式 每行给出一组测试数据的答案，即 [a,b] 之间有多少不降数。 数据范围 $1≤ a ≤ b ≤2^{31}−1$ 样例输入 1 9 1 19 样例输出 9 18 解题思路 同样的套路， 先预处理$f$数组，我们用$f[i][j]$表示$i$位数，且最高位为$j$的不降数方案数。那么我们来列写一下状态转移方程，对于$f[i][j]$，要满足不降数的要求，则$f[i-1][k]$，$k$需满足$j \\leq k \\leq 9$，那么自然$f[i][j]=\\sum_{k=j}^9 f[i-1][k]$。而初始状态自然是$f[1][j]=1$。预处理完之后，我们就好做了，直接按数位$DP$的思想处理即可。代码附详细注释。 代码 /** *@filename:数字游戏 *@author: pursuit *@csdn:unique_pursuit *@email: 2825841950@qq.com *@created: 2021-05-12 14:57 **/ #include \u003cbits/stdc++.h\u003e using namespace std; typedef long long ll; const int maxn = 100000 + 5; const int mod = 1e9+7; int l,r; int f[11][11];//预处理f数组。其中f[i][j]表示i位数，且最高位为j的不降数方案数。 void init(){ for(int i=1;i\u003c10;i++)f[1][i]=1; for(int i=2;i\u003c11;i++){ for(int j=0;j\u003c10;j++){ for(int k=j;k\u003c10;k++){ f[i][j]+=f[i-1][k]; } } } } int dp(int n){ //1~n，这里我们需要特判n=0。 if(!n)return 0; vector\u003cint\u003e nums;//存储分割位数。 while(n)nums.push_back(n%10),n/=10; int last=0;//last存储上一位的最大值。 int ans=0;//答案。 for(int i=nums.size()-1;i\u003e=0;i--){ int x=nums[i]; //走左边的分支。因为要保持不降序，所以我们j\u003e=last。 for(int j=last;j\u003cx;j++){ ans+=f[i+1][j];//注意是i+1位。 } if(last\u003ex)break;//说明上一位比x大，不能构成降序了，直接退出。 last=x;//走右分支了，更新last。 if(!i)ans++;//全部枚举完了，自身也同样构成了一种方案。 } return ans; } int main(){ init(); while(cin\u003e\u003el\u003e\u003er){ cout\u003c\u003cdp(r)-dp(l-1)\u003c\u003cendl; } return 0; } ","date":"2021-05-12","objectID":"/posts/01.%E6%95%B0%E4%BD%8Ddp/:3:3","tags":["数位DP"],"title":"数位DP学习整理","uri":"/posts/01.%E6%95%B0%E4%BD%8Ddp/"},{"categories":["数据结构与算法"],"content":"3.4 3.4 windy数 题面 windy 定义了一种 windy 数。 不含前导零且相邻两个数字之差至少为 2 的正整数被称为 windy 数。windy 想知道，在 a 和 b 之间，包括 a 和 b ，总共有多少个 windy 数？ 输入格式 输入只有一行两个整数，分别表示 a 和 b。 输出格式 输出一行一个整数表示答案。 输入输出样例 输入 #1 1 10 输出 #1 9 输入 #2 25 50 输出 #2 20 说明/提示 数据规模与约定 对于全部的测试点，保证 $1 \\leq a \\leq b \\leq 2 \\times 10^9$。 解题思路 同样，我们先进行预处理$f$数组，其中$f[i][j]$表示$i$位，其中最高位为$j$的方案数。那么根据题意，状态转移方程即为$f[i][j]=\\sum_{}f[i-1][k]$，其中$0 \\leq k \\leq 9 \\space and \\space abs(k-j)\u003e=2$。而初始状态即为$dp[1][i]=1$。预处理完之后就好处理了，这里不再提供思路，请大家自己画出树结构并完成此题。 代码 /** *@filename:windy数 *@author: pursuit *@csdn:unique_pursuit *@email: 2825841950@qq.com *@created: 2021-05-12 15:43 **/ #include \u003cbits/stdc++.h\u003e using namespace std; typedef long long ll; const int maxn = 100000 + 5; const int mod = 1e9+7; int l,r; int f[11][10];//f数组。其中f[i][j]表示i位，其中最高位为j的方案数。 void init(){ for(int i=0;i\u003c10;i++)f[1][i]=1; for(int i=2;i\u003c11;i++){ for(int j=0;j\u003c10;j++){ for(int k=0;k\u003c10;k++){ if(abs(k-j)\u003e=2){ f[i][j]+=f[i-1][k]; } } } } } int dp(int n){ if(!n){ //特判n为0的情况，避免对之后操作造成影响。 return 0; } vector\u003cint\u003e nums;//存储分割位数。 int last=-2;//存储上一位的值。这里初值为-2,是因为我们需要确定1可以。 int ans=0;//答案。 while(n)nums.push_back(n%10),n/=10; for(int i=nums.size()-1;i\u003e=0;i--){ int x=nums[i]; //左分支。 for(int j=(i==nums.size()-1);j\u003cx;j++){ if(abs(j-last)\u003e=2){ //说明符合要求。 ans+=f[i+1][j]; } } if(abs(x-last)\u003c2)break;//不满足要去。 last=x; if(!i)ans++;//枚举到最后一位，自身也形成了一种方案。 } //特殊枚举有前导0的数。 for(int i=1;i\u003cnums.size();i++){ for(int j=1;j\u003c=9;j++){ ans+=f[i][j]; } } return ans; } void solve(){ } int main(){ init(); cin\u003e\u003el\u003e\u003er; cout\u003c\u003cdp(r)-dp(l-1)\u003c\u003cendl; solve(); return 0; } ","date":"2021-05-12","objectID":"/posts/01.%E6%95%B0%E4%BD%8Ddp/:3:4","tags":["数位DP"],"title":"数位DP学习整理","uri":"/posts/01.%E6%95%B0%E4%BD%8Ddp/"},{"categories":["数据结构与算法"],"content":"3.5 3.5 数字游戏Ⅱ 题面 由于科协里最近真的很流行数字游戏。 某人又命名了一种取模数，这种数字必须满足各位数字之和$modN$为 0。 现在大家又要玩游戏了，指定一个整数闭区间 [a.b]，问这个区间内有多少个取模数。 数据范围 $1≤a,b≤2^{31}−1$, $1≤N\u003c100$ 样例 输入 1 19 9 输出 2 解题思路 虽然这道题看起来很复杂，但是本质还是还是数位DP的套路，只不过现在性质是满足各位数字之和$mod N$为0。那么此题实际上困难点在于预处理，我们发现预处理这其实就是一个$dp$，我们用闫式$DP$分析法分析如下： 我们得到这个$f$数组有什么用呢？我们发现，如果我现在已知前面的位数相加为$last$，在左分支处，由于后面的数可以随便枚举，所以我们利用这个性质直接累加$f[i+1][j][mod(-last,p)]$即可得到种类数。故此按照数位$DP$步骤易解。 代码 /** *@filename:数字游戏Ⅱ *@author: pursuit *@csdn:unique_pursuit *@email: 2825841950@qq.com *@created: 2021-05-12 18:23 **/ #include \u003cbits/stdc++.h\u003e using namespace std; typedef long long ll; const int maxn = 100000 + 5; int l,r,p; int f[12][12][110];//f[i][j][k]表示i位数，最高位是j，其模n的余数是k的方案数。 //预处理也是一个dp过程。 int mod(int x,int y){ //由于c++中的%负数会得到负数，所以我们需要做一个偏移。 return (x%y+y)%y; } void init(){ memset(f,0,sizeof(f)); //预处理f数组。 for(int i=0;i\u003c10;i++)f[1][i][i%p]++; for(int i=2;i\u003c12;i++){ for(int j=0;j\u003c10;j++){ for(int k=0;k\u003cp;k++){ for(int x=0;x\u003c10;x++){ f[i][j][k]+=f[i-1][x][mod(k-j,p)]; } } } } } int dp(int n){ if(!n)return 1; vector\u003cint\u003e a;//存储切出来的位数。 while(n)a.push_back(n%10),n/=10; int last=0;//last存储前面数字之和。 int ans=0; for(int i=a.size()-1;i\u003e=0;i--){ int x=a[i]; for(int j=0;j\u003cx;j++){ //走左边分支。为了凑成模n余0，则接下来的所有位数相加+last模n为0，所以我们来个-last即可。 ans+=f[i+1][j][mod(-last,p)]; } last+=x; if(!i\u0026\u0026last%p==0)ans++;//判断本身是否符合条件。 } return ans; } void solve(){ } int main(){ while(cin\u003e\u003el\u003e\u003er\u003e\u003ep){ init(); cout\u003c\u003cdp(r)-dp(l-1)\u003c\u003cendl; } solve(); return 0; } ","date":"2021-05-12","objectID":"/posts/01.%E6%95%B0%E4%BD%8Ddp/:3:5","tags":["数位DP"],"title":"数位DP学习整理","uri":"/posts/01.%E6%95%B0%E4%BD%8Ddp/"},{"categories":["数据结构与算法"],"content":"3.6 3.6 不要62 题面 杭州人称那些傻乎乎粘嗒嗒的人为62（音：laoer）。 杭州交通管理局经常会扩充一些的士车牌照，新近出来一个好消息，以后上牌照，不再含有不吉利的数字了，这样一来，就可以消除个别的士司机和乘客的心理障碍，更安全地服务大众。 不吉利的数字为所有含有4或62的号码。例如： 62315 73418 88914 都属于不吉利号码。但是，61152虽然含有6和2，但不是62连号，所以不属于不吉利数字之列。 你的任务是，对于每次给出的一个牌照区间号，推断出交管局今次又要实际上给多少辆新的士车上牌照了。 Input 输入的都是整数对n、m（0\u003cn≤m\u003c1000000），如果遇到都是0的整数对，则输入结束。 Output 对于每个整数对，输出一个不含有不吉利数字的统计个数，该数值占一行位置。 Sample Input 1 100 0 0 Sample Output 80 解题思路 这道题相对来说比较简单，因为预处理这一部分我们很容易想到。用$f[i][j]$表示$i$位数字且最高位为$j$的方案数。那么我们排除掉特殊情况进行状态转移即可。代码附详细注释。 代码 /** *@filename:不要62 *@author: pursuit *@csdn:unique_pursuit *@email: 2825841950@qq.com *@created: 2021-05-12 19:56 **/ #include \u003cbits/stdc++.h\u003e using namespace std; typedef long long ll; const int maxn = 100000 + 5; const int mod = 1e9+7; int l,r; int f[11][11];//f[i][j]表示i位数且最高位为j的方案数。 //那么我们来对这个进行分析，对于f[i][j]这个状态，我们根据题意我们转移的f[i-1][k]必须满足k!=4,j!=4. //并且jk!=62. void init(){ for(int i=0;i\u003c10;i++)f[1][i]=1; //排除4的情况。 f[1][4]=0; for(int i=2;i\u003c11;i++){ for(int j=0;j\u003c10;j++){ if(j==4)continue; for(int k=0;k\u003c10;k++){ if((j==6\u0026\u0026k==2)||k==4)continue; f[i][j]+=f[i-1][k]; } } } } int dp(int n){ if(!n)return 1; vector\u003cint\u003e a;//存储分割位数。 int ans=0,last=0;//last保存上一位的值。 while(n)a.push_back(n%10),n/=10; for(int i=a.size()-1;i\u003e=0;i--){ int x=a[i]; for(int j=0;j\u003cx;j++){ //走左边分支，我们需要判断。 if(j==4||(j==2\u0026\u0026last==6))continue; ans+=f[i+1][j]; } if(x==4||(last==6\u0026\u0026x==2))break; last=x; if(!i)ans++; } return ans; } void solve(){ } int main(){ init(); while(cin\u003e\u003el\u003e\u003er\u0026\u0026(l||r)){ cout\u003c\u003cdp(r)-dp(l-1)\u003c\u003cendl; solve(); } return 0; } ","date":"2021-05-12","objectID":"/posts/01.%E6%95%B0%E4%BD%8Ddp/:3:6","tags":["数位DP"],"title":"数位DP学习整理","uri":"/posts/01.%E6%95%B0%E4%BD%8Ddp/"},{"categories":["数据结构与算法"],"content":"3.7 3.7 恨7不成妻 由于此题太过变态，已单开一篇blog讲解： 点这里。 ","date":"2021-05-12","objectID":"/posts/01.%E6%95%B0%E4%BD%8Ddp/:3:7","tags":["数位DP"],"title":"数位DP学习整理","uri":"/posts/01.%E6%95%B0%E4%BD%8Ddp/"},{"categories":["数据结构与算法"],"content":"4 数位DP总结 做了这么多的题，我们发现数位$DP$确实是有套路的，难点就在于预处理，通常就是要用$DP$来预处理，这里推荐大家学一下闫式$DP$分析法。预处理完之后，就可以套路做题了。当然，学$DP$一定要多刷题，所以请各位一定要多多刷题哦！ ","date":"2021-05-12","objectID":"/posts/01.%E6%95%B0%E4%BD%8Ddp/:4:0","tags":["数位DP"],"title":"数位DP学习整理","uri":"/posts/01.%E6%95%B0%E4%BD%8Ddp/"},{"categories":["数据结构与算法"],"content":"1 问题引入 有这样一个问题:现在有这样一个数列$a$，你需要进行下面两种操作： 将某一个数加上 $x$ 求出某区间$[l,r]$每一个数的和 数列长度为$n( 1\\leq n \\leq 10^5)$，操作总数为$p(1\\leq p \\leq 10^5)$，时间限制为$1s$，如果是你你该如何处理？ 我们先来看看暴力能否出奇迹，对于单点修改操作，我们确实能在$O(1)$的时间完成，而对于区间求和操作，那么我们累加求和的时间复杂度为$O(r-l+1)$，在最坏的情况下，高达$O(n)$ ，这样算下来，处理这个问题需要$O(np)$的时间复杂度，$1s$是处理不完的。 那么，区间求和前缀和又是否可以呢？我们发现，如果用前缀和处理实际上就是让区间求和变为$O(1)$，而让单点修改就变为$O(n)$了，这样并没有任何变化。所以暴力做法肯定是不行的。 学过线段树的同学一定知道怎么写这道题，没学过的可以去学习下，这里指路一篇$blog$:线段树入门 但是，这道题用线段树未免也太大材小用了,况且线段树的代码量也十分多，所以树状数组就出现了，代码量少，简单易实现。我们继续往下看。 ","date":"2021-04-27","objectID":"/posts/02.%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%E8%AF%A6%E8%A7%A3/:1:0","tags":["树状数组"],"title":"树状数组详解(一维+二维+差分+前缀和+公式优化)","uri":"/posts/02.%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%E8%AF%A6%E8%A7%A3/"},{"categories":["数据结构与算法"],"content":"2 树状数组（单点修改，区间查询） 树状数组简单剖析 其中$A$数组是原数组，而$C$数组就是树状数组。为什么要一开始就放图呢？我们来发现一下它们的规律： $C1 = A1$ $C2 = A1+A2$ $C3 = A3$ $C4 = A1+A2+A3+A4$ $C5 = A5$ $C6 = A5+A6$ $C7 = A7$ $C8 = A1+A2+A3+A4+A5+A6+A7+A8$ 我们不难发现：$C[i] = A[i - 2^k+1] + A[i - 2^k+2] + … + A[i];$， //$k$为$i$的二进制中从最低位到高位连续零的长度，换句话说，$C[i]$管辖了包括$A[i]$自己的前$2^k$个元素 ，这样的好处是什么呢？我们发现，如果对某个元素更改了，那么我们只需要更改管辖了这个元素的$C$，那么如果对某个区间$[l,r]$求和，那么我们相当于求$SUM[r]-SUM[l-1]$，而求$SUM[i]$也特别简单，我们只需要求$i$这个点管辖的区间和$C[i]$并统计，再往前跳到未被$i$管辖的区间累加$C$即可，直到到达数组头部。也就是$SUM[i] = C[i] + C[i-2^{k_1 }]+ C[(i - 2^k_1) - 2^k_2] + …..；$。 lowbit函数求解$2^k$ 那么关键的一个问题来了，我们怎么求$2^k$，我们知道$k$为$i$的二进制中从最低位到高位连续零的长度，所以$2^k=i\u0026(i-1)$，这里不予证明。求$2^k$一般用一个函数来描述，即$lowbit$。如下： int lowbit(int x){ return x\u0026(-x); } add函数：单点修改 对于单点修改，我们实际上很好处理，只需要将管辖这个点的$C$全部加上$x$即可，如下： void add(int pos,int x){ while(pos\u003c=n){ c[pos]+=x; pos+=lowbit(pos); } } getSum函数：区间求和 区间求和就是上文中利用的原理，我们很容易就能实现，我们首先要能求前$i$个元素的和，如下： int getSum(int pos){ int ans=0; while(pos\u003e0){ ans+=c[pos]; pos-=lowbit(pos); } return ans; } ​ 那么，$[l,r]$区间的和自然易得，即为：getSum(r)-getSum(l-1)。 时间复杂度分析 不难，发现，树状数组实际上就是一棵树，其有$n$个结点，那么易知在单点修改和区间求和的问题处理上都能在$O(log_2n)$的时间内完成。所以总体时间复杂度为$O(nlog_2n)$，是非常有效的。 ","date":"2021-04-27","objectID":"/posts/02.%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%E8%AF%A6%E8%A7%A3/:2:0","tags":["树状数组"],"title":"树状数组详解(一维+二维+差分+前缀和+公式优化)","uri":"/posts/02.%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%E8%AF%A6%E8%A7%A3/"},{"categories":["数据结构与算法"],"content":"3 差分树状数组（区间修改，单点查询） 原理 我们首先要知道差分数组是什么，和前缀和数组其实离不开关系，$c[i]=SUM[i]-SUM[i-1]$，其中原数组相当于可以看成是存储了相邻两个前缀和的差值，那么映射到差分数组（因为原数组可以看成是存储了差分数组的前缀和）我们可以看成就是存储了相邻两个数之间的差值，即$d[i]=c[i]-c[i-1]$，而$d[1]=c[1]-c[0]=c[1]$，所以我们利用这个关系可以推导出:$a[i]=d[1]+d[2]+…+d[i]$，那么我们就是将单点查询转化为区间求和了，那么如果对于区间修改呢？对于差分数组，假设修改区间$[l,r]$，让这个区间每个元素$+x$，我们只需要更改$d[l]=d[l]+x$，$d[r+1]=d[r+1]-x$，这样我们保证只会影响到$[l,r]$这个区间的元素。故我们通过差分把这个区间修改、单点查询的问题转化为单点修改区间查询的问题，那么我们存储的树状数组实际和是哪个存储是差分数组的树状数组。 ","date":"2021-04-27","objectID":"/posts/02.%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%E8%AF%A6%E8%A7%A3/:3:0","tags":["树状数组"],"title":"树状数组详解(一维+二维+差分+前缀和+公式优化)","uri":"/posts/02.%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%E8%AF%A6%E8%A7%A3/"},{"categories":["数据结构与算法"],"content":"4 差分树状数组+公式优化（区间修改，区间查询） 原理 刚刚结束了利用差分实现区间修改，单点查询，而对于区间查询，这确实也是个问题。如果我们知道了区间查询，实际上这种类型的题我们就没必要使用线段树去写了，直接用树状数组就可以解决。我们来看，实际上还是利用差分数组，那么如何将区间查询的时间复杂度也变为$O(log_2n)$呢，区间查询的基础是快速求出数组$a[1:n]$的前缀和，而显然数组$a[1:n]$的前缀和为 $$a[1]+a[2]+…+a[i]=d[1]i+d[2](i-1)+…+d[i]1=d[1](i+1)+d[2](i+1)+…+d[i](i+1)-(d[1]*1+d[2]*2+…+d[i]i)\\ =(i+1)(d[1]+d[2]+…+d[i])-(d[1]*1+d[2]*2+…+d[i]*i)$$ ，所以我们就可以在原来的数组$c[i]$记录$d[i]$的基础上。再开一个数组记录$d[i]*i$即可。这样，我们就实现了区间查询。 ","date":"2021-04-27","objectID":"/posts/02.%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%E8%AF%A6%E8%A7%A3/:4:0","tags":["树状数组"],"title":"树状数组详解(一维+二维+差分+前缀和+公式优化)","uri":"/posts/02.%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%E8%AF%A6%E8%A7%A3/"},{"categories":["数据结构与算法"],"content":"5 二维树状数组（单点修改，区间查询） 解释 数组$C[x]$记录了的是右端点为$x$、长度为$lowbit(x)$的区间的区间和。那么我们也可以类似地定义$C[x][y]$记录的是右下角为$(x,y)$，高为 $lowbit(x)$，宽为$lowbit(y) $的区间的区间和。那么按照一维树状数组去处理即可，这里给出这三个函数。 $lowbit$函数 int lowbit(int x){ return x\u0026(-x); } $add$函数 void add(int x,int y,int value){ //在(x,y)处增加value. for(int i=x;i\u003c=n;i+=lowbit(i)){ for(int j=y;j\u003c=n;j+=lowbit(j)){ c[i][j]+=value; } } } $getSum$函数 int getSum(int x,int y){ //如果求解[x1,y1]~[x2,y2]之间的和，那么就是getSum(x2,y2)-getSum(x2,y1)-getSum(x1,y2)+getSum(x1,y1). int ans=0; for(int i=x;i\u003e0;i-=lowbit(i)){ for(int j=y;j\u003e0;j-=lowbit(j)){ ans+=c[i][j]; } } return ans=0; } ","date":"2021-04-27","objectID":"/posts/02.%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%E8%AF%A6%E8%A7%A3/:5:0","tags":["树状数组"],"title":"树状数组详解(一维+二维+差分+前缀和+公式优化)","uri":"/posts/02.%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%E8%AF%A6%E8%A7%A3/"},{"categories":["数据结构与算法"],"content":"6 二维差分树状数组（区间修改，单点查询） 二维差分树状数组推导 处理这个问题，我们首先要知道二维差分数组怎么表示，那么还是和二维前缀和数组联系起来，即$c[i,j]=SUM[i,j]-SUM[i-1,j]-SUM[i,j-1]+SUM[i-1,j-1]$，原数组实际上就可以看做是存储了$(i,j)$的前缀和与$(i-1,j)$和$(i,j-1)$的前缀和的差值。 那么映射到二维差分数组即是$d[i,j]=c[i,j]-c[i-1,j]-c[i,j-1]+c[i-1,j-1]$，其中$d[1,1]=c[1,1]$，那么$c[n][m]=\\sum_{i=1}^{n}\\sum_{j=1}^{m}d[i][j]$，所以对于区间修改，我们是给$(x_1,y_1),(x_2,y_2)$之间形成的矩阵加上$x$，那么实际上我们只需要变动四个点，$d[x_1][x_2]+=x,d[x_1][y_2]-=x,d[x_2][y_1]-=x,d[x_2][y_2]+=x$ ，那么这样就和一维差分数组一样了，区间修改单点查询问题我们利用二维差分数组就可以转化为单点修改区间查询了，我们的树状数组则是建立二维差分树状数组。那么这样这三个函数同理也很简单的就可以写出来了。 ","date":"2021-04-27","objectID":"/posts/02.%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%E8%AF%A6%E8%A7%A3/:6:0","tags":["树状数组"],"title":"树状数组详解(一维+二维+差分+前缀和+公式优化)","uri":"/posts/02.%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%E8%AF%A6%E8%A7%A3/"},{"categories":["数据结构与算法"],"content":"7 二维差分树状数组+公式推导（区间修改，区间查询） 推导 和一维的一样，如果我们需要求解$(x_1,y_1)$和$(x_2,y_2)$形成矩阵的和，同时又要实现区间修改，那么在原有的二维差分树状数组是行不通的，那么我们就需要将区间查询的时间复杂度也降为$log_2n$，我们知道$SUM[i][j]=\\sum_{x=1}^i\\sum_{y=1}^ja[x][y]$，而$a[x][y]=\\sum_{u=1}^x\\sum_{v=1}^yd[u][v]$，则$SUM[i][j]=\\sum_{x=1}^i\\sum_{y=1}^j\\sum_{u=1}^x\\sum_{v=1}^yd[u][v]$，由于这个公式非常复杂，所以我们可以按照一维差分树状数组那样来统计$d[u][v]$出现了多少次，我们发现，从$a[1][1]$到$a[i][j]$，$d[1][1]$都需要出现一次，则$d[1][1]$出现了$i\\times j$次，那么同理$d[1][2]$出现了$i*(j-1)$次，其余同等规律。所以 $$SUM[i][j]=\\sum_{x=1}^i\\sum_{y=1}^jd[x][y](i+1-x)(j+1-y)$$ ，我们同样可以将这样拆分成四个部分，即 $$SUM[i][j]=(i+1)(j+1)\\sum_{x=1}^i\\sum_{y=1}^jd[x][y]-(j+1)\\sum_{x=1}^i\\sum_{y=1}^jxd[x][y]-(i+1) \\sum_{x=1}^i\\sum_{y=1}^jyd[x][y]+\\sum_{x=1}^i\\sum_{y=1}^jxyd[x][y] $$。所以我们只需要在原来$C1[i][j]$记录$d[i][j]$的基础上，再开三个树状数组记录$d[i][j]*i,d[i][j]*j,d[i][j]*ij$即可。这样就可以通过数组$a[i][j]$的差分数组$d[i][j]$来得到$a[i][j]$的前缀和数组$SUM[i][j]$了。 ","date":"2021-04-27","objectID":"/posts/02.%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%E8%AF%A6%E8%A7%A3/:7:0","tags":["树状数组"],"title":"树状数组详解(一维+二维+差分+前缀和+公式优化)","uri":"/posts/02.%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%E8%AF%A6%E8%A7%A3/"},{"categories":["问题记录"],"content":"由于博主最近由CB转到Vscode了，可是发现我最爱用的万能头文件\u003cbits/stdc++.h\u003e使用不了。于是我找了各种办法，终于解决了。为了帮助到同样遇到这样问题的你们，所以在这里列出详细解决方法。 首先，我们要知道问题根源所在，为什么引入iostream可以，而引入bits/stdc++.h不行，我们点击鼠标右键对这两个头文件转到定义。 发现尝试万能头文件的时候显示未定义，而尝试isotream的时候跳转到： 我们发现，这即是iostream头文件的定义，这里给出了它的路径。我们看看它在什么文件下。 右键选择在文件资源管理器中显示。我们看到如下： 这些都是好多头文件的定义，我们vscode引入头文件都是从这里寻找引入的。 那么我们试想，如果我们把bits/stdc++.h头文件的定义给出，是不是就可以引入了？在官网，有bits/stdc++.h头文件的内容，这里贴出如下： // C++ includes used for precompiling -*- C++ -*- // Copyright (C) 2003-2014 Free Software Foundation, Inc. This file is part of the GNU ISO C++ Library. This library is free// software; you can redistribute it and/or modify it under the// terms of the GNU General Public License as published by the// Free Software Foundation; either version 3, or (at your option)// any later version. // This library is distributed in the hope that it will be useful,// but WITHOUT ANY WARRANTY; without even the implied warranty of// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the// GNU General Public License for more details. // Under Section 7 of GPL version 3, you are granted additional// permissions described in the GCC Runtime Library Exception, version// 3.1, as published by the Free Software Foundation. // You should have received a copy of the GNU General Public License and// a copy of the GCC Runtime Library Exception along with this program;// see the files COPYING3 and COPYING.RUNTIME respectively. If not, see// \u003chttp://www.gnu.org/licenses/\u003e. /** @file stdc++.h * This is an implementation file for a precompiled header. */ // 17.4.1.2 Headers // C #ifndef _GLIBCXX_NO_ASSERT #include \u003ccassert\u003e #endif #include \u003ccctype\u003e #include \u003ccerrno\u003e #include \u003ccfloat\u003e #include \u003cciso646\u003e #include \u003cclimits\u003e #include \u003cclocale\u003e #include \u003ccmath\u003e #include \u003ccsetjmp\u003e #include \u003ccsignal\u003e #include \u003ccstdarg\u003e #include \u003ccstddef\u003e #include \u003ccstdio\u003e #include \u003ccstdlib\u003e #include \u003ccstring\u003e #include \u003cctime\u003e #if __cplusplus \u003e= 201103L #include \u003cccomplex\u003e #include \u003ccfenv\u003e #include \u003ccinttypes\u003e #include \u003ccstdalign\u003e #include \u003ccstdbool\u003e #include \u003ccstdint\u003e #include \u003cctgmath\u003e #include \u003ccwchar\u003e #include \u003ccwctype\u003e #endif // C++ #include \u003calgorithm\u003e #include \u003cbitset\u003e #include \u003ccomplex\u003e #include \u003cdeque\u003e #include \u003cexception\u003e #include \u003cfstream\u003e #include \u003cfunctional\u003e #include \u003ciomanip\u003e #include \u003cios\u003e #include \u003ciosfwd\u003e #include \u003ciostream\u003e #include \u003cistream\u003e #include \u003citerator\u003e #include \u003climits\u003e #include \u003clist\u003e #include \u003clocale\u003e #include \u003cmap\u003e #include \u003cmemory\u003e #include \u003cnew\u003e #include \u003cnumeric\u003e #include \u003costream\u003e #include \u003cqueue\u003e #include \u003cset\u003e #include \u003csstream\u003e #include \u003cstack\u003e #include \u003cstdexcept\u003e #include \u003cstreambuf\u003e #include \u003cstring\u003e #include \u003ctypeinfo\u003e #include \u003cutility\u003e #include \u003cvalarray\u003e #include \u003cvector\u003e #if __cplusplus \u003e= 201103L #include \u003carray\u003e #include \u003catomic\u003e #include \u003cchrono\u003e #include \u003ccondition_variable\u003e #include \u003cforward_list\u003e #include \u003cfuture\u003e #include \u003cinitializer_list\u003e #include \u003cmutex\u003e #include \u003crandom\u003e #include \u003cratio\u003e #include \u003cregex\u003e #include \u003cscoped_allocator\u003e #include \u003csystem_error\u003e #include \u003cthread\u003e #include \u003ctuple\u003e #include \u003ctypeindex\u003e #include \u003ctype_traits\u003e #include \u003cunordered_map\u003e #include \u003cunordered_set\u003e #endif 这里还有一个小细节，我们知道/(斜杆)其实代表目录的，也就是说stdc++.h才是头文件名，它在bits这个文件夹下的，所以我们要做的就是新建一个名为bits的文件夹。然后在vscode中新建一个文件：stdc++.h，将我们上面万能头文件的定义复制到该文件。保存在bits文件目录下即可。 我们测试helloworld程序，发现可以使用。问题解决。 ","date":"2021-03-12","objectID":"/posts/01.%E8%A7%A3%E5%86%B3vscode%E4%B8%AD%E4%B8%8D%E8%83%BD%E4%BD%BF%E7%94%A8%E4%B8%87%E8%83%BD%E5%A4%B4%E6%96%87%E4%BB%B6%E7%9A%84%E9%97%AE%E9%A2%98/:0:0","tags":["Vscode","竞赛"],"title":"解决VSCode中不能使用万能头文件的问题","uri":"/posts/01.%E8%A7%A3%E5%86%B3vscode%E4%B8%AD%E4%B8%8D%E8%83%BD%E4%BD%BF%E7%94%A8%E4%B8%87%E8%83%BD%E5%A4%B4%E6%96%87%E4%BB%B6%E7%9A%84%E9%97%AE%E9%A2%98/"},{"categories":["技巧"],"content":"1 常用设置 按住Ctrl滚滚轮，代码的字体会随你心意变大变小。 在编辑区按住右键可拖动代码，省去拉（尤其是横向）滚动条之麻烦；相关设置：Mouse Drag Scrolling。 Ctrl+D可复制当前行或选中块。 Ctrl+Shift+C注释掉当前行或选中块，Ctrl+Shift+X则解除注释。 Tab缩进当前行或选中块,Shift+Tab减少缩进。 可拖动选中块使其移动到新位置，按住Ctrl则为复制到新位置。 按下Atl，再拖动鼠标，可以实现部分选择（即只选中一个区域内的字符，而不会包含它们所在行的其他字符)。 需要更大编辑空间时，F2和Shift+F2分别可以显隐下方Logs \u0026 others栏和左方的Management栏。 Ctrl+R可以替换； ","date":"2020-11-24","objectID":"/posts/03.codeblocks%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%8F%8A%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E8%AE%BE%E7%BD%AE/:1:0","tags":["CodeBlocks"],"title":"CodeBlocks快捷键及一些常用设置","uri":"/posts/03.codeblocks%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%8F%8A%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E8%AE%BE%E7%BD%AE/"},{"categories":["技巧"],"content":"2 优化代码自动完成功能： 进Settings里的Editor：在Code-completion and symbol browser中， 将Automatically launch when typed # letter中的4改成2，这样打两个字母就会有提示了。 将Keyword sets to additionally include中1到9都勾上（可在Syntax highlighting 的keywords…中设置，其中1是C++关键字，3是Doxygen关键字；我曾将wxWidgets的类名都加入7并设置相应的字体（粗黑 体），看代码时特别爽） 将Delay for auto-kick-in when typing [.::-\u003e]拉到 200ms，这样快点出来提示 选中Case-sensitive match，防止一些无关的东西干扰，如果你想它帮你纠正大小写，那就去掉勾 设置快捷键： 进Settings里的Editor： 在Keyboard short-cuts中将Edit-\u003eCode complete的快捷键由Ctrl+Space改为Alt+/，因为前者与中文输入法切换冲突，该快捷键为已经输入的（不是正在输入的）词提供自动完成。 ","date":"2020-11-24","objectID":"/posts/03.codeblocks%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%8F%8A%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E8%AE%BE%E7%BD%AE/:2:0","tags":["CodeBlocks"],"title":"CodeBlocks快捷键及一些常用设置","uri":"/posts/03.codeblocks%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%8F%8A%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E8%AE%BE%E7%BD%AE/"},{"categories":["技巧"],"content":"3 多学一招 看Abbreviation一栏，里面定义了许多缩写（还可以自定义），只要输入这些缩写，并按Ctrl+J，就可以自动完成常用的代码框架，并将光标放在恰当的地方（自定义时用|表达）。常用的有：guard、class、switch等。 如果你声明了一个类，你可以在cpp文件中右击，Insert-\u003eAll class methods without implementation…来插入你还没定义的方法的定义（省去不少打字的功夫哦），也可使用Insert-\u003eClass Method declaration/implementation…来插入一个方法的声明或定义。 ","date":"2020-11-24","objectID":"/posts/03.codeblocks%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%8F%8A%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E8%AE%BE%E7%BD%AE/:3:0","tags":["CodeBlocks"],"title":"CodeBlocks快捷键及一些常用设置","uri":"/posts/03.codeblocks%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%8F%8A%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E8%AE%BE%E7%BD%AE/"},{"categories":["技巧"],"content":"4 导航相关 Ctrl+G 到达指定行，ALT+G 到达指定文件，Ctrl+Alt+G 到达指定函数（支持头文件中的函数定义），F11 切换源文件与头文件。 Ctrl+PageUp 到达上一个函数，Ctrl+PageDown 到达下一个函数。 Ctrl+B 添加书签，Alt+PageUp和Alt+PageDown可以切换书签。 Ctrl+Shift+B可找到匹配的括号。 看长代码时，可右击，Folding-\u003eFold All，然后慢慢展开来看，也可充分利用左方Management栏的Symbol浏览器。 在一个变量、函数或宏上右击，三个以Find开头的菜单项，分别可以为你转到它的声明、定义和找到所有出现的地方（按F2在下方Thread Search那里查看）。 其他： General Settings中可以设置缩进、自动换行等细节。 让Code::Blocks永远记住你的Layout，尤其是debug的layout，善用debug工具栏。 备份C:/Documents and Settings/[你的用户名]/Application Data/codeblocks/Default.conf，如遇重装，将其放在codeblocks.exe所在目录，就不会丢失你的配置；这样也可以 打造出Code::Blocks的绿色版。 Ctrl+L 剪切选中行 F11 切换源文件与头文件 F10 全屏 Ctrl+Shift+B 括号匹配 按下ATL，再拖动鼠标，可以实现部分选择 Ctrl+B 添加书签，ALT+PageUp和PageDown可以切换书签。 Ctrl+G 到达指定行 ALT+G 到达指定文件 Ctrl+Alt+G 到达指定函数（支持头文件中的函数定义） Ctrl+PageUp 到达上一个函数 Ctrl+PageDown 到达下一个函数 ","date":"2020-11-24","objectID":"/posts/03.codeblocks%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%8F%8A%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E8%AE%BE%E7%BD%AE/:4:0","tags":["CodeBlocks"],"title":"CodeBlocks快捷键及一些常用设置","uri":"/posts/03.codeblocks%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%8F%8A%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E8%AE%BE%E7%BD%AE/"},{"categories":["技巧"],"content":"1 cin、cout优化 在默认情况下， std::cin/std::cout 是极为迟缓的输入/输出方式，而 scanf/printf 比 std::cin/std::cout 快得多。 可是为什么会这样呢？如果我更习惯使用C++的输出方式，那么有没有什么办法解决输入输出缓慢的问题呢？ 这是因为在默认情况下，cin与stdin总是保持同步的，也就是说这两种方法可以混用，而不必担心文件指针混乱，同时cout和stdout也一样，两者混用不会输出顺序错乱。由于这个特性，所以导致cin和cout有许多额外的开销。 那么我们如何禁用这个特性呢？ ","date":"2020-08-18","objectID":"/posts/04.%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%BC%98%E5%8C%96%E9%98%B2%E6%AD%A2tle/:1:0","tags":["优化","竞赛"],"title":"算法竞赛常用技巧——输入输出优化（防止TLE）","uri":"/posts/04.%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%BC%98%E5%8C%96%E9%98%B2%E6%AD%A2tle/"},{"categories":["技巧"],"content":"2 关闭同步/解除绑定 std::ios::sync_with_stdio(false) 这个函数是一个“是否兼容 stdio”的开关，C++ 为了兼容 C，保证程序在使用了 printf 和 std::cout 的时候不发生混乱，将输出流绑到了一起。 这其实是 C++ 为了兼容而采取的保守措施。我们可以在进行 IO 操作之前将 stdio 解除绑定，但是在这样做之后要注意不能同时使用 std::cin/std::cout 和 scanf/printf。更严格的来说：关闭之后C++ IO和C IO 两者不能混用，否则会造成IO混乱。 ","date":"2020-08-18","objectID":"/posts/04.%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%BC%98%E5%8C%96%E9%98%B2%E6%AD%A2tle/:2:0","tags":["优化","竞赛"],"title":"算法竞赛常用技巧——输入输出优化（防止TLE）","uri":"/posts/04.%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%BC%98%E5%8C%96%E9%98%B2%E6%AD%A2tle/"},{"categories":["技巧"],"content":"3 tie函数加速 还有一种影响速度的原因是：在默认的情况下 std::cin 绑定的是 std::cout ，每次执行 « 操作符的时候都要调用 flush() ，这样会增加 IO 负担。 tie 是将两个 stream 绑定的函数，空参数的话返回当前的输出流指针。 可以通过 std::cin.tie(0) 和std:cout.tie(0)（0 表示 NULL）来解除 std::cin 与 std::cout 的绑定，进一步加快执行效率。 在这两种情况优化下，std::cin和std::cout的速度就和scanf和printf基本一样了，甚至更快。 std::ios::sync_with_stdio(false); std::cin.tie(0); std::cout.tie(0); //如果编译开启了 C++11 或更高版本，建议使用 std::cin.tie(nullptr); 注意： scanf 和 printf 依然有优化的空间，这就是本章所介绍的内容——输入和输出优化。 注意，接下来介绍的输入和输出优化均针对整型数据（函数实现读写），若要支持其他类型的数据（如浮点数），可自行按照本页面介绍的优化原理来编写代码。 ","date":"2020-08-18","objectID":"/posts/04.%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%BC%98%E5%8C%96%E9%98%B2%E6%AD%A2tle/:3:0","tags":["优化","竞赛"],"title":"算法竞赛常用技巧——输入输出优化（防止TLE）","uri":"/posts/04.%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%BC%98%E5%8C%96%E9%98%B2%E6%AD%A2tle/"},{"categories":["技巧"],"content":"4 更快的输入优化getchar() ","date":"2020-08-18","objectID":"/posts/04.%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%BC%98%E5%8C%96%E9%98%B2%E6%AD%A2tle/:4:0","tags":["优化","竞赛"],"title":"算法竞赛常用技巧——输入输出优化（防止TLE）","uri":"/posts/04.%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%BC%98%E5%8C%96%E9%98%B2%E6%AD%A2tle/"},{"categories":["技巧"],"content":"4.1 原理 众所周知， getchar 是用来读入 1 byte 的数据并将其转换为 char 类型的函数，且速度很快，故可以用“读入字符——转换为整型”来代替缓慢的读入 每个整数由两部分组成——符号和数字，整数的 ‘+’ 通常是省略的，且不会对后面数字所代表的值产生影响，而 ‘-’ 不可省略，因此要进行判定。 10 进制整数中是不含空格或除 0~9 和正负号外的其他字符的，因此在读入不应存在于整数中的字符（通常为空格）时，就可以判定已经读入结束 C 和 C++ 语言分别在 ctype.h 和 cctype 头文件中，提供了函数 isdigit , 这个函数会检查传入的参数是否为十进制数字字符，是则返回 true ，否则返回 false 。对应的，在下面的代码中，可以使用 isdigit(ch) 代替 ch \u003e= ‘0’ \u0026\u0026 ch \u003c= ‘9’ ，而可以使用 !isdigit(ch) 代替 ch \u003c‘0’ || ch\u003e ‘9’。 ","date":"2020-08-18","objectID":"/posts/04.%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%BC%98%E5%8C%96%E9%98%B2%E6%AD%A2tle/:4:1","tags":["优化","竞赛"],"title":"算法竞赛常用技巧——输入输出优化（防止TLE）","uri":"/posts/04.%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%BC%98%E5%8C%96%E9%98%B2%E6%AD%A2tle/"},{"categories":["技巧"],"content":"4.2 代码实现输入函数read() int read() { int x = 0, w = 1; char ch = 0; //我们判断是否为十进制数字字符可以使用isdight()函数来判断，这里不再展示。 while (ch \u003c '0' || ch \u003e '9') { // ch 不是数字时 if (ch == '-') w = -1; // 判断是否为负 ch = getchar(); // 继续读入 } while (ch \u003e= '0' \u0026\u0026 ch \u003c= '9') { // ch 是数字时，我们输入结束标志为空格或回车。 x = x * 10 + (ch - '0'); // 将新读入的数字’加’在 x 的后面 // 此处也可以使用 (x\u003c\u003c3)+(x\u003c\u003c1) 的写法来代替 x*10 即：x=(x\u003c\u003c3)+(x\u003c\u003c1)+(ch-'0');用位运算效率更高，这里相当于x*8+x*2+(ch-'0'); //利用ASCII码转换为对应数字。 ch = getchar(); // 继续读入 } return x * w; // 数字 * 正负号 = 实际数值 } 举例 ：我们输入数据时可以这样调用read函数:num=read()。 ","date":"2020-08-18","objectID":"/posts/04.%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%BC%98%E5%8C%96%E9%98%B2%E6%AD%A2tle/:4:2","tags":["优化","竞赛"],"title":"算法竞赛常用技巧——输入输出优化（防止TLE）","uri":"/posts/04.%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%BC%98%E5%8C%96%E9%98%B2%E6%AD%A2tle/"},{"categories":["技巧"],"content":"5 更快的输出优化putchar() ","date":"2020-08-18","objectID":"/posts/04.%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%BC%98%E5%8C%96%E9%98%B2%E6%AD%A2tle/:5:0","tags":["优化","竞赛"],"title":"算法竞赛常用技巧——输入输出优化（防止TLE）","uri":"/posts/04.%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%BC%98%E5%8C%96%E9%98%B2%E6%AD%A2tle/"},{"categories":["技巧"],"content":"5.1 原理 同样是众所周知， putchar 是用来输出单个字符的函数,因此将数字的每一位转化为字符输出以加速,要注意的是，负号要单独判断输出，并且每次 %（mod）取出的是数字末位，因此要倒序输出。 ","date":"2020-08-18","objectID":"/posts/04.%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%BC%98%E5%8C%96%E9%98%B2%E6%AD%A2tle/:5:1","tags":["优化","竞赛"],"title":"算法竞赛常用技巧——输入输出优化（防止TLE）","uri":"/posts/04.%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%BC%98%E5%8C%96%E9%98%B2%E6%AD%A2tle/"},{"categories":["技巧"],"content":"5.2 代码实现 递归版 void write(int x) { if (x \u003c 0) { // 判负 + 输出负号 + 变原数为正数 x = -x; putchar('-'); } if (x \u003e 9) write(x / 10); // 递归，将除最后一位外的其他部分放到递归中输出 putchar(x % 10 + '0'); // 已经输出（递归）完 x 末位前的所有数字，输出末位 } 由于递归的任务量比较大，我们可以利用栈来实现非递归。 非递归版 inline void write(int x) { static int sta[35]; int top = 0; do { sta[top++] = x % 10, x /= 10;//将取出的元素入栈。 } while (x); while (top) putchar(sta[--top] + 48); //由于我们要输出字符，这里进行转换： 48 是 '0' } OK，这就是经典的输入输出的优化做法，通常cf榜上的大佬用的都是后面这种方法，这确实很快，比scanf和printf快了约$1/3$了吧。我自己常用的就是第一种优化方法，通常我会利用宏定义来避免这么繁琐，如：#define IOS ios::sync_with_stdio(false);cin.tie(0); cout.tie(0) 那么，在主函数直接使用IOS;语句即可实现优化功能。 ","date":"2020-08-18","objectID":"/posts/04.%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%BC%98%E5%8C%96%E9%98%B2%E6%AD%A2tle/:5:2","tags":["优化","竞赛"],"title":"算法竞赛常用技巧——输入输出优化（防止TLE）","uri":"/posts/04.%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%BC%98%E5%8C%96%E9%98%B2%E6%AD%A2tle/"},{"categories":["数据结构与算法"],"content":"1 简介 Kruskal算法是一种用来查找最小生成树（$MST$）的算法，由Joseph Kruskal在1956年发表。求最小生成树的算法常用有两种：Kruskal算法和Prim算法。这里指路一篇Prim算法的详解blog：https://blog.csdn.net/hzf0701/article/details/107927858。与Prim算法不同的是，该算法的核心思想是归并边，而Prim算法的核心思想是归并点。这里我们会在后面的实现过程中看到。 ","date":"2020-08-11","objectID":"/posts/03.kruskal%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:1:0","tags":["最小生成树"],"title":"Kruskal算法详解","uri":"/posts/03.kruskal%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"2 构造过程 假设连通网$N=(V,E)$，将$N$中的边按权值从小到大的顺序排列。 ①初始状态为只有$n$个顶点而无边的非连通图$T=(V,{})$，图中每个顶点自成一个连通分量。 ②在$E$中选择权值最小的边，若该边依附的顶点落在$T$中不同的连通分量上（即不形成回路），则将此边将入到$T$中，否则舍去此边而选择下一条权值最小的边。 ③重复②，直到$T$中所有的顶点都在同一连通分量上为止。 这个算法的构造过程十分简洁明了，那么为什么这样的构造过程能否形成最小生成树呢？我们来看第二个步骤，因为我们选取的边的顶点是不同的连通分量，且边权值是最小的，所以我们保证加入的边都不使得$T$有回路，且权值也最小。这样最后当所有的连通分量都相同时，即所有的顶点都在生成树中被连接成功了，我们构造成的树也就是最小生成树了。 ","date":"2020-08-11","objectID":"/posts/03.kruskal%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:2:0","tags":["最小生成树"],"title":"Kruskal算法详解","uri":"/posts/03.kruskal%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"3 示例 ","date":"2020-08-11","objectID":"/posts/03.kruskal%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:3:0","tags":["最小生成树"],"title":"Kruskal算法详解","uri":"/posts/03.kruskal%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"4 算法实现 步骤： ①将存储边的数组temp按权值从小到大排序，注意进行运算符重载。 ②初始化连通分量数组$verx$。 ③依次查看数组temp的边，循环执行以下操作。 依次从排好序的数组temp中选出一条边$(u,v)$； 在$verx$中分别查找$u$和$v$所在的连通分量$v_1和v_2$，进行判断。 如果$v_1$和$v_2$不等，说明所选的两个顶点分别属于不同的连通分量，则将此边存入最小生成树$tree$，并合并$v_1$和$v_2$这个两个连通分量。 如果$v_1$和$v_2$相等，则说明所选的两个顶点属于同一个连通分量，舍去此边而选择下一条权值最小的边。 #include\u003cbits/stdc++.h\u003e //POJ不支持 #define rep(i,a,n) for (int i=a;i\u003c=n;i++)//i为循环变量，a为初始值，n为界限值，递增 #define per(i,a,n) for (int i=a;i\u003e=n;i--)//i为循环变量， a为初始值，n为界限值，递减。 #define pb push_back #define IOS ios::sync_with_stdio(false);cin.tie(0); cout.tie(0) #define fi first #define se second #define mp make_pair using namespace std; const int inf = 0x3f3f3f3f;//无穷大 const int maxn = 1e5;//最大值。 typedef long long ll; typedef long double ld; typedef pair\u003cll, ll\u003e pll; typedef pair\u003cint, int\u003e pii; //*******************************分割线，以上为自定义代码模板***************************************// struct edge{ int s;//边的起始顶点。 int e;//边的终端顶点。 int w;//边权值。 bool operator \u003c (const edge \u0026a){ return w\u003ca.w; } }; edge temp[maxn];//临时数组存储边。 int verx[maxn];//辅助数组，判断是否连通。 edge tree[maxn];//最小生成树。 int n,m;//n*n的图，m条边。 int cnt;//统计生成结点个数，若不满足n个，则生成失败。 int sum;//最小生成树权值总和。 void print(){ //打印最小生成树函数。 cout\u003c\u003c\"最小生成树的权值总和为：\"\u003c\u003csum\u003c\u003cendl; rep(i,0,cnt-1){ cout\u003c\u003ctree[i].s\u003c\u003c\" \"\u003c\u003ctree[i].e\u003c\u003c\"边权值为\"\u003c\u003ctree[i].w\u003c\u003cendl; } } void Kruskal(){ rep(i,1,n) verx[i]=i;//这里表示各顶点自成一个连通分量。 cnt=0;sum=0; sort(temp,temp+m);//将边按权值排列。 int v1,v2; rep(i,0,m-1){ v1=verx[temp[i].s]; v2=verx[temp[i].e]; if(v1!=v2){ tree[cnt].s=temp[i].s;tree[cnt].e=temp[i].e;tree[cnt].w=temp[i].w;//并入最小生成树。 rep(j,1,n){ //合并v1和v2的两个分量，即两个集合统一编号。 if(verx[j]==v2)verx[j]=v1; //默认集合编号为v2的改为v1. } sum+=tree[cnt].w; cnt++; } } //结束双层for循环之后得到tree即是最小生成树。 print(); } int main(){ //freopen(\"in.txt\", \"r\", stdin);//提交的时候要注释掉 IOS; while(cin\u003e\u003en\u003e\u003em){ int u,v,w; rep(i,0,m-1){ cin\u003e\u003eu\u003e\u003ev\u003e\u003ew; temp[i].s=u;temp[i].e=v;temp[i].w=w; } Kruskal(); } return 0; } ","date":"2020-08-11","objectID":"/posts/03.kruskal%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:4:0","tags":["最小生成树"],"title":"Kruskal算法详解","uri":"/posts/03.kruskal%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"5 算法分析 对于有$m$条边和$n$个顶点的图。在$for$循环中最耗时的操作就是合并两个不同的连通分量，第一个循环语句的频度为$m$，第二个循环由于存在$if$语句，所以平均频度是$log_2n$，所以该算法的平均时间复杂度为$O(mlog_2n)$，故和Prim算法相比 此算法适合用于稀疏图。 ","date":"2020-08-11","objectID":"/posts/03.kruskal%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:5:0","tags":["最小生成树"],"title":"Kruskal算法详解","uri":"/posts/03.kruskal%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"6 测试 以示例数据为测试样例： 7 11 1 2 7 1 4 5 2 4 9 2 3 8 2 5 7 4 5 15 4 6 6 6 7 11 5 6 8 5 7 9 3 5 5 测试结果如图： ","date":"2020-08-11","objectID":"/posts/03.kruskal%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:6:0","tags":["最小生成树"],"title":"Kruskal算法详解","uri":"/posts/03.kruskal%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"前言：理解线段树着实花了我很多时间，主要之前一直有个误区，就是对线段树中存储的信息，我认为只能是区间和，可万万没想到呀，它还可以是别的东西：区间最小值、区间最大值等等呀，我表示👤(已黑化)，好了，言归正传，博主是完全理解了线段树之后才有勇气写这篇文章的，所以我是根据一个完全初学者到理解线段树的过程来写下这篇文章的，不会像其他文章一下难以理解，当然，本文也只是我学习整理的，如果有错误的话，还请评论区留言或私信我，共同进步。 线段树讲解共有两篇，这一篇为入门，另一篇为进阶。 ","date":"2020-08-07","objectID":"/posts/01.%E7%BA%BF%E6%AE%B5%E6%A0%91%E5%85%A5%E9%97%A8/:0:0","tags":["线段树"],"title":"线段树入门","uri":"/posts/01.%E7%BA%BF%E6%AE%B5%E6%A0%91%E5%85%A5%E9%97%A8/"},{"categories":["数据结构与算法"],"content":"1 什么是线段树？ 线段树的基本概念 在深入学习线段树之前，我们首先要了解线段树是什么？线段树本质也是一颗二叉搜索树，也被认为是区间树（即每个结点都有一段区间，我们也认为是线段）。那有小伙伴可能就要问了，什么是二叉搜索树？二叉搜索树顾名思义：前提是一颗二叉树，它的每个结点度都小于等于2，即每个结点最多有两个子树。其次就是搜索，这是关键，我们这个线段树在其中都有一个区间，那么搜索即是可以在这个区间上搜索你想要的值，这就是搜索，其中，每个结点存储的信息是由你来定的，如果你想求区间和，那么就可以存储区间和，如果你想求区间最大值，那么你可以存储区间最大值，只要可行，你都可以进行你想要的操作。 线段树的注意事项 在给定了大小给定了叶子结点数目的时候这个线段树就已经确定了，我们不能进行添加和删除元素，不是说不能对已有叶子结点赋值，是不能对其进行扩大或者减小。因为在大多数情况中，对于线段树来说，区间本身都是固定的，不考虑新增和删除元素。所以用数组存储的话，直接用静态数组就好了，不用动态数组。 线段树的大小一定要开叶子结点数目（即原有点对点的数据数组大小）的四倍。例如叶子结点数目是maxn，那么我们通常会开线段树的大小为maxn«2。因为线段树也是一颗完全二叉树，当最大的时候可能是满二叉树。我们来证明一下，我们这样想：最深一层的数目是n，则此线段树的高度为$\\lceil$$\\log_2n\\rceil$,我们可知$\\lceil$$\\log_2n\\rceil$ $\\leq$ $log_2n+1$。那么我们通过然后通过等比数列求和公式（$\\frac{a_1(1-q^x)}{1-q}$）求得二叉树的节点个数，具体公式为$\\frac{1*(1-2^x)}{1-2}$，（$x$为树的层数，为树的高度$+1$），化简可得$2^{log_2n+1+1}-1$,整理之后即为$4n$（近似计算忽略掉-1) 我们进行乘除法运算的时候要使用位运算（« »一定要仔细理解这两个运算符），而避免使用基本的数学运算，因为我们会频繁使用结点坐标更新，用位运算会更快一点，而且还可以防WR。 在表示坐标的时候，若一个结点下标为i，那么它的父节点就是i»1。如果这个结点是这个父节点的左孩子，那么右孩子下标就是i+1。如果这个结点是父节点的右孩子，那么左孩子的下标就是i-1。那个这个结点的左孩子下标就是i«1，右孩子下标就是(i«1)=1（这里一定要使用括号改变运算符优先级，因为位运算的优先级属实低。） 要根据你想解决的问题来设置结点的数据信息。区间求和和区间最值所进行的是不太一样的，所更改的信息也都要注意，但都是一个本质，就是从下往上更新，到达根节点就退出。 线段树不一定是满二叉树，也就是说线段树的叶子结点不一定是在最后一层。线段树也不一定是完全二叉树（切记！）。但我们可以把线段树看成是满二叉树，对于不存在的结点我们视为空就行。 线段树能解决的问题 线段树的适用范围很广，可以在线维护修改以及查询区间上的最值，求和。使用一维线段树可以快速的查找某一个节点在若干条线段中出现的次数，时间复杂度为O(logN)。线段树更可以扩充到二维线段树（矩阵树）和三维线段树（空间树），这里我们不作讲解。（其实博主也暂时不会😄） 你问我线段树算什么东西？今天我就告诉你，单点、区间朴素查询处理做的我线段树能做！单点、区间朴素查询没有的速度我有！这就是线段树。（战术后仰） ","date":"2020-08-07","objectID":"/posts/01.%E7%BA%BF%E6%AE%B5%E6%A0%91%E5%85%A5%E9%97%A8/:1:0","tags":["线段树"],"title":"线段树入门","uri":"/posts/01.%E7%BA%BF%E6%AE%B5%E6%A0%91%E5%85%A5%E9%97%A8/"},{"categories":["数据结构与算法"],"content":"2 线段树的基本内容 我们先看一颗线段树： 不然发现线段树的特点，每个结点都有一个值和区间，每个结点的左右孩子都存储了父结点的一半的区间，且它们的序号是按照层次顺序编号的。在日常处理中，我们通常是使用结构体数组来作为线段树的存储结构，因为这样我们就可以利用下标的关系来找到父节点和孩子结点了。例如我们已知一个结点的下标为i，那么： 对于父结点：i»1（这个进行的操作其实就是i/2，前面提到，这样会快很多） 具体证明也很简单，把线段树看成一个完全二叉树（空结点也当作使用）对于任意一个结点i来说，它所在此二叉树的$log_2i$ 层，则此层共有$2^{log2(i)}$个结点，同样对于k的左子树那层来说有$2^{log_2{k}+1}$个结点，则结点k和左子树间隔了$22^{log_2(i)}-i + 2(i-2^{log_2(k)})$个结点，然后这就很简单就得到$k+22^{log_2(k)}-k + 2(k-2^{log2(k)}) = 2*k$的关系了吧，右子树也就等于左子树结点+1。 对于左孩子结点：左孩子下标：i«1（这些是同理的，即是由父结点推孩子结点。） 对于右孩子结点：右孩子下标：i«1|1 了解了这些关系，我们是有能力去建立一颗线段树的，因为线段树也是树，所以我们自然可以利用递归的思想去建树，不会很难，我也写全了注释。 const int maxn = 1e5;//最大值。 struct Node{ int left; //左端点 int right; //右端点 int value;//代表区间[left,right]的信息，可以是区间和，也可以是区间最值。 }node[maxn\u003c\u003c2];//这里我们要开4倍大小，防止数据溢出 int father[maxn];//存储原来数据在线段树中的下标，易于从下向上更新区间数据。例如father[i]表示原来的第i个数据在线段树中的下标，这些在线段树中都是叶子结点。 void BuildTree(int i,int l,int r){ node[i].left=l;node[i].right=r;//存储各自结点的区间 node[i].value=0; //初始化为0. if(l==r){ //说明已经到了叶子结点。 father[l]=i;//存储下标。 return; } BuildTree(i\u003c\u003c1,l,(l+r)/2); //递归初始化左子树 BuildTree((i\u003c\u003c1)+1,(l+r)/2+1,r);//递归初始化右子树。 } 这样，我们的线段树就建好了。我们来看线段树有哪些基本操作吧。 ","date":"2020-08-07","objectID":"/posts/01.%E7%BA%BF%E6%AE%B5%E6%A0%91%E5%85%A5%E9%97%A8/:2:0","tags":["线段树"],"title":"线段树入门","uri":"/posts/01.%E7%BA%BF%E6%AE%B5%E6%A0%91%E5%85%A5%E9%97%A8/"},{"categories":["数据结构与算法"],"content":"3 线段树的基本操作 我们这里以结点的值value代表区间和来处理。 ","date":"2020-08-07","objectID":"/posts/01.%E7%BA%BF%E6%AE%B5%E6%A0%91%E5%85%A5%E9%97%A8/:3:0","tags":["线段树"],"title":"线段树入门","uri":"/posts/01.%E7%BA%BF%E6%AE%B5%E6%A0%91%E5%85%A5%E9%97%A8/"},{"categories":["数据结构与算法"],"content":"3.1 点更新 这很好办，有没有注意我们是使用了一个father数组，如果我在原数组中修改第i个元素的值，我们是直接可以node[father[i]].value=w，这就是我们使用father数组的好处，那你可能会问了，我们这样是不是要使用三个数组？大可不必，我们没必要给原有数据开一个数组存放，因为我们本身就已经把数据放在线段树中了，不管线段树中存放的是区间和还是区间最值，对于叶子结点来说，它就是本身。那么我们加入了点，自然也要更新整棵树，那有关这个叶子结点到根节点的路径自然全部都是要更新的，我们则是从下往上利用递归思想来更新的。 void UpdateTree(int ri){ if(ri==1){ return; } int fi=ri\u003e\u003e1;//获得父结点下标。 node[fi].value=node[fi\u003c\u003c1].value+node[fi\u003c\u003c1|1].value;//两段区间总和。 UpdateTree(fi); } ","date":"2020-08-07","objectID":"/posts/01.%E7%BA%BF%E6%AE%B5%E6%A0%91%E5%85%A5%E9%97%A8/:3:1","tags":["线段树"],"title":"线段树入门","uri":"/posts/01.%E7%BA%BF%E6%AE%B5%E6%A0%91%E5%85%A5%E9%97%A8/"},{"categories":["数据结构与算法"],"content":"3.2 区间查询 我们有了线段树，可却不对它进行相关查询，那这颗线段树也只是精致的花瓶而已。我们最重要的就是进行区间查询，现在如果我想知道某个区间和的话，我们应该怎样来处理呢？我们知道根节点是存放了整个区间的信息，然后它的孩子结点则存放了它一半区间的信息，这样则显而易见，我们从根节点开始自上往下查询即可。我们本着下面的思想就一目了然了。 1、如果这个区间被完全包括在目标区间里面，直接返回这个区间的值 2、如果这个区间的左儿子和目标区间有交集，那么搜索左儿子 3、如果这个区间的右儿子和目标区间有交集，那么搜索右儿子 OK，整活。 //区间查询，调用函数时为QueryTree(1,l,r)，即从根节点自上往下查询。 int QueryTree(int i,int l,int r){ int sum=0; if(l==node[i].left\u0026\u0026r==node[i].right){ //如果刚好就是这个区间，我们直接返回。 sum+=node[i].value; return sum; } i=i\u003c\u003c1; if(l\u003c=node[i].right){ //说明部分包含左子树 if(r\u003c=node[i].right){ //说明全包含在左子树。 sum+=QueryTree(i,l,r); } else{ sum+=QueryTree(i,l,node[i].right); } } i+=1; if(r\u003e=node[i].left){ //说明部分包含右子树 if(l\u003e=node[i].left){ //说明全包含在右子树。 sum+=QueryTree(i,l,r); } else{ sum+=QueryTree(i,node[i].left,r); } } return sum; //返回求得的区间和。 } 区间查询不断二分，易知时间复杂度为O($log_2n$)。 线段树的基本操作就是这些，当然，这只是入门，灵活使用线段树以及更深层次的利用线段树的道路还很长，我们一起加油！ 主函数部分测试： int main(){ freopen(\"in.txt\", \"r\", stdin);//提交的时候要注释掉 ios::sync_with_stdio(false);//打消iostream中输入输出缓存，节省时间。 cin.tie(0); cout.tie(0);//可以通过tie(0)（0表示NULL）来解除cin与cout的绑定，进一步加快执行效率。 int n,m,g; while(cin\u003e\u003en\u003e\u003em){ BuildTree(1,1,n); rep(i,1,n){ cin\u003e\u003eg; node[father[i]].value=g; UpdateTree(father[i]); } char ch; int a,b; while(m--){ cin\u003e\u003ech\u003e\u003ea\u003e\u003eb; if(ch=='Q'){ cout\u003c\u003cQueryTree(1,a,b)\u003c\u003cendl;; } else{ node[father[a]].value=b; UpdateTree(father[a]); } } } return 0; } 测试数据： 6 5 2 3 8 23 1 9 Q 1 6 S 2 3 Q 1 6 S 3 4 Q 1 6 测试结果： ","date":"2020-08-07","objectID":"/posts/01.%E7%BA%BF%E6%AE%B5%E6%A0%91%E5%85%A5%E9%97%A8/:3:2","tags":["线段树"],"title":"线段树入门","uri":"/posts/01.%E7%BA%BF%E6%AE%B5%E6%A0%91%E5%85%A5%E9%97%A8/"},{"categories":["数据结构与算法"],"content":"PS：此算法不能用于求负权图，要求所有边的权重都为非负值。 ","date":"2020-07-29","objectID":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:0:0","tags":["最短路"],"title":"Dijkstra算法教程","uri":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"1 简介 迪杰斯特拉算法(Dijkstra)是由荷兰计算机科学家狄克斯特拉于1959 年提出的，因此又叫狄克斯特拉算法。这是从一个顶点到其余各顶点的最短路径算法，解决的是有权图中最短路径问题。迪杰斯特拉算法主要特点是从起始点开始，采用贪心算法的策略，每次遍历到始点距离最近且未访问过的顶点的邻接节点，直到扩展到终点为止。 ","date":"2020-07-29","objectID":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:1:0","tags":["最短路"],"title":"Dijkstra算法教程","uri":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"2 算法思想与原理 dijkstra算法思想是基于贪心算法思想的。所谓贪心算法即始终保持当前迭代解为当前最优解。意思就是在已知的条件下或是当前拥有的全部条件下保证最优解，若在此后的迭代中由于加入了新的条件使得产生了更优解则替代此前的最优解。通过不断的迭代不断保证每次迭代的结果都是当前最优解，那么当迭代到最后一轮时得到的就会是全局最优解。 由于下一轮迭代会参考上一轮的最优解，因此每一轮的迭代的工作量基本一致，降低了整体工作的复杂性。 在最短路径的问题中，局部最优解即当前的最短路径或者说是在当前的已知条件下起点到其余各点的最短距离。关键就在于已知条件，这也是Dijkstra算法最精妙的地方。我们来解释一下。 对于Dijkstra算法，我们假设初始集合（也就是初始条件）不存在任何顶点的，即所有顶点之间是不存在任何路径的，即我们认为所有顶点之间的距离都是无穷大。那么开始加入新的条件，因为我们已知源点距源点距离最小，所以加入进去，并加入它的边，在该条件下，更新该源点到其余顶点的最短距离，选出没有加入到已知集合的距源点距离最小的点，此点最短距离也被确定了（因为其他路径都比这条路径大，无法通过其他路径间接到达这个顶点使得路径更小），然后加入该点与其余还未加入已知条件顶点的边，并以该点迭代刷新最短距离。再重复以上操作，直至所有顶点都加入已知条件集合。 ","date":"2020-07-29","objectID":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:2:0","tags":["最短路"],"title":"Dijkstra算法教程","uri":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"3 具体步骤 选择起点$start$与终点$end$； 所有点除起点外加入未知集合，并将起点加入已知集合，即至标志位为真，意为已确定该点到源点的最短路径； 初始化计算，更新起点与其他各点的耗费$dis(start,n)$; 在未知集合中，选择dis(start,n)中值最小的点x，将x加入已知集合。 对于剩余顶点中，计算$dis(start,n)\u003edis(start,x)+dis(x,n)$ 若真则$dis(start,n)=dis(start,x)+dis(x,n)$，此时start与n点路径经过x点。循环直至goal点加入已知列表，取得$dis(start,goal)$即为最短距离。 ","date":"2020-07-29","objectID":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:3:0","tags":["最短路"],"title":"Dijkstra算法教程","uri":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"4 动态展示 ","date":"2020-07-29","objectID":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:4:0","tags":["最短路"],"title":"Dijkstra算法教程","uri":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"5 一般代码实现（以邻接矩阵为例） ","date":"2020-07-29","objectID":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:5:0","tags":["最短路"],"title":"Dijkstra算法教程","uri":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"5.1 基本数据 const int inf=0x3f3f3f3f; //代表无穷大。 const int maxn=100;//最大顶点数 int n,m;//n个顶点，m条边。 bool visited[maxn];//判断是否确定到源点的最终最短距离。 int graph[maxn][maxn];//带权图 int dis[maxn];//顶点到源点的最短距离。 int start,goal;//起点与目标点。 ","date":"2020-07-29","objectID":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:5:1","tags":["最短路"],"title":"Dijkstra算法教程","uri":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"5.2 初始化 void init(){ memset(visited,false,sizeof(visited)); for(int i=1;i\u003c=n;i++){ dis[i]=graph[start][i];//初始化dis数组。 } } ","date":"2020-07-29","objectID":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:5:2","tags":["最短路"],"title":"Dijkstra算法教程","uri":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"5.3 dijkstra算法核心 void dijkstra(){ //源点为源点start。 int minn;//记录每趟最短路径中最小的路径值。 int pos;//记录得到的minn所对应的下标。 init();//调用初始化函数。 visited[start]=true; for(int i=1;i\u003c=n;i++){ //将n个顶点依次加入判断。 minn=inf; for(int j=1;j\u003c=n;j++){ if(!visited[j]\u0026\u0026dis[j]\u003cminn){ minn=dis[j]; pos=j; } } //经过这趟for循环后我们找到的就是我们想要的点，可以确定这点到源点的最终最短距离了。 visited[pos]=true;//我们将此点并入已知集合。 //接下来就是更新dis数组了，也就是当前最短距离，这都是针对还没有并入已知集合的点。 for(int j=1;j\u003c=n;j++){ if(!visited[j]\u0026\u0026dis[j]\u003edis[pos]+graph[pos][j]) dis[j]=dis[pos]+graph[pos][j]; } } //退出循环后，所有的点都已并入已知集合中，得到的dis数组也就是最终最短距离了。 cout\u003c\u003cdis[goal]\u003c\u003cendl;//输出目标点到源点的最短路径长度。 } ","date":"2020-07-29","objectID":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:5:3","tags":["最短路"],"title":"Dijkstra算法教程","uri":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"5.4 主函数与头文件等 #include\u003cbits/stdc++.h\u003e using namespace std; int main() { while(cin\u003e\u003en\u003e\u003em){ memset(graph,inf,sizeof(graph)); int u,v,w; for(int i=0;i\u003cm;i++){ cin\u003e\u003eu\u003e\u003ev\u003e\u003ew; // graph[u][v]=w;//有向图 graph[u][v]=graph[v][u]=w;//无向图 } cin\u003e\u003estart\u003e\u003egoal;//输入起点与终点。 dijkstra(); } return 0; } ","date":"2020-07-29","objectID":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:5:4","tags":["最短路"],"title":"Dijkstra算法教程","uri":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"6 拓展 如果你学会了dijkstra，那恭喜你成功突破了一关。但是，没有优化的dijkstra算法时间复杂度为$O(n^2)$，如果顶点很多边很少呢等等卡邻接矩阵的题，那么建议你还是要学一下dijkstra的优化版了。详情点击：Dijkstra算法优化~~你一定可以看懂的四种进阶优化 ","date":"2020-07-29","objectID":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:6:0","tags":["最短路"],"title":"Dijkstra算法教程","uri":"/posts/02.dijkstra%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"1 最小生成树（MST） 在一给定的无向图$G = (V, E)$ 中，$(u, v)$代表连接顶点$u$ 与顶点 $v$ 的边，而 $w(u, v)$ 代表此边的权重，若存在 $T$ 为 $E$ 的子集且为无循环图，使得 $w(T)$ 最小，则此 $T$ 为 $G$ 的最小生成树，因为$T$是由图$G$产生的。 最小生成树其实是最小权重生成树的简称。我们称求取该生成树的问题成为最小生成树问题。一个连通图可能有多个生成树。当图中的边具有权值时，总会有一个生成树的边的权值之和小于或者等于其它生成树的边的权值之和。广义上而言，对于非连通无向图来说，它的每一连通分量同样有最小生成树，它们的并被称为最小生成森林。以有线电视电缆的架设为例，若只能沿着街道布线，则以街道为边，而路口为顶点，其中必然有一最小生成树能使布线成本最低。 如图，这个是一个平面图，图中黑色线描述的就是最小生成树，它的权值之和小于其他的生成树。 那么，我们如何来求最小生成树呢，由最小生成树的定义我们可以知道构建最小生成树是可以利用贪心算法去实现的，我们接下来介绍的两种算法也都是利用贪心算法去求得$MST$的。因为贪心算法的策略就是在每一步尽可能多的选择中选择最优的，在当前看是最好的选择，这种策略虽然一般不能在全局中寻找到最优解，但是对于最小生成树问题来说，它的确可以找到一颗权重最小的树。 ","date":"2020-07-29","objectID":"/posts/04.prim%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:1:0","tags":["最小生成树"],"title":"Prim算法详解","uri":"/posts/04.prim%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"2 Prim算法 ","date":"2020-07-29","objectID":"/posts/04.prim%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:2:0","tags":["最小生成树"],"title":"Prim算法详解","uri":"/posts/04.prim%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"2.1 简介 普里姆算法（Prim’s algorithm），图论中的一种算法，可在加权连通图里搜索最小生成树。意即由此算法搜索到的边子集所构成的树中，不但包括了连通图里的所有顶点，且其所有边的权值之和亦为最小。该算法于1930年由捷克数学家沃伊捷赫·亚尔尼克发现；并在1957年由美国计算机科学家罗伯特·普里姆独立发现；1959年，艾兹格·迪科斯彻再次发现了该算法。因此，在某些场合，普里姆算法又被称为DJP算法、亚尔尼克算法或普里姆－亚尔尼克算法。（来源于维基百科） ","date":"2020-07-29","objectID":"/posts/04.prim%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:2:1","tags":["最小生成树"],"title":"Prim算法详解","uri":"/posts/04.prim%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"2.2 具体步骤 Prim算法是利用贪心算法实现的，我们确定根节点，从这个结点出发。普里姆算法按照以下步骤逐步扩大树中所含顶点的数目，直到遍及连通图的所有顶点。下面描述我们假设$N=(V,E)$是连通网，$TE$是$N$上最小生成树中边的集合。 ① $U={u_0}(u_0∈V) ,TE= {}$。 ​ ② 在所有$u∈U,v∈(V-U)$的边$(u,v)∈E$找到一条权值最小的边$(u_0,v_0)$并入集合$TE$，同时$v_0$并入集合$U$。 ③ 重复②步骤，知道$U=V$为止。 此时$TE$中必有$n-1$条边，则$T=(V,TE)$即为我们求得的$N$的最小生成树。 ","date":"2020-07-29","objectID":"/posts/04.prim%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:2:2","tags":["最小生成树"],"title":"Prim算法详解","uri":"/posts/04.prim%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"2.3 算法示例图 ","date":"2020-07-29","objectID":"/posts/04.prim%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:2:3","tags":["最小生成树"],"title":"Prim算法详解","uri":"/posts/04.prim%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"2.4 算法实现 我们如果对Dijkstra算法很熟悉的话，Prim算法也很好实现了，它们都是利用了一样的思路，但却不相同。我们用利用$lowcost$数组来表示到集合中最近的距离，用$closest$数组来表示最小生成树的边。怎么来表示呢？我们用顶点来形容边，也就是说我们要求的就是$closet$数组。其中$closest[i]$表示的值就是与$i$顶点相邻边的顶点序号。具体看代码（附带打印最小生成树代码）。 #include\u003cbits/stdc++.h\u003e //POJ不支持 #define rep(i,a,n) for (int i=a;i\u003c=n;i++)//i为循环变量，a为初始值，n为界限值，递增 #define per(i,a,n) for (int i=a;i\u003e=n;i--)//i为循环变量， a为初始值，n为界限值，递减。 #define pb push_back #define IOS ios::sync_with_stdio(false);cin.tie(0); cout.tie(0) #define fi first #define se second #define mp make_pair using namespace std; const int inf = 0x3f3f3f3f;//无穷大 const int maxn = 1e3;//最大值。 typedef long long ll; typedef long double ld; typedef pair\u003cll, ll\u003e pll; typedef pair\u003cint, int\u003e pii; //*******************************分割线，以上为自定义代码模板***************************************// int n,m;//图的大小和边数。 int graph[maxn][maxn];//图 int lowcost[maxn],closest[maxn];//lowcost[i]表示i到距离集合最近的距离，closest[i]表示i与之相连边的顶点序号。 int sum;//计算最小生成树的权值总和。 void Prim(int s){ //初始化操作，获取基本信息。 rep(i,1,n){ if(i==s) lowcost[i]=0; else lowcost[i]=graph[s][i]; closest[i]=s; } int minn,pos;//距离集合最近的边，pos代表该点的终边下标。 sum=0; rep(i,1,n){ minn=inf; rep(j,1,n){ //找出距离点集合最近的边。 if(lowcost[j]!=0\u0026\u0026lowcost[j]\u003cminn){ minn=lowcost[j]; pos=j; } } if(minn==inf)break;//说明没有找到。 sum+=minn;//计算最小生成树的权值之和。 lowcost[pos]=0;//加入点集合。 rep(j,1,n){ //由于点集合中加入了新的点，我们要去更新。 if(lowcost[j]!=0\u0026\u0026graph[pos][j]\u003clowcost[j]){ lowcost[j]=graph[pos][j]; closest[j]=pos;//改变与顶点j相连的顶点序号。 } } } cout\u003c\u003csum\u003c\u003cendl;//closest数组就是我们要的最小生成树。它代表的就是边。 } void print(int s){ //打印最小生成树。 int temp; rep(i,1,n){ //等于s自然不算，故除去这个为n-1条边。 if(i!=s){ temp=closest[i]; cout\u003c\u003ctemp\u003c\u003c\"-\u003e\"\u003c\u003ci\u003c\u003c\"边权值为：\"\u003c\u003cgraph[temp][i]\u003c\u003cendl; } } } int main(){ //freopen(\"in.txt\", \"r\", stdin);//提交的时候要注释掉 IOS; while(cin\u003e\u003en\u003e\u003em){ memset(graph,inf,sizeof(graph));//初始化。 int u,v,w;//临时变量。 rep(i,1,m){ cin\u003e\u003eu\u003e\u003ev\u003e\u003ew; //视情况而论，我这里以无向图为例。 graph[u][v]=graph[v][u]=w; } //任取根结点，我这里默认取1. Prim(1); print(1);//打印最小生成树。 } return 0; } ","date":"2020-07-29","objectID":"/posts/04.prim%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:2:4","tags":["最小生成树"],"title":"Prim算法详解","uri":"/posts/04.prim%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"2.5 算法分析 对于此算法，我们图中有$n$个顶点，则第一个进行初始化的循环语句的频度为$n$,第二个循环语句的频度为$n$，但其中第二个循环中有两个内循环：第一个是在$lowcost$中求最小值，其频度为$n$，第二个是重新选择具有最小权值的边，频度为$n$，由此我们可知Prim算法的时间复杂度为$O(n^2)$，与图中的边数无关，故十分适合于稠密图。 ","date":"2020-07-29","objectID":"/posts/04.prim%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:2:5","tags":["最小生成树"],"title":"Prim算法详解","uri":"/posts/04.prim%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"2.6 测试 我们用示例来测试： 7 11 1 2 7 1 4 5 2 4 9 2 3 8 2 5 7 4 5 15 4 6 6 6 7 11 5 6 8 5 7 9 3 5 5 测试结果如图： ","date":"2020-07-29","objectID":"/posts/04.prim%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:2:6","tags":["最小生成树"],"title":"Prim算法详解","uri":"/posts/04.prim%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"1 简介 Floyd算法又称为插点法，是一种利用动态规划的思想寻找给定的加权图中多源点之间最短路径的算法，可以正确处理有向图或无向图或负权（但不可存在负权回路)的最短路径问题，同时也被用于计算有向图的传递闭包。该算法名称以创始人之一、1978年图灵奖获得者、斯坦福大学计算机科学系教授罗伯特·弗洛伊德命名。 ","date":"2020-07-27","objectID":"/posts/01.floyd%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:1:0","tags":["最短路"],"title":"Floyd算法教程","uri":"/posts/01.floyd%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"2 算法原理 在给出的一张具有权值图中，我们已知每个顶点v与每个顶点u中的最短距离(即使无法到达，我们也认为是有距离的，但距离为无穷大）。对于最短距离表示，我们用dis[v][u]来表示顶点v到顶点u的最短距离，一开始没进行任何操作时，则表示他们的最短距离，就是顶点v到达顶点u的直接距离。 OK，那么如果我现在有一个中转站（中转顶点temp），我先从顶点v到达顶点temp，再从顶点temp到达顶点u，则这段距离我们可以表示为dis[v][temp]+dis[temp][u]，如果这段距离比我们目前的直接到达方式更小的话，那么我们不就可以更新我们的最短距离dis[v][u]了吗？那么temp这个中转顶点可以是图中的所有顶点，如果我们不断把所有顶点插入作为中转顶点，再不断更新最短距离，最后，得到的dis[n][n]自然是多源点之间的最短路径了。我们由上述推导也可求得我们的状态转移方程dis[v][u]=min(dis[v][u],dis[v][temp]+dis[temp][u])，这就是Floyd算法的思想与原理，不断插入中转顶点，利用动态规划思想来实现。 这里我们还要记录最短路径的方案，针对有些要求最短路径方案的题，我们用path[v][u]的值来记录顶点v到顶点u的中转顶点，若为-1则表示无中转顶点。 ","date":"2020-07-27","objectID":"/posts/01.floyd%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:2:0","tags":["最短路"],"title":"Floyd算法教程","uri":"/posts/01.floyd%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"3 邻接矩阵解题模板 存储结构： const int maxn=1000;//maxn表示图的最大顶点数 int graph[maxn][maxn]; int n;//图的实际顶点数 int dis[maxn][maxn];//最短距离 const int inf=0x3f3f3f3f;//代表无穷大 int path[maxn][maxn];//记录中转顶点 //Floyd算法核心 void floyd(int n){ //顶点数目。 int i,j,k;//循环变量。 memset(dis,inf,sizeof(dis));//调用这个函数需包含memory.h头文件 memset(path,-1,sizeof(path)); for(i=0;i\u003cn;i++){ for(int j=0;j\u003cn;j++){ //初始化dis。 dis[i][j]=graph[i][j]; } } for(k=0;k\u003cn;k++){ //不断插点 for(i=0;i\u003cn;i++){ for(j=0;j\u003cn;j++){ //对图中所有点之间的最短距离进行更新。 if(dis[i][j]\u003edis[i][k]+dis[k][j]){ path[i][j]=k;//记录中转顶点。 dis[i][j]=dis[i][k]+dis[k][j];//更新。 } } } } } 我们现在来输出最短路径，由于我们记录了中转顶点，那么我们可以借助我们求得的path数组来实现。如果path[i][j]的值不为-1的话，说明这个值就为中转顶点，可这样最短路径就求出来了吗？显然不是，我们还要继续判断i和k之间以及k和j之间有没有中转顶点。我们可以利用递归思想来实现这个方法输出最短路径。 void print_path(int i,int j){ int k=path[i][j]; if(k==-1) //说明没有中转顶点，直接返回. return; print_path(i,k);//寻找i和k之间 cout\u003c\u003ck\u003c\u003c\",\"; print_path(k,j);//寻找k和j之间 } 最后，再设置一个打印我们所求的结果的方法，比较简单，核心就是上面两个函数。 void print_result(){ int i,j; for(i=0;i\u003cn;i++){ for(j=0;j\u003cn;j++){ if(dis[i][j]==inf){ //我们先前说过，无法到达我们设置距离为无穷大，则他们之前没有路径 cout\u003c\u003ci\u003c\u003c\"和\"\u003c\u003cj\u003c\u003c\"之间没有路径\"\u003c\u003cendl; } else{ cout\u003c\u003ci\u003c\u003c\"和\"\u003c\u003cj\u003c\u003c\"的最短路径为\"\u003c\u003cdis[i][j]\u003c\u003cendl; cout\u003c\u003c\"路径方案为：\"\u003c\u003ci\u003c\u003c\",\"; print_path(i,j); cout\u003c\u003cj\u003c\u003cendl; } } } } ","date":"2020-07-27","objectID":"/posts/01.floyd%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:3:0","tags":["最短路"],"title":"Floyd算法教程","uri":"/posts/01.floyd%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["数据结构与算法"],"content":"4 邻接表解题模板 存储结构： const int maxn=1000; typedef struct arc{ //边的信息 int adjust;//该边所指向的顶点。 int weight;//该边的权值。 struct arc *next;//指向一条边。 }arc,*arclink; typedef struct vex{ arclink firstarc;//该顶点的第一条边。 }vex,vexs[maxn]; typedef struct graph{ vexs adj; int arcnum;//边数 int vexnum;//顶点数 }graph; graph G; //初始化操作就不在这写了，最短距离还是用dis[maxn][maxn]表示，中转站顶点用path[maxn][maxn]毕竟我们的核心是解决Floyd算法。 void floyd(){ int i,j,k; //初始化dis for(i=0;i\u003cG.vexnum;i++){ for(j=0;j\u003cG.vexnum;j++){ if(i==j)dis[i][j]=0; else dis[i][j]=inf; } } memset(path,-1,sizeof(path));//初始化path数组 arclink *p;//辅助作用 for(i=0;i\u003cG.vexnum;i++){ p=G.adj[i].firstarc; while(p){ //此操作是为了记录所有顶点之间的距离 dis[i][s-\u003eadjust]=s-\u003ewight; s=s-\u003enext; } } //到了这一步，就跟上面的是一样了，因为我们已经得到了dis数组和path数组的值了。下面利用dp并记录中转顶点，同种套路。 } ","date":"2020-07-27","objectID":"/posts/01.floyd%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/:4:0","tags":["最短路"],"title":"Floyd算法教程","uri":"/posts/01.floyd%E7%AE%97%E6%B3%95%E6%95%99%E7%A8%8B/"},{"categories":["技巧"],"content":"1 菜单栏 文件：alt+F 编辑：alt+E 段落：alt+P 格式：alt+O 视图：alt+V 主题：alt+T 帮助：alt+H ","date":"2020-07-09","objectID":"/posts/02.typora%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/:1:0","tags":["Typora"],"title":"Typora常用快捷键","uri":"/posts/02.typora%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"categories":["技巧"],"content":"2 文件操作 新建：Ctrl+N 新建窗口：Ctrl+Shift+N 打开：Ctrl+O 快速打开：Ctrl+P 保存：Ctrl+S 另存为：Ctrl+Shift+S 偏好：Ctrl+, 关闭：Ctrl+W ","date":"2020-07-09","objectID":"/posts/02.typora%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/:2:0","tags":["Typora"],"title":"Typora常用快捷键","uri":"/posts/02.typora%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"categories":["技巧"],"content":"3 编辑 撤销：Ctrl+Z 重做：Ctrl+Y 剪切：Ctrl+X 复制：Ctrl+C 粘贴：Ctrl+V 复制为MarkDown：Ctrl+Shift+C 粘贴为纯文本：Ctrl+Shift+V 全选：Ctrl+A 选中当前行/句：Ctrl+L 选中当前格式文本：Ctrl+E 选中当前词：Ctrl+D 跳转到文首：Ctrl+Home 跳转到所选内容：Ctrl+J 跳转到文末：Ctrl+End 查找：Ctrl+F 查找下一个：F3 查找上一个：Shift+F3 替换：Ctrl+H ","date":"2020-07-09","objectID":"/posts/02.typora%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/:3:0","tags":["Typora"],"title":"Typora常用快捷键","uri":"/posts/02.typora%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"categories":["技巧"],"content":"4 段落 标题：Ctrl+1/2/3/4/5 段落：Ctrl+0 增大标题级别：Ctrl+= 减少标题级别：Ctrl+- 表格：Ctrl+T 代码块：Ctrl+Shift+K 公式块：Ctrl+Shift+M 引用：Ctrl+Shift+Q 有序列表：Ctrl+Shift+[ 无序列表：Ctrl+Shift+] 增加缩进：Ctrl+] 减少缩进：Ctrl+[ ","date":"2020-07-09","objectID":"/posts/02.typora%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/:4:0","tags":["Typora"],"title":"Typora常用快捷键","uri":"/posts/02.typora%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"categories":["技巧"],"content":"5 格式 加粗：Ctrl+B 斜体：Ctrl+I 下划线：Ctrl+U 代码：Ctrl+Shift+` 删除线：Alt+Shift+5 超链接：Ctrl+K 图像：Ctrl+Shift+I 清除样式：Ctrl+ ","date":"2020-07-09","objectID":"/posts/02.typora%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/:5:0","tags":["Typora"],"title":"Typora常用快捷键","uri":"/posts/02.typora%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"categories":["技巧"],"content":"6 视图 显示隐藏侧边栏：Ctrl+Shift+L 大纲视图：Ctrl+Shift+1 文档列表视图：Ctrl+Shift+2 文件树视图：Ctrl+Shift+3 源代码模式：Ctrl+/ 专注模式：F8 打字机模式：F9 切换全屏：F11 实际大小：Ctrl+Shift+0 放大：Ctrl+Shift+= 缩小：Ctrl+Shift+- 应用内窗口切换：Ctrl+Tab 打开DevTools：Shift+F12 ","date":"2020-07-09","objectID":"/posts/02.typora%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/:6:0","tags":["Typora"],"title":"Typora常用快捷键","uri":"/posts/02.typora%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"categories":["数据结构与算法"],"content":"1 二分搜索升天词 转自：labuladong ","date":"2020-01-21","objectID":"/posts/01.%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/:1:0","tags":["查找"],"title":"二分查找的奇技淫巧","uri":"/posts/01.%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"},{"categories":["数据结构与算法"],"content":"2 手写二分查找模板 二分模板一共有两个，分别适用于不同情况。 算法思路：假设目标值在闭区间$[l, r]$中， 每次将区间长度缩小一半，当$l = r$时，我们就找到了目标值。 ","date":"2020-01-21","objectID":"/posts/01.%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/:2:0","tags":["查找"],"title":"二分查找的奇技淫巧","uri":"/posts/01.%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"},{"categories":["数据结构与算法"],"content":"2.1 版本1 当我们将区间$[l, r]$划分成$[l, mid]$和$[mid + 1, r]$时，其更新操作是$r = mid$或者$l = mid + 1$;，计算$mid$时不需要加$1$。 bool check(int x) { ... ... } int binary_search_1(int l, int r) { while (l \u003c r) { int mid = (l + r) \u003e\u003e 1; if (check(mid)) { r = mid; } else { l = mid + 1; } } return l; } ","date":"2020-01-21","objectID":"/posts/01.%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/:2:1","tags":["查找"],"title":"二分查找的奇技淫巧","uri":"/posts/01.%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"},{"categories":["数据结构与算法"],"content":"2.2 版本2 当我们将区间$[l, r]$划分成$[l, mid-1]$和$[mid, r]$时，其更新操作是$r = mid - 1$或者$l = mid$;，此时为了防止死循环，计算$mid$时需要加$1$。 bool check(int x) { ... ... } int binary_search_2(int l, int r) { while (l \u003c r) { int mid = (l + r + 1) \u003e\u003e 1; if (check(mid)) { // check为判断函数，我们自己手写的规则 l = mid; } else { r = mid - 1; } } return l; } ","date":"2020-01-21","objectID":"/posts/01.%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/:2:2","tags":["查找"],"title":"二分查找的奇技淫巧","uri":"/posts/01.%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"},{"categories":["数据结构与算法"],"content":"3 利用C++自带的lower_bound和upper_bound函数 ","date":"2020-01-21","objectID":"/posts/01.%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/:3:0","tags":["查找"],"title":"二分查找的奇技淫巧","uri":"/posts/01.%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"},{"categories":["数据结构与算法"],"content":"3.1 自带函数源码 lower_bound：返回一个迭代器，迭代器指向[first, last)不小于val的第一个元素。如果范围内的所有元素比较小于val，则函数返回last。 template \u003cclass ForwardIterator, class T\u003e ForwardIterator lower_bound (ForwardIterator first, ForwardIterator last, const T\u0026 val) { ForwardIterator it; iterator_traits\u003cForwardIterator\u003e::difference_type count, step; count = distance(first,last); while (count\u003e0) { it = first; step=count/2; advance (it,step); if (*it\u003cval) { // or: if (comp(*it,val)), for version (2) first=++it; count-=step+1; } else count=step; } return first; } upper_bound：返回一个迭代器，迭代器指向[first, last)大于val的第一个元素。如果范围内的所有元素比较都不大于val，则函数返回last。 template \u003cclass ForwardIterator, class T\u003e ForwardIterator upper_bound (ForwardIterator first, ForwardIterator last, const T\u0026 val) { ForwardIterator it; iterator_traits\u003cForwardIterator\u003e::difference_type count, step; count = std::distance(first,last); while (count\u003e0) { it = first; step=count/2; std::advance (it,step); if (!(val\u003c*it)) // or: if (!comp(val,*it)), for version (2) { first=++it; count-=step+1; } else count=step; } return first; } 根据源码，我们很容易就可以使用它们，不用自己手写了，但如果需要自定义比较规则，实际上就是需要我们实现一个check函数即可。 ","date":"2020-01-21","objectID":"/posts/01.%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/:3:1","tags":["查找"],"title":"二分查找的奇技淫巧","uri":"/posts/01.%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"},{"categories":["数据结构与算法"],"content":"3.2 进阶—自定义比较规则 在 C++ 中有很多情况下，我们需要自定义比较器，无非就是三种情况： 对一个自定义的 struct 重写它的 operator \u003c 方法 定义一个``Comparator`函数 定义一个Comparator结构体对象 自定义结构体 如果我们自定义了一个struct，然后想要对其排序又不想额外写一个比较器，那么最好实现它的 operaotr \u003c 方法。 struct node{ string s; node(string s) { this-\u003es = s; } bool operator \u003c (const node \u0026a) const { // 注意这两个const，必须要加上，否则会报错，前者const是能接收非const和const的实参，后者const是表明该函数不会修改类成员变量。 return this-\u003es.size() \u003c a.s.size(); } }; 这样，我们就可以使用了。如下： vector\u003cnode\u003e v(10, node(\"111\")); int pos = lower_bound(v.begin(), v.end(), node(\"111\")) - v.begin(); 函数比较器 可以通过编写一个外部的比较器函数，实现 \u003c 功能。 struct node{ string s; node(string s) { this-\u003es = s; } }; bool cmp(const string \u0026s1, const string \u0026s2) { return s1.size() \u003c s2.size(); } 这个通常用于自定义排序，其他的会报错，应该是不支持函数比较器，读者可自行尝试。 vector\u003cstring\u003e v(10, \"111\"); sort(v.begin(), v.end(), cmp); 函数对象比较器 所谓函数对象是指实现了 operator () 的类或者结构体。可以用这样的一个对象来代替函数作为比较器。 struct cmper { bool operator() (const string \u0026s1, const string \u0026s2) const { return s1.size() \u003c s2.size(); } }; 这个通常用于自定义排序，其他的会报错，应该是不支持函数比较器，读者可自行尝试。 vector\u003cstring\u003e v(10, \"111\"); sort(v.begin(), v.end(), cmper()); ","date":"2020-01-21","objectID":"/posts/01.%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/:3:2","tags":["查找"],"title":"二分查找的奇技淫巧","uri":"/posts/01.%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"}]