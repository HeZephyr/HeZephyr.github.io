<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>深度学习 - 分类 | ZephyrHe</title><link>https://hezephyr.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link><description>深度学习 - 分类 | ZephyrHe</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>unique.hzf@gmail.com (HeZephyr)</managingEditor><webMaster>unique.hzf@gmail.com (HeZephyr)</webMaster><copyright>本站内容采用 CC BY-NC-SA 4.0 国际许可协议。</copyright><lastBuildDate>Wed, 17 Jul 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://hezephyr.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="self" type="application/rss+xml"/><item><title>【论文阅读笔记】 Attention Is All You Need</title><link>https://hezephyr.github.io/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/</link><pubDate>Wed, 17 Jul 2024 00:00:00 +0000</pubDate><author>HeZephyr</author><guid>https://hezephyr.github.io/posts/03.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0transformer/</guid><description><![CDATA[<h2 id="1-引言" class="heading-element"><span>1 1 引言</span>
  <a href="#1-%e5%bc%95%e8%a8%80" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>循环神经网络(RNN)，特别是长短期记忆和门控循环神经网络（<strong>编码器-解码器</strong>架构），已成为序列建模和转换问题（如语言建模和机器翻译）的先进方法，众多研究在不断推动其发展。</p>
<p><a class="lightgallery" href="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/RNN?size=large" data-thumbnail="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/RNN?size=small" data-sub-html="<h2>RNN做机器翻译</h2>"><img loading="lazy" src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/RNN" alt="RNN做机器翻译" srcset="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/RNN?size=small, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/RNN?size=medium 1.5x, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/RNN?size=large 2x" data-title="RNN做机器翻译" class="suffix-invalid suffix-invalid__small suffix-invalid__large" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
<p>但RNN通常<font color="red">沿输入和输出序列的符号位置</font>进行计算，其固有的顺序性导致训练示例内难以并行化，在序列长度较长时，由于内存限制跨示例的批处理，这一问题更加突出。尽管近期通过一些技术改进了计算效率，<font color="red">但顺序计算的基本限制仍未改变</font>。</p>
<p>且RNN使用共享权值矩阵，在面临较长序列时，会有梯度消失的问题(也可以说是后面词的梯度会覆盖前面的梯度)。即使后序的LSTM和GRU对这一部分做了改进，但也无法完全解决该问题。</p>
<p><font color="red">注意力机制</font>已成为各种序列建模和转换模型的重要组成部分，能在不考虑输入或输出序列距离的情况下对依赖关系进行建模，但在大多数情况下与循环网络结合使用。</p>
<p>作者提出了 Transformer 模型，该模型摒弃了循环单元和卷积单元，完全依赖注意力机制来建立输入和输出之间的全局依赖关系，允许更多的并行化。</p>
<h2 id="2-背景" class="heading-element"><span>2 2 背景</span>
  <a href="#2-%e8%83%8c%e6%99%af" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p><font color="red">减少序列计算量和加速计算</font>是序列处理模型中的基本思想。ByteNet和ConvS2S通过使用卷积神经网络并行计算，计算量和序列中位置的距离相关。ConvS2S是线性关系，而ByteNet是对数关系，使得长距离关系学习困难。Transformer将这个过程减少到常数规模，尽管降低了有效分辨率，但<strong>多头注意力机制</strong>弥补了这一点。</p>
<p>自注意力机制（内部注意力机制）为<font color="red">序列的不同位置分配权重，并学习表示向量</font>，已在阅读理解、文本摘要等任务中表现出色。</p>
<p>端到端记忆网络通常基于循环注意力机制，已用于简单语言翻译等任务。而Transformer 是<font color="red">第一个完全依赖自注意力</font>来计算其输入和输出表示的转换模型。</p>
<h2 id="3-模型架构" class="heading-element"><span>3 3 模型架构</span>
  <a href="#3-%e6%a8%a1%e5%9e%8b%e6%9e%b6%e6%9e%84" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>Transformer中沿用了非常经典的编码器-解码器架构，编码器将输入的序列$(x_1,\dots,x_n)$转化成一个表示向量$\boldsymbol{z}=(z_1,\dots,z_n)$，而编码器依据向量$\boldsymbol{z}$逐步生成输出序列$(y_1,\dots,y_m)$，并且模型在每个步骤中都是<strong>自回归</strong>的，会将先前生成的符号作为生成下一个的额外输入，例如这一步要生成$y_t$，要将$(y_1,\dots,y_{t-1})$都拿到也作为输入。</p>
<p>同时Transformer模型在编码器和解码器中都使用堆叠自注意力机制和逐点全连接层，如下图的左半部分和右半部分所示。</p>
<img src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/Transformer_Architecture" alt="image-20240707194838925" style="zoom: 33%;" />
<h3 id="31-编码器堆叠和解码器堆叠" class="heading-element"><span>3.1 3.1 编码器堆叠和解码器堆叠</span>
  <a href="#31-%e7%bc%96%e7%a0%81%e5%99%a8%e5%a0%86%e5%8f%a0%e5%92%8c%e8%a7%a3%e7%a0%81%e5%99%a8%e5%a0%86%e5%8f%a0" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p>编码器由 $6$ 个相同的层堆叠而成。每个层包含两个子层：<font color="red">多头自注意力机制和逐位置全连接前馈神经网络</font>。每个子层都使用了残差连接，然后进行层规范化（<strong>防止模型过拟合</strong>）。假设每一层的输入是$x$，那么每一层的输出结果可以表示为：
$$
\text{LayerNorm}(x+\text{Sublayer(x)})
$$
其中</p>
<ul>
<li>$\text{SubLayer}$是当前子层本身实现的运算函数，比如注意力运算和全连接运算；</li>
<li>模型中的所有子层以及嵌入层的输出维度均为 $d_{\text{model}} = 512$（便于残差连接）。</li>
</ul>
<p>解码器同样由 6 个层组成。其结构与编码器类似，但多了一个<strong>对编码器输出进行关注的多头注意力子层</strong>。并且在<strong>自注意力子层中进行了修改</strong>，以防止信息左向流动。这种掩码机制，结合输出嵌入向量向后偏移一个位置，确保位置 $i$ 的预测仅依赖于位置小于 $i$ 的已知输出。</p>
<h3 id="32-注意力机制" class="heading-element"><span>3.2 3.2 注意力机制</span>
  <a href="#32-%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p>注意力机制就是对一系列的query和一系列的key-value对，我们需要确定对于每个query而言不同 value 的重要程度，而这个权重是根据 query 和key 的相关度计算得到的。</p>
<h4 id="321-缩放的点积注意力机制" class="heading-element"><span>3.2.1 3.2.1 缩放的点积注意力机制</span>
  <a href="#321-%e7%bc%a9%e6%94%be%e7%9a%84%e7%82%b9%e7%a7%af%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h4><p>Transformer模型中使用的是缩放的点积注意力机制。在这种机制中，注意力计算涉及query和key的维度为  $d_k$ )，以及value的维度为 $d_v$ 。通过引入一个<strong>缩放因子</strong>$\sqrt{d_k}$，可以控制注意力分布的稳定性和计算效率。</p>
<img src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/Scaled_Dot_Product_Attention" alt="image-20240707205349089" style="zoom:33%;" />
<p>我们用向量化的方式可以将这种注意力机制的计算过程表示成：
$$
\text{Attention}(Q,K,V)=\text{softmax}(\frac{QK^T}{\sqrt{d_k}})V
$$
与传统的注意力机制相比，缩放的点积注意力计算速度更快。缩放参数用于调节注意力计算的规模，以确保对于不同大小的输入，注意力权重的计算结果都能保持在合理的范围内。特别是在$\text{softmax}$函数的应用中，由于指数函数的快速增长特性，<font color="red">缩放可以有效防止某些权重过大</font>，而其他权重接近零的情况，确保了计算结果的平稳性和有效性。</p>
<h4 id="322-多头注意力机制" class="heading-element"><span>3.2.2 3.2.2 多头注意力机制</span>
  <a href="#322-%e5%a4%9a%e5%a4%b4%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h4><h4 id="heading" class="heading-element"><span>3.2.3 </span>
  <a href="#heading" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h4><p>Transformer采用了多头注意力机制，将query、key和value进行$h$次投影，然后对$h$个投影并行计算注意力，再将这些结果组合并线性投影生成最终的多头注意力输出。多头注意力使模型能够共同关注不同表示子空间和不同位置的信息。</p>
<img src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/Multi_Head_Attention" alt="image-20240707214205509" style="zoom:50%;" />
<p>多头注意力机制的计算公式为：
$$
\operatorname{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, \ldots, \text{head}_h) W^O
$$
其中每个头的计算方式为：</p>
<p>$$
\text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)
$$
参数的维度如下：</p>
<ul>
<li>$( Q, K, V)$ 的输入维度为 $( d_{model} )$（通常为$512$）</li>
<li>$W_i^Q \in \mathbb{R}^{d_{model} \times d_k},  W_i^K \in \mathbb{R}^{d_{model} \times d_k}, W_i^V \in \mathbb{R}^{d_{model} \times d_v}, W^O \in \mathbb{R}^{hd_v \times d_{model}}$</li>
</ul>
<p>作者在Transformer中设置 $h = 8$  个头，每个头的维度为 $d_k = d_v = \frac{d_{model}}{h} = 64$。</p>
<h4 id="323-transformer中注意力机制的应用" class="heading-element"><span>3.2.4 3.2.3 Transformer中注意力机制的应用</span>
  <a href="#323-transformer%e4%b8%ad%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6%e7%9a%84%e5%ba%94%e7%94%a8" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h4><ul>
<li>在解码器的“编码器-解码器注意力层”中，query 来自上一个解码器层，而 key 和值 value 来自编码器的输出。这使得解码器中的每个位置都可以参与到输入序列所有位置的注意力计算中。</li>
</ul>
<ol>
<li><strong>编码器-解码器注意力层</strong>： 在这一层中，query 来自上一个解码器，而记忆 key 和 value 来自编码器的输出。这使得解码器中的每个位置都可以关注输入序列中的所有位置。</li>
<li><strong>编码器中的自注意力层</strong>： 编码器包含自注意力层。在这种自注意力机制中，<font color="red">query, key 和 value 都来自同一位置，即编码器前一层的输出</font>。这样，编码器中的每个位置都可以关注编码器前一层中的所有位置，从而捕捉输入序列中不同位置之间的全局依赖关系。</li>
<li><strong>解码器中的自注意力层</strong>： 解码器中的自注意力层的key，value和query也是同源的。但为了保持自回归属性，防止序列中前面的内容被后面的内容所影响，解码器在自注意力计算中加入了掩码机制。具体来说，通过在缩放的点积注意力中，将$\operatorname{softmax}$输入中对应非法连接的值设置为$-\infin$，来屏蔽这些连接。</li>
</ol>
<h3 id="33-逐位置全连接前馈神经网络" class="heading-element"><span>3.3 3.3 逐位置全连接前馈神经网络</span>
  <a href="#33-%e9%80%90%e4%bd%8d%e7%bd%ae%e5%85%a8%e8%bf%9e%e6%8e%a5%e5%89%8d%e9%a6%88%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><h3 id="transformer中的逐位置全连接前馈神经网络" class="heading-element"><span>3.4 Transformer中的逐位置全连接前馈神经网络</span>
  <a href="#transformer%e4%b8%ad%e7%9a%84%e9%80%90%e4%bd%8d%e7%bd%ae%e5%85%a8%e8%bf%9e%e6%8e%a5%e5%89%8d%e9%a6%88%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p>在Transformer中，逐位置全连接前馈神经网络用于增强模型对序列中每个位置信息的处理能力，这种网络结构包含两个线性变换层和$\operatorname{ReLU}$激活函数，用于每个位置独立地进行相同的操作。其数学表示如下：</p>
<p>$$
\text{FFN}(x) = \max(0, x W_1 + b_1) W_2 + b_2
$$</p>
<p>虽然不同位置的线性变换相同，但各层使用的参数不同。其中，$x$ 是输入向量，维度为 $d_{\text{model}} = 512$ ，而内层的维度为$d_{ff}=2048$，$W_1$ 和 $W_2$ 是两个线性变换的权重矩阵，$b_1$ 和 $b_2$ 是相应的偏置向量。这个结构类似于<code>kernel size</code>为1的卷积操作。</p>
<h3 id="34-嵌入和softmax" class="heading-element"><span>3.5 3.4 嵌入和Softmax</span>
  <a href="#34-%e5%b5%8c%e5%85%a5%e5%92%8csoftmax" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p>和其他序列转换模型类似，Transformer 使用学习得到的嵌入将输入的token和输出的token转换为维度为 $ d_{\text{model}} $ 的向量。Transformer 还使用学习得到的线性变换和$\text{softmax}$函数将解码器的输出转换为预测的下一个token的概率。在Transformer中两个嵌入层和$\text{softmax}$之前的线性变换层之间共享相同的权重矩阵（<strong>减少模型的参数数量，降低过拟合的风险</strong>），同时在嵌入层中，我们将这些权重乘以  $\sqrt{d_{\text{model}}}$（<strong>缩放嵌入权重，防止梯度消失</strong>）。</p>
<h3 id="35-位置编码" class="heading-element"><span>3.6 3.5 位置编码</span>
  <a href="#35-%e4%bd%8d%e7%bd%ae%e7%bc%96%e7%a0%81" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p>在Transformer模型中，由于没有循环和卷积单元，为了处理序列数据的位置信息，引入了位置编码。位置编码是为序列中的每个位置添加特定的向量表示，以便模型能够区分不同位置的token。在Transformer中的位置编码使用了sin函数和cos函数，这种方法不同于传统的学习得到的位置嵌入，而是采用固定的函数形式，即</p>
<p>$$
\text{PE}<em>{\text{pos}, 2i} = \sin\left(\frac{\text{pos}}{10000^{\frac{2i}{ d</em>{\text{model}}}}}\right)\
\text{PE}<em>{\text{pos}, 2i+1} = \cos\left(\frac{\text{pos}}{10000^{\frac{2i}{ d</em>{\text{model}}}}}\right)
$$</p>
<p>这里的$\text{pos}$表示位置而$i$表示维度，也就是对于位于$\text{pos}$位置的token的嵌入向量第$i$维加上这样一个值。</p>
<h2 id="4-为什么使用自注意力机制" class="heading-element"><span>4 4 为什么使用自注意力机制</span>
  <a href="#4-%e4%b8%ba%e4%bb%80%e4%b9%88%e4%bd%bf%e7%94%a8%e8%87%aa%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>在处理序列数据时，长距离依赖关系的学习是一个关键挑战。论文中对比了使用自注意力、循环单元和卷积单元等不同模型结构时的计算量、时间复杂度和最大依赖路径长度。其中，最大依赖路径长度指的是任意两个输入输出位置之间信息传递的最长路径。</p>
<p><a class="lightgallery" href="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/Maximum_Path_Lengths?size=large" data-thumbnail="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/Maximum_Path_Lengths?size=small" data-sub-html="<h2>image-20240707224337637</h2>"><img loading="lazy" src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/Maximum_Path_Lengths" alt="image-20240707224337637" srcset="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/Maximum_Path_Lengths?size=small, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/Maximum_Path_Lengths?size=medium 1.5x, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/Maximum_Path_Lengths?size=large 2x" data-title="image-20240707224337637" class="suffix-invalid suffix-invalid__small suffix-invalid__large" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
<p>在传统的循环神经网络（RNN）中，信息是逐步传递的，因此全局视角下，任意两个位置之间的最长信息传递路径往往是以序列长度 $n$ 为量级的。这种逐步传递导致了RNN在捕捉长距离依赖时可能面临的挑战，尤其是在处理长序列时效果不佳。</p>
<p>相比之下，<font color="red">Transformer利用自注意力机制直接将每个位置与所有其他位置进行关联，避免了逐步传递的过程</font>，使得任意两个位置之间的信息传递路径变得极为直接和高效。这种直接的路径传递方式使得Transformer能够更有效地捕捉到长距离的依赖关系，而不受序列长度的限制。</p>
<p>因此，Transformer凭借其独特的注意力机制，实现了“Attention is all you need”的理念，强调了在序列建模中注意力机制的重要性和效果。它不仅仅是一种模型结构的创新，更是在解决长距离依赖问题上的一次重大突破。Transformer的成功不仅在于其高效的信息传递路径，还在于其能够在更大范围内捕捉和利用序列中的关联信息，从而提升了序列建模任务的性能和效果。</p>
<h2 id="5-训练" class="heading-element"><span>5 5 训练</span>
  <a href="#5-%e8%ae%ad%e7%bb%83" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>在论文中，训练Transformer模型涉及到几个关键的优化和正则化策略。</p>
<h3 id="51-优化器" class="heading-element"><span>5.1 5.1 优化器</span>
  <a href="#51-%e4%bc%98%e5%8c%96%e5%99%a8" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p>模型的训练使用了Adam优化器，并采用了一种自适应的学习率。学习率 $\text{lr}$ 的计算方式如下所示：
$$
\text{lr} = d_{\text{model}}^{-0.5} \times \min(\text{step_num}^{-0.5}, \text{step_num} \times \text{warm_up_steps}^{-1.5})
$$
这种自适应学习率的设计有助于在训练初期快速提升学习率，以加速模型收敛，而在训练后期逐渐降低学习率，以更细致地调整模型参数，提升训练的稳定性和效果。</p>
<h3 id="52-正则化" class="heading-element"><span>5.2 5.2 正则化</span>
  <a href="#52-%e6%ad%a3%e5%88%99%e5%8c%96" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p>Transformer模型采用了多种正则化方法，以提升泛化能力和训练稳定性：</p>
<ol>
<li>
<p><strong>残差连接</strong>：在每个子层之间都使用了残差连接，这种连接方式有助于减少梯度消失问题，并简化了模型的训练和优化过程。</p>
</li>
<li>
<p><strong>Dropout</strong>：在输入嵌入向量和位置编码相加后的层中使用了Dropout，选择的Dropout概率为0.1。Dropout通过随机地将部分神经元的输出置为零，有助于防止模型过拟合，并增强泛化能力。</p>
</li>
<li>
<p><strong>标签平滑处理</strong>：这是一种用于改善模型训练和提高评价指标（如BLEU分数）的技术。标签平滑处理通过将真实标签替换为一个分布更平滑的目标分布，从而减少模型对训练数据中特定标签的过度自信，提升泛化能力和性能评估的一致性。</p>
</li>
</ol>
]]></description></item><item><title>【论文阅读笔记】 SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks</title><link>https://hezephyr.github.io/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/</link><pubDate>Wed, 17 Jul 2024 00:00:00 +0000</pubDate><author>HeZephyr</author><guid>https://hezephyr.github.io/posts/04.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0skexgen/</guid><description><![CDATA[<h2 id="摘要" class="heading-element"><span>1 摘要</span>
  <a href="#%e6%91%98%e8%a6%81" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>SkexGen是一种新颖的<font color="red">自回归生成模型</font>，用于创建CAD构造序列，其中包含<font color="red">草图和拉伸建模操作</font>。这个模型利用不同的Transformer架构将构造序列中的<strong>拓扑、几何和拉伸变化</strong>编码到<strong>解耦的码本</strong>中。<strong>自回归</strong>Transformer解码器根据码本向量生成具有特定属性的CAD构造序列。广泛的实验表明，我们的解耦码本表示可以生成多样且高质量的CAD模型，增强了用户的控制能力，并能够有效探索设计空间。</p>
<p><a href="https://github.com/samxuxiang/SkexGen"target="_blank" rel="external nofollow noopener noreferrer">【code】<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h2 id="1-引言" class="heading-element"><span>2 1 引言</span>
  <a href="#1-%e5%bc%95%e8%a8%80" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>SkexGen是一种新颖的自回归生成模型，使用离散码本进行CAD模型生成。作者采用草图和拉伸建模语言来描述CAD构造序列，其中草图操作创建二维原语，拉伸操作将它们提升并组合成三维。<font color="red">Transformer编码器学习到解耦的潜在表示，作为三个码本，分别捕捉构造序列的拓扑、几何和拉伸变化</font>。给定码本向量，自回归Transformer解码器生成草图和拉伸构造序列，进而处理成CAD模型。</p>
<p>作者在一个大规模草图和拉伸数据集（<a href="https://drive.google.com/drive/folders/1mSJBZjKC-Z5I7pLPTgb4b5ZP-Y6itvGG"target="_blank" rel="external nofollow noopener noreferrer">DeepCAD数据集，需要将其转换为SkexGen格式<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>）上评估了SkexGen。与多个baseline和最先进方法进行的定性和定量评估表明，SkexGen生成了更真实和多样的CAD模型，同时实现了有效的控制和高效的设计空间探索，这是以往方法无法实现的。作者做出了以下贡献：</p>
<ul>
<li><strong>SkexGen架构</strong>，自回归生成高质量和多样化的CAD构造序列。</li>
<li><strong>解耦的码本</strong>，编码构造序列的拓扑、几何和拉伸变化，实现了设计的有效控制和探索。</li>
<li>在<strong>公共基准</strong>上的广泛定性和定量评估，展示了最先进的性能。</li>
</ul>
<h2 id="2-相关工作" class="heading-element"><span>3 2 相关工作</span>
  <a href="#2-%e7%9b%b8%e5%85%b3%e5%b7%a5%e4%bd%9c" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><ul>
<li>
<p><strong>构造性实体几何（CSG）</strong></p>
<p>3D形状由参数化基元通过布尔运算组成的CSG树表达。这种轻量级表示已广泛用于与程序合成、神经引导程序合成、无监督学习和专用参数化基元结合的重建任务中。<font color="red">但参数化CAD仍主导机械设计，并且广泛使用草图和拉伸建模操作</font>。</p>
</li>
<li>
<p><strong>构造序列生成</strong></p>
<ul>
<li>PolyGen开创：使用Transformer和指针网络预测n-gon网格顶点和面。</li>
<li>数据集推动：大规模CAD建模操作数据集促进直接学习用户建模操作。</li>
<li>拉伸操作预测：预测拉伸操作序列以部分恢复构造序列，但没有底层草图信息。<font color="red">预测线、弧、圆等草图基元的序列是形成CAD二维基础的关键构造块，可通过添加拉伸操作轻松扩展到3D</font>。</li>
<li>Transformer架构的应用：应用于草图和拉伸序列生成，<font color="red">但在用户控制方面存在局限</font>。</li>
</ul>
<p>现有的方法通常将<font color="red">网络条件设置为用户提供的图像、点云或手绘草图</font>，只是将现有设计转换为CAD构造序列表示，<font color="red">而没有提供对拓扑和几何的单独控制</font>来探索相关设计的空间。作者的方法则提供对拓扑和几何的单独控制。</p>
</li>
<li>
<p><strong>码本架构</strong></p>
<p>自引入以来，码本已在许多图像和音频生成任务中证明有效，提高了生成图像的多样性并提供了额外的用户控制。由于其高结构规律性，它们特别适合于编码CAD建模序列。</p>
</li>
</ul>
<h2 id="3-草图和拉伸构造序列" class="heading-element"><span>4 3 草图和拉伸构造序列</span>
  <a href="#3-%e8%8d%89%e5%9b%be%e5%92%8c%e6%8b%89%e4%bc%b8%e6%9e%84%e9%80%a0%e5%ba%8f%e5%88%97" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>作者定义了一个草图和拉伸构造序列表示法，作为基元的层次结构，这一构造基于TurtleGen和DeepCAD的基础，并进行了若干修改，使表示法更具表现力和学习适应性，如下图所示，该示例模型由两个草图组成，这些草图由面、环和曲线构成。序列以拓扑token（$T_1$）开始，表示曲线的起点（类型为弧线），接着两个几何token（$G_1,G_2$），每个token存储一个二维点坐标，。</p>
<img src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/SkexGen_Construction_Seq_Example.png" alt="image-20240709221547861" style="zoom: 50%;" />
<p><strong>基元层次结构：</strong></p>
<ul>
<li><strong>曲线</strong>：最低级别的基元，包括直线、弧线或圆。</li>
<li><strong>环</strong>：一个闭合路径，由一个（例如圆）或多个曲线（例如直线-弧线-直线）组成。</li>
<li><strong>面</strong>：<font color="red">一个由环限定的二维区域</font>，这是我们的表示法中新增加的。具体来说，<font color="red">一个面由一个外环和若干内环（洞）构成</font>，这在许多CAD系统中是一个惯例。</li>
<li><strong>草图</strong>：由一个或多个面组成。</li>
<li><strong>拉伸草图</strong>：通过拉伸草图形成的三维体积。</li>
<li><strong>草图和拉伸模型</strong>：通过布尔操作（例如交集、并集和差集）由多个拉伸草图组成。<font color="red">注意，DeepCAD的表示法没有面基元，无法表示具有多个面的草图（例如Figure 1中的ES1）</font>。</li>
</ul>
<h2 id="4-skexgen架构" class="heading-element"><span>5 4 SkexGen架构</span>
  <a href="#4-skexgen%e6%9e%b6%e6%9e%84" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>SkexGen 是一种自回归生成模型，通过两个网络分支中的三个解耦码本学习草图和拉伸模型的变体。图2展示了SkexGen的架构。“草图”分支学习二维草图的拓扑和几何变体，“拉伸”分支学习三维拉伸的变体（如方向）。两个分支架构类似，本节重点介绍草图分支，包含两个编码器和一个解码器。</p>
<img src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/SkexGen_Architecture.png" alt="image-20240709221648006" style="zoom:50%;" />
<h3 id="41-拓扑编码器" class="heading-element"><span>5.1 4.1 拓扑编码器</span>
  <a href="#41-%e6%8b%93%e6%89%91%e7%bc%96%e7%a0%81%e5%99%a8" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p>拓扑编码器接收输入的子序列，token为：</p>
<ol>
<li>
<p><strong>拓扑token（T）</strong>：表示三种曲线类型之一（直线/弧线/圆）。</p>
</li>
<li>
<p><strong>结束基元token（E）</strong>：表示三种基元类型之一（环/面/草图）的结束。</p>
</li>
<li>
<p><strong>结束序列token（End）</strong>：表示序列的结束。</p>
</li>
</ol>
<p>因此，token初始化为一个7维（= 3+3+1）的独热向量</p>
<ul>
<li>
<p><strong>嵌入</strong></p>
<p>独热向量转换为256维嵌入。作者考虑拓扑token $T$，其中$h_{T} ^{tp}$是7维独热向量，$i_T$表示其在输入子序列中的索引，其嵌入向量计算公式为：</p>
<p>$$
T \leftarrow \mathbf{W}^\text{tp} h_{T} ^{tp} + \mathbf{p}^{(i_T)}
$$</p>
<p>其中$\mathbf{W}^\text{tp}\in \mathbb{R}^{d_E\times 7}$表示可学习矩阵，$\mathbf{p}^{(i_T)}$表示拓扑子序列索引$i_T$处的可学习位置编码。</p>
</li>
<li>
<p><strong>架构</strong></p>
<p>编码器基于Transformer（<font color="red">四层，每层包含八头自注意层、层规范化和前馈层</font>）。根据Vision Transformer，<strong>输入的拓扑信息编码为一个“码token”</strong>，预先加入到输入中，并初始化为一个可学习的嵌入$Z_{tp}$。令$Z_{tp}^e$为编码器输出的码token嵌入。嵌入$Z_{tp}^e$被量化为大小为$N({\mathbf{b}_{tp}\text{ | }i=1,2\cdots N})$的<strong>码本最近码</strong>。</p>
<p>编码和量化后的最终码token $Z_{tp}^Q$被传递给解码器。</p>
<p>$$
Z^Q_{tp} \leftarrow \mathbf{b}^{(k)}<em>{tp}, \text{where }
k = \text{argmin}</em>{j} | Z^e_{<em>{tp}} - b^{(j)}</em>{tp} |^2
$$</p>
<p>f这里为了简单起见，只假设了一个码token，拓扑编码器实际上由四个码token，并产生四个输出码token（$Z^{Q_{(1)}}<em>{tp},Z^{Q</em>{(2)}}<em>{tp},Z^{Q</em>{(3)}}<em>{tp},Z^{Q</em>{(4)}}_{tp}$）。作者尝试了不同的码本大小，发现 $N = 500$ 可以取得良好效果。</p>
</li>
</ul>
<h3 id="42-几何编码器" class="heading-element"><span>5.2 4.2 几何编码器</span>
  <a href="#42-%e5%87%a0%e4%bd%95%e7%bc%96%e7%a0%81%e5%99%a8" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><ul>
<li>
<p><strong>输入token</strong></p>
<ul>
<li>
<p>几何token（G）：包含一个二维点坐标</p>
</li>
<li>
<p>结束基元token（E）：表示四种基元类型之一（曲线/面/环/草图）的结束</p>
</li>
<li>
<p>结束序列token（End）</p>
</li>
</ul>
<p>几何token G 指定沿曲线的一个二维点坐标。由于坐标是数值型的，作者将<font color="red">草图离散化</font>为$64\times 64$（6位）像素，并考虑$64^2$个可能的像素位置。因此，一个$4101(=64^2+4+1)$维的独热向量唯一确定了token信息。</p>
</li>
<li>
<p><strong>嵌入</strong></p>
<p>我们按照4.1中的嵌入公式并使用$\mathbf{W^{ge}}\in\mathbb{R}^{d_E\times 4101}$和位置编码来初始化输入token嵌入。token E和End类似于拓扑Token的初始化，通过将它们的独热向量$h^{ge}_G\in \mathbb{R}^{4101}$乘以$\mathbf{W^{ge}}$并加上位置编码。几何Token G的初始化不同：</p>
<p>$$
G \leftarrow \mathbf{W^{ge}} h^{ge}_G + \mathbf{W}^xh^x_G +
\mathbf{W}^y h^y_G + \mathbf{p}^{(i_G)}.
$$</p>
<p>几何token $G$具有附加的坐标嵌入，$h^x_G,h^y_G\in \mathbb{R}^{64}$是指示像素的$x,y$坐标的独热向量。坐标嵌入是可选的，但可以进一步提高实验结果。</p>
</li>
<li>
<p><strong>架构</strong></p>
<ul>
<li>类似于拓扑编码器，基于Transformer。</li>
<li>生成嵌入 $Z^{{e_{(i)}}}<em>{ge}$ 和量化后的码token $Z^{Q</em>{(i)}}_{ge}$ 。</li>
<li>使用两个码token，码本大小 $N = 1000$。</li>
</ul>
</li>
</ul>
<h3 id="43-草图解码器" class="heading-element"><span>5.3 4.3 草图解码器</span>
  <a href="#43-%e8%8d%89%e5%9b%be%e8%a7%a3%e7%a0%81%e5%99%a8" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p>草图解码器以拓扑和几何码本为输入，生成几何token $G$和结束基元token $E$（用于曲线/环/面/草图），以恢复草图子序列。</p>
<blockquote>
<p>注意，不生成拓扑标记T，因为它们可以根据每条曲线内的几何标记数量推断出来（即，直线/弧线/圆分别有1/2/4个G标记）。这意味着几何编码器和草图解码器有相似的子序列（Figure 2）。</p>
</blockquote>
<ul>
<li>
<p><strong>输入</strong></p>
<p>给定前$k-1$个token，自回归解码器预测第$k$个token的条件概率。训练输入序列向右移一位，前面添加“start”符号（由位置编码初始化）。由于解码器中可能的token类型与几何编码器相同，我们使用相同的$4101$维独热编码方案，并使用带有位置编码的可学习矩阵（大小为 $d_E \times 4101$）初始化嵌入向量。</p>
</li>
<li>
<p><strong>输出</strong></p>
<p>解码器生成“向左移一位”的子序列，即预测输入中的原始$k$个标记（见Figure 2）。令$K$为草图解码器输出中的一个标记，其具有 $d_E$ 维嵌入。我们使用可学习矩阵 $\mathbf{W^{out}} \in \mathbb{R}^{4101 \times d_E}$ 来预测4101个类别的概率：$h^\text{out}_K \leftarrow \text{softmax} (\mathbf{W^\text{out}} K)$</p>
</li>
<li>
<p><strong>交叉注意力</strong></p>
<p><font color="red">Transformer架构通过交叉注意力从拓扑和几何码本中分别取四个和两个量化码本向量</font>。为了区分两个不同的码本，我们借鉴位置编码的思想，分别向拓扑码 ${ Z^{Q_{(i)}}<em>{tp} }$ 和几何码 ${ Z^{Q</em>{(i)}}<em>{ge} }$ 添加可学习嵌入向量 $\mathbf{p}^{(q</em>{tp})} \in \mathbb{R}^{4 \times d_E}$和 $\mathbf{p}^{(q_{ge})} \in \mathbb{R}^{2 \times d_E}$ ：</p>
<p>$$
Z^{{Q_{(i)}}}<em>{tp} + p^{(q</em>{tp})} \quad \text{or} \quad
Z^{Q_{(i)}}<em>{ge}+ p^{(q</em>{ge})}.
$$</p>
<p>基础网络设置与编码器相同（即四层，每层八头），<font color="red">但它是带掩码的自回归（仅关注先前的标记）</font>。</p>
</li>
</ul>
<h3 id="44-训练" class="heading-element"><span>5.4 4.4 训练</span>
  <a href="#44-%e8%ae%ad%e7%bb%83" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p>拓扑编码器、几何编码器和草图解码器通过三种损失函数联合训练：</p>
<p>$$
\sum_K \text{CrossEntropy}(h^\text{out}<em>K, h^\text{gt}<em>K) + \
| \text{sg} (Z^{e}</em>{tp}) - \mathbf{b}</em>{tp} |<em>2^2 + \beta
| Z^{e}</em>{tp} - \text{sg} (\mathbf{b}<em>{tp}) |<em>2^2 + \
| \text{sg} (Z^{e}</em>{ge}) - \mathbf{b}</em>{ge}
|<em>2^2 + \beta | Z^{e}</em>{ge} - \text{sg} (b_{ge}) |_2^2.
$$</p>
<ul>
<li>
<p>第一行计算序列重建损失，其中 $h^\text{out}_K$ 是草图解码器预测的概率， $h^\text{gt}_K$ 是真实的独热向量，<font color="red">利用交叉熵损失衡量准确度</font>。</p>
</li>
<li>
<p>第二行和第三行是VQ-VAE使用的标准码本和承诺损失。 $\text{sg}$ 表示<strong>停止梯度操作</strong>，在前向传播中是恒等函数，但在后向传播中阻止梯度。 $\beta$ <strong>缩放承诺损失</strong>，设为$0.25$，用于调整承诺损失的权重，这确保编码器输出绑定一个码向量。</p>
</li>
</ul>
<p>为了简化，我们省略了每个编码器中多个码本标记的明确写出。<font color="red">给定一个真实子序列，我们运行两个编码器并自回归地运行解码器，直到生成相同数量的标记</font>。训练采用教师强制的方式，即将真实token而非预测token输入解码器，保证每次迭代解码器仅专注于单步训练，从而简化训练流程并提升效率</p>
<h3 id="45-生成" class="heading-element"><span>5.5 4.5 生成</span>
  <a href="#45-%e7%94%9f%e6%88%90" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p>SkexGen 生成 CAD 模型分两步：</p>
<ol>
<li>从三个码本生成码。
<ul>
<li>
<p>采用训练完成的编码器（拓扑、几何、拉伸）从样本中提取码。</p>
</li>
<li>
<p>Transformer解码器被训练来生成这些<font color="red">非正态分布的量化码，即从码本中挑选码索引</font>。</p>
</li>
<li>
<p>允许架构微小修改以支持条件码生成，如“拓扑条件码选择器”，它基于给定拓扑码来挑选相应的几何和拉伸码。</p>
</li>
</ul>
</li>
<li>给定码生成草图和拉伸构造序列。
<ul>
<li>
<p>给定码，草图和拉伸解码器便通过核采样，自回归方式生成构造子序列。</p>
</li>
<li>
<p>这些子序列整合成完整的草图和拉伸序列，最终由CAD软件解析为边界表示。</p>
</li>
</ul>
</li>
</ol>
<h2 id="5-实验" class="heading-element"><span>6 5 实验</span>
  <a href="#5-%e5%ae%9e%e9%aa%8c" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>实验验证目标：</p>
<ul>
<li>
<p>SkexGen生成高质量和多样化结果的能力</p>
</li>
<li>
<p>码本对生成过程控制的程度</p>
</li>
<li>
<p>SkexGen在设计探索和插值应用中的表现</p>
</li>
</ul>
<h3 id="51-实验设置" class="heading-element"><span>6.1 5.1 实验设置</span>
  <a href="#51-%e5%ae%9e%e9%aa%8c%e8%ae%be%e7%bd%ae" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><ul>
<li>
<p><strong>数据集</strong>：使用DeepCAD数据集，包含178,238个序列，经去重和无效操作剔除，最终训练集含<strong>74,584个草图子序列</strong>与<strong>86,417个拉伸子序列</strong>。针对单一草图实验，经过从构造序列的步骤中提取草图并去重后，<strong>最终收集到114,985个训练样本</strong>。</p>
</li>
<li>
<p><strong>实现细节</strong>：SkexGen基于PyTorch开发，在RTX A5000上训练。采用与DeepCAD一致的设置，四层Transformer结构，每层含八个注意力头，层规范化，前馈维度512，输入嵌入256维，Dropout率0.1。使用Adam优化器，学习率0.001。线性预热和梯度裁剪与 DeepCAD 一致。<font color="red">我们在前25个epoch中跳过代码量化，发现这有助于稳定码本训练。对于数据增强，我们向几何标记的坐标添加小的随机噪声</font>。训练300个epoch，批量大小128。草图与拉伸子序列最大长度分别为200与100。在测试时，我们使用核采样方法以自回归方式采样码选择器和解码器。</p>
</li>
<li>
<p><strong>指标</strong>：</p>
<ul>
<li>
<p><strong>Fréchet Inception Distance (FID)</strong>：比较真实和生成数据分布的均值和协方差来衡量生成的保真度。</p>
</li>
<li>
<p><strong>覆盖率（COV）</strong>：基于表面上2,000个均匀采样点的最小 Chamfer 距离来衡量真实数据与生成数据的匹配百分比。</p>
</li>
<li>
<p><strong>最小匹配距离 (MMD)</strong>：生成样本与其在真实数据集中最近邻的平均最小匹配距离。</p>
</li>
<li>
<p><strong>Jensen-Shannon散度 (JSD)</strong>：基于边缘点分布衡量真实和生成分布的相似性。</p>
</li>
<li>
<p><strong>Novel Score</strong>：生成数据中未出现在训练集中的百分比。</p>
</li>
<li>
<p><strong>Unique Score</strong>：生成样本中仅出现一次的数据百分比，如果序列中的所有token在6位量化后相同，我们认为两个数据样本是相同的。</p>
</li>
</ul>
</li>
</ul>
<h3 id="52-随机生成" class="heading-element"><span>6.2 5.2 随机生成</span>
  <a href="#52-%e9%9a%8f%e6%9c%ba%e7%94%9f%e6%88%90" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p>为了评估 SkexGen 生成高质量和多样化结果的能力，我们随机生成每种类型的20,000个样本，并将 SkexGen 与四个其他基线进行比较：</p>
<ul>
<li>
<p>CurveGen</p>
</li>
<li>
<p>DeepCAD</p>
</li>
<li>
<p>单一码本的 SkexGen</p>
</li>
<li>
<p>带 VAE 的 SkexGen。</p>
</li>
</ul>
<blockquote>
<p>由于其他来自同时研究的草图生成模型依赖于草图约束标签，并且理想情况下需要草图约束求解器，这使得它们无法直接比较。</p>
</blockquote>
<p><strong>草图生成评估</strong>：结果如下表所示。SkexGen<strong>FID分数</strong>表现最优，证明其生成的草图质量最高。SkexGen在<strong>Novel</strong>上虽不及DeepCAD，但在<strong>Unique</strong>上与CurveGen相当或更优。且定性分析显示，DeepCAD虽然<strong>Novel</strong>得分高，但存在大量无效结果，如自相交曲线和未闭合几何，影响了FID评分。总体而言：</p>
<ul>
<li>
<p>SkexGen 生成的草图在<strong>质量上更好，形状更复杂，自相交更少，对称性更强</strong>。</p>
</li>
<li>
<p>CurveGen 也生成了质量不错的结果，<strong>但矩形和圆的复杂排列较少</strong>。</p>
</li>
<li>
<p>DeepCAD 可以生成比 CurveGen 更复杂的形状，<strong>但噪音很多</strong>。</p>
</li>
</ul>
<img src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/image-20240709222143401.png" alt="image-20240709222143401" style="zoom:50%;" />
<img src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/image-20240709222229350.png" alt="image-20240709222229350" style="zoom:33%;" />
<p><strong>CAD模型生成评估</strong>：结果如下表所示，SkexGen在所有评估指标上领先，尤其在形状复杂度、对称性以及频繁使用弧线方面表现出色。<font color="red">SkexGen能生成涉及多步骤草图和拉伸序列的CAD模型，而DeepCAD则主要生成单步模型</font>。表中间两行展示了多个解耦码本的有效性。减少到单个码本后，生成质量下降，SkexGen 类似于 VQ-VAE。当不使用码本时，结果最差，SkexGen 实际上变成了 VAE。</p>
<img src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/image-20240709222201905.png" alt="image-20240709222201905" style="zoom:50%;" />
<img src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/image-20240709222300874.png" alt="image-20240709222300874" style="zoom: 33%;" />
<p><strong>运行时间评估</strong>：尽管SkexGen的自回归采样过程使其比DeepCAD慢，但比CurveGen（具有两个依赖的自回归解码器）快，显示出采样效率的优化空间。</p>
<h3 id="53-可控生成" class="heading-element"><span>6.3 5.3 可控生成</span>
  <a href="#53-%e5%8f%af%e6%8e%a7%e7%94%9f%e6%88%90" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p>解耦码本实现了设计控制与探索，如下图所示：左侧“拓扑条件”：固定拓扑码，其他码通过核采样获得，展示相同结构的不同变体。右侧“几何条件”：固定几何码，改变其他码，体现一致几何下的多样形态。</p>
<img src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/image-20240709222419490.png" alt="image-20240709222419490" style="zoom: 33%;" />
<p>为了定量衡量三个码本之间的解耦程度，作者参考了$\beta\text{-VAE}$的评估方法。通过保持一个拓扑、几何或拉伸标记相同，并对其他部分进行采样，生成一对草图和拉伸序列。然后训练一个小型基于Transformer的分类器，通过编码潜在空间中所有数据对的平均成对差异来识别固定的码。SkexGen的分类准确率为99.8 ± 0.1%，证实码本间解耦效果显著。</p>
<h3 id="54-应用" class="heading-element"><span>6.4 5.4 应用</span>
  <a href="#54-%e5%ba%94%e7%94%a8" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><ul>
<li>
<p><strong>插值应用</strong></p>
<p>利用线性插值技术在模型的码之间探索，生成过渡模型。过程包括：编码模型提取关键码、线性插值这些码，再量化及生成插值模型。插值结果示例如Figure所示，线条演化为圆，矩形实体转为圆形空心盘，显示拓扑和几何动态变化。插值效果可能不平滑，因涉及复杂的离散拓扑变换。</p>
</li>
<li>
<p><strong>码混合应用</strong></p>
<p>通过混合不同数据的拓扑、几何和拉伸码，创造新颖设计组合。图8示例：保持拓扑形状，调整几何位置，如多个圆柱按方形布局排列。这些混合结果体现了系统的创新设计能力，超越了传统方法的局限。</p>
</li>
</ul>
<h2 id="6-总结" class="heading-element"><span>7 6 总结</span>
  <a href="#6-%e6%80%bb%e7%bb%93" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>SkexGen是一种新颖的自回归生成模型，专为CAD构造序列设计。它利用不同的Transformer架构将CAD构造序列中的拓扑、几何和拉伸变化编码为解耦码本。这些解码器可以生成具有特定属性的CAD构造序列。SkexGen的优势在于其能够生成多样且高质量的CAD模型，同时提高用户的控制能力和设计空间的探索效率。</p>
<p>模型的评估在一个大规模的CAD数据集上进行，结果表明，SkexGen相比多个基准和最新方法，生成的CAD模型更为真实和多样。此外，SkexGen的架构也增强了用户在设计过程中的控制能力，使其能够更有效地探索不同设计空间。</p>
<h4 id="61-限制" class="heading-element"><span>7.0.1 6.1 限制</span>
  <a href="#61-%e9%99%90%e5%88%b6" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h4><ol>
<li><strong>数据依赖</strong>：SkexGen依赖于大量的已标注CAD数据集，这些数据集的质量和多样性直接影响模型的表现。</li>
<li><strong>模型复杂性</strong>：该模型使用多个Transformer编码器和解码器来处理复杂的CAD构建序列，这增加了模型的复杂性和计算成本。</li>
<li><strong>拓扑和几何的分离</strong>：虽然这种分离有助于提高控制和生成多样性，但在实际应用中可能会导致模型难以学习到拓扑和几何之间的复杂关系。</li>
<li><strong>有限的建模操作</strong>：SkexGen主要关注草图和拉伸操作，未涉及其他的CAD建模操作，如旋转、扫掠、布尔运算等，限制了其应用范围（<font color="red">但可以通过导入CAD工具后编辑实现其他CAD建模操作</font>）。</li>
</ol>
<h4 id="62-创新点" class="heading-element"><span>7.0.2 6.2 创新点</span>
  <a href="#62-%e5%88%9b%e6%96%b0%e7%82%b9" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h4><ol>
<li><strong>自回归生成模型</strong>：SkexGen是一个自回归生成模型，能够生成高质量和多样化的CAD构建序列。</li>
<li><strong>解耦码本</strong>：使用了解耦码本架构，分别编码CAD构建序列中的拓扑、几何和拉伸变化，提高了用户控制和设计空间的探索效率。</li>
</ol>
]]></description></item><item><title>【论文阅读笔记】Hierarchical Neural Coding for Controllable CAD Model Generation</title><link>https://hezephyr.github.io/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/</link><pubDate>Wed, 17 Jul 2024 00:00:00 +0000</pubDate><author>HeZephyr</author><guid>https://hezephyr.github.io/posts/05.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0hierarchical-neural-coding-for-controllable-cad-model-generation/</guid><description></description></item></channel></rss>