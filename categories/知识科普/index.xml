<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>知识科普 - 分类 | ZephyrHe</title><link>https://hezephyr.github.io/categories/%E7%9F%A5%E8%AF%86%E7%A7%91%E6%99%AE/</link><description>知识科普 - 分类 | ZephyrHe</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>unique.hzf@gmail.com (HeZephyr)</managingEditor><webMaster>unique.hzf@gmail.com (HeZephyr)</webMaster><copyright>本站内容采用 CC BY-NC-SA 4.0 国际许可协议。</copyright><lastBuildDate>Sun, 12 May 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://hezephyr.github.io/categories/%E7%9F%A5%E8%AF%86%E7%A7%91%E6%99%AE/" rel="self" type="application/rss+xml"/><item><title>AI时代下的GPU生存工具包：每个开发人员必须了解的最基本知识</title><link>https://hezephyr.github.io/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/</link><pubDate>Sun, 12 May 2024 00:00:00 +0000</pubDate><author>HeZephyr</author><guid>https://hezephyr.github.io/posts/ai%E6%97%B6%E4%BB%A3%E4%B8%8B%E7%9A%84gpu%E7%94%9F%E5%AD%98%E5%B7%A5%E5%85%B7%E5%8C%85%E6%AF%8F%E4%B8%AA%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/</guid><description><![CDATA[<p><a href="https://journal.hexmos.com/gpu-survival-toolkit/"target="_blank" rel="external nofollow noopener noreferrer">翻译原文地址<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h2 id="cpu知识为何不再足够" class="heading-element"><span>1 CPU知识为何不再足够</span>
  <a href="#cpu%e7%9f%a5%e8%af%86%e4%b8%ba%e4%bd%95%e4%b8%8d%e5%86%8d%e8%b6%b3%e5%a4%9f" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>在当今的人工智能时代，大多数开发者都是按照CPU的方式进行训练。这种认知也已经成为我们学术中的一部分，因此很自然地会<strong>以CPU为导向</strong>来思考和解决问题。</p>
<p>然而，CPU 的问题在于它们<strong>依赖于串行架构</strong>。在当今世界中，我们依赖大量并行任务的情况下，CPU 无法很好地处理这些场景。</p>
<p>因此，开发者面临着如下问题。</p>
<ul>
<li>
<p><strong>执行并行任务</strong></p>
<blockquote>
<p>CPU 传统上是线性运行的，一次执行一条指令。这种限制源于这样一个事实：CPU 通常具有一些针对单线程性能进行优化的强大内核。当面临多个任务时，CPU会分配其资源来逐个处理每个任务，从而导致指令的顺序执行。在需要同时关注众多任务的情况下，这种方法变得低效。</p>
<p>尽管我们通过诸如多线程等技术来提高CPU性能，但CPU的基本设计理念是优先考虑顺序执行。</p>
</blockquote>
</li>
<li>
<p><strong>高效运行AI模型</strong></p>
<blockquote>
<p>AI 模型采用 Transformer 等先进架构，利用并行处理来增强性能。与顺序运行的<strong>旧递归神经网络 (RNN)</strong> 不同，<strong>GPT 等现代 Transformer</strong> 可以同时处理多个单词，从而提高训练效率和能力。因为当我们并行训练时，会产生更大的模型，而更大的模型会产生更好的输出。</p>
<p>并行的概念已从自然语言处理扩展到<strong>图像识别</strong>等其他领域。例如，图像识别架构 AlexNet 通过同时处理图像的不同部分，展示了并行处理的威力，从而实现准确的模式识别。</p>
<p>然而，CPU 的设计侧重于单线程性能，很难充分挖掘并行处理的潜力。它们难以有效分配和执行复杂AI模型所需的大量并行计算。</p>
</blockquote>
</li>
</ul>
<h2 id="gpu驱动开发如何解决这些问题" class="heading-element"><span>2 GPU驱动开发如何解决这些问题</span>
  <a href="#gpu%e9%a9%b1%e5%8a%a8%e5%bc%80%e5%8f%91%e5%a6%82%e4%bd%95%e8%a7%a3%e5%86%b3%e8%bf%99%e4%ba%9b%e9%97%ae%e9%a2%98" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><ul>
<li>
<p><strong>GPU 核心的大规模并行性</strong></p>
<blockquote>
<p>与 CPU 中<strong>更大、更强大的内核</strong>相比，工程师设计的 GPU 具有<strong>更小、高度专业化的内核</strong>。该架构允许 GPU 同时执行多个并行任务。</p>
<p>GPU 中的大量核心非常适合依赖于并行性的工作负载，例如图形渲染和复杂的数学计算。</p>
<p>如下图所示，5.3.2使用 GPU 并行性来减少复杂任务所需的时间。</p>
<p><a class="lightgallery" href="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/55f060b6b97ac9b7c285a8732c69829e12e3211339b992c18ec49716a6fac938.png?size=large" data-thumbnail="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/55f060b6b97ac9b7c285a8732c69829e12e3211339b992c18ec49716a6fac938.png?size=small" data-sub-html="<h2>GPUDemo1</h2>"><img loading="lazy" src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/55f060b6b97ac9b7c285a8732c69829e12e3211339b992c18ec49716a6fac938.png" alt="GPUDemo1" srcset="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/55f060b6b97ac9b7c285a8732c69829e12e3211339b992c18ec49716a6fac938.png?size=small, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/55f060b6b97ac9b7c285a8732c69829e12e3211339b992c18ec49716a6fac938.png?size=medium 1.5x, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/55f060b6b97ac9b7c285a8732c69829e12e3211339b992c18ec49716a6fac938.png?size=large 2x" data-title="GPUDemo1" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
</blockquote>
</li>
<li>
<p><strong>AI 模型中使用的并行性</strong></p>
<blockquote>
<p>人工智能模型，特别是基于 <a href="https://www.tensorflow.org/?ref=journal.hexmos.com"target="_blank" rel="external nofollow noopener noreferrer">TensorFlow<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> 等深度学习框架构建的模型，表现出高度的并行性。神经网络训练涉及大量矩阵运算，而 GPU 凭借其庞大的核心数量，擅长并行化这些运算。 TensorFlow 与其他流行的深度学习框架一起进行优化，以利用 GPU 的能力来加速模型训练和推理。</p>
<p>如下图所示，5.3.3使用 GPU 的强大功能来训练神经网络。</p>
<p><a class="lightgallery" href="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/5078635f14fc266b48058cafe1f214608eecd89f0ddfebfc481df24704a7bba9.png?size=large" data-thumbnail="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/5078635f14fc266b48058cafe1f214608eecd89f0ddfebfc481df24704a7bba9.png?size=small" data-sub-html="<h2>GPUDemo1</h2>"><img loading="lazy" src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/5078635f14fc266b48058cafe1f214608eecd89f0ddfebfc481df24704a7bba9.png" alt="GPUDemo1" srcset="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/5078635f14fc266b48058cafe1f214608eecd89f0ddfebfc481df24704a7bba9.png?size=small, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/5078635f14fc266b48058cafe1f214608eecd89f0ddfebfc481df24704a7bba9.png?size=medium 1.5x, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/5078635f14fc266b48058cafe1f214608eecd89f0ddfebfc481df24704a7bba9.png?size=large 2x" data-title="GPUDemo1" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
</blockquote>
</li>
</ul>
<h2 id="gpu和cpu有什么区别" class="heading-element"><span>3 GPU和CPU有什么区别</span>
  <a href="#gpu%e5%92%8ccpu%e6%9c%89%e4%bb%80%e4%b9%88%e5%8c%ba%e5%88%ab" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><ul>
<li>
<p><strong>CPU</strong></p>
<ul>
<li>
<p><strong>串行架构</strong></p>
<blockquote>
<p>中央处理单元 (CPU) 的设计重点是顺序处理。它们擅长线性执行一组指令。CPU 针对需要高单线程性能的任务进行了优化，例如：</p>
<ul>
<li><strong>通用计算</strong></li>
<li><strong>系统操作</strong></li>
<li><strong>处理涉及条件分支的复杂算法</strong></li>
</ul>
</blockquote>
</li>
<li>
<p><strong>并行任务的核心数量有限</strong></p>
<blockquote>
<p>CPU 的核心数量较少，在消费级处理器中通常为 <strong>2-16</strong> 个核心。每个内核都能够独立处理自己的指令集。</p>
</blockquote>
</li>
</ul>
</li>
<li>
<p><strong>GPU</strong></p>
<ul>
<li>
<p><strong>并行架构</strong></p>
<blockquote>
<p>图形处理单元（GPU）采用并行架构设计，使其能够高效地执行并行处理任务。这有利于：</p>
<ul>
<li><strong>渲染图形</strong></li>
<li><strong>执行复杂的数学计算</strong></li>
<li><strong>运行可并行算法</strong></li>
</ul>
<p>GPU 通过将多个任务分解为更小的并行子任务来同时处理多个任务。</p>
</blockquote>
</li>
<li>
<p><strong>数千个内核用于并行任务</strong></p>
<blockquote>
<p>与 CPU 不同，GPU 拥有更多的核心，通常有数千个。这些内核被组织成流式多处理器 (SM) 或类似的结构。丰富的内核使 GPU 能够同时处理大量数据，非常适合并行任务，例如图像和视频处理、深度学习和科学模拟。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h2 id="gpu类型" class="heading-element"><span>4 GPU类型</span>
  <a href="#gpu%e7%b1%bb%e5%9e%8b" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><ul>
<li>
<p><strong>通用 Gpu</strong></p>
<blockquote>
<p>通用 GPU 实例（P3 和 P4 实例）适用于广泛的工作负载，包括机器学习训练和推理、图像处理和视频编码。它们的平衡性能使它们成为各种计算任务的理想选择。</p>
</blockquote>
</li>
<li>
<p><strong>推理优化的 GPU</strong></p>
<blockquote>
<p>推理是运行已经训练好的 AI 模型并对实时数据进行预测或任务求解的过程。推理优化的 GPU 实例（P5 和 Inf1 实例）在低延迟和成本效率至关重要的情况下表现出色，特别适用于机器学习推理任务。</p>
</blockquote>
</li>
<li>
<p><strong>图形优化的 GPU</strong></p>
<blockquote>
<p>图形优化的 GPU 实例（G4 实例）专门设计用于处理图形密集型任务，如视频游戏开发中的 3D 图形渲染。这些实例非常适合需要处理大量图形数据的应用程序。</p>
</blockquote>
</li>
<li>
<p><strong>托管 GPU</strong></p>
<blockquote>
<p>Amazon SageMaker 是一种托管服务，为机器学习提供了易于使用的 GPU 实例。它提供对多种 GPU 实例（包括 P3、P4 和 P5 实例）的访问，适用于想要轻松开始机器学习而无需管理底层基础设施的组织。</p>
</blockquote>
</li>
</ul>
<h2 id="使用-nvidia-的-cuda-进行-gpu-驱动开发" class="heading-element"><span>5 使用 Nvidia 的 CUDA 进行 GPU 驱动开发</span>
  <a href="#%e4%bd%bf%e7%94%a8-nvidia-%e7%9a%84-cuda-%e8%bf%9b%e8%a1%8c-gpu-%e9%a9%b1%e5%8a%a8%e5%bc%80%e5%8f%91" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>CUDA 是 NVIDIA 开发的并行计算平台和编程模型，使开发人员能够利用 GPU 加速器的强大功能来加速其应用程序。</p>
<h3 id="linux安装cuda" class="heading-element"><span>5.1 Linux安装CUDA</span>
  <a href="#linux%e5%ae%89%e8%a3%85cuda" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><ol>
<li>
<p>下载<a href="https://developer.nvidia.com/cuda-downloads?ref=journal.hexmos.com"target="_blank" rel="external nofollow noopener noreferrer">CUDA<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
<li>
<p>从上面的链接下载基本安装程序以及驱动程序安装程序</p>
</li>
<li>
<p>转到主文件夹中的 <code>.bashrc</code>（如果使用其他shell则使用对应的配置文件）</p>
</li>
<li>
<p>在配置文件中添加以下行：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl"><span class="k">export</span> <span class="n">PATH</span><span class="o">=</span><span class="s2">&#34;/usr/local/cuda-12.3/bin:$PATH&#34;</span>
</span></span><span class="line"><span class="cl"><span class="k">export</span> <span class="n">LD_LIBRARY_PATH</span><span class="o">=</span><span class="s2">&#34;/usr/local/cuda-12.3/lib64:$LD_LIBRARY_PATH&#34;</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>然后执行以下命令：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl"><span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="n">cuda</span><span class="o">-</span><span class="n">toolkit</span>
</span></span><span class="line"><span class="cl"><span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="n">nvidia</span><span class="o">-</span><span class="n">gds</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<h3 id="基本命令" class="heading-element"><span>5.2 基本命令</span>
  <a href="#%e5%9f%ba%e6%9c%ac%e5%91%bd%e4%bb%a4" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><ul>
<li>
<p><code>lspci | grep VGA</code></p>
<blockquote>
<p>识别并列出系统中的 GPU。</p>
<p><a class="lightgallery" href="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/ea108a4de53720d8e4de22247f92b43481a000cfe41026826e52f4af020b9c0f-20240319153537737.png?size=large" data-thumbnail="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/ea108a4de53720d8e4de22247f92b43481a000cfe41026826e52f4af020b9c0f-20240319153537737.png?size=small" data-sub-html="<h2>Alt text</h2>"><img loading="lazy" src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/ea108a4de53720d8e4de22247f92b43481a000cfe41026826e52f4af020b9c0f-20240319153537737.png" alt="Alt text" srcset="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/ea108a4de53720d8e4de22247f92b43481a000cfe41026826e52f4af020b9c0f-20240319153537737.png?size=small, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/ea108a4de53720d8e4de22247f92b43481a000cfe41026826e52f4af020b9c0f-20240319153537737.png?size=medium 1.5x, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/ea108a4de53720d8e4de22247f92b43481a000cfe41026826e52f4af020b9c0f-20240319153537737.png?size=large 2x" data-title="Alt text" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
</blockquote>
</li>
<li>
<p><code>nvidia-smi</code></p>
<blockquote>
<p>“NVIDIA 系统管理界面”，它提供有关系统中 NVIDIA GPU 的详细信息，包括利用率、温度、内存使用情况等。</p>
<p><a class="lightgallery" href="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/b467adbefdfe4fced1552ca63134994c2924dc648955adb585c80d1a6356f10f.png?size=large" data-thumbnail="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/b467adbefdfe4fced1552ca63134994c2924dc648955adb585c80d1a6356f10f.png?size=small" data-sub-html="<h2>Alt text</h2>"><img loading="lazy" src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/b467adbefdfe4fced1552ca63134994c2924dc648955adb585c80d1a6356f10f.png" alt="Alt text" srcset="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/b467adbefdfe4fced1552ca63134994c2924dc648955adb585c80d1a6356f10f.png?size=small, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/b467adbefdfe4fced1552ca63134994c2924dc648955adb585c80d1a6356f10f.png?size=medium 1.5x, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/b467adbefdfe4fced1552ca63134994c2924dc648955adb585c80d1a6356f10f.png?size=large 2x" data-title="Alt text" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
</blockquote>
</li>
<li>
<p><code>sudo lshw -C display</code></p>
<blockquote>
<p>提供有关系统中显示控制器（包括显卡）的详细信息。</p>
<p><a class="lightgallery" href="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/0af5ca02e576f5da48a561ebffb4bd20e4051899cb1b1e69caca78aeff58cff7.png?size=large" data-thumbnail="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/0af5ca02e576f5da48a561ebffb4bd20e4051899cb1b1e69caca78aeff58cff7.png?size=small" data-sub-html="<h2>Alt text</h2>"><img loading="lazy" src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/0af5ca02e576f5da48a561ebffb4bd20e4051899cb1b1e69caca78aeff58cff7.png" alt="Alt text" srcset="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/0af5ca02e576f5da48a561ebffb4bd20e4051899cb1b1e69caca78aeff58cff7.png?size=small, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/0af5ca02e576f5da48a561ebffb4bd20e4051899cb1b1e69caca78aeff58cff7.png?size=medium 1.5x, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/0af5ca02e576f5da48a561ebffb4bd20e4051899cb1b1e69caca78aeff58cff7.png?size=large 2x" data-title="Alt text" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
</blockquote>
</li>
<li>
<p><code>inxi -G</code></p>
<blockquote>
<p>提供有关图形子系统的信息，包括有关 GPU 和显示器的详细信息。</p>
<p><a class="lightgallery" href="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/8352bf05d3be3b8085e837de0f69f244ab6c34041c6b462cf78513fcae6373c0.png?size=large" data-thumbnail="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/8352bf05d3be3b8085e837de0f69f244ab6c34041c6b462cf78513fcae6373c0.png?size=small" data-sub-html="<h2>Alt text</h2>"><img loading="lazy" src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/8352bf05d3be3b8085e837de0f69f244ab6c34041c6b462cf78513fcae6373c0.png" alt="Alt text" srcset="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/8352bf05d3be3b8085e837de0f69f244ab6c34041c6b462cf78513fcae6373c0.png?size=small, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/8352bf05d3be3b8085e837de0f69f244ab6c34041c6b462cf78513fcae6373c0.png?size=medium 1.5x, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/8352bf05d3be3b8085e837de0f69f244ab6c34041c6b462cf78513fcae6373c0.png?size=large 2x" data-title="Alt text" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
</blockquote>
</li>
<li>
<p><code>sudo hwinfo --gfxcard</code></p>
<blockquote>
<p><a class="lightgallery" href="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/70fa1b931593c213a1a949dbc700d47cca2e933cee331d63e03e0806d6327baa.png?size=large" data-thumbnail="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/70fa1b931593c213a1a949dbc700d47cca2e933cee331d63e03e0806d6327baa.png?size=small" data-sub-html="<h2>Alt text</h2>"><img loading="lazy" src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/70fa1b931593c213a1a949dbc700d47cca2e933cee331d63e03e0806d6327baa.png" alt="Alt text" srcset="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/70fa1b931593c213a1a949dbc700d47cca2e933cee331d63e03e0806d6327baa.png?size=small, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/70fa1b931593c213a1a949dbc700d47cca2e933cee331d63e03e0806d6327baa.png?size=medium 1.5x, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/70fa1b931593c213a1a949dbc700d47cca2e933cee331d63e03e0806d6327baa.png?size=large 2x" data-title="Alt text" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
</blockquote>
</li>
</ul>
<h3 id="开始使用cuda框架" class="heading-element"><span>5.3 开始使用CUDA框架</span>
  <a href="#%e5%bc%80%e5%a7%8b%e4%bd%bf%e7%94%a8cuda%e6%a1%86%e6%9e%b6" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p>当我们安装了 CUDA 框架后，让我们开始执行展示其功能的操作。</p>
<h4 id="数组加法问题" class="heading-element"><span>5.3.1 数组加法问题</span>
  <a href="#%e6%95%b0%e7%bb%84%e5%8a%a0%e6%b3%95%e9%97%ae%e9%a2%98" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h4><p>数组加法问题是演示 GPU 并行化的一个合适问题。考虑以下数组：</p>
<ul>
<li>
<p>数组 $A = [1,2,3,4,5,6]$</p>
</li>
<li>
<p>数组 $B = [7,8,9,10,11,12]$</p>
</li>
<li>
<p>我们需要存储每个元素的和并将其存储在数组$C$中。我们需要存储每个元素的和并将其存储在数组$C$中。</p>
</li>
<li>
<p>就像 $C = [1+7,2+8,3+9,4+10,5+11,6+12] = [8,10,12,14,16,18]$</p>
</li>
<li>
<p>如果CPU要执行这样的操作，它将执行如下代码所示的操作。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp"></span><span class="kt">int</span> <span class="n">a</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">};</span>
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="n">b</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">};</span>
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="n">c</span><span class="p">[</span><span class="mi">6</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">6</span><span class="p">;</span>  <span class="c1">// Number of elements
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nf">printf</span><span class="p">(</span><span class="s">&#34;c[%d] = %d&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
</ul>
<p>这种方法是逐个遍历数组元素并依次执行加法。然而，当处理大量数字时，这种方法由于其顺序性质而变得缓慢。</p>
<p>为了解决这个限制，GPU 通过并行化加法过程提供了一种解决方案。与依次执行运算的 CPU 不同，GPU 可以同时执行多项加法。例如，运算$1+7、2+8、3+9、4+10、5+11$和$6+12$可以借助GPU并行化同时执行。</p>
<p>利用CUDA，我们将使用内核文件 (.cu) 进行展示。实现并行加法的代码如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">vectorAdd</span><span class="p">(</span><span class="kt">int</span><span class="o">*</span> <span class="n">a</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span> <span class="n">b</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span> <span class="n">c</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><code>__global__</code> 说明符表明该函数是一个内核函数，将在 GPU 上调用。</li>
<li><code>vectorAdd</code> 采用三个整数指针（$a$、$b$ 和 $c$）作为参数，表示要相加的向量。</li>
<li><code>threadIdx.x</code> 检索当前线程的索引（在一维网格中）。</li>
<li>向量 $a$ 和 $b$ 的相应元素之和存储在向量 $c$ 中。</li>
</ul>
<p>现在我们来看看主要功能。创建指针 <code>cudaA</code> 、 <code>cudaB</code> 和 <code>cudaC</code> 来指向 GPU 上的内存。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="c1">// 利用 CUDA 使用并行计算加法的函数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">a</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">};</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">b</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">};</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">c</span><span class="p">[</span><span class="k">sizeof</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">)]</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">};</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// 创建指向 GPU 的指针
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">int</span><span class="o">*</span> <span class="n">cudaA</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span><span class="o">*</span> <span class="n">cudaB</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span><span class="o">*</span> <span class="n">cudaC</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span></span></span></code></pre></td></tr></table>
</div>
</div><p>使用 <code>cudaMalloc</code> ，在 GPU 上为向量 <code>cudaA</code>、<code>cudaB</code> 和 <code>cudaC</code> 分配内存。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="c1">// 在GPU中分配内存
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cudaA</span><span class="p">,</span><span class="k">sizeof</span><span class="p">(</span><span class="n">a</span><span class="p">));</span>
</span></span><span class="line"><span class="cl"><span class="nf">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cudaB</span><span class="p">,</span><span class="k">sizeof</span><span class="p">(</span><span class="n">b</span><span class="p">));</span>
</span></span><span class="line"><span class="cl"><span class="nf">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cudaC</span><span class="p">,</span><span class="k">sizeof</span><span class="p">(</span><span class="n">c</span><span class="p">));</span></span></span></code></pre></td></tr></table>
</div>
</div><p>内核函数 <code>vectorAdd</code> 使用一个块和等于向量大小的多个线程启动。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="c1">// 用一个程序块和与向量大小相等的线程数启动内核
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">vectorAdd</span> <span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">&gt;&gt;&gt;</span> <span class="p">(</span><span class="n">cudaA</span><span class="p">,</span> <span class="n">cudaB</span><span class="p">,</span> <span class="n">cudaC</span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div><p>结果向量 <code>cudaC</code> 从GPU复制回主机。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="c1">// 将结果向量复制回主机
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">cudaMemcpy</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">cudaC</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">c</span><span class="p">),</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div><p>然后我们可以照常打印结果</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl">    <span class="c1">// 打印结果
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">/</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">);</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nf">printf</span><span class="p">(</span><span class="s">&#34;c[%d] = %d&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p>为了执行此代码，我们将使用 <code>nvcc</code> 命令。我们将得到输出为：</p>
<p><a class="lightgallery" href="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/144c2193b0d5ad71eb7bd4da490534fb278ed174df6ec8c6411b039f16757116.png?size=large" data-thumbnail="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/144c2193b0d5ad71eb7bd4da490534fb278ed174df6ec8c6411b039f16757116.png?size=small" data-sub-html="<h2>GPU Output</h2>"><img loading="lazy" src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/144c2193b0d5ad71eb7bd4da490534fb278ed174df6ec8c6411b039f16757116.png" alt="GPU Output" srcset="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/144c2193b0d5ad71eb7bd4da490534fb278ed174df6ec8c6411b039f16757116.png?size=small, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/144c2193b0d5ad71eb7bd4da490534fb278ed174df6ec8c6411b039f16757116.png?size=medium 1.5x, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/144c2193b0d5ad71eb7bd4da490534fb278ed174df6ec8c6411b039f16757116.png?size=large 2x" data-title="GPU Output" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
<p>这是<a href="https://github.com/RijulTP/GPUToolkit/tree/main/array-addition?ref=journal.hexmos.com"target="_blank" rel="external nofollow noopener noreferrer">完整的代码<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>供读者参考。</p>
<h4 id="使用-gpu-在-python-中优化图像生成" class="heading-element"><span>5.3.2 使用 GPU 在 Python 中优化图像生成</span>
  <a href="#%e4%bd%bf%e7%94%a8-gpu-%e5%9c%a8-python-%e4%b8%ad%e4%bc%98%e5%8c%96%e5%9b%be%e5%83%8f%e7%94%9f%e6%88%90" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h4><p>本节探讨使用 GPU 处理来优化性能密集型任务，例如图像生成。</p>
<p><strong>Mandelbrot 集</strong>是一种数学构造，它根据规定方程中特定数字的行为形成复杂的视觉模式。生成一个这样的图案需要耗费大量资源。在下面的代码片段中，您可以观察到使用 CPU 处理生成 Mandelbrot 集的传统方法，该方法速度很慢。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="c1"># 导入必要的库</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">pylab</span> <span class="kn">import</span> <span class="n">imshow</span><span class="p">,</span> <span class="n">show</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">timeit</span> <span class="kn">import</span> <span class="n">default_timer</span> <span class="k">as</span> <span class="n">timer</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 计算给定点 (x, y) 的 Mandelbrot 集的函数</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">mandel</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_iters</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span> <span class="o">=</span> <span class="nb">complex</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">z</span> <span class="o">=</span> <span class="mf">0.0</span><span class="n">j</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 迭代检查该点是否在 Mandelbrot 集中</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iters</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">*</span><span class="n">z</span> <span class="o">+</span> <span class="n">c</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">real</span><span class="o">*</span><span class="n">z</span><span class="o">.</span><span class="n">real</span> <span class="o">+</span> <span class="n">z</span><span class="o">.</span><span class="n">imag</span><span class="o">*</span><span class="n">z</span><span class="o">.</span><span class="n">imag</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">4</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">i</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 如果在最大迭代次数内，则将其视为集合的一部分</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">max_iters</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 在指定区域内创建 Mandelbrot 分形的函数</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">create_fractal</span><span class="p">(</span><span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">,</span> <span class="n">min_y</span><span class="p">,</span> <span class="n">max_y</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">iters</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">height</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">width</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 根据指定区域计算像素大小</span>
</span></span><span class="line"><span class="cl">    <span class="n">pixel_size_x</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_x</span> <span class="o">-</span> <span class="n">min_x</span><span class="p">)</span> <span class="o">/</span> <span class="n">width</span>
</span></span><span class="line"><span class="cl">    <span class="n">pixel_size_y</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_y</span> <span class="o">-</span> <span class="n">min_y</span><span class="p">)</span> <span class="o">/</span> <span class="n">height</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 在图像中迭代每个像素并计算Mandelbrot值</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">width</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">real</span> <span class="o">=</span> <span class="n">min_x</span> <span class="o">+</span> <span class="n">x</span> <span class="o">*</span> <span class="n">pixel_size_x</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">height</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">imag</span> <span class="o">=</span> <span class="n">min_y</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="n">pixel_size_y</span>
</span></span><span class="line"><span class="cl">            <span class="n">color</span> <span class="o">=</span> <span class="n">mandel</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">imag</span><span class="p">,</span> <span class="n">iters</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">image</span><span class="p">[</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">color</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 为 Mandelbrot 集创建一个空白图像数组</span>
</span></span><span class="line"><span class="cl"><span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1536</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 记录性能测量的开始时间</span>
</span></span><span class="line"><span class="cl"><span class="n">start</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 在指定的区域和迭代次数内生成Mandelbrot集合</span>
</span></span><span class="line"><span class="cl"><span class="n">create_fractal</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 计算创建 Mandelbrot 集所需的时间</span>
</span></span><span class="line"><span class="cl"><span class="n">dt</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 打印生成 Mandelbrot 集所需的时间</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Mandelbrot created in </span><span class="si">%f</span><span class="s2"> s&#34;</span> <span class="o">%</span> <span class="n">dt</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用 matplotlib 显示 Mandelbrot 集</span>
</span></span><span class="line"><span class="cl"><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">show</span><span class="p">()</span></span></span></code></pre></td></tr></table>
</div>
</div><p>上面的代码在 <code>4.07</code> 秒内生成输出。<a class="lightgallery" href="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/14af8fd709215ad96688a3364deefea9cfc2fa13497810587106cef04c5a413c.png?size=large" data-thumbnail="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/14af8fd709215ad96688a3364deefea9cfc2fa13497810587106cef04c5a413c.png?size=small" data-sub-html="<h2>Mandelbrot without GPU</h2>"><img loading="lazy" src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/14af8fd709215ad96688a3364deefea9cfc2fa13497810587106cef04c5a413c.png" alt="Mandelbrot without GPU" srcset="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/14af8fd709215ad96688a3364deefea9cfc2fa13497810587106cef04c5a413c.png?size=small, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/14af8fd709215ad96688a3364deefea9cfc2fa13497810587106cef04c5a413c.png?size=medium 1.5x, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/14af8fd709215ad96688a3364deefea9cfc2fa13497810587106cef04c5a413c.png?size=large 2x" data-title="Mandelbrot without GPU" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
<p>为了加快速度，我们可以使用 <a href="https://numba.pydata.org/?ref=journal.hexmos.com"target="_blank" rel="external nofollow noopener noreferrer">Numba<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> 库将代码与 GPU 并行化，具体操作如下：</p>
<ul>
<li>
<p>我们将从 numba 导入即时编译、用于 GPU 加速的 CUDA 以及其他工具库</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">jit</span><span class="p">,</span> <span class="n">cuda</span><span class="p">,</span> <span class="n">uint32</span><span class="p">,</span> <span class="n">f8</span><span class="p">,</span> <span class="n">uint8</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">pylab</span> <span class="kn">import</span> <span class="n">imshow</span><span class="p">,</span> <span class="n">show</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">timeit</span> <span class="kn">import</span> <span class="n">default_timer</span> <span class="k">as</span> <span class="n">timer</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p><code>@jit</code> 装饰器指示 Numba 执行即时编译，将 Python 代码转换为机器代码以提高执行速度。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@jit</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">mandel</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_iters</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span> <span class="o">=</span> <span class="nb">complex</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">z</span> <span class="o">=</span> <span class="mf">0.0</span><span class="n">j</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iters</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">*</span><span class="n">z</span> <span class="o">+</span> <span class="n">c</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">real</span><span class="o">*</span><span class="n">z</span><span class="o">.</span><span class="n">real</span> <span class="o">+</span> <span class="n">z</span><span class="o">.</span><span class="n">imag</span><span class="o">*</span><span class="n">z</span><span class="o">.</span><span class="n">imag</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">4</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">i</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">max_iters</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p><code>mandel_gpu</code> 是使用 <code>cuda.jit</code> 创建的 mandel 函数的 GPU 兼容版本。这允许将 mandel 逻辑卸载到 GPU。这是通过使用 <code>@cuda.jit</code> 装饰器并指定函数参数的数据类型（<code>f8</code> 表示浮点数，``uint32<code> 表示无符号32位整数）来完成的。</code>device=True` 参数指示该函数将在 GPU 上运行。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">mandel_gpu</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">((</span><span class="n">f8</span><span class="p">,</span> <span class="n">f8</span><span class="p">,</span> <span class="n">uint32</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span><span class="n">mandel</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p><code>mandel_kernel</code> 函数被定义为在 CUDA GPU 上执行。它负责跨 GPU 线程并行生成 Mandelbrot 集。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@cuda.jit</span><span class="p">((</span><span class="n">f8</span><span class="p">,</span> <span class="n">f8</span><span class="p">,</span> <span class="n">f8</span><span class="p">,</span> <span class="n">f8</span><span class="p">,</span> <span class="n">uint8</span><span class="p">[:,:],</span> <span class="n">uint32</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">mandel_kernel</span><span class="p">(</span><span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">,</span> <span class="n">min_y</span><span class="p">,</span> <span class="n">max_y</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">iters</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">height</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">width</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">pixel_size_x</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_x</span> <span class="o">-</span> <span class="n">min_x</span><span class="p">)</span> <span class="o">/</span> <span class="n">width</span>
</span></span><span class="line"><span class="cl">    <span class="n">pixel_size_y</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_y</span> <span class="o">-</span> <span class="n">min_y</span><span class="p">)</span> <span class="o">/</span> <span class="n">height</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">startX</span><span class="p">,</span> <span class="n">startY</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">gridX</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">gridDim</span><span class="o">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
</span></span><span class="line"><span class="cl">    <span class="n">gridY</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">gridDim</span><span class="o">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">y</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">startX</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">gridX</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">real</span> <span class="o">=</span> <span class="n">min_x</span> <span class="o">+</span> <span class="n">x</span> <span class="o">*</span> <span class="n">pixel_size_x</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">startY</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">gridY</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">imag</span> <span class="o">=</span> <span class="n">min_y</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="n">pixel_size_y</span>
</span></span><span class="line"><span class="cl">            <span class="n">image</span><span class="p">[</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">mandel_gpu</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">imag</span><span class="p">,</span> <span class="n">iters</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>现在，我们可以在 <code>create_fractal_gpu</code> 函数中使用 GPU 加速的 Mandelbrot 集生成。该函数分配 GPU 内存，启动 GPU 内核 (mandel_kernel)，并将结果复制回 CPU。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">create_fractal_gpu</span><span class="p">(</span><span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">,</span> <span class="n">min_y</span><span class="p">,</span> <span class="n">max_y</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">iters</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Step 1: 为图像分配GPU内存</span>
</span></span><span class="line"><span class="cl">    <span class="n">d_image</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Step 2: 定义GPU并行化的线程和块数</span>
</span></span><span class="line"><span class="cl">    <span class="n">threadsperblock</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">blockspergrid_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">threadsperblock</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">    <span class="n">blockspergrid_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">threadsperblock</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">    <span class="n">blockspergrid</span> <span class="o">=</span> <span class="p">(</span><span class="n">blockspergrid_x</span><span class="p">,</span> <span class="n">blockspergrid_y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Step 3: 测量开始时间</span>
</span></span><span class="line"><span class="cl">    <span class="n">start</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Step 4: 启动 GPU 内核（mandel_kernel）在 GPU 上计算 Mandelbrot 集。</span>
</span></span><span class="line"><span class="cl">    <span class="n">mandel_kernel</span><span class="p">[</span><span class="n">blockspergrid</span><span class="p">,</span> <span class="n">threadsperblock</span><span class="p">](</span><span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">,</span> <span class="n">min_y</span><span class="p">,</span> <span class="n">max_y</span><span class="p">,</span> <span class="n">d_image</span><span class="p">,</span> <span class="n">iters</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Step 5: 等待 GPU 完成其工作（同步）</span>
</span></span><span class="line"><span class="cl">    <span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Step 6: 测量GPU处理所需的时间</span>
</span></span><span class="line"><span class="cl">    <span class="n">dt</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Step 7: 将结果从 GPU 内存复制回 CPU</span>
</span></span><span class="line"><span class="cl">    <span class="n">d_image</span><span class="o">.</span><span class="n">copy_to_host</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Step 8: 显示 Mandelbrot 集图像</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Mandelbrot created on GPU in </span><span class="si">%f</span><span class="s2"> s&#34;</span> <span class="o">%</span> <span class="n">dt</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">show</span><span class="p">()</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
</ul>
<p>上面的代码在 <code>0.0046 seconds</code> 中执行。这比我们之前的基于 CPU 的代码要快得多。</p>
<p><a class="lightgallery" href="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/4d62577a332918dc7b5fefc924f27aa6c62599e101e1494184860b82e0e8ddd2.png?size=large" data-thumbnail="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/4d62577a332918dc7b5fefc924f27aa6c62599e101e1494184860b82e0e8ddd2.png?size=small" data-sub-html="<h2>Mandelbrot with GPU</h2>"><img loading="lazy" src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/4d62577a332918dc7b5fefc924f27aa6c62599e101e1494184860b82e0e8ddd2.png" alt="Mandelbrot with GPU" srcset="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/4d62577a332918dc7b5fefc924f27aa6c62599e101e1494184860b82e0e8ddd2.png?size=small, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/4d62577a332918dc7b5fefc924f27aa6c62599e101e1494184860b82e0e8ddd2.png?size=medium 1.5x, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/4d62577a332918dc7b5fefc924f27aa6c62599e101e1494184860b82e0e8ddd2.png?size=large 2x" data-title="Mandelbrot with GPU" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
<p>这是<a href="https://github.com/RijulTP/GPUToolkit/tree/main/mandelbrot?ref=journal.hexmos.com"target="_blank" rel="external nofollow noopener noreferrer">完整的代码<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>供读者参考。</p>
<h4 id="使用-gpu-训练猫狗神经网络" class="heading-element"><span>5.3.3 使用 GPU 训练猫狗神经网络</span>
  <a href="#%e4%bd%bf%e7%94%a8-gpu-%e8%ae%ad%e7%bb%83%e7%8c%ab%e7%8b%97%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h4><p>我们现在看到的热门话题之一是 GPU 如何在人工智能中使用，因此为了证明我们将创建一个神经网络来区分猫和狗。我们将使用以下代码训练和使用猫与狗模型，其中使用了卷积神经网络（CNN），您可以阅读有关它的<a href="https://www.analyticsvidhya.com/blog/2021/06/beginner-friendly-project-cat-and-dog-classification-using-cnn/?ref=journal.hexmos.com"target="_blank" rel="external nofollow noopener noreferrer">更多详细信息<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>。</p>
<ul>
<li>
<p><strong>先决条件</strong></p>
<ol>
<li>
<p>CUDA</p>
</li>
<li>
<p>Tensorflow -&gt; 可以通过 <code>pip install tensorflow[and-cuda]</code> 安装</p>
</li>
<li>
<p>我们将使用来自<a href="https://www.kaggle.com/competitions/dogs-vs-cats/overview?ref=journal.hexmos.com"target="_blank" rel="external nofollow noopener noreferrer">kaggle<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>的猫和狗的数据集</p>
</li>
<li>
<p>下载完成后，解压，将训练文件夹中的猫和狗的图片整理到不同的子文件夹中，如下图所示。</p>
<p><a class="lightgallery" href="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/47b0cc05fa99283bd8dcd39a801809bdf5521a285df558c1436460ddf4d1ebdd.png?size=large" data-thumbnail="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/47b0cc05fa99283bd8dcd39a801809bdf5521a285df558c1436460ddf4d1ebdd.png?size=small" data-sub-html="<h2>CNN File Structure</h2>"><img loading="lazy" src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/47b0cc05fa99283bd8dcd39a801809bdf5521a285df558c1436460ddf4d1ebdd.png" alt="CNN File Structure" srcset="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/47b0cc05fa99283bd8dcd39a801809bdf5521a285df558c1436460ddf4d1ebdd.png?size=small, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/47b0cc05fa99283bd8dcd39a801809bdf5521a285df558c1436460ddf4d1ebdd.png?size=medium 1.5x, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/47b0cc05fa99283bd8dcd39a801809bdf5521a285df558c1436460ddf4d1ebdd.png?size=large 2x" data-title="CNN File Structure" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
</li>
</ol>
</li>
<li>
<p><strong>导入库</strong></p>
<blockquote>
<ul>
<li>
<p><code>pandas</code> 和 <code>numpy</code> 用于数据操作。</p>
</li>
<li>
<p><code>Sequential</code>用于在神经网络中创建线性层堆栈。</p>
</li>
<li>
<p><code>Convolution2D</code>、``MaxPooling2D<code>、</code>Dense<code>和</code>Flatten` 是用于构建卷积神经网络 (CNN) 的层。</p>
</li>
<li>
<p><code>ImageDataGenerator </code>用于在训练期间进行实时数据增强。</p>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Convolution2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Flatten</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">ImageDataGenerator</span></span></span></code></pre></td></tr></table>
</div>
</div></blockquote>
</li>
<li>
<p><strong>初始化卷积神经网络</strong></p>
<blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">classifier</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span></span></span></code></pre></td></tr></table>
</div>
</div></blockquote>
</li>
<li>
<p><strong>加载训练数据</strong></p>
<blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">train_datagen</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span><span class="p">(</span>
</span></span><span class="line"><span class="cl"> <span class="n">rescale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="n">shear_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="n">zoom_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="n">horizontal_flip</span><span class="o">=</span><span class="kc">True</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">test_datagen</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span><span class="p">(</span><span class="n">rescale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">training_set</span> <span class="o">=</span> <span class="n">train_datagen</span><span class="o">.</span><span class="n">flow_from_directory</span><span class="p">(</span>
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;./training_set&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
</span></span><span class="line"><span class="cl"> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="n">class_mode</span><span class="o">=</span><span class="s1">&#39;binary&#39;</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">test_set</span> <span class="o">=</span> <span class="n">test_datagen</span><span class="o">.</span><span class="n">flow_from_directory</span><span class="p">(</span>
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;./test_set&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
</span></span><span class="line"><span class="cl"> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="n">class_mode</span><span class="o">=</span><span class="s1">&#39;binary&#39;</span></span></span></code></pre></td></tr></table>
</div>
</div></blockquote>
</li>
<li>
<p><strong>构建 CNN 架构</strong></p>
<blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">classifier</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Convolution2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">classifier</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl"><span class="n">classifier</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="n">classifier</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">classifier</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span></span></span></code></pre></td></tr></table>
</div>
</div></blockquote>
</li>
<li>
<p><strong>编译模型</strong></p>
<blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">classifier</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span></span></span></code></pre></td></tr></table>
</div>
</div></blockquote>
</li>
<li>
<p><strong>训练模型</strong></p>
<blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training_set</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="n">test_set</span><span class="p">,</span> <span class="n">validation_steps</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">classifier</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;trained_model.h5&#39;</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div></blockquote>
</li>
</ul>
<p>一旦我们训练完模型，模型就会使用 <code>classifier.save</code> 存储在 <code>.h5</code> 文件中。在下面的代码中，我们将使用这个 <code>trained_model.h5</code> 文件来识别猫和狗。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">keras.utils</span> <span class="k">as</span> <span class="nn">image</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">predict_image</span><span class="p">(</span><span class="n">imagepath</span><span class="p">,</span> <span class="n">classifier</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">predict</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">load_img</span><span class="p">(</span><span class="n">imagepath</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">predict_modified</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">predict</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">predict_modified</span> <span class="o">=</span> <span class="n">predict_modified</span> <span class="o">/</span> <span class="mi">255</span>
</span></span><span class="line"><span class="cl">    <span class="n">predict_modified</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">predict_modified</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">result</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">predict_modified</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">prediction</span> <span class="o">=</span> <span class="s1">&#39;dog&#39;</span>
</span></span><span class="line"><span class="cl">        <span class="n">probability</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Probability = &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">probability</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Prediction = &#34;</span> <span class="o">+</span> <span class="n">prediction</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">prediction</span> <span class="o">=</span> <span class="s1">&#39;cat&#39;</span>
</span></span><span class="line"><span class="cl">        <span class="n">probability</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Probability = &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">probability</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Prediction = &#34;</span> <span class="o">+</span> <span class="n">prediction</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 加载训练好的模型</span>
</span></span><span class="line"><span class="cl"><span class="n">loaded_classifier</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;trained_model.h5&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 示例用法</span>
</span></span><span class="line"><span class="cl"><span class="n">dog_image</span> <span class="o">=</span> <span class="s2">&#34;dog.jpg&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">predict_image</span><span class="p">(</span><span class="n">dog_image</span><span class="p">,</span> <span class="n">loaded_classifier</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">cat_image</span> <span class="o">=</span> <span class="s2">&#34;cat.jpg&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">predict_image</span><span class="p">(</span><span class="n">cat_image</span><span class="p">,</span> <span class="n">loaded_classifier</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div><p>输出结果如下：</p>
<p><a class="lightgallery" href="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/d546542af4055bc7163bc49055d5a623a44ad0cc3022d02d0aaa791b9a83d75b.png?size=large" data-thumbnail="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/d546542af4055bc7163bc49055d5a623a44ad0cc3022d02d0aaa791b9a83d75b.png?size=small" data-sub-html="<h2>Alt text</h2>"><img loading="lazy" src="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/d546542af4055bc7163bc49055d5a623a44ad0cc3022d02d0aaa791b9a83d75b.png" alt="Alt text" srcset="https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/d546542af4055bc7163bc49055d5a623a44ad0cc3022d02d0aaa791b9a83d75b.png?size=small, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/d546542af4055bc7163bc49055d5a623a44ad0cc3022d02d0aaa791b9a83d75b.png?size=medium 1.5x, https://raw.githubusercontent.com/unique-pure/NewPicGoLibrary/main/img/d546542af4055bc7163bc49055d5a623a44ad0cc3022d02d0aaa791b9a83d75b.png?size=large 2x" data-title="Alt text" style="background: url(/images/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;for(const i of ['style', 'data-title','onerror','onload']){this.removeAttribute(i);}"/></a></p>
<p>这是<a href="https://github.com/RijulTP/GPUToolkit/tree/main/neural-network?ref=journal.hexmos.com"target="_blank" rel="external nofollow noopener noreferrer">完整的代码<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>供读者学习参考。</p>
<h2 id="结论" class="heading-element"><span>6 结论</span>
  <a href="#%e7%bb%93%e8%ae%ba" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>在即将到来的AI时代，GPU是一个不容忽视的东西，我们应该更加了解它的能力。随着我们从传统的串行算法过渡到日益流行的并行算法，GPU 成为加速复杂计算不可或缺的工具。 GPU 的并行处理能力在处理人工智能和机器学习任务固有的海量数据集和复杂的神经网络架构方面特别有优势。此外，GPU 的作用超出了传统的机器学习领域，在科学研究、模拟和数据密集型任务中找到了应用。事实证明，GPU 的并行处理能力有助于解决从药物发现、气候建模到金融模拟等各个领域的挑战。</p>
]]></description></item></channel></rss>